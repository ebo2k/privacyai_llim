id,score,content,type,summary
Digital Services Act (DSA) - Contextual paragraph (55),0.743544698,"Details of the contextual paragraph (55) of the Digital Services Act (DSA): Restriction of visibility may consist in demotion in ranking or in recommender systems, as well as in limiting accessibility by one or more recipients of the service or blocking the user from an online community without the user being aware ('shadow banning'). The monetisation via advertising revenue of information provided by the recipient of the service can be restricted by suspending or terminating the monetary payment or revenue associated to that information. The obligation to provide a statement of reasons should however not apply with respect to deceptive high-volume commercial content disseminated through intentional manipulation of the service, in particular inauthentic use of the service such as the use of bots or fake accounts or other deceptive uses of the service. Irrespective of other possibilities to challenge the decision of the provider of hosting services, the recipient of the service should always have a right to effective remedy before a court in accordance with the national law.",recital,"The Digital Services Act (DSA) allows online platforms to limit the visibility of users or content, including lowering their ranking, limiting who can see their posts, or secretly blocking them ('shadow banning'). It also allows platforms to cut off advertising revenue for certain content. However, platforms don't have to explain these actions if they're taken against deceptive or manipulative content, like fake accounts or bots. Regardless of these rules, users always have the right to challenge a platform's decision in court, according to local laws."
Digital Markets Act (DMA) - Contextual Paragraph (41),0.742179394,"Details of the Contextual Paragraph (41) in the Digital Markets Act (DMA): The ability of end users to acquire content, subscriptions, features or other items outside the core platform services of the gatekeeper should not be undermined or restricted. In particular, a situation should be avoided whereby gatekeepers restrict end users from access to, and use of, such services via a software application running on their core platform service. For example, subscribers to online content purchased outside a software application, software application store or virtual assistant should not be prevented from accessing such online content on a software application on the core platform service of the gatekeeper simply because it was purchased outside such software application, software application store or virtual assistant.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 41) that protects consumers' rights to use content, subscriptions, and other items they've purchased outside of a major digital platform's core services. This means that big tech companies, referred to as ""gatekeepers"", can't stop you from using a service or content you've bought elsewhere on their platforms. For instance, if you subscribe to an online service outside of a particular app, app store, or virtual assistant, you should still be able to access it on that platform, regardless of where you originally purchased it."
Digital Services Act (DSA) - Contextual paragraph (23),0.741742194,"Details of the contextual paragraph (23) of the Digital Services Act (DSA): The exemption of liability should not apply where the recipient of the service is acting under the authority or the control of the provider of a hosting service. For example, where the provider of an online platform that allows consumers to conclude distance contracts with traders determines the price of the goods or services offered by the trader, it could be considered that the trader acts under the authority or control of that online platform.",recital,"The Digital Services Act (DSA) states that online platforms, like those offering distance contracts, cannot avoid responsibility if they have authority or control over the service recipient. For instance, if an online platform sets the price for a trader's goods or services, the platform is considered to have control over the trader and cannot claim exemption from liability."
Digital Services Act (DSA) - Contextual paragraph (83),0.741702557,"Details of the contextual paragraph (83) of the Digital Services Act (DSA): A fourth category of risks stems from similar concerns relating to the design, functioning or use, including through manipulation, of very large online platforms and of very large online search engines with an actual or foreseeable negative effect on the protection of public health, minors and serious negative consequences to a person's physical and mental well-being, or on gender-based violence. Such risks may also stem from coordinated disinformation campaigns related to public health, or from online interface design that may stimulate behavioural addictions of recipients of the service.",recital,"The Digital Services Act (DSA) identifies a fourth category of risks related to large online platforms and search engines. This includes potential harm to public health, minors, and individuals' physical and mental well-being, as well as the risk of gender-based violence. These risks could arise from the misuse or manipulation of these platforms, coordinated disinformation campaigns about public health, or designs that could lead to addictive behaviors in users."
Digital Services Act (DSA) - Contextual paragraph (73),0.741684616,"Details of the contextual paragraph (73) of the Digital Services Act (DSA): To ensure an efficient and adequate application of that obligation, without imposing any disproportionate burdens, providers of online platforms allowing consumers to conclude distance contracts with traders should make best efforts to assess the reliability of the information provided by the traders concerned, in particular by using freely available official online databases and online interfaces, such as national trade registers and the VAT Information Exchange System, or request the traders concerned to provide trustworthy supporting documents, such as copies of identity documents, certified payment accounts' statements, company certificates and trade register certificates. They may also use other sources, available for use at a distance, which offer a similar degree of reliability for the purpose of complying with this obligation. However, the providers of online platforms concerned should not be required to engage in excessive or costly online fact-finding exercises or to carry out disproportionate verifications on the spot. Nor should such providers, which have made the best efforts required by this Regulation, be understood as guaranteeing the reliability of the information towards consumer or other interested parties.",recital,"The Digital Services Act (DSA) requires online platforms that facilitate distance contracts between consumers and traders to make reasonable efforts to verify the reliability of the trader's information. This could involve using free, official online databases such as national trade registers or VAT Information Exchange System, or asking traders for credible supporting documents. However, the DSA does not require these platforms to conduct extensive or expensive online investigations or on-site checks. Furthermore, even if the platforms have made their best efforts to verify the information, they are not guaranteeing its accuracy to consumers or other interested parties."
Digital Markets Act (DMA) - Contextual Paragraph (49),0.741647303,"Details of the Contextual Paragraph (49) in the Digital Markets Act (DMA): A gatekeeper can use different means to favour its own or third-party services or products on its operating system, virtual assistant or web browser, to the detriment of the same or similar services that end users could obtain through other third parties. This can for instance happen where certain software applications or services are preinstalled by a gatekeeper. To enable end user choice, gatekeepers should not prevent end users from un-installing any software applications on their operating system. It should be possible for the gatekeeper to restrict such un-installation only when such software applications are essential to the functioning of the operating system or the device. Gatekeepers should also allow end users to easily change the default settings on the operating system, virtual assistant and web browser when those default settings favour their own software applications and services. This includes prompting a choice screen, at the moment of the users"" first use of an online search engine, virtual assistant or web browser of the gatekeeper listed in the designation decision, allowing end users to select an alternative default service when the operating system of the gatekeeper directs end users to those online search engine, virtual assistant or web browser and when the virtual assistant or the web browser of the gatekeeper direct the user to the online search engine listed in the designation decision.",rectial,"The Digital Markets Act (DMA) states that a 'gatekeeper' (a company controlling access to a digital service or product) should not unfairly promote its own or third-party products or services over others. This could happen if certain apps or services are pre-installed by the gatekeeper. To ensure fair choice, gatekeepers must not stop users from uninstalling any apps on their devices unless they are essential for the device to function. Gatekeepers must also let users easily change default settings on their devices if these settings favor their own apps and services. This includes offering a choice screen when users first use an online search engine, virtual assistant or web browser, allowing them to select an alternative default service."
Digital Services Act (DSA) - Contextual paragraph (149),0.741526484,"Details of the contextual paragraph (149) of the Digital Services Act (DSA): Without prejudice to the rights of recipients of services to turn to a representative in accordance with the Directive (EU) 2020/1828 of the European Parliament and of the Council (33) or to any other type of representation under national law, recipients of the services should also have the right to mandate a legal person or a public body to exercise their rights provided for in this Regulation. Such rights may include the rights related to the submission of notices, the challenging of the decisions taken by providers of intermediary services, and the lodging of complaints against the providers for infringing this Regulation. Certain bodies, organisations and associations have particular expertise and competence in detecting and flagging erroneous or unjustified content moderation decisions, and their complaints on behalf of recipients of the service may have a positive impact on freedom of expression and of information in general, therefore, providers of online platforms should treat those complaints without undue delay.",recital,"The Digital Services Act (DSA) allows users of digital services to appoint a legal entity or public body to exercise their rights under this law. These rights might include submitting notices, challenging decisions made by service providers, and filing complaints against providers for violating the DSA. Certain groups with expertise in identifying and reporting unfair content moderation decisions can file complaints on behalf of users. This could positively affect freedom of expression and information. Service providers should promptly address these complaints."
Digital Services Act (DSA) - Contextual paragraph (108),0.741512418,"Details of the contextual paragraph (108) of the Digital Services Act (DSA): In addition to the crisis response mechanism for very large online platforms and very large online search engines, the Commission may initiate the drawing up of voluntary crisis protocols to coordinate a rapid, collective and cross-border response in the online environment. Such can be the case, for example, where online platforms are misused for the rapid spread of illegal content or disinformation or where the need arises for rapid dissemination of reliable information. In light of the important role of very large online platforms in disseminating information in our societies and across borders, providers of such platforms should be encouraged in drawing up and applying specific crisis protocols. Such crisis protocols should be activated only for a limited period of time and the measures adopted should also be limited to what is strictly necessary to address the extraordinary circumstance. Those measures should be consistent with this Regulation, and should not amount to a general obligation for the participating providers of very large online platforms and of very large online search engines to monitor the information which they transmit or store, nor actively to seek facts or circumstances indicating illegal content.",recital,"The Digital Services Act (DSA) includes a provision (paragraph 108) for the creation of voluntary crisis protocols. These protocols are intended to help large online platforms and search engines respond quickly and collectively to issues like the spread of illegal content or disinformation, or the need to share reliable information quickly. The protocols should only be used for a short time and should only include measures necessary to address the specific crisis. The measures should comply with the DSA and should not require the platforms or search engines to constantly monitor the information they transmit or store, or actively look for illegal content."
Digital Services Act (DSA) - Contextual paragraph (140),0.741448224,"Details of the contextual paragraph (140) of the Digital Services Act (DSA): In view of both the particular challenges that may arise in seeking to ensure compliance by providers of very large online platforms or of very large online search engines and the importance of doing so effectively, considering their size and impact and the harms that they may cause, the Commission should have strong investigative and enforcement powers to allow it to investigate, enforce and monitor compliance with the rules laid down in this Regulation, in full respect of the fundamental right to be heard and to have access to the file in the context of enforcement proceedings, the principle of proportionality and the rights and interests of the affected parties.",recital,"The Digital Services Act (DSA) is a new law that addresses the challenges of ensuring large online platforms and search engines follow rules. Given their size and potential harm, the law gives the Commission strong powers to investigate and enforce compliance with the regulations. However, it also respects the fundamental rights of those involved, including the right to be heard and access files during enforcement proceedings. The law also considers the principle of proportionality and the rights and interests of the affected parties."
Digital Services Act (DSA) - Contextual paragraph (48),0.741387,"Details of the contextual paragraph (48) of the Digital Services Act (DSA): Given their special role and reach, it is appropriate to impose on very large online platforms and very large online search engines additional requirements regarding information and transparency of their terms and conditions. Consequently, providers of very large online platforms and very large online search engines should provide their terms and conditions in the official languages of all Member States in which they offer their services and should also provide recipients of the services with a concise and easily readable summary of the main elements of the terms and conditions. Such summaries should identify the main elements of the information requirements, including the possibility of easily opting out from optional clauses.",recital,"The Digital Services Act (DSA) introduces new rules for big online platforms and search engines. These companies must now provide their terms and conditions in all languages of the countries where they operate. They also need to give users a short, easy-to-understand summary of these terms. This summary should highlight key points, including how to opt out of any optional parts. This law aims to make it easier for users to understand what they're agreeing to when using these services."
Digital Services Act (DSA) - Contextual paragraph (28),0.741178513,"Details of the contextual paragraph (28) of the Digital Services Act (DSA): Since 2000, new technologies have emerged that improve the availability, efficiency, speed, reliability, capacity and security of systems for the transmission, 'findability' and storage of data online, leading to an increasingly complex online ecosystem. In this regard, it should be recalled that providers of services establishing and facilitating the underlying logical architecture and proper functioning of the internet, including technical auxiliary functions, can also benefit from the exemptions from liability set out in this Regulation, to the extent that their services qualify as 'mere conduit', 'caching' or 'hosting' services. Such services include, as the case may be, wireless local area networks, domain name system (DNS) services, top-level domain name registries, registrars, certificate authorities that issue digital certificates, virtual private networks, online search engines, cloud infrastructure services, or content delivery networks, that enable, locate or improve the functions of other providers of intermediary services. Likewise, services used for communications purposes, and the technical means of their delivery, have also evolved considerably, giving rise to online services such as Voice over IP, messaging services and web-based email services, where the communication is delivered via an internet access service. Those services, too, can benefit from the exemptions from liability, to the extent that they qualify as 'mere conduit', 'caching' or 'hosting' services.",recital,"The Digital Services Act (DSA) recognizes that technology has greatly advanced since 2000, creating a complex online ecosystem. The DSA clarifies that providers of services that help the internet function properly can be exempt from liability if their services are classified as 'mere conduit', 'caching' or 'hosting' services. This can include services like Wi-Fi networks, domain name systems, digital certificate issuers, virtual private networks, search engines, cloud services, and content delivery networks. Additionally, communication services like Voice over IP, messaging services and web-based email services can also be exempt from liability if they meet the same classifications."
General Data Protection Regulation (GDPR) - Contextual Paragraph (153),0.741038084,"Details of the Contextual Paragraph (153) in the General Data Protection Regulation (GDPR): Member States law should reconcile the rules governing freedom of expression and information, including journalistic, academic, artistic and or literary expression with the right to the protection of personal data pursuant to this Regulation. The processing of personal data solely for journalistic purposes, or for the purposes of academic, artistic or literary expression should be subject to derogations or exemptions from certain provisions of this Regulation if necessary to reconcile the right to the protection of personal data with the right to freedom of expression and information, as enshrined in Article 11 of the Charter. This should apply in particular to the processing of personal data in the audiovisual field and in news archives and press libraries. Therefore, Member States should adopt legislative measures which lay down the exemptions and derogations necessary for the purpose of balancing those fundamental rights. Member States should adopt such exemptions and derogations on general principles, the rights of the data subject, the controller and the processor, the transfer of personal data to third countries or international organisations, the independent supervisory authorities, cooperation and consistency, and specific data-processing situations. Where such exemptions or derogations differ from one Member State to another, the law of the Member State to which the controller is subject should apply. In order to take account of the importance of the right to freedom of expression in every democratic society, it is necessary to interpret notions relating to that freedom, such as journalism, broadly.",recital,"The General Data Protection Regulation (GDPR) states that each member country should create laws that balance the right to freedom of expression and information (including journalism, academics, art, and literature) with the right to protect personal data. This may involve exceptions to some GDPR rules, particularly for data used in news, audiovisual content, and libraries. These exceptions should be based on general principles, the rights of the individual and data controllers, data transfer to third countries, independent authorities, cooperation, and specific data situations. If these exceptions vary between countries, the laws of the country where the data controller is located should apply. The definition of freedom of expression, such as journalism, should be interpreted broadly."
General Data Protection Regulation (GDPR) - Contextual Paragraph (170),0.740949631,"Details of the Contextual Paragraph (170) in the General Data Protection Regulation (GDPR): Since the objective of this Regulation, namely to ensure an equivalent level of protection of natural persons and the free flow of personal data throughout the Union, cannot be sufficiently achieved by the Member States and can rather, by reason of the scale or effects of the action, be better achieved at Union level, the Union may adopt measures, in accordance with the principle of subsidiarity as set out in Article 5 of the Treaty on European Union (TEU). In accordance with the principle of proportionality as set out in that Article, this Regulation does not go beyond what is necessary in order to achieve that objective.",recital,"The General Data Protection Regulation (GDPR) aims to protect individuals' personal data and ensure its free movement within the European Union (EU). The law states that individual member states cannot provide this protection adequately on their own, so the EU has stepped in to address the issue. The GDPR has been designed to offer the necessary protection without overstepping its bounds, following the principles of subsidiarity and proportionality outlined in the Treaty on European Union."
Digital Services Act (DSA) - Contextual paragraph (78),0.740827322,"Details of the contextual paragraph (78) of the Digital Services Act (DSA): In view of the network effects characterising the platform economy, the user base of an online platform or an online search engine may quickly expand and reach the dimension of a very large online platform or a very large online search engine, with the related impact on the internal market. This may be the case in the event of exponential growth experienced in short periods of time, or by a large global presence and turnover allowing the online platform or the online search engine to fully exploit network effects and economies of scale and of scope. A high annual turnover or market capitalisation can in particular be an indication of fast scalability in terms of user reach. In those cases, the Digital Services Coordinator of establishment or the Commission should be able to request more frequent reporting from the provider of the online platform or of the online search engine on the number of active recipients of the service to be able to timely identify the moment at which that platform or that search engine should be designated as a very large online platform or very large online search engine, respectively, for the purposes of this Regulation.",recital,"The Digital Services Act (DSA) recognizes that online platforms and search engines can grow rapidly, impacting the online market. This growth can be due to a sudden increase in users or a large global presence. High yearly profits or market value can indicate this quick growth. If this happens, the DSA allows for the Digital Services Coordinator or the Commission to ask for more frequent reports from these platforms or search engines. These reports will help identify when these platforms or search engines become very large, which will affect how they are regulated under the DSA."
Digital Services Act (DSA) - Contextual paragraph (116),0.740566432,"Details of the contextual paragraph (116) of the Digital Services Act (DSA): In the course of the exercise of those powers, the competent authorities should comply with the applicable national rules regarding procedures and matters such as the need for a prior judicial authorisation to enter certain premises and legal professional privilege. Those provisions should in particular ensure respect for the fundamental rights to an effective remedy and to a fair trial, including the rights of defence, and, the right to respect for private life. In this regard, the guarantees provided for in relation to the proceedings of the Commission pursuant to this Regulation could serve as an appropriate point of reference. A prior, fair and impartial procedure should be guaranteed before taking any final decision, including the right to be heard of the persons concerned, and the right to have access to the file, while respecting confidentiality and professional and business secrecy, as well as the obligation to give meaningful reasons for the decisions. This should not preclude the taking of measures, however, in duly substantiated cases of urgency and subject to appropriate conditions and procedural arrangements. The exercise of powers should also be proportionate to, inter alia the nature and the overall actual or potential harm caused by the infringement or suspected infringement. The competent authorities should take all relevant facts and circumstances of the case into account, including information gathered by competent authorities in other Member States.",recital,"The Digital Services Act (DSA) requires authorities to follow national rules when exercising their powers, including needing court approval to enter certain places and respecting the confidentiality of legal advice. The law is designed to uphold fundamental rights like a fair trial, effective remedies, and privacy. Before making any final decisions, authorities must ensure a fair process, including hearing from the people involved and providing access to the case file while maintaining confidentiality. Urgent actions can be taken under certain conditions. The actions taken should be proportionate to the harm caused by the violation. Authorities should consider all relevant facts and information, including data from authorities in other member states."
Digital Services Act (DSA) - Contextual paragraph (63),0.740538239,"Details of the contextual paragraph (63) of the Digital Services Act (DSA): The misuse of online platforms by frequently providing manifestly illegal content or by frequently submitting manifestly unfounded notices or complaints under the mechanisms and systems, respectively, established under this Regulation undermines trust and harms the rights and legitimate interests of the parties concerned. Therefore, there is a need to put in place appropriate, proportionate and effective safeguards against such misuse, that need to respect the rights and legitimate interests of all parties involved, including the applicable fundamental rights and freedoms as enshrined in the Charter, in particular the freedom of expression. Information should be considered to be manifestly illegal content and notices or complaints should be considered manifestly unfounded where it is evident to a layperson, without any substantive analysis, that the content is illegal or, respectively, that the notices or complaints are unfounded.",recital,"The Digital Services Act (DSA) addresses the misuse of online platforms, specifically the frequent posting of clearly illegal content or the submission of obviously baseless complaints. The DSA aims to protect the rights of all parties involved and maintain trust in online platforms. It calls for safeguards to prevent such misuse, while respecting everyone's rights, including freedom of expression. Content or complaints are considered clearly illegal or baseless if an average person can easily identify them as such without needing a detailed analysis."
Digital Services Act (DSA) - Contextual paragraph (86),0.740377903,"Details of the contextual paragraph (86) of the Digital Services Act (DSA): Providers of very large online platforms and of very large online search engines should deploy the necessary means to diligently mitigate the systemic risks identified in the risk assessments, in observance of fundamental rights. Any measures adopted should respect the due diligence requirements of this Regulation and be reasonable and effective in mitigating the specific systemic risks identified. They should be proportionate in light of the economic capacity of the provider of the very large online platform or of the very large online search engine and the need to avoid unnecessary restrictions on the use of their service, taking due account of potential negative effects on those fundamental rights. Those providers should give particular consideration to the impact on freedom of expression.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to take necessary steps to mitigate any systemic risks identified in their risk assessments, while respecting user rights. Any measures they adopt should be reasonable, effective, and proportionate to their economic capacity. They should not unnecessarily restrict the use of their service and should consider potential negative impacts on user rights, particularly freedom of expression."
Digital Services Act (DSA) - Contextual paragraph (47),0.740114629,"Details of the contextual paragraph (47) of the Digital Services Act (DSA): When designing, applying and enforcing those restrictions, providers of intermediary services should act in a non-arbitrary and non-discriminatory manner and take into account the rights and legitimate interests of the recipients of the service, including fundamental rights as enshrined in the Charter. For example, providers of very large online platforms should in particular pay due regard to freedom of expression and of information, including media freedom and pluralism. All providers of intermediary services should also pay due regard to relevant international standards for the protection of human rights, such as the United Nations Guiding Principles on Business and Human Rights.",recital,"The Digital Services Act (DSA) requires providers of intermediary services to act fairly and without bias when setting and enforcing rules. They must consider the rights and interests of their users, including fundamental freedoms like freedom of expression and information. This is particularly important for large online platforms. Additionally, all providers must respect international human rights standards, such as the United Nations Guiding Principles on Business and Human Rights."
Digital Markets Act (DMA) - Contextual Paragraph (102),0.739694476,"Details of the Contextual Paragraph (102) in the Digital Markets Act (DMA): Whistleblowers can bring new information to the attention of competent authorities which can help the competent authorities detect infringements of this Regulation and enable them to impose penalties. It should be ensured that adequate arrangements are in place to enable whistleblowers to alert the competent authorities to actual or potential infringements of this Regulation and to protect the whistleblowers from retaliation. For that purpose, it should be provided in this Regulation that Directive (EU) 2019/1937 of the European Parliament and of the Council ( 20) is applicable to the reporting of breaches of this Regulation and to the protection of persons reporting such breaches.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 102) that encourages whistleblowers to report any violations of the law to the appropriate authorities. The law ensures that there are sufficient measures in place to allow whistleblowers to report any actual or potential violations of the law, and to protect them from any backlash or retaliation. The law also states that the European Parliament's Directive (EU) 2019/1937 applies to the reporting of these violations and the protection of the whistleblowers."
Digital Services Act (DSA) - Contextual paragraph (61),0.7396788,"Details of the contextual paragraph (61) of the Digital Services Act (DSA): Action against illegal content can be taken more quickly and reliably where providers of online platforms take the necessary measures to ensure that notices submitted by trusted flaggers, acting within their designated area of expertise, through the notice and action mechanisms required by this Regulation are treated with priority, without prejudice to the requirement to process and decide upon all notices submitted under those mechanisms in a timely, diligent and non-arbitrary manner. Such trusted flagger status should be awarded by the Digital Services Coordinator of the Member State in which the applicant is established and should be recognised by all providers of online platforms within the scope of this Regulation. Such trusted flagger status should only be awarded to entities, and not individuals, that have demonstrated, among other things, that they have particular expertise and competence in tackling illegal content and that they work in a diligent, accurate and objective manner. Such entities can be public in nature, such as, for terrorist content, internet referral units of national law enforcement authorities or of the European Union Agency for Law Enforcement Cooperation ('Europol') or they can be non-governmental organisations and private or semi-public bodies such as the organisations part of the INHOPE network of hotlines for reporting child sexual abuse material and organisations committed to notifying illegal racist and xenophobic expressions online. To avoid diminishing the added value of such mechanism, the overall number of trusted flaggers awarded in accordance with this Regulation should be limited. In particular, industry associations representing their members' interests are encouraged to apply for the status of trusted flaggers, without prejudice to the right of private entities or individuals to enter into bilateral agreements with the providers of online platforms.",recital,"The Digital Services Act (DSA) introduces a new system for tackling illegal online content. It encourages online platforms to prioritize reports from ""trusted flaggers,"" experts in identifying and reporting such content. These trusted flaggers, which can be public entities like law enforcement or private organizations like child abuse hotlines, are recognized by all online platforms under this law. They must be entities, not individuals, and must demonstrate expertise in identifying illegal content. The number of trusted flaggers will be limited to ensure the system's effectiveness. Industry associations are encouraged to apply for trusted flagger status, but private entities and individuals can still make agreements with online platforms."
Digital Services Act (DSA) - Contextual paragraph (90),0.739091456,"Details of the contextual paragraph (90) of the Digital Services Act (DSA): Providers of very large online platforms and of very large online search engines should ensure that their approach to risk assessment and mitigation is based on the best available information and scientific insights and that they test their assumptions with the groups most impacted by the risks and the measures they take. To this end, they should, where appropriate, conduct their risk assessments and design their risk mitigation measures with the involvement of representatives of the recipients of the service, representatives of groups potentially impacted by their services, independent experts and civil society organisations. They should seek to embed such consultations into their methodologies for assessing the risks and designing mitigation measures, including, as appropriate, surveys, focus groups, round tables, and other consultation and design methods. In the assessment on whether a measure is reasonable, proportionate and effective, special consideration should be given to the right to freedom of expression.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to base their risk assessments and mitigation strategies on the best available information and scientific insights. They should also test their assumptions with the groups most affected by these risks and measures. This might involve conducting risk assessments and designing risk mitigation measures with the input of service users, groups potentially affected by their services, independent experts, and civil society organizations. This could include surveys, focus groups, round tables, and other consultation methods. When deciding if a measure is reasonable, proportionate, and effective, special attention should be paid to the right to freedom of expression."
Digital Services Act (DSA) - Contextual paragraph (126),0.739037037,"Details of the contextual paragraph (126) of the Digital Services Act (DSA): The rules of this Regulation on the allocation of competence should be without prejudice to the provisions of Union law and national rules on private international law concerning jurisdiction and applicable law in civil and commercial matters, such as proceedings brought by consumers in the courts of the Member State where they are domiciled in accordance with relevant provisions of Union law. Regarding the obligations imposed by this Regulation on providers of intermediary services to inform the issuing authority of the effect given to the orders to act against illegal content and orders to provide information, the rules on allocation of competence should only apply to the supervision of enforcement of those obligations, but not to other matters related to the order, such as the competence to issue the order.",recital,"The Digital Services Act (DSA) sets rules about who has the power to enforce its provisions. However, these rules don't affect existing EU and national laws about which court has jurisdiction in civil and commercial cases, including cases where consumers sue in their home country's courts. The DSA requires online service providers to tell the authority that issued an order against illegal content about how they complied with that order. The rules about who has the power to enforce the DSA only apply to making sure these obligations are met, not to other issues related to the order, like who has the power to issue the order."
General Data Protection Regulation (GDPR) - Contextual Paragraph (166),0.739019275,"Details of the Contextual Paragraph (166) in the General Data Protection Regulation (GDPR): In order to fulfil the objectives of this Regulation, namely to protect the fundamental rights and freedoms of natural persons and in particular their right to the protection of personal data and to ensure the free movement of personal data within the Union, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission. In particular, delegated acts should be adopted in respect of criteria and requirements for certification mechanisms, information to be presented by standardised icons and procedures for providing such icons. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level. The Commission, when preparing and drawing-up delegated acts, should ensure a simultaneous, timely and appropriate transmission of relevant documents to the European Parliament and to the Council.",recital,"The General Data Protection Regulation (GDPR) Paragraph 166 aims to protect the rights and freedoms of individuals, particularly their personal data, and ensure free movement of this data within the EU. The Commission has the power to create acts that determine the criteria for certification mechanisms, the information presented by standard icons, and the procedures for providing these icons. The Commission should consult appropriately during its preparations, including with experts. It should also ensure that relevant documents are timely and appropriately shared with the European Parliament and the Council."
Digital Services Act (DSA) - Contextual paragraph (131),0.738666475,"Details of the contextual paragraph (131) of the Digital Services Act (DSA): In order to ensure a consistent application of this Regulation, it is necessary to set up an independent advisory group at Union level, a European Board for Digital Services, which should support the Commission and help coordinate the actions of Digital Services Coordinators. The Board should consist of the Digital Services Coordinators, where these have been appointed, without prejudice to the possibility for Digital Services Coordinators to invite in its meetings or appoint ad hoc delegates from other competent authorities entrusted with specific tasks under this Regulation, where that is required pursuant to their national allocation of tasks and competences. In case of multiple participants from one Member State, the voting right should remain limited to one representative per Member State.",recital,"The Digital Services Act (DSA) is introducing a new independent advisory group called the European Board for Digital Services. This board will assist the Commission and coordinate the actions of Digital Services Coordinators. These coordinators can invite or appoint delegates from other authorities to join their meetings if needed. However, each Member State will only have one vote, regardless of how many participants they have."
Digital Services Act (DSA) - Contextual paragraph (81),0.738475502,"Details of the contextual paragraph (81) of the Digital Services Act (DSA): A second category concerns the actual or foreseeable impact of the service on the exercise of fundamental rights, as protected by the Charter, including but not limited to human dignity, freedom of expression and of information, including media freedom and pluralism, the right to private life, data protection, the right to non-discrimination, the rights of the child and consumer protection. Such risks may arise, for example, in relation to the design of the algorithmic systems used by the very large online platform or by the very large online search engine or the misuse of their service through the submission of abusive notices or other methods for silencing speech or hampering competition. When assessing risks to the rights of the child, providers of very large online platforms and of very large online search engines should consider for example how easy it is for minors to understand the design and functioning of the service, as well as how minors can be exposed through their service to content that may impair minors' health, physical, mental and moral development. Such risks may arise, for example, in relation to the design of online interfaces which intentionally or unintentionally exploit the weaknesses and inexperience of minors or which may cause addictive behaviour.",recital,"The Digital Services Act (DSA) introduces new rules to protect fundamental rights online. These rights include human dignity, freedom of speech, privacy, data protection, anti-discrimination, children's rights, and consumer protection. The law is particularly concerned with the potential negative impacts of algorithmic systems used by large online platforms and search engines. Examples of such impacts include the misuse of these services to silence speech or hinder competition, and the potential harm to minors. The law requires these providers to consider how their design may be understood by minors and how it may expose them to harmful content. It also addresses concerns about designs that exploit minors' inexperience or encourage addictive behavior."
Digital Markets Act (DMA) - Contextual Paragraph (56),0.737983525,"Details of the Contextual Paragraph (56) in the Digital Markets Act (DMA): Gatekeepers can also have a dual role as developers of operating systems and device manufacturers, including any technical functionality that such a device may have. For example, a gatekeeper that is a manufacturer of a device can restrict access to some of the functionalities in that device, such as near-field-communication technology, secure elements and processors, authentication mechanisms and the software used to operate those technologies, which can be required for the effective provision of a service provided together with, or in support of, the core platform service by the gatekeeper as well as by any potential third-party undertaking providing such service.",rectial,"The Digital Markets Act (DMA) discusses how large tech companies, referred to as ""gatekeepers,"" can also be creators of operating systems and devices. These gatekeepers can limit access to certain features on their devices, such as secure elements, processors, and the software that operates these technologies. This can affect both the services provided by the gatekeeper and any third-party services. In simpler terms, big tech companies can control what parts of their devices and systems other companies can use, which can influence the services those other companies can offer."
Digital Services Act (DSA) - Contextual paragraph (146),0.737980664,"Details of the contextual paragraph (146) of the Digital Services Act (DSA): The provider of the very large online platform or of the very large online search engine concerned and other persons subject to the exercise of the Commission's powers whose interests may be affected by a decision should be given the opportunity of submitting their observations beforehand, and the decisions taken should be widely publicised. While ensuring the rights of defence of the parties concerned, in particular, the right of access to the file, it is essential that confidential information be protected. Furthermore, while respecting the confidentiality of the information, the Commission should ensure that any information relied on for the purpose of its decision is disclosed to an extent that allows the addressee of the decision to understand the facts and considerations that led up to the decision.",recital,"The Digital Services Act (DSA) requires that large online platforms and search engines, as well as other parties potentially impacted by a decision, have the opportunity to provide their input before a decision is made. These decisions must be made public. The DSA also emphasizes the importance of protecting confidential information while ensuring the rights of the parties involved, including access to relevant files. The Commission must disclose any information used in making its decision, while maintaining confidentiality, so that the recipient of the decision can understand the reasoning behind it."
Digital Markets Act (DMA) - Contextual Paragraph (54),0.737731576,"Details of the Contextual Paragraph (54) in the Digital Markets Act (DMA): Gatekeepers can hamper the ability of end users to access online content and services, including software applications. Therefore, rules should be established to ensure that the rights of end users to access an open internet are not compromised by the conduct of gatekeepers. Gatekeepers can also technically limit the ability of end users to effectively switch between different undertakings providing internet access service, in particular through their control over hardware or operating systems. This distorts the level playing field for internet access services and ultimately harms end users. It should therefore be ensured that gatekeepers do not unduly restrict end users in choosing the undertaking providing their internet access service.",rectial,"The Digital Markets Act (DMA) includes a new rule, Paragraph 54, to protect internet users. This law is designed to prevent ""gatekeepers"" (companies that control access to online content and services) from limiting users' access to the internet or making it difficult for users to switch between different internet providers. The law aims to ensure a fair and open internet by preventing these gatekeepers from controlling or restricting users' choice of internet service."
General Data Protection Regulation (GDPR) - Contextual Paragraph (141),0.737688184,"Details of the Contextual Paragraph (141) in the General Data Protection Regulation (GDPR): Every data subject should have the right to lodge a complaint with a single supervisory authority, in particular in the Member State of his or her habitual residence, and the right to an effective judicial remedy in accordance with Article 47 of the Charter if the data subject considers that his or her rights under this Regulation are infringed or where the supervisory authority does not act on a complaint, partially or wholly rejects or dismisses a complaint or does not act where such action is necessary to protect the rights of the data subject. The investigation following a complaint should be carried out, subject to judicial review, to the extent that is appropriate in the specific case. The supervisory authority should inform the data subject of the progress and the outcome of the complaint within a reasonable period. If the case requires further investigation or coordination with another supervisory authority, intermediate information should be given to the data subject. In order to facilitate the submission of complaints, each supervisory authority should take measures such as providing a complaint submission form which can also be completed electronically, without excluding other means of communication.",recital,"The General Data Protection Regulation (GDPR) states that everyone has the right to file a complaint with a single supervisory authority, especially in their home country, if they believe their data protection rights have been violated. If the authority doesn't act on the complaint or dismisses it, they can seek legal action. The authority must keep the person informed about the progress and outcome of the complaint. If more investigation is needed, they should be updated regularly. To make it easier to file complaints, each authority should provide an electronic complaint form, but other methods of communication should also be available."
Digital Services Act (DSA) - Contextual paragraph (121),0.737615168,"Details of the contextual paragraph (121) of the Digital Services Act (DSA): Without prejudice to the provisions on the exemption from liability provided for in this Regulation as regards the information transmitted or stored at the request of a recipient of the service, a provider of intermediary services should be liable for the damages suffered by recipients of the service that are caused by an infringement of the obligations set out in this Regulation by that provider. Such compensation should be in accordance with the rules and procedures set out in the applicable national law and without prejudice to other possibilities for redress available under consumer protection rules.",recital,"The Digital Services Act (DSA) states that digital service providers can be held responsible for any harm suffered by their users due to the provider's failure to follow the rules set out in the DSA. This means that if a user suffers damage because a service provider didn't follow the DSA's rules, the user can seek compensation. The amount of compensation and how it's given will be determined by the laws of the user's country. This doesn't affect any other rights the user might have under consumer protection laws."
General Data Protection Regulation (GDPR) - Contextual Paragraph (143),0.73751843,"Details of the Contextual Paragraph (143) in the General Data Protection Regulation (GDPR): Any natural or legal person has the right to bring an action for annulment of decisions of the Board before the Court of Justice under the conditions provided for in Article 263 TFEU. As addressees of such decisions, the supervisory authorities concerned which wish to challenge them have to bring action within two months of being notified of them, in accordance with Article 263 TFEU. Where decisions of the Board are of direct and individual concern to a controller, processor or complainant, the latter may bring an action for annulment against those decisions within two months of their publication on the website of the Board, in accordance with Article 263 TFEU. Without prejudice to this right under Article 263 TFEU, each natural or legal person should have an effective judicial remedy before the competent national court against a decision of a supervisory authority which produces legal effects concerning that person. Such a decision concerns in particular the exercise of investigative, corrective and authorisation powers by the supervisory authority or the dismissal or rejection of complaints. However, the right to an effective judicial remedy does not encompass measures taken by supervisory authorities which are not legally binding, such as opinions issued by or advice provided by the supervisory authority. Proceedings against a supervisory authority should be brought before the courts of the Member State where the supervisory authority is established and should be conducted in accordance with that Member State's procedural law. Those courts should exercise full jurisdiction, which should include jurisdiction to examine all questions of fact and law relevant to the dispute before them. Where a complaint has been rejected or dismissed by a supervisory authority, the complainant may bring proceedings before the courts in the same Member State. In the context of judicial remedies relating to the application of this Regulation, national courts which consider a decision on the question necessary to enable them to give judgment, may, or in the case provided for in Article 267 TFEU, must, request the Court of Justice to give a preliminary ruling on the interpretation of Union law, including this Regulation. Furthermore, where a decision of a supervisory authority implementing a decision of the Board is challenged before a national court and the validity of the decision of the Board is at issue, that national court does not have the power to declare the Board's decision invalid but must refer the question of validity to the Court of Justice in accordance with Article 267 TFEU as interpreted by the Court of Justice, where it considers the decision invalid. However, a national court may not refer a question on the validity of the decision of the Board at the request of a natural or legal person which had the opportunity to bring an action for annulment of that decision, in particular if it was directly and individually concerned by that decision, but had not done so within the period laid down in Article 263 TFEU.",recital,"The General Data Protection Regulation (GDPR) Paragraph 143 allows any person or entity to challenge decisions made by the Board in court. If a supervisory authority wants to challenge a decision, they must do so within two months of being notified. If a decision directly affects a controller, processor, or complainant, they can challenge it within two months of its publication on the Board's website. However, non-binding measures like opinions or advice can't be legally challenged. Legal action against a supervisory authority must take place in the country where the authority is based. If a complaint is rejected, the complainant can take it to court in the same country. If a national court questions the validity of the Board's decision, it must refer the question to the Court of Justice, unless the person or entity had a chance to challenge the decision but did not do so within the specified period."
Digital Services Act (DSA) - Contextual paragraph (82),0.7375108,"Details of the contextual paragraph (82) of the Digital Services Act (DSA): A third category of risks concerns the actual or foreseeable negative effects on democratic processes, civic discourse and electoral processes, as well as public security.",recital,"The Digital Services Act (DSA) includes a section (paragraph 82) that addresses potential threats to democratic processes, public discussions, elections, and public safety. These risks could be real or predicted. The law is designed to protect these crucial aspects of society from any negative impacts that might arise from digital services."
Digital Services Act (DSA) - Contextual paragraph (43),0.737413824,"Details of the contextual paragraph (43) of the Digital Services Act (DSA): Providers of intermediary services should also be required to designate a single point of contact for recipients of services, enabling rapid, direct and efficient communication in particular by easily accessible means such as telephone numbers, email addresses, electronic contact forms, chatbots or instant messaging. It should be explicitly indicated when a recipient of the service communicates with chatbots. Providers of intermediary services should allow recipients of services to choose means of direct and efficient communication which do not solely rely on automated tools. Providers of intermediary services should make all reasonable efforts to guarantee that sufficient human and financial resources are allocated to ensure that this communication is performed in a timely and efficient manner.",recital,"The Digital Services Act (DSA) requires online service providers to have a single, easy-to-reach contact point for users. This could be through phone numbers, email addresses, electronic forms, chatbots, or instant messaging. If a user is communicating with a chatbot, it should be clearly stated. Users should also have the option to communicate through non-automated methods. The service providers must ensure they have enough staff and funds to maintain efficient and timely communication."
General Data Protection Regulation (GDPR) - Contextual Paragraph (130),0.737312794,"Details of the Contextual Paragraph (130) in the General Data Protection Regulation (GDPR): Where the supervisory authority with which the complaint has been lodged is not the lead supervisory authority, the lead supervisory authority should closely cooperate with the supervisory authority with which the complaint has been lodged in accordance with the provisions on cooperation and consistency laid down in this Regulation. In such cases, the lead supervisory authority should, when taking measures intended to produce legal effects, including the imposition of administrative fines, take utmost account of the view of the supervisory authority with which the complaint has been lodged and which should remain competent to carry out any investigation on the territory of its own Member State in liaison with the competent supervisory authority.",recital,"The General Data Protection Regulation (GDPR) Paragraph 130 states that if a privacy complaint is lodged with a supervisory authority that isn't the main one, the main (lead) authority must work closely with the one that received the complaint. This cooperation should follow the rules set out in the GDPR. When the lead authority takes actions that have legal consequences, like imposing fines, it should strongly consider the viewpoint of the authority that received the complaint. The authority that received the complaint still has the power to investigate within its own territory, working together with the lead authority."
Digital Services Act (DSA) - Contextual paragraph (2),0.736955643,"Details of the contextual paragraph (2) of the Digital Services Act (DSA): Member States are increasingly introducing, or are considering introducing, national laws on the matters covered by this Regulation, imposing, in particular, diligence requirements for providers of intermediary services as regards the way they should tackle illegal content, online disinformation or other societal risks. Those diverging national laws negatively affect the internal market, which, pursuant to Article 26 of the Treaty on the Functioning of the European Union (TFEU), comprises an area without internal frontiers in which the free movement of goods and services and freedom of establishment are ensured, taking into account the inherently cross-border nature of the internet, which is generally used to provide those services. The conditions for the provision of intermediary services across the internal market should be harmonised, so as to provide businesses with access to new markets and opportunities to exploit the benefits of the internal market, while allowing consumers and other recipients of the services to have increased choice. Business users, consumers and other users are considered to be 'recipients of the service' for the purpose of this Regulation.",recital,"The Digital Services Act (DSA) is a new law addressing the issue of how online service providers handle illegal content and misinformation. Currently, individual countries within the EU are creating their own laws about this, which can create confusion and inconsistency. The DSA aims to create a unified approach across the EU, considering the borderless nature of the internet. This will make it easier for businesses to operate across different countries within the EU, and give consumers more choice. The DSA refers to businesses, consumers, and users as 'recipients of the service' in this context."
Artifical Inellegence Act (AI Act) - Overview paragraph 26,0.736772299,"Aritifical Intelligence Act (AI Act) overview paragraph (26): In accordance with Articles 2 and 2a of Protocol No 22 on the position of Denmark, annexed to the TEU and TFEU, Denmark is not bound by rules laid down in Article 5(1), point (d), (2) and (3) of this Regulation adopted on the basis of Article 16 of the TFEU, or subject to their application, which relate to the processing of personal data by the Member States when carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU.",recital,"The Artificial Intelligence Act (AI Act) states that Denmark, as per Articles 2 and 2a of Protocol No 22, is not obligated to follow certain rules related to the processing of personal data by Member States. These rules, outlined in Article 5 of this Regulation and based on Article 16 of the TFEU, pertain to activities under Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU. In simpler terms, when it comes to certain activities involving personal data, Denmark has different obligations than other Member States under this AI law."
Digital Services Act (DSA) - Contextual paragraph (152),0.736640751,"Details of the contextual paragraph (152) of the Digital Services Act (DSA): In order to fulfil the objectives of this Regulation, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to supplement this Regulation, in respect of criteria for the identification of very large online platforms and of very large online search engines, the procedural steps, methodologies and reporting templates for the audits, the technical specifications for access requests and the detailed methodology and procedures for setting the supervisory fee. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making (35). In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States' experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.",recital,"The Digital Services Act (DSA) gives the Commission the power to create additional rules to support the Act. These rules will detail how to identify large online platforms and search engines, the steps and methods for audits, how to request access, and how to set supervisory fees. The Commission must consult with experts and follow the principles of the Interinstitutional Agreement of 13 April 2016 on Better Law-Making. The European Parliament and the Council must be included in the preparation of these rules, receiving all documents at the same time as Member States' experts and having access to relevant meetings."
Digital Services Act (DSA) - Contextual paragraph (94),0.736498713,"Details of the contextual paragraph (94) of the Digital Services Act (DSA): The obligations on assessment and mitigation of risks should trigger, on a case-by-case basis, the need for providers of very large online platforms and of very large online search engines to assess and, where necessary, adjust the design of their recommender systems, for example by taking measures to prevent or minimise biases that lead to the discrimination of persons in vulnerable situations, in particular where such adjustment is in accordance with data protection law and when the information is personalised on the basis of special categories of personal data referred to in Article 9 of the Regulation (EU) 2016/679. In addition, and complementing the transparency obligations applicable to online platforms as regards their recommender systems, providers of very large online platforms and of very large online search engines should consistently ensure that recipients of their service enjoy alternative options which are not based on profiling, within the meaning of Regulation (EU) 2016/679, for the main parameters of their recommender systems. Such choices should be directly accessible from the online interface where the recommendations are presented.",recital,"The Digital Services Act (DSA) now requires large online platforms and search engines to evaluate and adjust their recommendation systems to prevent biases, especially those that could discriminate against vulnerable individuals. This adjustment should comply with data protection laws and apply when personalizing information based on special categories of personal data. In addition to transparency, these providers must also offer alternatives to their users that are not based on profiling for their recommendation systems. These alternatives should be easily accessible from the platform where the recommendations are presented."
Digital Markets Act (DMA) - Contextual Paragraph (4),0.736485183,"Details of the Contextual Paragraph (4) in the Digital Markets Act (DMA): The combination of those features of gatekeeper is likely to lead, in many cases, to serious imbalances in bargaining power and, consequently, to unfair practices and conditions for business users, as well as for end users of core platform services provided by gatekeepers, to the detriment of prices, quality, fair competition, choice and innovation in the digital sector",rectial,"The Digital Markets Act (DMA) is a new law that addresses issues with powerful online platforms, known as 'gatekeepers'. These gatekeepers often have a lot of control, which can lead to unfair practices and conditions for businesses and consumers using their services. This imbalance of power can negatively affect prices, quality, competition, choice, and innovation in the digital sector. The DMA is designed to correct these imbalances and ensure fairer conditions for all."
Digital Markets Act (DMA) - Contextual Paragraph (5),0.736275494,"Details of the Contextual Paragraph (5) in the Digital Markets Act (DMA): It follows that the market processes are often incapable of ensuring fair economic outcomes with regard to core platform services. Although Articles 101 and 102 of the Treaty on the Functioning of the European Union (TFEU) apply to the conduct of gatekeepers, the scope of those provisions is limited to certain instances of market power, for example dominance on specific markets and of anti-competitive behaviour, and enforcement occurs ex post and requires an extensive investigation of often very complex facts on a case by case basis. Moreover, existing Union law does not address, or does not address effectively, the challenges to the effective functioning of the internal market posed by the conduct of gatekeepers that are not necessarily dominant in competition-law terms.",rectial,"The Digital Markets Act (DMA) acknowledges that market processes often fail to ensure fair outcomes in core platform services. Although the Treaty on the Functioning of the European Union (TFEU) rules apply to gatekeepers (major players in the digital market), these rules only cover certain cases of market power and anti-competitive behavior. These cases are dealt with after they occur and require thorough investigation, which can be complex and time-consuming. Furthermore, current Union law doesn't effectively address the issues caused by gatekeepers who may not be dominant in terms of competition law."
Digital Services Act (DSA) - Contextual paragraph (24),0.736264229,"Details of the contextual paragraph (24) of the Digital Services Act (DSA): In order to ensure the effective protection of consumers when engaging in intermediated commercial transactions online, certain providers of hosting services, namely online platforms that allow consumers to conclude distance contracts with traders, should not be able to benefit from the exemption from liability for hosting service providers established in this Regulation, in so far as those online platforms present the relevant information relating to the transactions at issue in such a way as to lead consumers to believe that that information was provided by those online platforms themselves or by traders acting under their authority or control, and that those online platforms thus have knowledge of or control over the information, even if that may in reality not be the case. Examples of such behaviour could be where an online platform fails to display clearly the identity of the trader, as required by this Regulation, where an online platform withholds the identity or contact details of the trader until after the conclusion of the contract concluded between the trader and the consumer, or where an online platform markets the product or service in its own name rather than in the name of the trader who will supply that product or service. In that regard, it should be determined objectively, on the basis of all relevant circumstances, whether the presentation could lead an average consumer to believe that the information in question was provided by the online platform itself or by traders acting under its authority or control.",recital,"The Digital Services Act (DSA) aims to protect consumers during online transactions. It states that online platforms, such as those hosting sales between consumers and traders, can't claim exemption from liability if they present information in a way that misleads consumers into thinking it's provided by the platform or traders under their control. This could be the case if the platform doesn't clearly display the trader's identity, hides the trader's details until after a contract is concluded, or markets a product in its own name instead of the trader's. The law will judge whether the presentation could mislead an average consumer based on all relevant circumstances."
General Data Protection Regulation (GDPR) - Contextual Paragraph (118),0.736215174,Details of the Contextual Paragraph (118) in the General Data Protection Regulation (GDPR): The independence of supervisory authorities should not mean that the supervisory authorities cannot be subject to control or monitoring mechanisms regarding their financial expenditure or to judicial review,recital,"The General Data Protection Regulation (GDPR) includes a clause (Paragraph 118) that says even though data protection authorities are independent, they can still be checked or monitored for their spending. They can also be subject to legal review. This means that while they have the freedom to operate, they must still follow financial and legal rules."
Digital Markets Act (DMA) - Contextual Paragraph (92),0.736158192,"Details of the Contextual Paragraph (92) in the Digital Markets Act (DMA): In order to safeguard the harmonised application and enforcement of this Regulation, it is important to ensure that national authorities, including national courts, have all necessary information to ensure that their decisions do not run counter to a decision adopted by the Commission under this Regulation. National courts should be allowed to ask the Commission to send them information or opinions on questions concerning the application of this Regulation. At the same time, the Commission should be able to submit oral or written observations to national courts. This is without prejudice to the ability of national courts to request a preliminary ruling under Article 267 TFEU.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 92) that aims to ensure consistent application of the regulation across different national authorities, including courts. This provision allows national courts to request information or opinions from the Commission on how to apply the regulation. The Commission can also provide feedback to national courts. This is to ensure that decisions made by national courts are in line with the Commission's decisions under the DMA. This does not affect the right of national courts to request a preliminary ruling under Article 267 TFEU."
Digital Markets Act (DMA) - Contextual Paragraph (83),0.736121,Details of the Contextual Paragraph (83) in the Digital Markets Act (DMA): The Commission should also be empowered to conduct inspections of any undertaking or association of undertakings and to interview any persons who could be in possession of useful information and to record the statements made.,rectial,The Digital Markets Act (DMA) now gives the Commission the power to conduct inspections of any business or group of businesses. They can also interview anyone who might have useful information and document their statements. This is to ensure that all activities are in line with the rules and regulations set out in the DMA.
Digital Markets Act (DMA) - Contextual Paragraph (55),0.73597765,"Details of the Contextual Paragraph (55) in the Digital Markets Act (DMA): A gatekeeper can provide services or hardware, such as wearable devices, that access hardware or software features of a device accessed or controlled via an operating system or virtual assistant in order to offer specific functionalities to end users. In that case, competing service or hardware providers, such as providers of wearable devices, require equally effective interoperability with, and access for the purposes of interoperability to, the same hardware or software features to be able to provide a competitive offering to end users.",rectial,"The Digital Markets Act (DMA) has introduced a new rule (Paragraph 55) to ensure fair competition in the digital market. According to this rule, if a dominant company (gatekeeper) provides services or hardware like wearable devices, it must also allow its competitors to access the same device features. This means that all companies should have equal opportunities to create competitive products for consumers. This law aims to promote fair competition and innovation in the digital market."
Digital Services Act (DSA) - Contextual paragraph (18),0.7359519,"Details of the contextual paragraph (18) of the Digital Services Act (DSA): The exemptions from liability established in this Regulation should not apply where, instead of confining itself to providing the services neutrally by a merely technical and automatic processing of the information provided by the recipient of the service, the provider of intermediary services plays an active role of such a kind as to give it knowledge of, or control over, that information. Those exemptions should accordingly not be available in respect of liability relating to information provided not by the recipient of the service but by the provider of the intermediary service itself, including where the information has been developed under the editorial responsibility of that provider.",recital,"The Digital Services Act (DSA) states that online service providers can't claim exemptions from liability if they play an active role in controlling or knowing the information they process, rather than just neutrally providing services. This means if the service provider is responsible for the information, including when they have editorial control over it, they can't avoid responsibility if something goes wrong. This rule applies even when the information isn't provided by the user, but by the service provider themselves."
General Data Protection Regulation (GDPR) - Contextual Paragraph (142),0.735850513,"Details of the Contextual Paragraph (142) in the General Data Protection Regulation (GDPR): Where a data subject considers that his or her rights under this Regulation are infringed, he or she should have the right to mandate a not-for-profit body, organisation or association which is constituted in accordance with the law of a Member State, has statutory objectives which are in the public interest and is active in the field of the protection of personal data to lodge a complaint on his or her behalf with a supervisory authority, exercise the right to a judicial remedy on behalf of data subjects or, if provided for in Member State law, exercise the right to receive compensation on behalf of data subjects. A Member State may provide for such a body, organisation or association to have the right to lodge a complaint in that Member State, independently of a data subject's mandate, and the right to an effective judicial remedy where it has reasons to consider that the rights of a data subject have been infringed as a result of the processing of personal data which infringes this Regulation. That body, organisation or association may not be allowed to claim compensation on a data subject's behalf independently of the data subject's mandate.",recital,"The General Data Protection Regulation (GDPR) Paragraph 142 allows individuals who believe their data rights have been violated to appoint a non-profit group to file a complaint or seek legal action on their behalf. This group must be legally established in a member state, serve the public interest, and specialize in personal data protection. It can also independently file a complaint if it believes a person's rights have been violated. However, it cannot seek compensation for the individual without their explicit permission."
Digital Services Act (DSA) - Contextual paragraph (54),0.7358464,"Details of the contextual paragraph (54) of the Digital Services Act (DSA): Where a provider of hosting services decides, on the ground that the information provided by the recipients is illegal content or is incompatible with its terms and conditions, to remove or disable access to information provided by a recipient of the service or to otherwise restrict its visibility or monetisation, for instance following receipt of a notice or acting on its own initiative, including exclusively by automated means, that provider should inform in a clear and easily comprehensible way the recipient of its decision, the reasons for its decision and the available possibilities for redress to contest the decision, in view of the negative consequences that such decisions may have for the recipient, including as regards the exercise of its fundamental right to freedom of expression. That obligation should apply irrespective of the reasons for the decision, in particular whether the action has been taken because the information notified is considered to be illegal content or incompatible with the applicable terms and conditions. Where the decision was taken following receipt of a notice, the provider of hosting services should only reveal the identity of the person or entity who submitted the notice to the recipient of the service where this information is necessary to identify the illegality of the content, such as in cases of infringements of intellectual property rights.",recital,"The Digital Services Act (DSA) requires online hosting service providers to clearly inform users if their content is removed or access is restricted due to violation of terms and conditions or illegal content. This notification should include the reason for the action and options for challenging the decision. This rule applies regardless of why the action was taken. If the action was based on a complaint, the complainant's identity should only be disclosed if it's necessary to prove the content was illegal, such as in copyright infringement cases."
Digital Services Act (DSA) - Contextual paragraph (79),0.735710442,"Details of the contextual paragraph (79) of the Digital Services Act (DSA): Very large online platforms and very large online search engines can be used in a way that strongly influences safety online, the shaping of public opinion and discourse, as well as online trade. The way they design their services is generally optimised to benefit their often advertising-driven business models and can cause societal concerns. Effective regulation and enforcement is necessary in order to effectively identify and mitigate the risks and the societal and economic harm that may arise. Under this Regulation, providers of very large online platforms and of very large online search engines should therefore assess the systemic risks stemming from the design, functioning and use of their services, as well as from potential misuses by the recipients of the service, and should take appropriate mitigating measures in observance of fundamental rights. In determining the significance of potential negative effects and impacts, providers should consider the severity of the potential impact and the probability of all such systemic risks. For example, they could assess whether the potential negative impact can affect a large number of persons, its potential irreversibility, or how difficult it is to remedy and restore the situation prevailing prior to the potential impact.",recital,"The Digital Services Act (DSA) is a new law that addresses the influence of large online platforms and search engines on online safety, public opinion, and e-commerce. The DSA recognizes that these platforms often prioritize their advertising-based business models, which can lead to societal issues. To address this, the DSA requires these providers to assess and mitigate any systemic risks associated with their services, including potential misuse by users. They must also consider the severity and likelihood of these risks. This could involve assessing whether a negative impact could affect many people, its potential irreversibility, or the difficulty of restoring the situation to its original state."
Digital Services Act (DSA) - Contextual paragraph (11),0.73558569,"Details of the contextual paragraph (11) of the Digital Services Act (DSA): It should be clarified that this Regulation is without prejudice to Union law on copyright and related rights, including Directives 2001/29/EC (21), 2004/48/EC (22) and (EU) 2019/790 (23) of the European Parliament and of the Council, which establish specific rules and procedures that should remain unaffected.",recital,"The Digital Services Act (DSA) is a new law that doesn't change any existing European Union copyright laws. This means that the rules and procedures outlined in Directives 2001/29/EC, 2004/48/EC, and (EU) 2019/790 remain the same. These directives establish specific copyright and related rights, which the DSA does not affect."
Digital Services Act (DSA) - Contextual paragraph (74),0.735568762,"Details of the contextual paragraph (74) of the Digital Services Act (DSA): Providers of online platforms allowing consumers to conclude distance contracts with traders should design and organise their online interface in a way that enables traders to comply with their obligations under relevant Union law, in particular the requirements set out in Articles 6 and 8 of Directive 2011/83/EU, Article 7 of Directive 2005/29/EC, Articles 5 and 6 of Directive 2000/31/EC and Article 3 of Directive 98/6/EC of the European Parliament and of the Council (31). For that purpose, the providers of online platforms concerned should make best efforts to assess whether the traders using their services have uploaded complete information on their online interfaces, in line with relevant applicable Union law. The providers of online platforms should ensure that products or services are not offered as long as such information is not complete. This should not amount to an obligation for the providers of online platforms concerned to generally monitor the products or services offered by traders through their services nor a general fact-finding obligation, in particular to assess the accuracy of the information provided by traders. The online interfaces should be user-friendly and easily accessible for traders and consumers. Additionally and after allowing the offering of the product or service by the trader, the providers of online platforms concerned should make reasonable efforts to randomly check whether the products or services offered have been identified as being illegal in any official, freely accessible and machine-readable online databases or online interfaces available in a Member State or in the Union. The Commission should also encourage traceability of products through technology solutions such as digitally signed Quick Response codes (or 'QR codes') or non-fungible tokens. The Commission should promote the development of standards and, in the absence of them, of market led solutions which can be acceptable to the parties concerned.",recital,"The Digital Services Act (DSA) requires online platform providers to ensure their interfaces are designed in a way that helps traders meet their legal obligations. This includes making sure traders provide complete information about their products or services before they're offered. However, platform providers aren't expected to constantly monitor traders or verify the accuracy of their information. The platforms should be user-friendly and easily accessible for both traders and consumers. After a product or service is offered, platform providers should make reasonable efforts to check if they're identified as illegal in any official online databases. The Commission also encourages the use of technology like QR codes or non-fungible tokens for product traceability, and promotes the development of standards or market-led solutions."
General Data Protection Regulation (GDPR) - Contextual Paragraph (151),0.735515416,"Details of the Contextual Paragraph (151) in the General Data Protection Regulation (GDPR): The legal systems of Denmark and Estonia do not allow for administrative fines as set out in this Regulation. The rules on administrative fines may be applied in such a manner that in Denmark the fine is imposed by competent national courts as a criminal penalty and in Estonia the fine is imposed by the supervisory authority in the framework of a misdemeanour procedure, provided that such an application of the rules in those Member States has an equivalent effect to administrative fines imposed by supervisory authorities. Therefore the competent national courts should take into account the recommendation by the supervisory authority initiating the fine. In any event, the fines imposed should be effective, proportionate and dissuasive.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 151) that allows Denmark and Estonia to enforce GDPR fines differently due to their unique legal systems. In Denmark, GDPR fines can be imposed by national courts as criminal penalties, while in Estonia, the supervisory authority can impose fines during a misdemeanour procedure. These alternative methods are acceptable as long as they have the same impact as the administrative fines typically imposed by supervisory authorities under GDPR. National courts should consider recommendations from the supervisory authority when determining fines. All fines should be effective, proportionate, and serve as a deterrent."
Digital Services Act (DSA) - Contextual paragraph (119),0.735500455,"Details of the contextual paragraph (119) of the Digital Services Act (DSA): Member States should ensure that Digital Services Coordinators can take measures that are effective in addressing and proportionate to certain particularly serious and persistent infringements of this Regulation. Especially where those measures can affect the rights and interests of third parties, as may be the case in particular where the access to online interfaces is restricted, it is appropriate to require that the measures are subject to additional safeguards. In particular, third parties potentially affected should be afforded the opportunity to be heard and such orders should only be issued when powers to take such measures as provided by other acts of Union law or by national law, for instance to protect collective interests of consumers, to ensure the prompt removal of web pages containing or disseminating child pornography, or to disable access to services that are being used by a third party to infringe an intellectual property right, are not reasonably available.",recital,"The Digital Services Act (DSA) requires Member States to ensure that their Digital Services Coordinators can take effective and balanced actions against serious and persistent violations of the law. If these actions could impact the rights and interests of third parties, such as restricting access to online platforms, additional safeguards are required. Specifically, third parties who may be affected should have the chance to voice their concerns. These actions should only be taken when other legal options, like protecting consumer interests, removing web pages with child pornography, or blocking access to services infringing intellectual property rights, are not reasonably available."
Digital Services Act (DSA) - Contextual paragraph (21),0.735492527,"Details of the contextual paragraph (21) of the Digital Services Act (DSA): A provider should be able to benefit from the exemptions from liability for 'mere conduit' and for 'caching' services when it is in no way involved with the information transmitted or accessed. This requires, among other things, that the provider does not modify the information that it transmits or to which it provides access. However, this requirement should not be understood to cover manipulations of a technical nature which take place in the course of the transmission or access, as long as those manipulations do not alter the integrity of the information transmitted or to which access is provided.",recital,"The Digital Services Act (DSA) states that a digital service provider can be exempt from liability for 'mere conduit' and 'caching' services if it doesn't involve itself with the information transmitted or accessed. This means the provider cannot change the information it transmits or provides access to. However, this doesn't include technical manipulations made during transmission or access, as long as they don't change the original information's integrity."
General Data Protection Regulation (GDPR) - Contextual Paragraph (5),0.735281587,"Details of the Contextual Paragraph (5) in the General Data Protection Regulation (GDPR): The economic and social integration resulting from the functioning of the internal market has led to a substantial increase in cross-border flows of personal data. The exchange of personal data between public and private actors, including natural persons, associations and undertakings across the Union has increased. National authorities in the Member States are being called upon by Union law to cooperate and exchange personal data so as to be able to perform their duties or carry out tasks on behalf of an authority in another Member State.",recital,"The General Data Protection Regulation (GDPR) acknowledges that due to economic and social integration, there's been a significant rise in cross-border sharing of personal data. This includes exchanges between individuals, businesses, and organizations across the European Union. The law also notes that national authorities in member states are increasingly required to share personal data with each other to fulfill their responsibilities or tasks on behalf of an authority in a different member state."
Digital Services Act (DSA) - Contextual paragraph (137),0.735223413,"Details of the contextual paragraph (137) of the Digital Services Act (DSA): Given the importance of very large online platforms or very large online search engines, in view of their reach and impact, their failure to comply with the specific obligations applicable to them may affect a substantial number of recipients of the services across different Member States and may cause large societal harms, while such failures may also be particularly complex to identify and address. For this reason the Commission, in cooperation with the Digital Services Coordinators and the Board, should develop the Union expertise and capabilities as regards the supervision of very large online platforms or very large online search engines. The Commission should therefore be able to coordinate and rely on the expertise and resources of such authorities, for example by analysing, on a permanent or temporary basis, specific trends or issues emerging with regard to one or more very large online platforms or very large online search engines. Member States should cooperate with the Commission in developing such capabilities, including through secondment of personnel where appropriate, and contributing to the creation of a common Union supervisory capacity. In order to develop the Union expertise and capabilities, the Commission may also draw on the expertise and capabilities of the Observatory on the Online Platform Economy as set up in Commission Decision of 26 April 2018 on setting up the group of experts for the Observatory on the Online Platform Economy, relevant expert bodies, as well as centres of excellence. The Commission may invite experts with specific expertise, including in particular vetted researchers, representatives of Union agencies and bodies, industry representatives, associations representing users or civil society, international organisations, experts from the private sector, as well as other stakeholders.",recital,"The Digital Services Act (DSA) acknowledges that large online platforms and search engines have a significant societal impact. If they fail to meet their obligations, it can affect many users across different countries and cause widespread harm. These issues can be difficult to identify and address. Therefore, the European Commission, along with Digital Services Coordinators and the Board, will work to improve their expertise in supervising these platforms. They will rely on the resources and knowledge of various authorities to analyze trends and issues related to these platforms. Member states are expected to assist the Commission in building these capabilities, potentially through staff secondments. The Commission may also utilize the expertise of the Observatory on the Online Platform Economy and other expert bodies, inviting representatives from various sectors to contribute their knowledge."
Digital Markets Act (DMA) - Contextual Paragraph (42),0.735212,"Details of the Contextual Paragraph (42) in the Digital Markets Act (DMA): To safeguard a fair commercial environment and protect the contestability of the digital sector it is important to safeguard the right of business users and end users, including whistleblowers, to raise concerns about unfair practices by gatekeepers raising any issue of non-compliance with the relevant Union or national law with any relevant administrative or other public authorities, including national courts. For example, it is possible that business users or end users will want to complain about different types of unfair practices, such as discriminatory access conditions, unjustified closing of business user accounts or unclear grounds for product de-listings. Any practice that would in any way inhibit or hinder those users in raising their concerns or in seeking available redress, for instance by means of confidentiality clauses in agreements or other written terms, should therefore be prohibited. This prohibition should be without prejudice to the right of business users and gatekeepers to lay down in their agreements the terms of use including the use of lawful complaints-handling mechanisms, including any use of alternative dispute resolution mechanisms or of the jurisdiction of specific courts in compliance with respective Union and national law. This should also be without prejudice to the role gatekeepers play in the fight against illegal content online.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 42) to protect the rights of businesses, users, and whistleblowers to report any unfair practices by digital gatekeepers (big tech companies) to relevant authorities. This could include complaints about discriminatory access, unjust closure of accounts, or unclear reasons for product removal. The law prohibits any practice that could prevent users from raising their concerns, such as confidentiality clauses in contracts. However, this doesn't prevent businesses and gatekeepers from setting terms of use in their agreements, including legal complaint-handling mechanisms. The law also doesn't affect the role of gatekeepers in combating illegal online content."
General Data Protection Regulation (GDPR) - Contextual Paragraph (71),0.735205472,"Details of the Contextual Paragraph (71) in the General Data Protection Regulation (GDPR): The data subject should have the right not to be subject to a decision, which may include a measure, evaluating personal aspects relating to him or her which is based solely on automated processing and which produces legal effects concerning him or her or similarly significantly affects him or her, such as automatic refusal of an online credit application or e-recruiting practices without any human intervention. Such processing includes ""profiling"" that consists of any form of automated processing of personal data evaluating the personal aspects relating to a natural person, in particular to analyse or predict aspects concerning the data subject's performance at work, economic situation, health, personal preferences or interests, reliability or behaviour, location or movements, where it produces legal effects concerning him or her or similarly significantly affects him or her. However, decision-making based on such processing, including profiling, should be allowed where expressly authorised by Union or Member State law to which the controller is subject, including for fraud and tax-evasion monitoring and prevention purposes conducted in accordance with the regulations, standards and recommendations of Union institutions or national oversight bodies and to ensure the security and reliability of a service provided by the controller, or necessary for the entering or performance of a contract between the data subject and a controller, or when the data subject has given his or her explicit consent. In any case, such processing should be subject to suitable safeguards, which should include specific information to the data subject and the right to obtain human intervention, to express his or her point of view, to obtain an explanation of the decision reached after such assessment and to challenge the decision. Such measure should not concern a child. In order to ensure fair and transparent processing in respect of the data subject, taking into account the specific circumstances and context in which the personal data are processed, the controller should use appropriate mathematical or statistical procedures for the profiling, implement technical and organisational measures appropriate to ensure, in particular, that factors which result in inaccuracies in personal data are corrected and the risk of errors is minimised, secure personal data in a manner that takes account of the potential risks involved for the interests and rights of the data subject and that prevents, inter alia, discriminatory effects on natural persons on the basis of racial or ethnic origin, political opinion, religion or beliefs, trade union membership, genetic or health status or sexual orientation, or that result in measures having such an effect. Automated decision-making and profiling based on special categories of personal data should be allowed only under specific conditions.",recital,"The General Data Protection Regulation (GDPR) gives individuals the right to not be subject to decisions made solely by automated processes, such as online credit applications or job recruitment, that significantly affect them. This includes ""profiling"", where personal data is used to predict things like work performance, financial status, or personal preferences. However, automated decisions can be made if authorized by law, necessary for a contract, or if the individual has given explicit consent. The law also requires that safeguards are in place, including the right for individuals to challenge automated decisions. It also mandates that data processing be fair and transparent, with measures to minimize errors and prevent discrimination. Automated decisions based on sensitive data are only allowed under specific conditions."
Digital Services Act (DSA) - Article 68 Power to take interviews and statements,0.735126555,"Article 68 Power to take interviews and statements in the Digital Services Act (DSA):  1.   In order to carry out the tasks assigned to it under this Section, the Commission may interview any natural or legal person who consents to being interviewed for the purpose of collecting information, relating to the subject-matter of an investigation, in relation to the suspected infringement. The Commission shall be entitled to record such interview by appropriate technical means.

2.   If the interview referred to in paragraph 1 is conducted on other premises than those of the Commission, the Commission shall inform the Digital Services Coordinator of the Member State in the territory of which the interview takes place. If so requested by that Digital Services Coordinator, its officials may assist the officials and other accompanying persons authorised by the Commission to conduct the interview.",article,"The Digital Services Act (DSA) allows the Commission to interview anyone who agrees to provide information related to an investigation into a suspected violation. These interviews can be recorded. If the interview takes place somewhere other than the Commission's premises, the local Digital Services Coordinator must be informed. If required, the Coordinator's officials can assist the Commission in conducting the interview."
Digital Services Act (DSA) - Contextual paragraph (27),0.73499918,"Details of the contextual paragraph (27) of the Digital Services Act (DSA): Whilst the rules on liability of providers of intermediary services set out in this Regulation concentrate on the exemption from liability of providers of intermediary services, it is important to recall that, despite the generally important role played by such providers, the problem of illegal content and activities online should not be dealt with by solely focusing on their liability and responsibilities. Where possible, third parties affected by illegal content transmitted or stored online should attempt to resolve conflicts relating to such content without involving the providers of intermediary services in question. Recipients of the service should be held liable, where the applicable rules of Union and national law determining such liability so provide, for the illegal content that they provide and may disseminate to the public through intermediary services. Where appropriate, other actors, such as group moderators in closed online environments, in particular in the case of large groups, should also help to avoid the spread of illegal content online, in accordance with the applicable law. Furthermore, where it is necessary to involve information society services providers, including providers of intermediary services, any requests or orders for such involvement should, as a general rule, be directed to the specific provider that has the technical and operational ability to act against specific items of illegal content, so as to prevent and minimise any possible negative effects on the availability and accessibility of information that is not illegal content.",recital,"The Digital Services Act (DSA) outlines the responsibilities of online service providers. While these providers are often exempt from liability for illegal content or activities, the DSA encourages resolving issues without involving them. Instead, the law suggests that the person who posts or shares illegal content should be held accountable, based on existing Union and national laws. Additionally, other online actors, like group moderators, should help prevent the spread of illegal content. If service providers need to get involved, requests should be directed to the specific provider capable of addressing the illegal content, to minimize impact on legal content accessibility."
Digital Services Act (DSA) - Article 7 Voluntary own-initiative investigations and legal compliance,0.73497963,"Article 7 Voluntary own-initiative investigations and legal compliance in the Digital Services Act (DSA):  Providers of intermediary services shall not be deemed ineligible for the exemptions from liability referred to in Articles 4, 5 and 6 solely because they, in good faith and in a diligent manner, carry out voluntary own-initiative investigations into, or take other measures aimed at detecting, identifying and removing, or disabling access to, illegal content, or take the necessary measures to comply with the requirements of Union law and national law in compliance with Union law, including the requirements set out in this Regulation.",article,"The new Digital Services Act (DSA) states that online service providers won't lose certain legal protections just because they voluntarily investigate or take actions to find and remove illegal content. They also won't be penalized for taking necessary steps to comply with EU and national laws, including the rules of the DSA. This means that they can proactively work to keep their platforms safe and legal without fear of losing their liability exemptions."
Digital Services Act (DSA) - Contextual paragraph (3),0.734978616,"Details of the contextual paragraph (3) of the Digital Services Act (DSA): Responsible and diligent behaviour by providers of intermediary services is essential for a safe, predictable and trustworthy online environment and for allowing Union citizens and other persons to exercise their fundamental rights guaranteed in the Charter of Fundamental Rights of the European Union (the 'Charter'), in particular the freedom of expression and of information, the freedom to conduct a business, the right to non-discrimination and the attainment of a high level of consumer protection.",recital,"The Digital Services Act (DSA) is a new law that emphasizes the importance of responsible behavior by online service providers. This law is crucial for maintaining a safe and trustworthy online environment. It also ensures that European Union citizens and other individuals can exercise their fundamental rights as outlined in the Charter of Fundamental Rights of the European Union. These rights include freedom of expression and information, the freedom to conduct business, the right to non-discrimination, and a high level of consumer protection."
Digital Markets Act (DMA) - Contextual Paragraph (53),0.734912872,"Details of the Contextual Paragraph (53) in the Digital Markets Act (DMA): Gatekeepers should not restrict or prevent the free choice of end users by technically or otherwise preventing switching between or subscription to different software applications and services. This would allow more undertakings to offer their services, thereby ultimately providing greater choice to the end users. Gatekeepers should ensure a free choice irrespective of whether they are the manufacturer of any hardware by means of which such software applications or services are accessed and should not raise artificial technical or other barriers so as to make switching impossible or ineffective. The mere offering of a given product or service to consumers, including by means of pre-installation, as well as the improvement of the offering to end users, such as price reductions or increased quality, should not be construed as constituting a prohibited barrier to switching.",rectial,"The Digital Markets Act (DMA) includes a provision, Paragraph 53, that aims to protect consumer choice. It states that 'gatekeepers' (companies controlling access to software applications and services) should not prevent users from switching between or subscribing to different apps and services. This is meant to encourage competition and provide more options for users. Gatekeepers should ensure this freedom, regardless of whether they manufacture the hardware used to access these services. They are also prohibited from creating technical or other obstacles that make switching difficult. However, offering or improving a product or service, such as through pre-installation or offering price reductions, is not considered a barrier to switching."
Digital Markets Act (DMA) - Contextual Paragraph (90),0.734912038,"Details of the Contextual Paragraph (90) in the Digital Markets Act (DMA): The coherent, effective and complementary enforcement of available legal instruments applied to gatekeepers requires cooperation and coordination between the Commission and national authorities within the remit of their competences. The Commission and national authorities should cooperate and coordinate their actions necessary for the enforcement of the available legal instruments applied to gatekeepers within the meaning of this Regulation and respect the principle of sincere cooperation laid down in Article 4 of the Treaty on European Union (TEU). It should be possible for the support from national authorities to the Commission to include providing the Commission with all necessary information in their possession or assisting the Commission, at its request, with the exercise of its powers so that the Commission is better able to carry out its duties under this Regulation.",rectial,"The Digital Markets Act (DMA) Paragraph (90) requires the European Commission and national authorities to work together to enforce laws for digital gatekeepers. This cooperation involves sharing information and assisting each other, ensuring that the Commission can effectively perform its duties under the DMA. The principle of sincere cooperation, as outlined in Article 4 of the Treaty on European Union (TEU), should be respected in this process."
Digital Services Act (DSA) - Contextual paragraph (25),0.734906495,"Details of the contextual paragraph (25) of the Digital Services Act (DSA): The exemptions from liability established in this Regulation should not affect the possibility of injunctions of different kinds against providers of intermediary services, even where they meet the conditions set out as part of those exemptions. Such injunctions could, in particular, consist of orders by courts or administrative authorities, issued in compliance with Union law, requiring the termination or prevention of any infringement, including the removal of illegal content specified in such orders, or the disabling of access to it.",recital,"The Digital Services Act (DSA) includes a clause (paragraph 25) that allows legal or administrative authorities to issue orders against digital service providers, even if these providers are technically exempt from liability under the DSA. These orders could require the provider to stop or prevent any violations, including removing illegal content or blocking access to it, as long as they comply with Union law."
Digital Services Act (DSA) - Contextual paragraph (155),0.734862685,"Details of the contextual paragraph (155) of the Digital Services Act (DSA): Since the objectives of this Regulation, namely to contribute to the proper functioning of the internal market and to ensure a safe, predictable and trusted online environment in which the fundamental rights enshrined in the Charter are duly protected, cannot be sufficiently achieved by the Member States because they cannot achieve the necessary harmonisation and cooperation by acting alone, but can rather, by reason of territorial and personal scope, be better achieved at the Union level, the Union may adopt measures, in accordance with the principle of subsidiarity as set out in Article 5 of the Treaty on European Union. In accordance with the principle of proportionality as set out in that Article, this Regulation does not go beyond what is necessary in order to achieve those objectives.",recital,"The Digital Services Act (DSA) aims to ensure a safe, predictable, and trustworthy online environment that protects fundamental rights. The DSA acknowledges that individual Member States cannot achieve this alone due to challenges in harmonization and cooperation, and thus, the responsibility is better handled at the Union level. The DSA will adopt measures according to the principle of subsidiarity, as stated in Article 5 of the Treaty on European Union, ensuring that the regulation is not more extensive than necessary to achieve its objectives."
General Data Protection Regulation (GDPR) - Article 77 Right to lodge a complaint with a supervisory authority,0.734642208,"Details of Article 77 Right to lodge a complaint with a supervisory authority in the General Data Protection Regulation (GDPR): 1. Without prejudice to any other administrative or judicial remedy, every data subject shall have the right to lodge a complaint with a supervisory authority, in particular in the Member State of his or her habitual residence, place of work or place of the alleged infringement if the data subject considers that the processing of personal data relating to him or her infringes this Regulation. 2. The supervisory authority with which the complaint has been lodged shall inform the complainant on the progress and the outcome of the complaint including the possibility of a judicial remedy pursuant to Article 78.",article,"The General Data Protection Regulation (GDPR) includes Article 77, which gives you the right to file a complaint with a supervisory authority if you believe your personal data has been misused. You can file this complaint in the country where you live, work, or where the alleged misuse occurred. The authority will then keep you updated on the progress of your complaint and any possible legal solutions. This is in addition to any other legal or administrative remedies you might have."
Digital Services Act (DSA) - Contextual paragraph (134),0.734570205,"Details of the contextual paragraph (134) of the Digital Services Act (DSA): The Board should bring together the representatives of the Digital Services Coordinators and possible other competent authorities under the chairmanship of the Commission, with a view to ensuring an assessment of matters submitted to it in a fully European dimension. In view of possible cross-cutting elements that may be of relevance for other regulatory frameworks at Union level, the Board should be allowed to cooperate with other Union bodies, offices, agencies and advisory groups with responsibilities in fields such as equality, including gender equality, and non-discrimination, data protection, electronic communications, audiovisual services, detection and investigation of frauds against the Union budget as regards custom duties, consumer protection, or competition law, as necessary for the performance of its tasks.",recital,"The Digital Services Act (DSA) introduces a new board that will include representatives from various digital service authorities. The board, led by the Commission, will ensure that all matters are assessed from a European perspective. The board can also collaborate with other European Union bodies responsible for areas like equality, data protection, electronic communications, audiovisual services, fraud detection, consumer protection, and competition law. This collaboration will help the board perform its tasks more effectively."
General Data Protection Regulation (GDPR) - Contextual Paragraph (104),0.734567702,"Details of the Contextual Paragraph (104) in the General Data Protection Regulation (GDPR): In line with the fundamental values on which the Union is founded, in particular the protection of human rights, the Commission should, in its assessment of the third country, or of a territory or specified sector within a third country, take into account how a particular third country respects the rule of law, access to justice as well as international human rights norms and standards and its general and sectoral law, including legislation concerning public security, defence and national security as well as public order and criminal law. The adoption of an adequacy decision with regard to a territory or a specified sector in a third country should take into account clear and objective criteria, such as specific processing activities and the scope of applicable legal standards and legislation in force in the third country. The third country should offer guarantees ensuring an adequate level of protection essentially equivalent to that ensured within the Union, in particular where personal data are processed in one or several specific sectors. In particular, the third country should ensure effective independent data protection supervision and should provide for cooperation mechanisms with the Member States' data protection authorities, and the data subjects should be provided with effective and enforceable rights and effective administrative and judicial redress.",recital,"The General Data Protection Regulation (GDPR) Paragraph 104 states that when assessing a non-EU country's data protection standards, the European Commission should consider how well the country respects the rule of law, human rights, and its own laws. This includes laws related to public safety, defense, national security, public order, and criminal law. The Commission should use clear criteria to decide if a country's data protection standards are adequate. These standards should be equivalent to those in the EU and should include effective independent supervision of data protection, cooperation with EU data protection authorities, and the provision of enforceable rights and legal remedies for individuals."
General Data Protection Regulation (GDPR) - Contextual Paragraph (30),0.734549224,"Details of the Contextual Paragraph (30) in the General Data Protection Regulation (GDPR): Natural persons may be associated with online identifiers provided by their devices, applications, tools and protocols, such as internet protocol addresses, cookie identifiers or other identifiers such as radio frequency identification tags. This may leave traces which, in particular when combined with unique identifiers and other information received by the servers, may be used to create profiles of the natural persons and identify them.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 30) that pertains to online identifiers. These are unique codes or labels that can be linked to individuals through their use of devices, apps, tools, or protocols like IP addresses or cookies. These identifiers can leave traces which, when combined with other information, can be used to create profiles of individuals and potentially identify them. This is important as it relates to data privacy and protection."
Digital Markets Act (DMA) - Contextual Paragraph (26),0.734543502,"Details of the Contextual Paragraph (26) in the Digital Markets Act (DMA): A particular subset of rules should apply to those undertakings providing core platform services for which it is foreseeable that they will enjoy an entrenched and durable position in the near future. The same specific features of core platform services make them prone to tipping: once an undertaking providing the core platform service has obtained a certain advantage over rivals or potential challengers in terms of scale or intermediation power, its position could become unassailable and the situation could evolve to the point that it is likely to become entrenched and durable in the near future. Undertakings can try to induce this tipping and emerge as gatekeeper by using some of the unfair conditions and practices regulated under this Regulation. In such a situation, it appears appropriate to intervene before the market tips irreversibly.",rectial,"The Digital Markets Act (DMA) introduces a set of rules for businesses providing core platform services, like social media or online marketplaces, that are likely to dominate the market in the near future. These businesses can gain an unfair advantage over competitors, making their position unchallengeable. This can lead to a 'tipping point' where they become the main gatekeeper in their market. The DMA aims to prevent this by regulating unfair practices and intervening before a company becomes too dominant."
General Data Protection Regulation (GDPR) - Contextual Paragraph (135),0.734527588,"Details of the Contextual Paragraph (135) in the General Data Protection Regulation (GDPR): In order to ensure the consistent application of this Regulation throughout the Union, a consistency mechanism for cooperation between the supervisory authorities should be established. That mechanism should in particular apply where a supervisory authority intends to adopt a measure intended to produce legal effects as regards processing operations which substantially affect a significant number of data subjects in several Member States. It should also apply where any supervisory authority concerned or the Commission requests that such matter should be handled in the consistency mechanism. That mechanism should be without prejudice to any measures that the Commission may take in the exercise of its powers under the Treaties.",recital,"The General Data Protection Regulation (GDPR) has introduced a new rule, Paragraph 135, which aims to ensure consistent application of data protection laws across the European Union. It establishes a cooperation mechanism between supervisory authorities, especially when a measure affecting data processing of many individuals in multiple member states is to be adopted. This mechanism also applies when any authority or the Commission requests its use. This does not affect any actions the Commission may take under its existing powers."
Digital Services Act (DSA) - Contextual paragraph (75),0.734429121,"Details of the contextual paragraph (75) of the Digital Services Act (DSA): Given the importance of very large online platforms, due to their reach, in particular as expressed in the number of recipients of the service, in facilitating public debate, economic transactions and the dissemination to the public of information, opinions and ideas and in influencing how recipients obtain and communicate information online, it is necessary to impose specific obligations on the providers of those platforms, in addition to the obligations applicable to all online platforms. Due to their critical role in locating and making information retrievable online, it is also necessary to impose those obligations, to the extent they are applicable, on the providers of very large online search engines. Those additional obligations on providers of very large online platforms and of very large online search engines are necessary to address those public policy concerns, there being no alternative and less restrictive measures that would effectively achieve the same result.",recital,"The Digital Services Act (DSA) recognizes the significant influence of very large online platforms and search engines due to their vast reach and role in public debate, economic transactions, and information dissemination. As such, the DSA imposes specific obligations on these platforms and search engines, in addition to standard online platform regulations. These additional obligations aim to address public policy concerns, as there are no other less restrictive measures that could effectively achieve the same outcome."
Digital Markets Act (DMA) - Contextual Paragraph (78),0.734393895,"Details of the Contextual Paragraph (78) in the Digital Markets Act (DMA): With regard to conduct by gatekeepers that is not covered by the obligations set out in this Regulation, the Commission should have the possibility to open a market investigation into new services and new practices for the purposes of identifying whether the obligations set out in this Regulation are to be supplemented by means of a delegated act falling within the scope of the empowerment set out for such delegated acts in this Regulation, or by presenting a proposal to amend this Regulation. This is without prejudice to the possibility for the Commission to, in appropriate cases, open proceedings under Article 101 or 102 TFEU. Such proceedings should be conducted in accordance with Council Regulation (EC) No 1/2003 ( 18). In cases of urgency due to the risk of serious and irreparable damage to competition, the Commission should consider adopting interim measures in accordance with Article 8 of Regulation (EC) No 1/2003.",rectial,"The Digital Markets Act (DMA) allows the Commission to investigate new services and practices not covered by existing rules. The aim is to identify whether additional obligations need to be added to the DMA. The Commission can either propose an amendment to the DMA or use its power to introduce new rules. This doesn't affect the Commission's ability to open legal proceedings under Article 101 or 102 TFEU. In urgent situations, where competition could be seriously and irreparably damaged, the Commission can adopt temporary measures. These investigations and measures will be conducted according to Council Regulation (EC) No 1/2003."
Digital Services Act (DSA) - Contextual paragraph (147),0.734269917,"Details of the contextual paragraph (147) of the Digital Services Act (DSA): In order to safeguard the harmonised application and enforcement of this Regulation, it is important to ensure that national authorities, including national courts, have all necessary information to ensure that their decisions do not run counter to a decision adopted by the Commission under this Regulation. This is without prejudice to Article 267 TFEU.",recital,"The Digital Services Act (DSA) includes a provision (paragraph 147) that aims to ensure consistency in how the law is applied and enforced across different national authorities, including courts. This means that these authorities should have all the information they need to make decisions that align with those made by the Commission under the DSA. This provision doesn't affect Article 267 TFEU."
Digital Services Act (DSA) - Contextual paragraph (124),0.734234631,"Details of the contextual paragraph (124) of the Digital Services Act (DSA): In view of their potential impact and the challenges involved in effectively supervising them, special rules are needed regarding the supervision and enforcement in respect of providers of very large online platforms and of very large online search engines. The Commission should be responsible, with the support of national competent authorities where relevant, for oversight and public enforcement of systemic issues, such as issues with a wide impact on collective interests of recipients of the service. Therefore, the Commission should have exclusive powers of supervision and enforcement of the additional obligations to manage systemic risks imposed on providers of very large online platforms and of very large online search engines by this Regulation. The exclusive powers of the Commission should be without prejudice to certain administrative tasks assigned by this Regulation to the competent authorities of the Member State of establishment, such as the vetting of researchers.",recital,"The Digital Services Act (DSA) introduces special rules for supervising and enforcing regulations on large online platforms and search engines due to their potential impact. The European Commission, supported by national authorities, will oversee and enforce issues that affect the collective interests of users. The Commission has exclusive power to supervise and enforce additional obligations to manage systemic risks imposed on these large online platforms and search engines. However, this doesn't affect certain administrative tasks assigned to the authorities of the member state where the company is established, such as the vetting of researchers."
Digital Markets Act (DMA) - Contextual Paragraph (66),0.734203219,"Details of the Contextual Paragraph (66) in the Digital Markets Act (DMA): As an additional element to ensure proportionality, gatekeepers should be given an opportunity to request the suspension, to the extent necessary, of a specific obligation in exceptional circumstances that lie beyond the control of the gatekeeper, such as an unforeseen external shock that has temporarily eliminated a significant part of end user demand for the relevant core platform service, where compliance with a specific obligation is shown by the gatekeeper to endanger the economic viability of the Union operations of the gatekeeper concerned. The Commission should identify the exceptional circumstances justifying the suspension and review it on a regular basis in order to assess whether the conditions for granting it are still viable.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 66) that allows large tech companies, referred to as gatekeepers, to request a pause on specific obligations in exceptional circumstances beyond their control. These circumstances could include unexpected events that drastically reduce user demand for their services, threatening the economic stability of their operations within the European Union. The European Commission will determine whether the circumstances warrant such a suspension and will regularly review the situation to see if the suspension is still necessary."
Digital Services Act (DSA) - Contextual paragraph (16),0.734105647,"Details of the contextual paragraph (16) of the Digital Services Act (DSA): The legal certainty provided by the horizontal framework of conditional exemptions from liability for providers of intermediary services, laid down in Directive 2000/31/EC, has allowed many novel services to emerge and scale up across the internal market. That framework should therefore be preserved. However, in view of the divergences when transposing and applying the relevant rules at national level, and for reasons of clarity and coherence, that framework should be incorporated in this Regulation. It is also necessary to clarify certain elements of that framework, having regard to the case-law of the Court of Justice of the European Union.",recital,"The Digital Services Act (DSA) aims to maintain the legal framework that exempts certain online service providers from liability, a rule established by Directive 2000/31/EC. This rule has allowed many new services to grow within the internal market. However, due to differences in how these rules are applied nationally, the DSA will incorporate this framework for clarity and consistency. The DSA will also clarify certain aspects of this framework, considering the case-law of the Court of Justice of the European Union."
Digital Services Act (DSA) - Contextual paragraph (129),0.734072685,"Details of the contextual paragraph (129) of the Digital Services Act (DSA): The Board should be able to refer the matter to the Commission in case of any disagreement as to the assessments or the measures taken or proposed or of a failure to adopt any measures in accordance with this Regulation following a cross-border cooperation request or a joint investigation. Where the Commission, on the basis of the information made available by the concerned authorities, considers that the proposed measures, including the proposed level of fines, cannot ensure the effective enforcement of the obligations laid down in this Regulation, it should accordingly be able to express its serious doubts and request the competent Digital Services Coordinator to re-assess the matter and take the necessary measures to ensure compliance with this Regulation within a defined period. This possibility is without prejudice to the Commission's general duty to oversee the application of, and where necessary enforce, Union law under the control of the Court of Justice of the European Union in accordance with the Treaties.",recital,"The Digital Services Act (DSA) allows the Board to refer any disagreements or failures in implementing measures to the Commission. If the Commission believes that the proposed actions, including potential fines, won't effectively enforce the DSA's rules, it can express its concerns and ask the Digital Services Coordinator to reassess the situation and ensure compliance within a certain timeframe. This doesn't affect the Commission's overall duty to supervise and enforce Union law under the control of the Court of Justice of the European Union."
Digital Services Act (DSA) - Contextual paragraph (109),0.73406589,"Details of the contextual paragraph (109) of the Digital Services Act (DSA): In order to ensure adequate oversight and enforcement of the obligations laid down in this Regulation, Member States should designate at least one authority with the task to supervise the application and enforce this Regulation, without prejudice to the possibility to designate an existing authority and to its legal form in accordance with national law. Member States should, however, be able to entrust more than one competent authority, with specific supervisory or enforcement tasks and competences concerning the application of this Regulation, for example for specific sectors where existing authorities may also be empowered, such as electronic communications' regulators, media regulators or consumer protection authorities, reflecting their domestic constitutional, organisational and administrative structure. In the exercise of their tasks, all competent authorities should contribute to the achievement of the objectives of this Regulation, namely to the proper functioning of the internal market for intermediary services where the harmonised rules for a safe, predictable and trusted online environment that facilitates innovation, and in particular the due diligence obligations applicable to different categories of providers of intermediary services, are effectively supervised and enforced, with a view to ensure that fundamental rights, as enshrined in the Charter, including the principle of consumer protection, are effectively protected. This Regulation does not require Member States to confer on competent authorities the task to adjudicate on the lawfulness of specific items of content.",recital,"The Digital Services Act (DSA) requires each member state to assign at least one authority to oversee and enforce the act. This authority could be an existing one and could take any legal form, according to national law. However, states can assign more than one authority if needed, for example, for specific sectors like electronic communications, media, or consumer protection. These authorities should work towards achieving the DSA's objectives, which include ensuring a safe, predictable online environment that encourages innovation. They will also oversee the due diligence obligations of different types of online service providers. The DSA does not require these authorities to decide on the legality of specific content."
Artifical Inellegence Act (AI Act) - Overview paragraph 18,0.733966291,"Aritifical Intelligence Act (AI Act) overview paragraph (18): Theuse ofAI systems for real-time remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement is considered particularly intrusive in the rights and freedoms of the concerned persons, to the extent that it may affect the private life of a large part of the population, evoke a feeling of constant surveillance and indirectly dissuade the exercise of the freedom of assembly and other fundamental rights. In addition, the immediacy of the impact and the limited opportunities for further checks or correctionsin relation to the use of such systems operating in real-time carry heightened risks for the rights and freedoms of the persons that are concerned by law enforcement activities.",recital,"The Artificial Intelligence Act (AI Act) states that using AI systems for real-time remote identification of people in public spaces for law enforcement purposes can be very intrusive. This could affect people's privacy, make them feel constantly watched, and discourage them from exercising their rights, such as freedom of assembly. The immediacy of this type of surveillance and the limited chances to correct or check the system could pose increased risks to people's rights and freedoms, particularly when used for law enforcement activities."
General Data Protection Regulation (GDPR) - Contextual Paragraph (7),0.733894408,"Details of the Contextual Paragraph (7) in the General Data Protection Regulation (GDPR): Those developments require a strong and more coherent data protection framework in the Union, backed by strong enforcement, given the importance of creating the trust that will allow the digital economy to develop across the internal market. Natural persons should have control of their own personal data. Legal and practical certainty for natural persons, economic operators and public authorities should be enhanced.",recital,"The General Data Protection Regulation (GDPR) is a new law that aims to strengthen and unify data protection for individuals within the European Union. It emphasizes the need for strong enforcement to build trust and facilitate the growth of the digital economy. The law asserts that individuals should have control over their personal data. It also aims to provide legal and practical certainty for individuals, businesses, and public authorities."
Digital Markets Act (DMA) - Contextual Paragraph (3),0.733809054,"Details of the Contextual Paragraph (3) in the Digital Markets Act (DMA): A small number of large undertakings providing core platform services have emerged with considerable economic power that could qualify them to be designated as gatekeepers pursuant to this Regulation. Typically, they feature an ability to connect many business users with many end users through their services, which, in turn, enables them to leverage their advantages, such as their access to large amounts of data, from one area of activity to another. Some of those undertakings exercise control over whole platform ecosystems in the digital economy and are structurally extremely difficult to challenge or contest by existing or new market operators, irrespective of how innovative and efficient those market operators may be. Contestability is reduced in particular due to the existence of very high barriers to entry or exit, including high investment costs, which cannot, or not easily, be recuperated in case of exit, and the absence of, or reduced access to, some key inputs in the digital economy, such as data. As a result, the likelihood increases that the underlying markets do not function well, or will soon fail to function well.",rectial,"The Digital Markets Act (DMA) recognizes that a few large companies providing core online services have gained significant economic power, making them 'gatekeepers' in the digital economy. These companies can connect many businesses with many consumers, and use their access to large amounts of data to their advantage. These gatekeepers often control entire digital platforms and are hard to compete with due to high entry and exit costs, and limited access to key resources like data. This can lead to market failures, as the markets may not function effectively."
Digital Services Act (DSA) - Contextual paragraph (52),0.733777046,"Details of the contextual paragraph (52) of the Digital Services Act (DSA): The rules on such notice and action mechanisms should be harmonised at Union level, so as to provide for the timely, diligent and non-arbitrary processing of notices on the basis of rules that are uniform, transparent and clear and that provide for robust safeguards to protect the right and legitimate interests of all affected parties, in particular their fundamental rights guaranteed by the Charter, irrespective of the Member State in which those parties are established or reside and of the field of law at issue. Those fundamental rights include but are not limited to: for the recipients of the service, the right to freedom of expression and of information, the right to respect for private and family life, the right to protection of personal data, the right to non-discrimination and the right to an effective remedy; for the service providers, the freedom to conduct a business, including the freedom of contract; for parties affected by illegal content, the right to human dignity, the rights of the child, the right to protection of property, including intellectual property, and the right to non-discrimination. Providers of hosting services should act upon notices in a timely manner, in particular by taking into account the type of illegal content being notified and the urgency of taking action. For instance, such providers can be expected to act without delay when allegedly illegal content involving a threat to life or safety of persons is being notified. The provider of hosting services should inform the individual or entity notifying the specific content without undue delay after taking a decision whether or not to act upon the notice.",recital,"The Digital Services Act (DSA) sets out new rules for online service providers. These rules aim to ensure that any reports of illegal content are dealt with quickly, fairly, and transparently. The DSA also includes strong protections for the rights of all parties involved, regardless of where they live in the EU. These rights include freedom of speech, privacy, data protection, non-discrimination, and access to legal remedies. Service providers also have the right to run their businesses freely. People affected by illegal content have additional rights, including the right to human dignity and property protection. Service providers are expected to act quickly on reports of illegal content, especially if it threatens someone's life or safety. After deciding whether to take action on a report, the service provider must inform the person or organization who made the report promptly."
Digital Markets Act (DMA) - Contextual Paragraph (57),0.733754635,"Details of the Contextual Paragraph (57) in the Digital Markets Act (DMA): If dual roles are used in a manner that prevents alternative service and hardware providers from having access under equal conditions to the same operating system, hardware or software features that are available or used by the gatekeeper in the provision of its own complementary or supporting services or hardware, this could significantly undermine innovation by such alternative providers, as well as choice for end users. The gatekeepers should, therefore, be required to ensure, free of charge, effective interoperability with, and access for the purposes of interoperability to, the same operating system, hardware or software features that are available or used in the provision of its own complementary and supporting services and hardware. Such access can equally be required by software applications related to the relevant services provided together with, or in support of, the core platform service in order to effectively develop and provide functionalities interoperable with those provided by gatekeepers. The aim of the obligations is to allow competing third parties to interconnect through interfaces or similar solutions to the respective features as effectively as the gatekeeper""s own services or hardware.",rectial,"The Digital Markets Act (DMA) aims to ensure fair competition in the digital market. Paragraph (57) states that companies controlling key digital services (gatekeepers) must not use their dual roles to block other service and hardware providers from accessing the same system or software features they use. This behavior could stifle innovation and limit user choice. Therefore, gatekeepers are required to provide, free of charge, effective interoperability with their systems or software features. This includes access for software applications connected to the services they provide. The goal is to allow competing companies to connect to the gatekeeper's features as effectively as the gatekeeper's own services or hardware."
General Data Protection Regulation (GDPR) - Contextual Paragraph (106),0.733750343,"Details of the Contextual Paragraph (106) in the General Data Protection Regulation (GDPR): The Commission should monitor the functioning of decisions on the level of protection in a third country, a territory or specified sector within a third country, or an international organisation, and monitor the functioning of decisions adopted on the basis of Article 25(6) or Article 26(4) of Directive 95/46/EC. In its adequacy decisions, the Commission should provide for a periodic review mechanism of their functioning. That periodic review should be conducted in consultation with the third country or international organisation in question and take into account all relevant developments in the third country or international organisation. For the purposes of monitoring and of carrying out the periodic reviews, the Commission should take into consideration the views and findings of the European Parliament and of the Council as well as of other relevant bodies and sources. The Commission should evaluate, within a reasonable time, the functioning of the latter decisions and report any relevant findings to the Committee within the meaning of Regulation (EU) No 182/2011 of the European Parliament and of the Council ( 1 ) as established under this Regulation, to the European Parliament and to the Council.",recital,"The General Data Protection Regulation (GDPR) requires the Commission to monitor how well decisions about data protection are working in third countries or international organizations. These decisions are based on certain articles of Directive 95/46/EC. The Commission must regularly review these decisions, consulting with the third country or organization in question, and considering any relevant changes. The views of the European Parliament, the Council, and other relevant bodies should be taken into account. The Commission should evaluate these decisions within a reasonable time and report any findings to the Committee established under Regulation (EU) No 182/2011, as well as to the European Parliament and Council."
Digital Services Act (DSA) - Contextual paragraph (26),0.733742714,"Details of the contextual paragraph (26) of the Digital Services Act (DSA): In order to create legal certainty, and not to discourage activities that aim to detect, identify and act against illegal content that providers of all categories of intermediary services undertake on a voluntary basis, it should be clarified that the mere fact that providers undertake such activities does not render unavailable the exemptions from liability set out in this Regulation, provided those activities are carried out in good faith and in a diligent manner. The condition of acting in good faith and in a diligent manner should include acting in an objective, non-discriminatory and proportionate manner, with due regard to the rights and legitimate interests of all parties involved, and providing the necessary safeguards against unjustified removal of legal content, in accordance with the objective and requirements of this Regulation. To that aim, the providers concerned should, for example, take reasonable measures to ensure that, where automated tools are used to conduct such activities, the relevant technology is sufficiently reliable to limit to the maximum extent possible the rate of errors. In addition, it is appropriate to clarify that the mere fact that the providers take measures, in good faith, to comply with the requirements of Union law, including those set out in this Regulation as regards the implementation of their terms and conditions, should not render unavailable the exemptions from liability set out in this Regulation. Therefore, any such activities and measures that a provider may have taken should not be taken into account when determining whether the provider can rely on an exemption from liability, in particular as regards whether the provider provides its service neutrally and can therefore fall within the scope of the relevant provision, without this rule however implying that the provider can necessarily rely thereon. Voluntary actions should not be used to circumvent the obligations of providers of intermediary services under this Regulation.",recital,"The Digital Services Act (DSA) paragraph (26) clarifies that online service providers can voluntarily take actions against illegal content without losing their liability exemptions, as long as they act in good faith and diligently. This includes being objective, non-discriminatory, and proportionate, respecting all parties' rights, and avoiding unjustified removal of legal content. If automated tools are used for this, they should be reliable to minimize errors. Providers can also take measures to comply with Union law without losing liability exemptions. These activities should not affect whether a provider can use an exemption, especially regarding neutrality of service. However, voluntary actions shouldn't be used to avoid obligations under the DSA."
General Data Protection Regulation (GDPR) - Contextual Paragraph (114),0.73373884,"Details of the Contextual Paragraph (114) in the General Data Protection Regulation (GDPR): In any case, where the Commission has taken no decision on the adequate level of data protection in a third country, the controller or processor should make use of solutions that provide data subjects with enforceable and effective rights as regards the processing of their data in the Union once those data have been transferred so that that they will continue to benefit from fundamental rights and safeguards.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Contextual Paragraph (114), stating that if the Commission hasn't decided on the level of data protection in a non-EU country, the company handling the data (controller or processor) must use solutions that allow people to enforce their rights regarding their data once it's transferred to the EU. This ensures that individuals continue to have basic rights and protections for their data."
Digital Services Act (DSA) - Contextual paragraph (89),0.733718455,"Details of the contextual paragraph (89) of the Digital Services Act (DSA): Providers of very large online platforms and of very large online search engines should take into account the best interests of minors in taking measures such as adapting the design of their service and their online interface, especially when their services are aimed at minors or predominantly used by them. They should ensure that their services are organised in a way that allows minors to access easily mechanisms provided for in this Regulation, where applicable, including notice and action and complaint mechanisms. They should also take measures to protect minors from content that may impair their physical, mental or moral development and provide tools that enable conditional access to such information. In selecting the appropriate mitigation measures, providers can consider, where appropriate, industry best practices, including as established through self-regulatory cooperation, such as codes of conduct, and should take into account the guidelines from the Commission.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to prioritize the safety of minors. This includes adjusting their services and online interface to suit minors, especially if their services are mainly used by them. These platforms should make it easy for minors to use safety mechanisms provided by the DSA, like reporting inappropriate content or making complaints. They should also protect minors from content that could harm their physical, mental, or moral development, and provide tools to limit access to such content. When deciding on protective measures, providers can look at successful strategies used in the industry, including self-regulated codes of conduct, and should also consider guidelines from the Commission."
Digital Markets Act (DMA) - Contextual Paragraph (50),0.733662248,"Details of the Contextual Paragraph (50) in the Digital Markets Act (DMA): The rules that a gatekeeper sets for the distribution of software applications can, in certain circumstances, restrict the ability of end users to install and effectively use third-party software applications or software application stores on hardware or operating systems of that gatekeeper and restrict the ability of end users to access such software applications or software application stores outside the core platform services of that gatekeeper. Such restrictions can limit the ability of developers of software applications to use alternative distribution channels and the ability of end users to choose between different software applications from different distribution channels and should be prohibited as unfair and liable to weaken the contestability of core platform services. To ensure contestability, the gatekeeper should furthermore allow the third-party software applications or software application stores to prompt the end user to decide whether that service should become the default and enable that change to be carried out easily. In order to ensure that third-party software applications or software application stores do not endanger the integrity of the hardware or operating system provided by the gatekeeper, it should be possible for the gatekeeper concerned to implement proportionate technical or contractual measures to achieve that goal if the gatekeeper demonstrates that such measures are necessary and justified and that there are no less-restrictive means to safeguard the integrity of the hardware or operating system. The integrity of the hardware or the operating system should include any design options that need to be implemented and maintained in order for the hardware or the operating system to be protected against unauthorised access, by ensuring that security controls specified for the hardware or the operating system concerned cannot be compromised. Furthermore, in order to ensure that third-party software applications or software application stores do not undermine end users"" security, it should be possible for the gatekeeper to implement strictly necessary and proportionate measures and settings, other than default settings, enabling end users to effectively protect security in relation to third-party software applications or software application stores if the gatekeeper demonstrates that such measures and settings are strictly necessary and justified and that there are no less-restrictive means to achieve that goal. The gatekeeper should be prevented from implementing such measures as a default setting or as pre-installation.",rectial,"The Digital Markets Act (DMA) aims to prevent tech giants (gatekeepers) from limiting users' access to third-party apps or app stores on their devices or operating systems. It also seeks to ensure that users have the option to choose these third-party services as their default. However, gatekeepers can take necessary measures to protect the integrity of their hardware or operating system, provided they prove these measures are necessary and there are no less restrictive alternatives. These measures should not be implemented as default settings or pre-installations. This law is designed to promote competition and user choice, while maintaining system security."
General Data Protection Regulation (GDPR) - Contextual Paragraph (107),0.733639956,"Details of the Contextual Paragraph (107) in the General Data Protection Regulation (GDPR): The Commission may recognise that a third country, a territory or a specified sector within a third country, or an international organisation no longer ensures an adequate level of data protection. Consequently the transfer of personal data to that third country or international organisation should be prohibited, unless the requirements in this Regulation relating to transfers subject to appropriate safeguards, including binding corporate rules, and derogations for specific situations are fulfilled. In that case, provision should be made for consultations between the Commission and such third countries or international organisations. The Commission should, in a timely manner, inform the third country or international organisation of the reasons and enter into consultations with it in order to remedy the situation.",recital,"The General Data Protection Regulation (GDPR) allows the Commission to decide that a third country, territory, sector, or international organization is no longer providing enough data protection. If this happens, personal data cannot be transferred to that place or organization unless certain safeguards are in place, such as specific corporate rules. If these conditions are met, the Commission will discuss the situation with the third country or organization. They will also inform them why they have made this decision and discuss how to improve the situation."
Digital Markets Act (DMA) - Contextual Paragraph (98),0.733517528,"Details of the Contextual Paragraph (98) in the Digital Markets Act (DMA): When adopting delegated acts under this Regulation, it is of particular importance that the Commission carries out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making ( 19). In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council should receive all documents at the same time as Member States' experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.",rectial,"The Digital Markets Act (DMA) Paragraph 98 states that when creating new rules under this law, the Commission must consult with experts and follow the principles of the Interinstitutional Agreement of 13 April 2016 on Better Law-Making. This ensures a fair process where the European Parliament and the Council receive all relevant documents at the same time as experts from Member States. Additionally, their experts must be allowed to attend meetings of Commission expert groups that are preparing these new rules."
Digital Markets Act (DMA) - Contextual Paragraph (25),0.73349613,"Details of the Contextual Paragraph (25) in the Digital Markets Act (DMA): Such an assessment can only be done in light of a market investigation, while taking into account the quantitative thresholds. In its assessment the Commission should pursue the objectives of preserving and fostering innovation and the quality of digital products and services, the degree to which prices are fair and competitive, and the degree to which quality or choice for business users and for end users is or remains high. Elements can be taken into account that are specific to the undertakings providing core platform services concerned, such as extreme scale or scope economies, very strong network effects, data-driven advantages, an ability to connect many business users with many end users through the multisidedness of those services, lock-in effects, lack of multi-homing, conglomerate corporate structure or vertical integration. In addition, a very high market capitalisation, a very high ratio of equity value over profit or a very high turnover derived from end users of a single core platform service can be used as indicators of the leveraging potential of such undertakings and of the tipping of the market in their favour. Together with market capitalisation, high relative growth rates are examples of dynamic parameters that are particularly relevant to identifying such undertakings providing core platform services for which it is foreseeable that they will become entrenched and durable. The Commission should be able to take a decision by drawing adverse inferences from facts available where the undertaking providing core platform services significantly obstructs the investigation by failing to comply with the investigative measures taken by the Commission.",rectial,"The Digital Markets Act (DMA) aims to ensure fair competition and high-quality digital products and services. It allows for investigations into companies providing core platform services, considering factors such as their size, network influence, data advantages, ability to connect businesses and end users, and their market dominance. The law also takes into account a company's market capitalization, profit-to-equity ratio, and revenue from a single platform service as indicators of potential market monopolization. High growth rates could suggest that a company is becoming too dominant. If a company obstructs an investigation, the Commission can make decisions based on the available facts."
Digital Services Act (DSA) - Contextual paragraph (112),0.733353913,"Details of the contextual paragraph (112) of the Digital Services Act (DSA): The competent authorities designated under this Regulation should also act in complete independence from private and public bodies, without the obligation or possibility to seek or receive instructions, including from the government, and without prejudice to the specific duties to cooperate with other competent authorities, the Digital Services Coordinators, the Board and the Commission. On the other hand, the independence of those authorities should not mean that they cannot be subject, in accordance with national constitutions and without endangering the achievement of the objectives of this Regulation, to proportionate accountability mechanisms regarding the general activities of the Digital Services Coordinators, such as their financial expenditure or reporting to the national parliaments. The requirement of independence should also not prevent the exercise of judicial review, or the possibility to consult or regularly exchange views with other national authorities, including law enforcement authorities, crisis management authorities or consumer protection authorities, where appropriate, in order to inform each other about ongoing investigations, without affecting the exercise of their respective powers.",recital,"The Digital Services Act (DSA) states that the authorities responsible for enforcing this law must operate independently from both private and public organizations, including the government. They are also required to cooperate with other relevant authorities, Digital Services Coordinators, and the Commission. Despite their independence, these authorities can be held accountable for their general activities, like their spending or reporting to national parliaments, as long as it doesn't hinder the objectives of the DSA. This independence also doesn't stop them from being reviewed by the courts or consulting with other national authorities, such as law enforcement or consumer protection agencies, to share information about ongoing investigations."
General Data Protection Regulation (GDPR) - Contextual Paragraph (138),0.733339369,"Details of the Contextual Paragraph (138) in the General Data Protection Regulation (GDPR): The application of such mechanism should be a condition for the lawfulness of a measure intended to produce legal effects by a supervisory authority in those cases where its application is mandatory. In other cases of crossborder relevance, the cooperation mechanism between the lead supervisory authority and supervisory authorities concerned should be applied and mutual assistance and joint operations might be carried out between the supervisory authorities concerned on a bilateral or multilateral basis without triggering the consistency mechanism.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 138) that requires a specific mechanism to be applied for a measure to be legally valid. This mechanism is mandatory in certain cases involving a supervisory authority. In other cross-border situations, the supervisory authorities should work together and may conduct joint operations. This cooperation does not require the use of the consistency mechanism."
Artifical Inellegence Act (AI Act) - Overview paragraph 39,0.73326993,"Aritifical Intelligence Act (AI Act) overview paragraph (39): AI systems used in migration, asylum and border control management affect people who are often in particularly vulnerable position and who are dependent on the outcome of the actions of the competent public authorities. The accuracy, non-discriminatory nature and transparency of the AI systems used in those contexts are therefore particularly important to guarantee the respect of the fundamental rights of the affected persons, notably their rights to free movement, non-discrimination, protection of private life and personal data, international protection and good administration. It is therefore appropriate to classify as high-risk AI systems intended to be used by the competent public authorities charged with tasks in the fields of migration, asylum and border control management as polygraphs and similar tools or to detect the emotional state of a natural person; for assessing certain risks posed by natural persons entering the territory of a Member State or applying for visa or asylum;for verifying the authenticity ofthe relevantdocuments of natural persons; for assisting competent public authorities for the examination of applications for asylum, visa and residence permits and associated complaints with regard to the objective to establish the eligibility of the natural persons applying for a status.AI systems in the area of migration, asylum and border control management covered by this Regulation should comply with the relevant procedural requirements set by the Directive 2013/32/EUof the European Parliament and of the Council49, the Regulation (EC) No 810/2009of the European Parliament and of the Council50and other relevant legislation.",recital,"The Artificial Intelligence Act (AI Act) states that AI systems used in migration, asylum, and border control must be accurate, non-discriminatory, and transparent to ensure the fundamental rights of individuals, such as free movement, privacy, and non-discrimination, are respected. These AI systems are considered high-risk and are used to detect emotional states, assess risks of individuals entering a country, verify document authenticity, and assist authorities in processing asylum, visa, and residence permit applications. These AI systems must comply with the procedural requirements set by Directive 2013/32/EU, Regulation (EC) No 810/2009, and other relevant laws."
Digital Markets Act (DMA) - Contextual Paragraph (23),0.733245611,"Details of the Contextual Paragraph (23) in the Digital Markets Act (DMA): An undertaking providing core platform services should be able, in exceptional circumstances, to rebut the presumption that the undertaking has a significant impact on the internal market by demonstrating that, although it meets the quantitative thresholds set out in this Regulation, it does not fulfil the requirements for designation as a gatekeeper. The burden of adducing evidence that the presumption deriving from the fulfilment of the quantitative thresholds should not apply should be borne by that undertaking. In its assessment of the evidence and arguments produced, the Commission should take into account only those elements which directly relate to the quantitative criteria, namely the impact of the undertaking providing core platform services on the internal market beyond revenue or market cap, such as its size in absolute terms, and the number of Member States in which it is present; by how much the actual business user and end user numbers exceed the thresholds and the importance of the undertaking""s core platform service considering the overall scale of activities of the respective core platform service; and the number of years for which the thresholds have been met. Any justification on economic grounds seeking to enter into market definition or to demonstrate efficiencies deriving from a specific type of behaviour by the undertaking providing core platform services should be discarded, as it is not relevant to the designation as a gatekeeper. If the arguments submitted are not sufficiently substantiated because they do not manifestly put into question the presumption, it should be possible for the Commission to reject the arguments within the timeframe of 45 working days provided for the designation. The Commission should be able to take a decision by relying on information available on the quantitative thresholds where the undertaking providing core platform services obstructs the investigation by failing to comply with the investigative measures taken by the Commission.",rectial,"The Digital Markets Act (DMA) allows companies providing core platform services to challenge the assumption that they significantly impact the internal market. They can do this by showing that even if they meet certain size or revenue criteria, they don't meet the requirements to be considered a ""gatekeeper"". The company must provide evidence to support this claim. The Commission will only consider factors related to size, revenue, presence in Member States, user numbers, and the importance of the company's core platform service. Economic justifications or efficiency arguments are not relevant. If the company's arguments are not convincing, the Commission can reject them within 45 working days. If the company obstructs the investigation, the Commission can make a decision based on available data."
Digital Services Act (DSA) - Contextual paragraph (125),0.73322475,"Details of the contextual paragraph (125) of the Digital Services Act (DSA): The powers of supervision and enforcement of due diligence obligations, other than the additional obligations to manage systemic risks imposed on providers of very large online platforms and of very large online search engines by this Regulation, should be shared by the Commission and by the national competent authorities. On the one hand, the Commission could in many instances be better placed to address systemic infringements committed by those providers, such as those affecting multiple Member States or serious repeated infringements or concerning a failure to establish effective mechanisms required by this Regulation. On the other hand, the competent authorities in the Member State where the main establishment of a provider of very large online platform or of very large online search engine is located could be better placed to address individual infringements committed by those providers, that do not raise any systemic or cross-border issues. In the interest of efficiency, to avoid duplication and to ensure compliance with the principle of ne bis in idem, it should be for the Commission to assess whether it deems it appropriate to exercise those shared competences in a given case and, once it has initiated proceedings, Member States should no longer have the ability to do so. Member States should cooperate closely both with each other and with the Commission, and the Commission should cooperate closely with the Member States, in order to ensure that the system of supervision and enforcement set up by this Regulation functions smoothly and effectively.",recital,"The Digital Services Act (DSA) gives both the European Commission and national authorities the power to enforce rules for large online platforms and search engines. If a company breaks the rules in multiple countries or repeatedly, the Commission will likely handle it. If the issue is specific to one country, that country's authorities will likely handle it. To avoid duplication, once the Commission starts proceedings, national authorities can't. All parties involved should work together to ensure the system works smoothly and effectively."
General Data Protection Regulation (GDPR) - Contextual Paragraph (6),0.733198643,"Details of the Contextual Paragraph (6) in the General Data Protection Regulation (GDPR): Rapid technological developments and globalisation have brought new challenges for the protection of personal data. The scale of the collection and sharing of personal data has increased significantly. Technology allows both private companies and public authorities to make use of personal data on an unprecedented scale in order to pursue their activities. Natural persons increasingly make personal information available publicly and globally. Technology has transformed both the economy and social life, and should further facilitate the free flow of personal data within the Union and the transfer to third countries and international organisations, while ensuring a high level of the protection of personal data.",recital,"The General Data Protection Regulation (GDPR) acknowledges that technology and globalization have led to more personal data being collected and shared than ever before. This includes both private companies and public authorities using this data on a large scale. Individuals are also sharing more personal information publicly. While technology has transformed the economy and social life, and should continue to allow the free flow of personal data, GDPR emphasizes the need for strong protection of personal data, including when it's transferred to other countries or international organizations."
Digital Services Act (DSA) - Contextual paragraph (22),0.73315,"Details of the contextual paragraph (22) of the Digital Services Act (DSA): In order to benefit from the exemption from liability for hosting services, the provider should, upon obtaining actual knowledge or awareness of illegal activities or illegal content, act expeditiously to remove or to disable access to that content. The removal or disabling of access should be undertaken in the observance of the fundamental rights of the recipients of the service, including the right to freedom of expression and of information. The provider can obtain such actual knowledge or awareness of the illegal nature of the content, inter alia through its own-initiative investigations or through notices submitted to it by individuals or entities in accordance with this Regulation in so far as such notices are sufficiently precise and adequately substantiated to allow a diligent economic operator to reasonably identify, assess and, where appropriate, act against the allegedly illegal content. However, such actual knowledge or awareness cannot be considered to be obtained solely on the ground that that provider is aware, in a general sense, of the fact that its service is also used to store illegal content. Furthermore, the fact that the provider automatically indexes information uploaded to its service, that it has a search function or that it recommends information on the basis of the profiles or preferences of the recipients of the service is not a sufficient ground for considering that provider to have 'specific' knowledge of illegal activities carried out on that platform or of illegal content stored on it.",recital,"The Digital Services Act (DSA) states that online service providers can avoid liability for illegal content if they promptly remove or block access to it once they become aware of its existence. This must be done while respecting users' rights, including freedom of expression. Providers can become aware of illegal content through their own investigations or through reports from users or other entities, as long as these reports are specific and well-supported. However, providers can't be considered aware of illegal content just because they know their service could be used to store such content. Also, simply having search or recommendation functions doesn't mean providers have specific knowledge of illegal activities or content on their platform."
General Data Protection Regulation (GDPR) - Contextual Paragraph (144),0.73314327,"Details of the Contextual Paragraph (144) in the General Data Protection Regulation (GDPR): Where a court seized of proceedings against a decision by a supervisory authority has reason to believe that proceedings concerning the same processing, such as the same subject matter as regards processing by the same controller or processor, or the same cause of action, are brought before a competent court in another Member State, it should contact that court in order to confirm the existence of such related proceedings. If related proceedings are pending before a court in another Member State, any court other than the court first seized may stay its proceedings or may, on request of one of the parties, decline jurisdiction in favour of the court first seized if that court has jurisdiction over the proceedings in question and its law permits the consolidation of such related proceedings. Proceedings are deemed to be related where they are so closely connected that it is expedient to hear and determine them together in order to avoid the risk of irreconcilable judgments resulting from separate proceedings.",recital,"The General Data Protection Regulation (GDPR) includes a new rule (Paragraph 144) that deals with legal cases involving data protection. If a court is handling a case and realizes that a similar case is being heard in another court within the same jurisdiction, the two courts should communicate. If the first court has the authority to handle both cases and it's allowed by their laws, the second court can either pause its proceedings or transfer its case to the first court. This is to ensure that the cases, which are closely related, are heard together to avoid conflicting judgments."
Digital Services Act (DSA) - Contextual paragraph (51),0.733096421,"Details of the contextual paragraph (51) of the Digital Services Act (DSA): Having regard to the need to take due account of the fundamental rights guaranteed under the Charter of all parties concerned, any action taken by a provider of hosting services pursuant to receiving a notice should be strictly targeted, in the sense that it should serve to remove or disable access to the specific items of information considered to constitute illegal content, without unduly affecting the freedom of expression and of information of recipients of the service. Notices should therefore, as a general rule, be directed to the providers of hosting services that can reasonably be expected to have the technical and operational ability to act against such specific items. The providers of hosting services who receive a notice for which they cannot, for technical or operational reasons, remove the specific item of information should inform the person or entity who submitted the notice.",recital,"The Digital Services Act (DSA) has a new provision (paragraph 51) that ensures the protection of fundamental rights. If a hosting service provider receives a notice about illegal content, they must only remove or disable access to that specific content, without infringing on freedom of expression or information. Generally, notices should only be sent to providers who are technically and operationally capable of addressing the issue. If a provider can't remove the content due to technical or operational reasons, they must inform the person who reported the content."
Digital Services Act (DSA) - Contextual paragraph (19),0.733071685,"Details of the contextual paragraph (19) of the Digital Services Act (DSA): In view of the different nature of the activities of 'mere conduit', 'caching' and 'hosting' and the different position and abilities of the providers of the services in question, it is necessary to distinguish the rules applicable to those activities, in so far as under this Regulation they are subject to different requirements and conditions and their scope differs, as interpreted by the Court of Justice of the European Union.",recital,"The Digital Services Act (DSA) recognizes that 'mere conduit', 'caching', and 'hosting' activities are different and are performed by service providers with varying capacities and roles. Therefore, it is necessary to have distinct rules for each of these activities. These rules will be based on the specific requirements, conditions, and scope of each activity, as defined by the Court of Justice of the European Union."
Digital Services Act (DSA) - Contextual paragraph (115),0.732937813,"Details of the contextual paragraph (115) of the Digital Services Act (DSA): Member States should set out in their national law, in accordance with Union law and in particular this Regulation and the Charter, the detailed conditions and limits for the exercise of the investigatory and enforcement powers of their Digital Services Coordinators, and other competent authorities where relevant, under this Regulation.",recital,The Digital Services Act (DSA) requires each member country to create their own laws that outline the specific terms and boundaries for their Digital Services Coordinators. These coordinators will have the power to investigate and enforce digital service regulations. These national laws must be in line with the overall rules and principles of the DSA and the Charter.
General Data Protection Regulation (GDPR) - Contextual Paragraph (59),0.732916594,"Details of the Contextual Paragraph (59) in the General Data Protection Regulation (GDPR): Modalities should be provided for facilitating the exercise of the data subject's rights under this Regulation, including mechanisms to request and, if applicable, obtain, free of charge, in particular, access to and rectification or erasure of personal data and the exercise of the right to object. The controller should also provide means for requests to be made electronically, especially where personal data are processed by electronic means. The controller should be obliged to respond to requests from the data subject without undue delay and at the latest within one month and to give reasons where the controller does not intend to comply with any such requests.",recital,"The General Data Protection Regulation (GDPR) mandates that companies must make it easy for individuals to access, correct, or delete their personal data for free. This includes providing electronic methods for such requests, especially if the data is processed electronically. Companies must respond to these requests promptly, within a month at the latest. If a company decides not to fulfill a request, it must provide a valid reason for its decision."
Digital Services Act (DSA) - Contextual paragraph (104),0.732910872,"Details of the contextual paragraph (104) of the Digital Services Act (DSA): It is appropriate that this Regulation identify certain areas of consideration for such codes of conduct. In particular, risk mitigation measures concerning specific types of illegal content should be explored via self- and co-regulatory agreements. Another area for consideration is the possible negative impacts of systemic risks on society and democracy, such as disinformation or manipulative and abusive activities or any adverse effects on minors. This includes coordinated operations aimed at amplifying information, including disinformation, such as the use of bots or fake accounts for the creation of intentionally inaccurate or misleading information, sometimes with a purpose of obtaining economic gain, which are particularly harmful for vulnerable recipients of the service, such as minors. In relation to such areas, adherence to and compliance with a given code of conduct by a very large online platform or a very large online search engine may be considered as an appropriate risk mitigating measure. The refusal without proper explanations by a provider of an online platform or of an online search engine of the Commission's invitation to participate in the application of such a code of conduct could be taken into account, where relevant, when determining whether the online platform or the online search engine has infringed the obligations laid down by this Regulation. The mere fact of participating in and implementing a given code of conduct should not in itself presume compliance with this Regulation.",recital,"The Digital Services Act (DSA) encourages online platforms and search engines to adopt codes of conduct that mitigate risks related to illegal content and harmful activities like disinformation and manipulation. This includes using bots or fake accounts to spread misleading information, which can be particularly harmful to vulnerable users like children. If large platforms or search engines refuse to participate in these codes without good reason, it could be seen as a violation of the DSA. However, simply participating in these codes doesn't automatically mean a platform or search engine is complying with the DSA."
Digital Services Act (DSA) - Contextual paragraph (92),0.732904911,"Details of the contextual paragraph (92) of the Digital Services Act (DSA): Given the need to ensure verification by independent experts, providers of very large online platforms and of very large online search engines should be accountable, through independent auditing, for their compliance with the obligations laid down by this Regulation and, where relevant, any complementary commitments undertaken pursuant to codes of conduct and crises protocols. In order to ensure that audits are carried out in an effective, efficient and timely manner, providers of very large online platforms and of very large online search engines should provide the necessary cooperation and assistance to the organisations carrying out the audits, including by giving the auditor access to all relevant data and premises necessary to perform the audit properly, including, where appropriate, to data related to algorithmic systems, and by answering oral or written questions. Auditors should also be able to make use of other sources of objective information, including studies by vetted researchers. Providers of very large online platforms and of very large online search engines should not undermine the performance of the audit. Audits should be performed according to best industry practices and high professional ethics and objectivity, with due regard, as appropriate, to auditing standards and codes of practice. Auditors should guarantee the confidentiality, security and integrity of the information, such as trade secrets, that they obtain when performing their tasks. This guarantee should not be a means to circumvent the applicability of audit obligations in this Regulation. Auditors should have the necessary expertise in the area of risk management and technical competence to audit algorithms. They should be independent, in order to be able to perform their tasks in an adequate and trustworthy manner. They should comply with core independence requirements for prohibited non-auditing services, firm rotation and non-contingent fees. If their independence and technical competence is not beyond doubt, they should resign or abstain from the audit engagement.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to undergo independent audits to ensure they are following the rules set by the DSA and any additional commitments they've made. These companies must cooperate with the auditors, providing them with all necessary data and access to their premises. The audits should be done in a timely, efficient manner and should not be hindered by the companies. The auditors must maintain confidentiality and integrity of the information they receive, and they should have expertise in risk management and technical competence to audit algorithms. They must also be independent and if their independence or competence is questionable, they should step down from the audit."
Digital Services Act (DSA) - Contextual paragraph (87),0.732811451,"Details of the contextual paragraph (87) of the Digital Services Act (DSA): Providers of very large online platforms and of very large online search engines should consider under such mitigating measures, for example, adapting any necessary design, feature or functioning of their service, such as the online interface design. They should adapt and apply their terms and conditions, as necessary, and in accordance with the rules of this Regulation on terms and conditions. Other appropriate measures could include adapting their content moderation systems and internal processes or adapting their decision-making processes and resources, including the content moderation personnel, their training and local expertise. This concerns in particular the speed and quality of processing of notices. In this regard, for example, the Code of conduct on countering illegal hate speech online of 2016 sets a benchmark to process valid notifications for removal of illegal hate speech in less than 24 hours. Providers of very large online platforms, in particular those primarily used for the dissemination to the public of pornographic content, should diligently meet all their obligations under this Regulation in respect of illegal content constituting cyber violence, including illegal pornographic content, especially with regard to ensuring that victims can effectively exercise their rights in relation to content representing non-consensual sharing of intimate or manipulated material through the rapid processing of notices and removal of such content without undue delay. Other types of illegal content may require longer or shorter timelines for processing of notices, which will depend on the facts, circumstances and types of illegal content at hand. Those providers may also initiate or increase cooperation with trusted flaggers and organise training sessions and exchanges with trusted flagger organisations.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to adjust their designs, features, and terms of service to comply with the law. This includes improving their content moderation systems and decision-making processes, particularly in relation to removing illegal content quickly and efficiently. The law sets a benchmark of less than 24 hours to remove illegal hate speech, once notified. Platforms that primarily share pornographic content must ensure they respond swiftly to illegal content, such as non-consensual intimate material, and protect victims' rights. The timelines for removing other types of illegal content may vary. The DSA also encourages these providers to work more closely with trusted flaggers and to provide them with training."
Digital Markets Act (DMA) - Contextual Paragraph (106),0.732795715,"Details of the Contextual Paragraph (106) in the Digital Markets Act (DMA): Without prejudice to the budgetary procedure and through existing financial instruments, adequate human, financial and technical resources should be allocated to the Commission to ensure that it can effectively perform its duties and exercise its powers in respect of the enforcement of this Regulation.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 106) that emphasizes the need for the Commission to have enough staff, money, and technology to effectively enforce the law. This will be achieved through existing financial mechanisms and within the budget framework. This ensures that the Commission has the necessary resources to carry out its responsibilities under the DMA."
Digital Services Act (DSA) - Contextual paragraph (139),0.732792616,"Details of the contextual paragraph (139) of the Digital Services Act (DSA): In order to effectively perform its tasks, the Commission should maintain a margin of discretion as to the decision to initiate proceedings against providers of very large online platforms or of very large online search engine. Once the Commission initiated the proceedings, the Digital Services Coordinators of establishment concerned should be precluded from exercising their investigative and enforcement powers in respect of the concerned conduct of the provider of the very large online platform or of very large online search engine, so as to avoid duplication, inconsistencies and risks from the viewpoint of the principle of ne bis in idem. The Commission, however, should be able to ask for the individual or joint contribution of the Digital Services Coordinators to the investigation. In accordance with the duty of sincere cooperation, the Digital Services Coordinator should make its best efforts in fulfilling justified and proportionate requests by the Commission in the context of an investigation. Moreover, the Digital Services Coordinator of establishment, as well as the Board and any other Digital Services Coordinators where relevant, should provide the Commission with all necessary information and assistance to allow it to perform its tasks effectively, including information gathered in the context of data gathering or data access exercises, to the extent that this is not precluded by the legal basis according to which the information has been gathered. Conversely, the Commission should keep the Digital Services Coordinator of establishment and the Board informed on the exercise of its powers and in particular when it intends to initiate the proceeding and exercise its investigatory powers. Moreover, when the Commission communicates its preliminary findings, including any matter to which it objects, to providers of very large online platforms or of very large online search engines concerned, it should also communicate them to the Board. The Board should provide its views on the objections and assessment made by the Commission, which should take this opinion into account in the reasoning underpinning Commission's final decision.",recital,"The Digital Services Act (DSA) allows the Commission to decide whether to initiate proceedings against large online platforms or search engines. Once proceedings begin, the Digital Services Coordinators (DSCs) of the involved establishment cannot conduct their own investigations to avoid duplication and inconsistencies. However, the Commission can request the DSCs' contribution to the investigation. The DSCs must cooperate fully, providing all necessary information and assistance. The Commission must keep the DSCs and the Board updated about its actions and preliminary findings. The Board can give its opinion on the Commission's findings, which the Commission should consider in its final decision."
Digital Services Act (DSA) - Contextual paragraph (62),0.732784152,"Details of the contextual paragraph (62) of the Digital Services Act (DSA): Trusted flaggers should publish easily comprehensible and detailed reports on notices submitted in accordance with this Regulation. Those reports should indicate information such as the number of notices categorised by the provider of hosting services, the type of content, and the action taken by the provider. Given that trusted flaggers have demonstrated expertise and competence, the processing of notices submitted by trusted flaggers can be expected to be less burdensome and therefore faster compared to notices submitted by other recipients of the service. However, the average time taken to process may still vary depending on factors including the type of illegal content, the quality of notices, and the actual technical procedures put in place for the submission of such notices.
For example, while the Code of conduct on countering illegal hate speech online of 2016 sets a benchmark for the participating companies with respect to the time needed to process valid notifications for removal of illegal hate speech, other types of illegal content may take considerably different timelines for processing, depending on the specific facts and circumstances and types of illegal content at stake. In order to avoid abuses of the trusted flagger status, it should be possible to suspend such status when a Digital Services Coordinator of establishment opened an investigation based on legitimate reasons. The rules of this Regulation on trusted flaggers should not be understood to prevent providers of online platforms from giving similar treatment to notices submitted by entities or individuals that have not been awarded trusted flagger status under this Regulation, from otherwise cooperating with other entities, in accordance with the applicable law, including this Regulation and Regulation (EU) 2016/794 of the European Parliament and of the Council (29). The rules of this Regulation should not prevent the providers of online platforms from making use of such trusted flagger or similar mechanisms to take quick and reliable action against content that is incompatible with their terms and conditions, in particular against content that is harmful for vulnerable recipients of the service, such as minors.",recital,"The Digital Services Act (DSA) states that trusted flaggers, who are experts in identifying illegal content, must publish clear reports about the notices they submit. These reports should include details like the number of notices, type of content, and actions taken by the hosting service provider. As trusted flaggers are skilled, their notices are processed faster than those from regular users. However, processing time can still vary based on factors like the type of illegal content and quality of notices. The DSA also allows for the suspension of a trusted flagger's status if an investigation is launched for valid reasons. The DSA doesn't stop online platforms from treating notices from non-trusted flaggers similarly, or from using trusted flaggers to quickly remove content that violates their terms and conditions."
Digital Services Act (DSA) - Contextual paragraph (106),0.732776284,"Details of the contextual paragraph (106) of the Digital Services Act (DSA): The rules on codes of conduct under this Regulation could serve as a basis for already established self-regulatory efforts at Union level, including the Product Safety Pledge, the Memorandum of understanding on the sale of counterfeit goods on the internet, the Code of conduct on countering illegal hate speech online, as well as the Code of Practice on Disinformation. In particular for the latter, following the Commission's guidance, the Code of Practice on Disinformation has been strengthened as announced in the European Democracy Action Plan.",recital,"The Digital Services Act (DSA) introduces new rules that may be used to strengthen existing self-regulatory efforts in the European Union. These include the Product Safety Pledge, the Memorandum of Understanding on the sale of counterfeit goods online, the Code of Conduct on countering illegal hate speech online, and the Code of Practice on Disinformation. The latter has been specifically reinforced following the Commission's guidance as part of the European Democracy Action Plan."
Digital Services Act (DSA) - Contextual paragraph (17),0.732773304,"Details of the contextual paragraph (17) of the Digital Services Act (DSA): The rules on liability of providers of intermediary services set out in this Regulation should only establish when the provider of intermediary services concerned cannot be held liable in relation to illegal content provided by the recipients of the service. Those rules should not be understood to provide a positive basis for establishing when a provider can be held liable, which is for the applicable rules of Union or national law to determine. Furthermore, the exemptions from liability established in this Regulation should apply in respect of any type of liability as regards any type of illegal content, irrespective of the precise subject matter or nature of those laws.",recital,"The Digital Services Act (DSA) sets rules about when online service providers can't be held responsible for illegal content posted by their users. However, it doesn't dictate when these providers can be held accountable - this is determined by other EU or national laws. The DSA's protections apply to all kinds of illegal content, regardless of the specific topic or nature of the laws being broken."
General Data Protection Regulation (GDPR) - Contextual Paragraph (103),0.732759178,"Details of the Contextual Paragraph (103) in the General Data Protection Regulation (GDPR): The Commission may decide with effect for the entire Union that a third country, a territory or specified sector within a third country, or an international organisation, offers an adequate level of data protection, thus providing legal certainty and uniformity throughout the Union as regards the third country or international organisation which is considered to provide such level of protection. In such cases, transfers of personal data to that third country or international organisation may take place without the need to obtain any further authorisation. The Commission may also decide, having given notice and a full statement setting out the reasons to the third country or international organisation, to revoke such a decision.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 103) that allows the European Commission to determine if a non-EU country, territory, or international organization has sufficient data protection laws. If deemed adequate, data can be transferred to that location without needing further approval. This ensures consistent data protection standards across the EU. The Commission also has the right to withdraw this status, but must provide a full explanation to the affected party."
Digital Services Act (DSA) - Contextual paragraph (153),0.732747793,"Details of the contextual paragraph (153) of the Digital Services Act (DSA): This Regulation respects the fundamental rights recognised by the Charter and the fundamental rights constituting general principles of Union law. Accordingly, this Regulation should be interpreted and applied in accordance with those fundamental rights, including the freedom of expression and of information, as well as the freedom and pluralism of the media. When exercising the powers set out in this Regulation, all public authorities involved should achieve, in situations where the relevant fundamental rights conflict, a fair balance between the rights concerned, in accordance with the principle of proportionality.",recital,"The Digital Services Act (DSA) is a new law that respects the fundamental rights recognized by the Charter and principles of Union law. It should be interpreted and applied in line with these rights, including freedom of expression, information, and media pluralism. When public authorities use the powers of this law, they must strike a fair balance between conflicting fundamental rights, adhering to the principle of proportionality."
General Data Protection Regulation (GDPR) - Contextual Paragraph (120),0.7326895,"Details of the Contextual Paragraph (120) in the General Data Protection Regulation (GDPR): Each supervisory authority should be provided with the financial and human resources, premises and infrastructure necessary for the effective performance of their tasks, including those related to mutual assistance and cooperation with other supervisory authorities throughout the Union. Each supervisory authority should have a separate, public annual budget, which may be part of the overall state or national budget.",recital,"The General Data Protection Regulation (GDPR) has a new section, Paragraph 120, which states that every supervisory authority must be given the funds, staff, facilities and infrastructure it needs to do its job effectively. This includes helping and working with other supervisory authorities across the Union. Each authority should have its own separate, public yearly budget, which can be included in the overall state or national budget."
General Data Protection Regulation (GDPR) - Contextual Paragraph (148),0.73267293,"Details of the Contextual Paragraph (148) in the General Data Protection Regulation (GDPR): In order to strengthen the enforcement of the rules of this Regulation, penalties including administrative fines should be imposed for any infringement of this Regulation, in addition to, or instead of appropriate measures imposed by the supervisory authority pursuant to this Regulation. In a case of a minor infringement or if the fine likely to be imposed would constitute a disproportionate burden to a natural person, a reprimand may be issued instead of a fine. Due regard should however be given to the nature, gravity and duration of the infringement, the intentional character of the infringement, actions taken to mitigate the damage suffered, degree of responsibility or any relevant previous infringements, the manner in which the infringement became known to the supervisory authority, compliance with measures ordered against the controller or processor, adherence to a code of conduct and any other aggravating or mitigating factor. The imposition of penalties including administrative fines should be subject to appropriate procedural safeguards in accordance with the general principles of Union law and the Charter, including effective judicial protection and due process.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 148, which strengthens the enforcement of privacy laws. If someone breaks these rules, they could face penalties, including fines. However, if the infringement is minor or the fine would be too much for an individual to handle, a warning may be given instead. The seriousness, intent, duration of the infringement, and any efforts to fix the damage will be considered when deciding the penalty. The person's past behavior and their response to the infringement will also be taken into account. All penalties will be given fairly, with the chance for legal protection and due process."
Digital Services Act (DSA) - Contextual paragraph (99),0.732610404,"Details of the contextual paragraph (99) of the Digital Services Act (DSA): Given the complexity of the functioning of the systems deployed and the systemic risks they present to society, providers of very large online platforms and of very large online search engines should establish a compliance function, which should be independent from the operational functions of those providers. The head of the compliance function should report directly to the management of those providers, including for concerns of non-compliance with this Regulation. The compliance officers that are part of the compliance function should have the necessary qualifications, knowledge, experience and ability to operationalise measures and monitor the compliance with this Regulation within the organisation of the providers of very large online platform or of very large online search engine. Providers of very large online platforms and of very large online search engines should ensure that the compliance function is involved, properly and in a timely manner, in all issues which relate to this Regulation including in the risk assessment and mitigation strategy and specific measures, as well as assessing compliance, where applicable, with commitments made by those providers under the codes of conduct and crisis protocols they subscribe to.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to establish a compliance function. This function should be separate from other operational functions and its head should report directly to the company's management, including any non-compliance issues with the DSA. The compliance officers should have the necessary skills and experience to implement measures and monitor compliance with the DSA. These companies should also ensure that the compliance function is involved in all issues related to the DSA, including risk assessment, mitigation strategies, specific measures, and checking compliance with any codes of conduct or crisis protocols the company subscribes to."
Digital Markets Act (DMA) - Contextual Paragraph (79),0.732593298,"Details of the Contextual Paragraph (79) in the Digital Markets Act (DMA): In the event that gatekeepers engage in a practice that is unfair or that limits the contestability of the core platform services that are already designated under this Regulation but without such practices being explicitly covered by the obligations laid down by this Regulation, the Commission should be able to update this Regulation through delegated acts. Such updates by way of delegated act should be subject to the same investigatory standard and therefore should be preceded by a market investigation. The Commission should also apply a predefined standard in identifying such types of practices. This legal standard should ensure that the type of obligations that gatekeepers could at any time face under this Regulation are sufficiently predictable.",rectial,"The Digital Markets Act (DMA) has a clause (Paragraph 79) that deals with unfair practices by gatekeepers of core platform services. If gatekeepers act unfairly or limit competition, even if their actions aren't specifically mentioned in the law, the Commission can update the law to address these practices. These updates will be based on thorough market investigations and will follow a predefined standard. This ensures that gatekeepers can anticipate what obligations they might face under this law."
Digital Markets Act (DMA) - Contextual Paragraph (94),0.732588828,"Details of the Contextual Paragraph (94) in the Digital Markets Act (DMA): Since the decisions taken by the Commission under this Regulation are subject to review by the Court of Justice in accordance with the TFEU, in accordance with Article 261 TFEU, the Court of Justice should have unlimited jurisdiction in respect of fines and penalty payments.",rectial,The Digital Markets Act (DMA) is a new law that includes a clause (Paragraph 94) stating that the decisions made by the Commission under this law can be reviewed by the Court of Justice. This is in line with the Treaty on the Functioning of the European Union (TFEU). This law also states that the Court of Justice should have complete authority over fines and penalty payments related to this law.
Digital Markets Act (DMA) - Contextual Paragraph (80),0.732583344,"Details of the Contextual Paragraph (80) in the Digital Markets Act (DMA): In order to ensure effective implementation and compliance with this Regulation, the Commission should have strong investigative and enforcement powers, to allow it to investigate, enforce and monitor the rules laid down in this Regulation, while at the same time ensuring the respect for the fundamental right to be heard and to have access to the file in the context of the enforcement proceedings. The Commission should dispose of these investigative powers also for the purpose of carrying out market investigations, including for the purpose of updating and reviewing this Regulation.",rectial,"The Digital Markets Act (DMA) grants the Commission strong powers to investigate and enforce the rules of the Act. This includes carrying out market investigations and reviewing the Act itself. However, the DMA also ensures that individuals' rights to be heard and access files in enforcement proceedings are respected. This balance aims to ensure effective implementation and compliance with the Act."
General Data Protection Regulation (GDPR) - Contextual Paragraph (169),0.732557356,"Details of the Contextual Paragraph (169) in the General Data Protection Regulation (GDPR): The Commission should adopt immediately applicable implementing acts where available evidence reveals that a third country, a territory or a specified sector within that third country, or an international organisation does not ensure an adequate level of protection, and imperative grounds of urgency so require.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 169) that allows the Commission to quickly implement actions if it's found that a country, territory, or specific sector within that country, or an international organization, isn't providing enough protection for personal data. This can be done when there's an urgent need based on strong evidence."
Digital Services Act (DSA) - Contextual paragraph (76),0.73254329,"Details of the contextual paragraph (76) of the Digital Services Act (DSA): Very large online platforms and very large online search engines may cause societal risks, different in scope and impact from those caused by smaller platforms. Providers of such very large online platforms and of very large online search engines should therefore bear the highest standard of due diligence obligations, proportionate to their societal impact. Once the number of active recipients of an online platform or of active recipients of an online search engine, calculated as an average over a period of six months, reaches a significant share of the Union population, the systemic risks the online platform or online search engine poses may have a disproportionate impact in the Union. Such significant reach should be considered to exist where such number exceeds an operational threshold set at 45 million, that is, a number equivalent to 10 % of the Union population. This operational threshold should be kept up to date and therefore the Commission should be empowered to supplement the provisions of this Regulation by adopting delegated acts, where necessary.",recital,"The Digital Services Act (DSA) states that large online platforms and search engines, due to their size, can pose societal risks. Therefore, these providers must meet high standards of due diligence, which should match their societal impact. If an online platform or search engine has a significant number of active users, averaging over six months, that equates to a substantial portion of the Union population, they may pose systemic risks. This significant reach is defined as exceeding 45 million users, or 10% of the Union population. The Commission can update these regulations as necessary."
General Data Protection Regulation (GDPR) - Contextual Paragraph (116),0.732488871,"Details of the Contextual Paragraph (116) in the General Data Protection Regulation (GDPR): When personal data moves across borders outside the Union it may put at increased risk the ability of natural persons to exercise data protection rights in particular to protect themselves from the unlawful use or disclosure of that information. At the same time, supervisory authorities may find that they are unable to pursue complaints or conduct investigations relating to the activities outside their borders. Their efforts to work together in the cross-border context may also be hampered by insufficient preventative or remedial powers, inconsistent legal regimes, and practical obstacles like resource constraints. Therefore, there is a need to promote closer cooperation among data protection supervisory authorities to help them exchange information and carry out investigations with their international counterparts. For the purposes of developing international cooperation mechanisms to facilitate and provide international mutual assistance for the enforcement of legislation for the protection of personal data, the Commission and the supervisory authorities should exchange information and cooperate in activities related to the exercise of their powers with competent authorities in third countries, based on reciprocity and in accordance with this Regulation.",recital,"The General Data Protection Regulation (GDPR) Paragraph 116 discusses the risks associated with personal data moving across international borders. It highlights potential difficulties in enforcing data protection rights and investigating complaints when data is transferred outside the European Union. The paragraph also points out the challenges faced by data protection authorities due to differences in legal systems and limited resources. To address these issues, the GDPR encourages stronger cooperation between data protection authorities and promotes the exchange of information and mutual assistance in enforcing data protection laws. This cooperation should be reciprocal and in line with the GDPR."
Digital Services Act (DSA) - Article 82 Requests for access restrictions and cooperation with national courts,0.732445121,"Article 82 Requests for access restrictions and cooperation with national courts in the Digital Services Act (DSA):  1.   Where all powers pursuant to this Section to bring about the cessation of an infringement of this Regulation have been exhausted, the infringement persists and causes serious harm which cannot be avoided through the exercise of other powers available under Union or national law, the Commission may request the Digital Services Coordinator of establishment of the provider of the very large online platform or of the very large online search engine concerned to act pursuant to Article 51(3).

Prior to making such request to the Digital Services Coordinator, the Commission shall invite interested parties to submit written observations within a period that shall not be less than 14 working days, describing the measures it intends to request and identifying the intended addressee or addressees thereof.

2.   Where the coherent application of this Regulation so requires, the Commission, acting on its own initiative, may submit written observations to the competent judicial authority referred to Article 51(3). With the permission of the judicial authority in question, it may also make oral observations.

For the purpose of the preparation of its observations only, the Commission may request that judicial authority to transmit or ensure the transmission to it of any documents necessary for the assessment of the case.

3.   When a national court rules on a matter which is already the subject matter of a decision adopted by the Commission under this Regulation, that national court shall not take any decision which runs counter to that Commission decision. National courts shall also avoid taking decisions which could conflict with a decision contemplated by the Commission in proceedings it has initiated under this Regulation. To that effect, a national court may assess whether it is necessary to stay its proceedings. This is without prejudice to Article 267 TFEU.",article,"The Digital Services Act (DSA) allows the Commission to request the Digital Services Coordinator to take action when an online platform or search engine is causing serious harm and other measures have failed to stop it. Before making this request, the Commission will invite feedback from interested parties for at least 14 working days. The Commission can also provide written or oral observations to the judicial authority if needed for the application of the DSA. If a national court is ruling on a case that the Commission has already made a decision on, the court should not make a decision that contradicts the Commission's decision. The court can also pause its proceedings if a decision from the Commission is pending."
General Data Protection Regulation (GDPR) - Contextual Paragraph (94),0.73238045,"Details of the Contextual Paragraph (94) in the General Data Protection Regulation (GDPR): Where a data protection impact assessment indicates that the processing would, in the absence of safeguards, security measures and mechanisms to mitigate the risk, result in a high risk to the rights and freedoms of natural persons and the controller is of the opinion that the risk cannot be mitigated by reasonable means in terms of available technologies and costs of implementation, the supervisory authority should be consulted prior to the start of processing activities. Such high risk is likely to result from certain types of processing and the extent and frequency of processing, which may result also in a realisation of damage or interference with the rights and freedoms of the natural person. The supervisory authority should respond to the request for consultation within a specified period. However, the absence of a reaction of the supervisory authority within that period should be without prejudice to any intervention of the supervisory authority in accordance with its tasks and powers laid down in this Regulation, including the power to prohibit processing operations. As part of that consultation process, the outcome of a data protection impact assessment carried out with regard to the processing at issue may be submitted to the supervisory authority, in particular the measures envisaged to mitigate the risk to the rights and freedoms of natural persons.",recital,"The General Data Protection Regulation (GDPR) Paragraph 94 states that if a data protection assessment shows that processing data could pose a high risk to individuals' rights and freedoms, and this risk cannot be reasonably reduced, then the supervisory authority must be consulted before data processing begins. The risk level may depend on the type, extent, and frequency of data processing. The supervisory authority should respond within a set timeframe, but even if they don't, they can still intervene later, including stopping data processing. As part of this consultation, the results of the data protection assessment can be submitted to the supervisory authority, especially any planned measures to reduce risk."
General Data Protection Regulation (GDPR) - Contextual Paragraph (137),0.732371151,"Details of the Contextual Paragraph (137) in the General Data Protection Regulation (GDPR): There may be an urgent need to act in order to protect the rights and freedoms of data subjects, in particular when the danger exists that the enforcement of a right of a data subject could be considerably impeded. A supervisory authority should therefore be able to adopt duly justified provisional measures on its territory with a specified period of validity which should not exceed three months.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 137) that allows for quick action to protect individuals' data rights. If there's an immediate risk that enforcing a person's data rights could be significantly obstructed, the supervisory authority can take temporary measures. These measures must be justified and can only last for up to three months."
General Data Protection Regulation (GDPR) - Contextual Paragraph (133),0.73233664,"Details of the Contextual Paragraph (133) in the General Data Protection Regulation (GDPR): The supervisory authorities should assist each other in performing their tasks and provide mutual assistance, so as to ensure the consistent application and enforcement of this Regulation in the internal market. A supervisory authority requesting mutual assistance may adopt a provisional measure if it receives no response to a request for mutual assistance within one month of the receipt of that request by the other supervisory authority.",recital,"The General Data Protection Regulation (GDPR) Paragraph 133 states that supervisory authorities must help each other to ensure the law is applied and enforced consistently. If one authority asks for help from another and doesn't get a response within a month, it can take temporary action."
General Data Protection Regulation (GDPR) - Contextual Paragraph (149),0.732269228,"Details of the Contextual Paragraph (149) in the General Data Protection Regulation (GDPR): Member States should be able to lay down the rules on criminal penalties for infringements of this Regulation, including for infringements of national rules adopted pursuant to and within the limits of this Regulation. Those criminal penalties may also allow for the deprivation of the profits obtained through infringements of this Regulation. However, the imposition of criminal penalties for infringements of such national rules and of administrative penalties should not lead to a breach of the principle of ne bis in idem, as interpreted by the Court of Justice.",recital,"The General Data Protection Regulation (GDPR) allows individual countries to establish their own rules for criminal penalties if someone breaks this law. This includes penalties for breaking any national rules that were created based on the GDPR. The penalties can also include taking away any profits made from breaking these rules. However, the law states that a person cannot be punished twice for the same crime, a principle known as ne bis in idem, as interpreted by the Court of Justice."
Digital Services Act (DSA) - Contextual paragraph (80),0.732150912,"Details of the contextual paragraph (80) of the Digital Services Act (DSA): Four categories of systemic risks should be assessed in-depth by the providers of very large online platforms and of very large online search engines. A first category concerns the risks associated with the dissemination of illegal content, such as the dissemination of child sexual abuse material or illegal hate speech or other types of misuse of their services for criminal offences, and the conduct of illegal activities, such as the sale of products or services prohibited by Union or national law, including dangerous or counterfeit products, or illegally-traded animals. For example, such dissemination or activities may constitute a significant systemic risk where access to illegal content may spread rapidly and widely through accounts with a particularly wide reach or other means of amplification. Providers of very large online platforms and of very large online search engines should assess the risk of dissemination of illegal content irrespective of whether or not the information is also incompatible with their terms and conditions. This assessment is without prejudice to the personal responsibility of the recipient of the service of very large online platforms or of the owners of websites indexed by very large online search engines for possible illegality of their activity under the applicable law.",recital,"The Digital Services Act (DSA) requires providers of large online platforms and search engines to thoroughly assess four categories of systemic risks. The first category pertains to the spread of illegal content, such as child sexual abuse material, hate speech, and other criminal activities, including the sale of banned or counterfeit goods, or illegally-traded animals. These providers must assess the risk of such illegal content spreading, regardless of whether it violates their terms and conditions. This does not absolve users of these platforms or owners of indexed websites from their legal responsibilities for any illegal activities."
Digital Markets Act (DMA) - Contextual Paragraph (62),0.73209095,"Details of the Contextual Paragraph (62) in the Digital Markets Act (DMA): For software application stores, online search engines and online social networking services listed in the designation decision, gatekeepers should publish and apply general conditions of access that should be fair, reasonable and nondiscriminatory. Those general conditions should provide for a Union based alternative dispute settlement mechanism that is easily accessible, impartial, independent and free of charge for the business user, without prejudice to the business user""s own cost and proportionate measures aimed at preventing the abuse of the dispute settlement mechanism by business users. The dispute settlement mechanism should be without prejudice to the right of business users to seek redress before judicial authorities in accordance with Union and national law. In particular, gatekeepers which provide access to software application stores are an important gateway for business users that seek to reach end users. In view of the imbalance in bargaining power between those gatekeepers and business users of their software application stores, those gatekeepers should not be allowed to impose general conditions, including pricing conditions, that would be unfair or lead to unjustified differentiation. Pricing or other general access conditions should be considered unfair if they lead to an imbalance of rights and obligations imposed on business users or confer an advantage on the gatekeeper which is disproportionate to the service provided by the gatekeeper to business users or lead to a disadvantage for business users in providing the same or similar services as the gatekeeper. The following benchmarks can serve as a yardstick to determine the fairness of general access conditions: prices charged or conditions imposed for the same or similar services by other providers of software application stores; prices charged or conditions imposed by the provider of the software application store for different related or similar services or to different types of end users; prices charged or conditions imposed by the provider of the software application store for the same service in different geographic regions; prices charged or conditions imposed by the provider of the software application store for the same service the gatekeeper provides to itself. This obligation should not establish an access right and it should be without prejudice to the ability of providers of software application stores, online search engines and online social networking services to take the required responsibility in the fight against illegal and unwanted content as set out in a Regulation on a single market for digital services.",rectial,"The Digital Markets Act (DMA) requires digital ""gatekeepers"" like app stores, search engines, and social networks to provide fair, reasonable, and non-discriminatory conditions for businesses to access their services. They must also offer a free, impartial dispute resolution system based in the EU. Businesses can still take legal action if needed. Gatekeepers cannot impose unfair conditions or prices that favor themselves or disadvantage businesses offering similar services. The fairness of these conditions can be judged by comparing prices and terms with other similar services, different user types, different regions, or the gatekeeper's own services. However, this doesn't give businesses a right to access, and gatekeepers can still take action against illegal or unwanted content."
General Data Protection Regulation (GDPR) - Contextual Paragraph (136),0.732069492,"Details of the Contextual Paragraph (136) in the General Data Protection Regulation (GDPR): In applying the consistency mechanism, the Board should, within a determined period of time, issue an opinion, if a majority of its members so decides or if so requested by any supervisory authority concerned or the Commission. The Board should also be empowered to adopt legally binding decisions where there are disputes between supervisory authorities. For that purpose, it should issue, in principle by a two-thirds majority of its members, legally binding decisions in clearly specified cases where there are conflicting views among supervisory authorities, in particular in the cooperation mechanism between the lead supervisory authority and supervisory authorities concerned on the merits of the case, in particular whether there is an infringement of this Regulation.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 136) that allows the Board to issue an opinion within a certain timeframe if a majority of its members agree or if requested by a supervisory authority or the Commission. The Board can also make legally binding decisions in cases of disputes between supervisory authorities. These decisions, which require a two-thirds majority vote, are used in cases where there are differing opinions among authorities, especially in matters of cooperation between the lead authority and other concerned authorities, and in determining if there has been a violation of the GDPR."
Digital Services Act (DSA) - Contextual paragraph (95),0.732060254,"Details of the contextual paragraph (95) of the Digital Services Act (DSA): Advertising systems used by very large online platforms and very large online search engines pose particular risks and require further public and regulatory supervision on account of their scale and ability to target and reach recipients of the service based on their behaviour within and outside that platform's or search engine's online interface. Very large online platforms or very large online search engines should ensure public access to repositories of advertisements presented on their online interfaces to facilitate supervision and research into emerging risks brought about by the distribution of advertising online, for example in relation to illegal advertisements or manipulative techniques and disinformation with a real and foreseeable negative impact on public health, public security, civil discourse, political participation and equality. Repositories should include the content of advertisements, including the name of the product, service or brand and the subject matter of the advertisement, and related data on the advertiser, and, if different, the natural or legal person who paid for the advertisement, and the delivery of the advertisement, in particular where targeted advertising is concerned. This information should include both information about targeting criteria and delivery criteria, in particular when advertisements are delivered to persons in vulnerable situations, such as minors.",recital,"The Digital Services Act (DSA) addresses the risks posed by advertising systems used by large online platforms and search engines. Due to their size and ability to target users based on their behavior, these platforms need more public and regulatory oversight. The DSA requires these platforms to provide public access to their advertisement repositories. This is to monitor and research potential risks, such as illegal ads or manipulative techniques that could harm public health, security, or equality. These repositories should include ad content, advertiser details, and information about who paid for and received the ad. This is especially important for targeted ads, particularly those aimed at vulnerable groups like minors."
General Data Protection Regulation (GDPR) - Contextual Paragraph (56),0.732056379,"Details of the Contextual Paragraph (56) in the General Data Protection Regulation (GDPR): Where in the course of electoral activities, the operation of the democratic system in a Member State requires that political parties compile personal data on people's political opinions, the processing of such data may be permitted for reasons of public interest, provided that appropriate safeguards are established.",recital,"The General Data Protection Regulation (GDPR) includes a clause (Paragraph 56) that allows political parties to collect personal data on people's political opinions during election activities, if it's necessary for the democratic process in a member state. However, this can only be done if it is in the public interest and there are proper protections in place to safeguard this data."
General Data Protection Regulation (GDPR) - Contextual Paragraph (121),0.732046604,"Details of the Contextual Paragraph (121) in the General Data Protection Regulation (GDPR): The general conditions for the member or members of the supervisory authority should be laid down by law in each Member State and should in particular provide that those members are to be appointed, by means of a transparent procedure, either by the parliament, government or the head of State of the Member State on the basis of a proposal from the government, a member of the government, the parliament or a chamber of the parliament, or by an independent body entrusted under Member State law. In order to ensure the independence of the supervisory authority, the member or members should act with integrity, refrain from any action that is incompatible with their duties and should not, during their term of office, engage in any incompatible occupation, whether gainful or not. The supervisory authority should have its own staff, chosen by the supervisory authority or an independent body established by Member State law, which should be subject to the exclusive direction of the member or members of the supervisory authority.",recital,"The General Data Protection Regulation (GDPR) Paragraph 121 states that each Member State must legally determine the conditions for members of the supervisory authority. These members should be appointed through a transparent process by the parliament, government, or head of state, based on a proposal from these entities or an independent body. To maintain the authority's independence, members must act with integrity, avoid actions that conflict with their duties, and not engage in any incompatible job during their term. The authority should have its own staff, selected by the authority or an independent body, and these staff should only report to the authority's members."
Digital Markets Act (DMA) - Contextual Paragraph (13),0.732028484,"Details of the Contextual Paragraph (13) in the Digital Markets Act (DMA): Weak contestability and unfair practices in the digital sector are more frequent and pronounced for certain digital services than for others. This is the case in particular for widespread and commonly used digital services that mostly directly intermediate between business users and end users and where features such as extreme scale economies, very strong network effects, an ability to connect many business users with many end users through the multisidedness of these services, lock-in effects, a lack of multi-homing or vertical integration are the most prevalent. Often, there is only one or very few large undertakings providing those digital services. Those undertakings have emerged most frequently as gatekeepers for business users and end users, with far-reaching impacts. In particular, they have gained the ability to easily set commercial conditions and terms in a unilateral and detrimental manner for their business users and end users. Accordingly, it is necessary to focus only on those digital services that are most broadly used by business users and end users and where concerns about weak contestability and unfair practices by gatekeepers are more apparent and pressing from an internal market perspective.",rectial,"The Digital Markets Act (DMA) addresses issues of unfair practices in the digital sector, particularly in widely used digital services that connect businesses and end users. These services often have a monopoly or near-monopoly, leading to them acting as gatekeepers and setting commercial terms that can be detrimental to their users. The DMA aims to focus on these services, where concerns about unfair practices are most apparent, to ensure a fairer digital market."
Digital Services Act (DSA) - Contextual paragraph (91),0.732020855,"Details of the contextual paragraph (91) of the Digital Services Act (DSA): In times of crisis, there might be a need for certain specific measures to be taken urgently by providers of very large online platforms, in addition to measures they would be taking in view of their other obligations under this Regulation. In that regard, a crisis should be considered to occur when extraordinary circumstances occur that can lead to a serious threat to public security or public health in the Union or significant parts thereof. Such crises could result from armed conflicts or acts of terrorism, including emerging conflicts or acts of terrorism, natural disasters such as earthquakes and hurricanes, as well as from pandemics and other serious cross-border threats to public health. The Commission should be able to require, upon recommendation by the European Board for Digital Services ('the Board'), providers of very large online platforms and providers of very large search engines to initiate a crisis response as a matter of urgency. Measures that those providers may identify and consider applying may include, for example, adapting content moderation processes and increasing the resources dedicated to content moderation, adapting terms and conditions, relevant algorithmic systems and advertising systems, further intensifying cooperation with trusted flaggers, taking awareness-raising measures and promoting trusted information and adapting the design of their online interfaces. The necessary requirements should be provided for to ensure that such measures are taken within a very short time frame and that the crisis response mechanism is only used where, and to the extent that, this is strictly necessary and any measures taken under this mechanism are effective and proportionate, taking due account of the rights and legitimate interests of all parties concerned. The use of the mechanism should be without prejudice to the other provisions of this Regulation, such as those on risk assessments and mitigation measures and the enforcement thereof and those on crisis protocols.",recital,"The Digital Services Act (DSA) allows for urgent action by large online platforms during crises that pose a serious threat to public safety or health. Crises can include terrorism, natural disasters, or pandemics. The European Board for Digital Services can instruct these platforms to initiate a crisis response, which may involve changes to content moderation, terms and conditions, algorithms, advertising systems, and interface design. These measures must be effective, proportionate, and respect the rights of all parties. They should be implemented quickly, but only when absolutely necessary. This crisis response mechanism does not replace other regulations, such as risk assessments and mitigation measures."
Digital Markets Act (DMA) - Contextual Paragraph (63),0.731928051,"Details of the Contextual Paragraph (63) in the Digital Markets Act (DMA): Gatekeepers can hamper the ability of business users and end users to unsubscribe from a core platform service that they have previously subscribed to. Therefore, rules should be established to avoid a situation in which gatekeepers undermine the rights of business users and end users to freely choose which core platform service they use. To safeguard free choice of business users and end users, a gatekeeper should not be allowed to make it unnecessarily difficult or complicated for business users or end users to unsubscribe from a core platform service. Closing an account or un-subscribing should not be made be more complicated than opening an account or subscribing to the same service. Gatekeepers should not demand additional fees when terminating contracts with their end users or business users. Gatekeepers should ensure that the conditions for terminating contracts are always proportionate and can be exercised without undue difficulty by end users, such as, for example, in relation to the reasons for termination, the notice period, or the form of such termination. This is without prejudice to national legislation applicable in accordance with the Union law laying down rights and obligations concerning conditions of termination of provision of core platform services by end users.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 63) to protect users and businesses from unfair practices by major online platforms, known as 'gatekeepers'. These platforms can't make it overly difficult or charge extra fees for users or businesses to cancel a service. The process of closing an account or unsubscribing should be as simple as signing up. Any conditions related to ending a contract, like reasons for termination or notice periods, should be fair and manageable. This rule doesn't interfere with any national laws about conditions for cancelling online services."
Digital Services Act (DSA) - Contextual paragraph (20),0.731905103,"Details of the contextual paragraph (20) of the Digital Services Act (DSA): Where a provider of intermediary services deliberately collaborates with a recipient of the services in order to undertake illegal activities, the services should not be deemed to have been provided neutrally and the provider should therefore not be able to benefit from the exemptions from liability provided for in this Regulation. This should be the case, for instance, where the provider offers its service with the main purpose of facilitating illegal activities, for example by making explicit that its purpose is to facilitate illegal activities or that its services are suited for that purpose. The fact alone that a service offers encrypted transmissions or any other system that makes the identification of the user impossible should not in itself qualify as facilitating illegal activities.",recital,"The Digital Services Act (DSA) states that if an online service provider knowingly works with a user to carry out illegal activities, the provider can't claim it's acting neutrally and won't be protected from legal consequences. This applies when the provider's main purpose is to assist in illegal activities. However, simply offering encrypted services or systems that hide user identity doesn't mean the provider is facilitating illegal activities."
General Data Protection Regulation (GDPR) - Contextual Paragraph (125),0.731858194,"Details of the Contextual Paragraph (125) in the General Data Protection Regulation (GDPR): The lead authority should be competent to adopt binding decisions regarding measures applying the powers conferred on it in accordance with this Regulation. In its capacity as lead authority, the supervisory authority should closely involve and coordinate the supervisory authorities concerned in the decision-making process. Where the decision is to reject the complaint by the data subject in whole or in part, that decision should be adopted by the supervisory authority with which the complaint has been lodged.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 125, which says that the main authority can make binding decisions about how to use its powers under this law. This main authority should work closely with and coordinate other supervisory authorities when making decisions. If a complaint from a data subject (the person whose data is involved) is to be rejected fully or partially, the decision should be made by the authority that received the complaint."
General Data Protection Regulation (GDPR) - Contextual Paragraph (102),0.731844246,"Details of the Contextual Paragraph (102) in the General Data Protection Regulation (GDPR): This Regulation is without prejudice to international agreements concluded between the Union and third countries regulating the transfer of personal data including appropriate safeguards for the data subjects. Member States may conclude international agreements which involve the transfer of personal data to third countries or international organisations, as far as such agreements do not affect this Regulation or any other provisions of Union law and include an appropriate level of protection for the fundamental rights of the data subjects.",recital,"The General Data Protection Regulation (GDPR) Paragraph 102 allows for international agreements involving the transfer of personal data, as long as they don't interfere with the GDPR or other Union laws. These agreements must provide adequate protection for the individuals' fundamental rights. This means that member states can make agreements to transfer personal data to other countries or organizations, but these agreements must not compromise the GDPR or other laws, and must ensure the protection of individuals' rights."
Digital Services Act (DSA) - Contextual paragraph (151),0.731835723,"Details of the contextual paragraph (151) of the Digital Services Act (DSA): In order to ensure uniform conditions for the implementation of this Regulation, implementing powers should be conferred on the Commission to lay down templates concerning the form, content and other details of reports on content moderation, to establish the amount of the annual supervisory fee charged on providers of very large online platforms and of very large online search engines, to lay down the practical arrangements for the proceedings, the hearings and the negotiated disclosure of information carried out in the context of supervision, investigation, enforcement and monitoring in respect of providers of very large online platforms and of very large online search engines, as well as to lay down the practical and operational arrangements for the functioning of the information sharing system and its interoperability with other relevant systems. Those powers should be exercised in accordance with Regulation (EU) No 182/2011 of the European Parliament and of the Council (34).",recital,"The Digital Services Act (DSA) is a new law that gives the European Commission the power to set rules for online platforms and search engines, particularly large ones. These rules will cover how these platforms report on content moderation, the annual supervisory fee they must pay, and how they share information. The law also outlines how investigations and enforcement will be conducted. All these powers will be exercised following the guidelines of Regulation (EU) No 182/2011. The goal is to create a uniform set of conditions for these platforms to operate under."
Digital Services Act (DSA) - Contextual paragraph (113),0.731759369,"Details of the contextual paragraph (113) of the Digital Services Act (DSA): Member States can designate an existing national authority with the function of the Digital Services Coordinator, or with specific tasks to supervise the application and enforce this Regulation, provided that any such appointed authority complies with the requirements laid down in this Regulation, such as in relation to its independence. Moreover, Member States are in principle not precluded from merging functions within an existing authority, in accordance with Union law. The measures to that effect may include, inter alia, the preclusion to dismiss the president or a board member of a collegiate body of an existing authority before the expiry of their terms of office, on the sole ground that an institutional reform has taken place involving the merger of different functions within one authority, in the absence of any rules guaranteeing that such dismissals do not jeopardise the independence and impartiality of such members.",recital,"The Digital Services Act (DSA) allows countries to assign an existing national authority to oversee and enforce the Act, as long as it meets the requirements of the DSA, particularly regarding its independence. Countries can also combine functions within an existing authority, following Union law. Measures can be put in place to prevent the dismissal of a president or board member of an existing authority before their term ends, even if institutional changes occur. This is to ensure that the independence and impartiality of these members are not compromised."
General Data Protection Regulation (GDPR) - Contextual Paragraph (1),0.7317307,"Details of the Contextual Paragraph (1) in the General Data Protection Regulation (GDPR): The protection of natural persons in relation to the processing of personal data is a fundamental right. 
Article 8(1) of the Charter of Fundamental Rights of the European Union (the ""Charter"") and Article 16(1) of the 
Treaty on the Functioning of the European Union (TFEU) provide that everyone has the right to the protection of 
personal data concerning him or her.",recital,"The General Data Protection Regulation (GDPR) is a new law that emphasizes the importance of protecting personal data as a fundamental right. This law, in accordance with Article 8(1) of the Charter of Fundamental Rights of the European Union and Article 16(1) of the Treaty on the Functioning of the European Union, ensures everyone's right to have their personal data protected."
General Data Protection Regulation (GDPR) - Contextual Paragraph (115),0.731713116,"Details of the Contextual Paragraph (115) in the General Data Protection Regulation (GDPR): Some third countries adopt laws, regulations and other legal acts which purport to directly regulate the processing activities of natural and legal persons under the jurisdiction of the Member States. This may include judgments of courts or tribunals or decisions of administrative authorities in third countries requiring a controller or processor to transfer or disclose personal data, and which are not based on an international agreement, such as a mutual legal assistance treaty, in force between the requesting third country and the Union or a Member State. The extraterritorial application of those laws, regulations and other legal acts may be in breach of international law and may impede the attainment of the protection of natural persons ensured in the Union by this Regulation. Transfers should only be allowed where the conditions of this Regulation for a transfer to third countries are met. This may be the case, inter alia, where disclosure is necessary for an important ground of public interest recognised in Union or Member State law to which the controller is subject.",recital,"The General Data Protection Regulation (GDPR) Paragraph 115 addresses the issue of third countries (countries outside the EU) creating laws that directly affect the data processing activities of individuals and businesses within the EU. This could involve foreign courts or authorities requiring the transfer or disclosure of personal data. If these demands aren't based on an international agreement, like a treaty, they could violate international law and undermine the data protection provided by the GDPR. As such, data transfers should only be permitted if they meet the GDPR's conditions for transfers to third countries. This might be allowed if the disclosure is necessary for a significant public interest as recognized by EU or Member State law."
General Data Protection Regulation (GDPR) - Contextual Paragraph (105),0.731688559,"Details of the Contextual Paragraph (105) in the General Data Protection Regulation (GDPR): Apart from the international commitments the third country or international organisation has entered into, the Commission should take account of obligations arising from the third country's or international organisation's participation in multilateral or regional systems in particular in relation to the protection of personal data, as well as the implementation of such obligations. In particular, the third country's accession to the Council of Europe Convention of 28 January 1981 for the Protection of Individuals with regard to the Automatic Processing of Personal Data and its Additional Protocol should be taken into account. The Commission should consult the Board when assessing the level of protection in third countries or international organisations.",recital,"The General Data Protection Regulation (GDPR) Paragraph 105 states that when determining if a non-EU country or organization is adequately protecting personal data, the European Commission should consider their international commitments. This includes their participation in systems designed to protect personal data and their adherence to the Council of Europe Convention of 28 January 1981, which deals with the automatic processing of personal data. The Commission should also consult the Board when assessing the level of data protection in these entities."
General Data Protection Regulation (GDPR) - Contextual Paragraph (75),0.731660903,"Details of the Contextual Paragraph (75) in the General Data Protection Regulation (GDPR): The risk to the rights and freedoms of natural persons, of varying likelihood and severity, may result from personal data processing which could lead to physical, material or non-material damage, in particular: where the processing may give rise to discrimination, identity theft or fraud, financial loss, damage to the reputation, loss of confidentiality of personal data protected by professional secrecy, unauthorised reversal of pseudonymisation, or any other significant economic or social disadvantage; where data subjects might be deprived of their rights and freedoms or prevented from exercising control over their personal data; where personal data are processed which reveal racial or ethnic origin, political opinions, religion or philosophical beliefs, trade union membership, and the processing of genetic data, data concerning health or data concerning sex life or criminal convictions and offences or related security measures; where personal aspects are evaluated, in particular analysing or predicting aspects concerning performance at work, economic situation, health, personal preferences or interests, reliability or behaviour, location or movements, in order to create or use personal profiles; where personal data of vulnerable natural persons, in particular of children, are processed; or where processing involves a large amount of personal data and affects a large number of data subjects.",recital,"The General Data Protection Regulation (GDPR) Paragraph 75 aims to protect individuals from risks and damages that could result from the misuse of their personal data. These risks include discrimination, identity theft, financial loss, damage to reputation, loss of privacy, and other significant disadvantages. The law also protects individuals from being deprived of their rights or control over their personal data. It pays particular attention to sensitive data such as racial or ethnic origin, political opinions, religious beliefs, health data, and criminal records. The law also covers the use of personal data to create or use personal profiles and the processing of data of vulnerable individuals, especially children. Lastly, it addresses situations where a large amount of personal data is processed, affecting many individuals."
General Data Protection Regulation (GDPR) - Contextual Paragraph (123),0.731629789,"Details of the Contextual Paragraph (123) in the General Data Protection Regulation (GDPR): The supervisory authorities should monitor the application of the provisions pursuant to this Regulation and contribute to its consistent application throughout the Union, in order to protect natural persons in relation to the processing of their personal data and to facilitate the free flow of personal data within the internal market. For that purpose, the supervisory authorities should cooperate with each other and with the Commission, without the need for any agreement between Member States on the provision of mutual assistance or on such cooperation.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 123, that ensures the protection of people's personal data and promotes the free flow of such data within the market. The supervisory authorities are tasked with monitoring the application of this law across the Union to ensure its consistent application. These authorities are also expected to collaborate with each other and the Commission, without needing any agreement between Member States. This is all aimed at protecting personal data and facilitating its movement within the market."
Digital Services Act (DSA) - Contextual paragraph (114),0.731622756,"Details of the contextual paragraph (114) of the Digital Services Act (DSA): Member States should provide the Digital Services Coordinator, and any other competent authority designated under this Regulation, with sufficient powers and means to ensure effective investigation and enforcement, in accordance with the tasks conferred on them. This includes the power of competent authorities to adopt interim measures in accordance with national law in case of risk of serious harm. Such interim measures, which may include orders to terminate or remedy a given alleged infringement, should not go beyond what is necessary to ensure that serious harm is prevented pending the final decision. The Digital Services Coordinators should in particular be able to search for and obtain information which is located in its territory, including in the context of joint investigations, with due regard to the fact that oversight and enforcement measures concerning a provider under the jurisdiction of another Member State or the Commission should be adopted by the Digital Services Coordinator of that other Member State, where relevant in accordance with the procedures relating to cross-border cooperation, or, where applicable, by the Commission.",recital,"The Digital Services Act (DSA) requires member countries to equip their Digital Services Coordinators and other relevant authorities with the necessary powers and resources to effectively investigate and enforce the law. These authorities can take temporary action, such as ordering the termination or remedy of a potential violation, to prevent serious harm while a final decision is being made. However, these actions should only be as drastic as necessary. Digital Services Coordinators can search for and obtain information within their territory, even during joint investigations. However, when dealing with a provider under another member country or the Commission's jurisdiction, the coordinator of that jurisdiction should take the lead, following procedures for cross-border cooperation or involving the Commission when needed."
General Data Protection Regulation (GDPR) - Contextual Paragraph (4),0.73161763,"Details of the Contextual Paragraph (4) in the General Data Protection Regulation (GDPR): The processing of personal data should be designed to serve mankind. The right to the protection of personal data is not an absolute right; it must be considered in relation to its function in society and be balanced against other fundamental rights, in accordance with the principle of proportionality. This Regulation respects all fundamental rights and observes the freedoms and principles recognised in the Charter as enshrined in the Treaties, in particular the respect for private and family life, home and communications, the protection of personal data, freedom of thought, conscience and religion, freedom of expression and information, freedom to conduct a business, the right to an effective remedy and to a fair trial, and cultural, religious and linguistic diversity.",recital,"The General Data Protection Regulation (GDPR) states that the use of personal data should benefit people. While the right to data protection is important, it's not absolute and must be balanced with other basic rights. This law respects all fundamental rights, including privacy, freedom of thought, religion, and expression, the right to conduct a business, and the right to a fair trial. It also respects cultural, religious, and linguistic diversity. The aim is to protect personal data while also considering its role in society."
Digital Markets Act (DMA) - Article 51 Amendment to Directive (EU) 2019/1937,0.731610298,"Details of Article 51 Amendment to Directive (EU) 2019/1937 in the Digital Markets Act (DMA): In Point J of Part I of the Annex to Directive (EU) 2019/1937, the following point is added: ""(iv) Regulation (EU) 2022/1925 of the European Parliament and of the Council of 14 September 2022 on contestable and fair markets in the digital sector and amending Directives (EU) 2019/1937 and (EU) 2020/1828 (Digital Markets Act) (OJ L 265, 21.9.2022, p. 1).""",article,"The Digital Markets Act (DMA) has been updated with an amendment, specifically Article 51 Amendment to Directive (EU) 2019/1937. This change introduces a new regulation, Regulation (EU) 2022/1925, which was established by the European Parliament and Council on September 14, 2022. This regulation aims to ensure fair and competitive digital markets. It also modifies previous directives, specifically Directives (EU) 2019/1937 and (EU) 2020/1828."
Digital Services Act (DSA) - Article 52 Penalties,0.731607437,"Article 53 Right to lodge a complaint in the Digital Services Act (DSA):  Recipients of the service and any body, organisation or association mandated to exercise the rights conferred by this Regulation on their behalf shall have the right to lodge a complaint against providers of intermediary services alleging an infringement of this Regulation with the Digital Services Coordinator of the Member State where the recipient of the service is located or established. The Digital Services Coordinator shall assess the complaint and, where appropriate, transmit it to the Digital Services Coordinator of establishment, accompanied, where considered appropriate, by an opinion. Where the complaint falls under the responsibility of another competent authority in its Member State, the Digital Services Coordinator receiving the complaint shall transmit it to that authority. During these proceedings, both parties shall have the right to be heard and receive appropriate information about the status of the complaint, in accordance with national law.",article,"Under the new Digital Services Act (DSA), anyone using a digital service, or an organization acting on their behalf, can file a complaint if they believe the service provider has broken the rules of the DSA. The complaint is filed with the Digital Services Coordinator in the user's home country. This Coordinator will review the complaint and, if necessary, pass it on to the appropriate authority. Both the person who filed the complaint and the service provider have the right to be heard and kept informed about the complaint's status, as per local laws."
General Data Protection Regulation (GDPR) - Contextual Paragraph (20),0.731562793,"Details of the Contextual Paragraph (20) in the General Data Protection Regulation (GDPR): While this Regulation applies, inter alia, to the activities of courts and other judicial authorities, Union or Member State law could specify the processing operations and processing procedures in relation to the processing of personal data by courts and other judicial authorities. The competence of the supervisory authorities should not cover the processing of personal data when courts are acting in their judicial capacity, in order to safeguard the independence of the judiciary in the performance of its judicial tasks, including decisionmaking. It should be possible to entrust supervision of such data processing operations to specific bodies within the judicial system of the Member State, which should, in particular ensure compliance with the rules of this Regulation, enhance awareness among members of the judiciary of their obligations under this Regulation and handle complaints in relation to such data processing operations.",recital,"The General Data Protection Regulation (GDPR) applies to courts and other judicial authorities. However, individual EU member states can set their own rules for how these bodies process personal data. When courts are acting in their judicial capacity, data processing is not overseen by the usual supervisory authorities. This is to protect the independence of the judiciary. Instead, specific bodies within each member state's judicial system will supervise data processing, ensuring compliance with GDPR, raising awareness of GDPR obligations among judiciary members, and handling related complaints."
General Data Protection Regulation (GDPR) - Contextual Paragraph (129),0.73154819,"Details of the Contextual Paragraph (129) in the General Data Protection Regulation (GDPR): In order to ensure consistent monitoring and enforcement of this Regulation throughout the Union, the supervisory authorities should have in each Member State the same tasks and effective powers, including powers of investigation, corrective powers and sanctions, and authorisation and advisory powers, in particular in cases of complaints from natural persons, and without prejudice to the powers of prosecutorial authorities under Member State law, to bring infringements of this Regulation to the attention of the judicial authorities and engage in legal proceedings. Such powers should also include the power to impose a temporary or definitive limitation, including a ban, on processing. Member States may specify other tasks related to the protection of personal data under this Regulation. The powers of supervisory authorities should be exercised in accordance with appropriate procedural safeguards set out in Union and Member State law, impartially, fairly and within a reasonable time. In particular each measure should be appropriate, necessary and proportionate in view of ensuring compliance with this Regulation, taking into account the circumstances of each individual case, respect the right of every person to be heard before any individual measure which would affect him or her adversely is taken and avoid superfluous costs and excessive inconveniences for the persons concerned. Investigatory powers as regards access to premises should be exercised in accordance with specific requirements in Member State procedural law, such as the requirement to obtain a prior judicial authorisation. Each legally binding measure of the supervisory authority should be in writing, be clear and unambiguous, indicate the supervisory authority which has issued the measure, the date of issue of the measure, bear the signature of the head, or a member of the supervisory authority authorised by him or her, give the reasons for the measure, and refer to the right of an effective remedy. This should not preclude additional requirements pursuant to Member State procedural law. The adoption of a legally binding decision implies that it may give rise to judicial review in the Member State of the supervisory authority that adopted the decision.",recital,"The General Data Protection Regulation (GDPR) Paragraph 129 states that each EU member state must have the same data protection rules and powers. This includes the ability to investigate, correct, and penalize violations, as well as provide advice and approve data processing activities. These powers should be used fairly, reasonably, and proportionately, considering each case's circumstances. Before taking any action that could negatively impact an individual, they must be given a chance to voice their concerns. Any legal action taken by the supervisory authorities should be clear, in writing, and open to judicial review. Each member state can also add their own additional data protection tasks as long as they align with the GDPR."
Digital Services Act (DSA) - Contextual paragraph (40),0.731486559,"Details of the contextual paragraph (40) of the Digital Services Act (DSA): In order to achieve the objectives of this Regulation, and in particular to improve the functioning of the internal market and ensure a safe and transparent online environment, it is necessary to establish a clear, effective, predictable and balanced set of harmonised due diligence obligations for providers of intermediary services. Those obligations should aim in particular to guarantee different public policy objectives such as the safety and trust of the recipients of the service, including consumers, minors and users at particular risk of being subject to hate speech, sexual harassment or other discriminatory actions, the protection of relevant fundamental rights enshrined in the Charter, the meaningful accountability of those providers and the empowerment of recipients and other affected parties, whilst facilitating the necessary oversight by competent authorities.",recital,"The Digital Services Act (DSA) aims to improve online safety and transparency. It sets out clear rules for online service providers to follow, to ensure they are accountable and their services are safe and trustworthy. It particularly focuses on protecting consumers, minors, and users who may be at risk of hate speech, sexual harassment, or discrimination. The DSA also aims to empower users and other parties affected by these services, while making it easier for authorities to oversee these providers. The goal is to create a balanced and predictable online environment that respects fundamental rights."
General Data Protection Regulation (GDPR) - Contextual Paragraph (117),0.731457174,"Details of the Contextual Paragraph (117) in the General Data Protection Regulation (GDPR): The establishment of supervisory authorities in Member States, empowered to perform their tasks and exercise their powers with complete independence, is an essential component of the protection of natural persons with regard to the processing of their personal data. Member States should be able to establish more than one supervisory authority, to reflect their constitutional, organisational and administrative structure.",recital,"The General Data Protection Regulation (GDPR) introduces a new rule, Paragraph 117, which allows member countries to set up independent supervisory authorities. These authorities are responsible for protecting individuals' personal data. They have the power to perform their duties without any interference. Furthermore, countries can establish more than one of these authorities to suit their specific constitutional, organizational, and administrative needs."
General Data Protection Regulation (GDPR) - Contextual Paragraph (2),0.731417418,"Details of the Contextual Paragraph (2) in the General Data Protection Regulation (GDPR): The principles of, and rules on the protection of natural persons with regard to the processing of their personal data should, whatever their nationality or residence, respect their fundamental rights and freedoms, in particular their right to the protection of personal data. This Regulation is intended to contribute to the accomplishment of an area of freedom, security and justice and of an economic union, to economic and social progress, to the strengthening and the convergence of the economies within the internal market, and to the well-being of natural persons.",recital,"The General Data Protection Regulation (GDPR) is a new law designed to protect the personal data of individuals, regardless of their nationality or residence. It aims to uphold their fundamental rights and freedoms, especially their right to data protection. The GDPR is meant to promote freedom, security, justice, and economic union. It also seeks to contribute to economic and social progress, strengthen and unify economies within the internal market, and enhance the well-being of individuals."
General Data Protection Regulation (GDPR) - Contextual Paragraph (80),0.731408834,"Details of the Contextual Paragraph (80) in the General Data Protection Regulation (GDPR): Where a controller or a processor not established in the Union is processing personal data of data subjects who are in the Union whose processing activities are related to the offering of goods or services, irrespective of whether a payment of the data subject is required, to such data subjects in the Union, or to the monitoring of their behaviour as far as their behaviour takes place within the Union, the controller or the processor should designate a representative, unless the processing is occasional, does not include processing, on a large scale, of special categories of personal data or the processing of personal data relating to criminal convictions and offences, and is unlikely to result in a risk to the rights and freedoms of natural persons, taking into account the nature, context, scope and purposes of the processing or if the controller is a public authority or body. The representative should act on behalf of the controller or the processor and may be addressed by any supervisory authority. The representative should be explicitly designated by a written mandate of the controller or of the processor to act on its behalf with regard to its obligations under this Regulation. The designation of such a representative does not affect the responsibility or liability of the controller or of the processor under this Regulation. Such a representative should perform its tasks according to the mandate received from the controller or processor, including cooperating with the competent supervisory authorities with regard to any action taken to ensure compliance with this Regulation. The designated representative should be subject to enforcement proceedings in the event of non-compliance by the controller or processor.",recital,"The General Data Protection Regulation (GDPR) Paragraph (80) states that companies not based in the EU, but processing personal data of EU residents, must appoint a representative in the EU. This applies whether the company is offering goods or services, or monitoring behavior of EU residents. Exceptions are made if the data processing is occasional, doesn't involve large-scale processing of special categories of data or criminal data, and poses no risk to individual rights and freedoms. Public authorities are also exempt. The representative, appointed in writing, acts on behalf of the company for GDPR compliance, and can be held accountable for non-compliance. The company remains responsible and liable under GDPR."
Digital Services Act (DSA) - Contextual paragraph (96),0.731388807,"Details of the contextual paragraph (96) of the Digital Services Act (DSA): In order to appropriately monitor and assess the compliance of very large online platforms and of very large online search engines with the obligations laid down by this Regulation, the Digital Services Coordinator of establishment or the Commission may require access to or reporting of specific data, including data related to algorithms. Such a requirement may include, for example, the data necessary to assess the risks and possible harms brought about by the very large online platform's or the very large online search engine's systems, data on the accuracy, functioning and testing of algorithmic systems for content moderation, recommender systems or advertising systems, including, where appropriate, training data and algorithms, or data on processes and outputs of content moderation or of internal complaint-handling systems within the meaning of this Regulation. Such data access requests should not include requests to produce specific information about individual recipients of the service for the purpose of determining compliance of such recipients with other applicable Union or national law. Investigations by researchers on the evolution and severity of online systemic risks are particularly important for bridging information asymmetries and establishing a resilient system of risk mitigation, informing providers of online platforms, providers of online search engines, Digital Services Coordinators, other competent authorities, the Commission and the public.",recital,"The Digital Services Act (DSA) allows the Digital Services Coordinator or the Commission to monitor large online platforms and search engines for compliance with the law. They can request access to specific data, including data on algorithms and content moderation systems, to assess potential risks and harms. However, they cannot request information about individual users to check if those users are following other laws. This law also highlights the importance of research into online risks to help create a safer online environment and inform platform providers, authorities, and the public."
General Data Protection Regulation (GDPR) - Contextual Paragraph (13),0.731334448,"Details of the Contextual Paragraph (13) in the General Data Protection Regulation (GDPR): In order to ensure a consistent level of protection for natural persons throughout the Union and to prevent divergences hampering the free movement of personal data within the internal market, a Regulation is necessary to provide legal certainty and transparency for economic operators, including micro, small and medium-sized enterprises, and to provide natural persons in all Member States with the same level of legally enforceable rights and obligations and responsibilities for controllers and processors, to ensure consistent monitoring of the processing of personal data, and equivalent sanctions in all Member States as well as effective cooperation between the supervisory authorities of different Member States. The proper functioning of the internal market requires that the free movement of personal data within the Union is not restricted or prohibited for reasons connected with the protection of natural persons with regard to the processing of personal data. To take account of the specific situation of micro, small and medium-sized enterprises, this Regulation includes a derogation for organisations with fewer than 250 employees with regard to record-keeping. In addition, the Union institutions and bodies, and Member States and their supervisory authorities, are encouraged to take account of the specific needs of micro, small and medium-sized enterprises in the application of this Regulation. The notion of micro, small and medium-sized enterprises should draw from Article 2 of the Annex to Commission Recommendation 2003/361/EC ( 1 ).",recital,"The General Data Protection Regulation (GDPR) aims to provide a consistent level of protection for individuals' personal data across the European Union. It seeks to ensure that businesses, including small and medium-sized enterprises, have clear legal guidelines for data handling. It also aims to provide individuals with enforceable rights regarding their data. The law promotes consistent monitoring of data processing and equal penalties across all member states. It also encourages cooperation between different countries' supervisory authorities. The law does not restrict the free movement of personal data within the EU, but it does provide exceptions for organizations with fewer than 250 employees regarding record-keeping. The law also encourages consideration of the specific needs of small and medium-sized enterprises."
Digital Services Act (DSA) - Contextual paragraph (88),0.731304109,"Details of the contextual paragraph (88) of the Digital Services Act (DSA): Providers of very large online platforms and of very large online search engines should also be diligent in the measures they take to test and, where necessary, adapt their algorithmic systems, not least their recommender systems. They may need to mitigate the negative effects of personalised recommendations and correct the criteria used in their recommendations. The advertising systems used by providers of very large online platforms and of very large online search engines can also be a catalyser for the systemic risks. Those providers should consider corrective measures, such as discontinuing advertising revenue for specific information, or other actions, such as improving the visibility of authoritative information sources, or more structurally adapting their advertising systems. Providers of very large online platforms and of very large online search engines may need to reinforce their internal processes or supervision of any of their activities, in particular as regards the detection of systemic risks, and conduct more frequent or targeted risk assessments related to new functionalities. In particular, where risks are shared across different online platforms or online search engines, they should cooperate with other service providers, including by initiating or joining existing codes of conduct or other self-regulatory measures. They should also consider awareness-raising actions, in particular where risks relate to disinformation campaigns.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to be more careful with their algorithmic systems, especially their recommendation systems. They may need to adjust these systems to reduce any negative effects of personalized recommendations. The DSA also highlights that the advertising systems these providers use can pose systemic risks. To address this, they might need to stop advertising revenue for certain information or improve the visibility of reliable information sources. They may also need to strengthen their internal processes, especially for identifying systemic risks, and carry out more frequent risk assessments. If risks are shared across different platforms or search engines, they should work together and consider joining self-regulatory measures. They should also raise awareness about risks related to disinformation campaigns."
Digital Services Act (DSA) - Contextual paragraph (100),0.731294811,"Details of the contextual paragraph (100) of the Digital Services Act (DSA): In view of the additional risks relating to their activities and their additional obligations under this Regulation, additional transparency requirements should apply specifically to very large online platforms and very large online search engines, notably to report comprehensively on the risk assessments performed and subsequent measures adopted as provided by this Regulation.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to follow additional transparency rules. These rules are due to the increased risks associated with their activities and extra responsibilities outlined in this law. Specifically, these companies must thoroughly report on any risk assessments they've conducted and the steps they've taken in response to those risks."
Digital Services Act (DSA) - Contextual paragraph (30),0.731275082,"Details of the contextual paragraph (30) of the Digital Services Act (DSA): Providers of intermediary services should not be, neither de jure, nor de facto, subject to a monitoring obligation with respect to obligations of a general nature. This does not concern monitoring obligations in a specific case and, in particular, does not affect orders by national authorities in accordance with national legislation, in compliance with Union law, as interpreted by the Court of Justice of the European Union, and in accordance with the conditions established in this Regulation. Nothing in this Regulation should be construed as an imposition of a general monitoring obligation or a general active fact-finding obligation, or as a general obligation for providers to take proactive measures in relation to illegal content.",recital,"The Digital Services Act (DSA) states that online service providers are not required, either by law or in practice, to constantly monitor their platforms for violations of general rules. However, they may be required to monitor specific cases if instructed by national authorities, as long as it complies with EU law. The DSA does not impose any obligation on these providers to actively seek out illegal content or to take preventative actions against such content."
General Data Protection Regulation (GDPR) - Article 57 Tasks,0.731246769,"Details of Article 57 Tasks in the General Data Protection Regulation (GDPR): 1. Without prejudice to other tasks set out under this Regulation, each supervisory authority shall on its territory: (a) monitor and enforce the application of this Regulation; (b) promote public awareness and understanding of the risks, rules, safeguards and rights in relation to processing. Activities addressed specifically to children shall receive specific attention; (c) advise, in accordance with Member State law, the national parliament, the government, and other institutions and bodies on legislative and administrative measures relating to the protection of natural persons' rights and freedoms with regard to processing; (d) promote the awareness of controllers and processors of their obligations under this Regulation; (e) upon request, provide information to any data subject concerning the exercise of their rights under this Regulation and, if appropriate, cooperate with the supervisory authorities in other Member States to that end; (f) handle complaints lodged by a data subject, or by a body, organisation or association in accordance with Article 80, and investigate, to the extent appropriate, the subject matter of the complaint and inform the complainant of the progress and the outcome of the investigation within a reasonable period, in particular if further investigation or coordination with another supervisory authority is necessary; (g) cooperate with, including sharing information and provide mutual assistance to, other supervisory authorities with a view to ensuring the consistency of application and enforcement of this Regulation; (h) conduct investigations on the application of this Regulation, including on the basis of information received from another supervisory authority or other public authority; (i) monitor relevant developments, insofar as they have an impact on the protection of personal data, in particular the development of information and communication technologies and commercial practices; (j) adopt standard contractual clauses referred to in Article 28(8) and in point (d) of Article 46(2); (k) establish and maintain a list in relation to the requirement for data protection impact assessment pursuant to Article 35(4); (l) give advice on the processing operations referred to in Article 36(2); (m) encourage the drawing up of codes of conduct pursuant to Article 40(1) and provide an opinion and approve such codes of conduct which provide sufficient safeguards, pursuant to Article 40(5); (n) encourage the establishment of data protection certification mechanisms and of data protection seals and marks pursuant to Article 42(1), and approve the criteria of certification pursuant to Article 42(5); (o) where applicable, carry out a periodic review of certifications issued in accordance with Article 42(7); (p) draft and publish the criteria for accreditation of a body for monitoring codes of conduct pursuant to Article 41 and of a certification body pursuant to Article 43; (q) conduct the accreditation of a body for monitoring codes of conduct pursuant to Article 41 and of a certification body pursuant to Article 43; (r) authorise contractual clauses and provisions referred to in Article 46(3); (s) approve binding corporate rules pursuant to Article 47; (t) contribute to the activities of the Board; (u) keep internal records of infringements of this Regulation and of measures taken in accordance with Article 58(2); and (v) fulfil any other tasks related to the protection of personal data. 2. Each supervisory authority shall facilitate the submission of complaints referred to in point (f) of paragraph 1 by measures such as a complaint submission form which can also be completed electronically, without excluding other means of communication. 3. The performance of the tasks of each supervisory authority shall be free of charge for the data subject and, where applicable, for the data protection officer. 4. Where requests are manifestly unfounded or excessive, in particular because of their repetitive character, the supervisory authority may charge a reasonable fee based on administrative costs, or refuse to act on the request. The supervisory authority shall bear the burden of demonstrating the manifestly unfounded or excessive character of the request.",article,"The General Data Protection Regulation (GDPR) Article 57 outlines the responsibilities of each supervisory authority in their territory. These include enforcing the regulation, promoting public awareness about data protection, advising government bodies on data protection measures, and handling complaints related to data protection. They also need to cooperate with other supervisory authorities to ensure consistency in applying the regulation, monitor developments impacting data protection, and encourage the establishment of data protection certification mechanisms. They are also responsible for authorizing contractual clauses and provisions related to data protection. The supervisory authority must facilitate the submission of complaints, including through electronic forms, and their services should be free of charge. However, they may charge a reasonable fee or refuse to act on requests that are manifestly unfounded or excessive."
Digital Markets Act (DMA) - Contextual Paragraph (84),0.731146216,"Details of the Contextual Paragraph (84) in the Digital Markets Act (DMA): Interim measures can be an important tool to ensure that, while an investigation is ongoing, the infringement being investigated does not lead to serious and irreparable damage for business users or end users of gatekeepers. This tool is important to avoid developments that could be very difficult to reverse by a decision taken by the Commission at the end of the proceedings. The Commission should therefore have the power to order interim measures in the context of proceedings opened in view of the possible adoption of a non-compliance decision. This power should apply in cases where the Commission has made a prima facie finding of infringement of obligations by gatekeepers and where there is a risk of serious and irreparable damage for business users or end users of gatekeepers. Interim measures should only apply for a specified period, either one ending with the conclusion of the proceedings by the Commission, or for a fixed period which can be renewed insofar as it is necessary and appropriate.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 84) that allows for temporary measures to be put in place while an investigation is ongoing. This is to prevent any serious and irreversible harm to businesses or consumers from the actions of dominant digital companies, known as gatekeepers. The European Commission has the authority to impose these interim measures if they find initial evidence of a violation by the gatekeeper and there's a risk of significant harm. These measures will only last for a certain time, either until the investigation concludes or for a set period that can be extended if needed."
Artifical Inellegence Act (AI Act) - Overview paragraph 41,0.731142759,"Aritifical Intelligence Act (AI Act) overview paragraph (41): The fact that an AI system is classified as high risk under this Regulation should not be interpreted as indicating that the use of the system is necessarily lawful under other acts of Union law or under national law compatible with Union law, such as on the protection of personal data, on the use of polygraphs and similar tools orother systems to detect the emotional state of natural persons. Any such use should continue to occur solely in accordance with the applicable requirements resulting from the Charter and from the applicable acts of secondary Union law and national law. This Regulation should not be understood as providing for the legal ground for processing of personal data, includingspecial categories of personal data,where relevant.",recital,"The Artificial Intelligence Act (AI Act) states that even if an AI system is deemed high-risk, it doesn't mean its use is automatically legal under other EU or national laws. This could include laws about personal data protection or the use of tools to detect people's emotional states. Any use of such systems should still follow the rules set by the Charter and other relevant laws. This Act doesn't provide a legal basis for processing personal data, including sensitive data."
Digital Markets Act (DMA) - Contextual Paragraph (6),0.73113966,"Details of the Contextual Paragraph (6) in the Digital Markets Act (DMA): Gatekeepers have a significant impact on the internal market, providing gateways for a large number of business users to reach end users everywhere in the Union and on different markets. The adverse impact of unfair practices on the internal market and the particularly weak contestability of core platform services, including the negative societal and economic implications of such unfair practices, have led national legislators and sectoral regulators to act. A number of regulatory solutions have already been adopted at national level or proposed to address unfair practices and the contestability of digital services or at least with regard to some of them. This has created divergent regulatory solutions which results in the fragmentation of the internal market, thus raising the risk of increased compliance costs due to different sets of national regulatory requirements.",rectial,"The Digital Markets Act (DMA) addresses the influence of major online platforms, or ""gatekeepers"", on the digital market. These gatekeepers have a significant impact on businesses and consumers across the EU. The DMA is designed to combat unfair practices by these gatekeepers, which can harm competition and have negative societal and economic effects. Previously, individual countries had their own rules to address these issues, leading to a fragmented and potentially costly regulatory landscape. The DMA aims to provide a unified approach across the EU to reduce compliance costs and ensure fair competition in the digital market."
General Data Protection Regulation (GDPR) - Contextual Paragraph (100),0.731110811,"Details of the Contextual Paragraph (100) in the General Data Protection Regulation (GDPR): In order to enhance transparency and compliance with this Regulation, the establishment of certification mechanisms and data protection seals and marks should be encouraged, allowing data subjects to quickly assess the level of data protection of relevant products and services.",recital,"The General Data Protection Regulation (GDPR) has introduced a new law, Contextual Paragraph (100), to improve transparency and adherence to the regulation. This law encourages the creation of certification mechanisms and data protection seals and marks. These will help individuals quickly determine the level of data protection offered by relevant products and services."
Digital Services Act (DSA) - Contextual paragraph (128),0.731089711,"Details of the contextual paragraph (128) of the Digital Services Act (DSA): The Digital Services Coordinator of destination, in particular on the basis of complaints received or of the input of other national competent authorities where appropriate, or the Board in case of issues involving at least three Member States, should be able to ask the Digital Services Coordinator of establishment to take investigatory or enforcement actions with regard to a provider under its competence. Such requests for action should be based on well-substantiated evidence showing the existence of an alleged infringement with negative impact on collective interests of the recipients of the service in its Member State or having a negative societal impact. The Digital Services Coordinator of establishment should be able to rely on mutual assistance or invite the requesting Digital Services Coordinator to a joint investigation in case further information is needed to take a decision, without prejudice to the possibility to request the Commission to assess the matter if it has reason to suspect that a systemic infringement by a very large online platform or a very large online search engine may be at stake.",recital,"The Digital Services Act (DSA) allows the Digital Services Coordinator of a country to request investigation or enforcement actions against a service provider if there's evidence of a violation negatively affecting the users of the service or society. This can be based on complaints, input from other authorities, or if issues involve at least three member states. The Coordinator can also invite the requesting party to a joint investigation or ask for help from other members. If a large online platform or search engine is suspected of systematic violations, the Commission can be asked to assess the situation."
General Data Protection Regulation (GDPR) - Contextual Paragraph (134),0.731043,"Details of the Contextual Paragraph (134) in the General Data Protection Regulation (GDPR): Each supervisory authority should, where appropriate, participate in joint operations with other supervisory authorities. The requested supervisory authority should be obliged to respond to the request within a specified time period.",recital,"The General Data Protection Regulation (GDPR) includes a rule (Paragraph 134) that encourages data protection authorities to work together when necessary. If one authority asks another for help, the second one is required to respond within a certain timeframe."
Digital Services Act (DSA) - Contextual paragraph (32),0.731020153,"Details of the contextual paragraph (32) of the Digital Services Act (DSA): The applicable Union or national law on the basis of which those orders are issued might require additional conditions and should be the basis for the enforcement of the respective orders. In the event of non-compliance with such orders, the issuing Member State should be able to enforce them in accordance with its national law. The applicable national law should be in compliance with Union law, including the Charter and the TFEU provisions on the freedom of establishment and the freedom to provide services within the Union, in particular with regard to online gambling and betting services. Similarly, the application of such national laws for the enforcement of the respective orders is without prejudice to applicable Union legal acts or international agreements concluded by the Union or by Member States relating to the cross-border recognition, execution and enforcement of those orders, in particular in civil and criminal matters. On the other hand, the enforcement of the obligation to inform the relevant authorities about the effect given to those orders, as opposed to the enforcement of the orders themselves, should be subject to the rules set out in this Regulation.",recital,"The Digital Services Act (DSA) allows member states to enforce orders based on their national laws, as long as they comply with Union law. This includes respecting the freedom to establish and provide services across the Union. However, enforcement of these orders should not interfere with existing Union legal acts or international agreements, especially those related to cross-border recognition and enforcement of orders. The enforcement of informing authorities about the execution of these orders should follow the rules set out in the DSA."
Digital Services Act (DSA) - Contextual paragraph (29),0.731017947,"Details of the contextual paragraph (29) of the Digital Services Act (DSA): Intermediary services span a wide range of economic activities which take place online and that develop continually to provide for transmission of information that is swift, safe and secure, and to ensure convenience of all participants of the online ecosystem. For example, 'mere conduit' intermediary services include generic categories of services, such as internet exchange points, wireless access points, virtual private networks, DNS services and resolvers, top-level domain name registries, registrars, certificate authorities that issue digital certificates, voice over IP and other interpersonal communication services, while generic examples of 'caching' intermediary services include the sole provision of content delivery networks, reverse proxies or content adaptation proxies. Such services are crucial to ensure the smooth and efficient transmission of information delivered on the internet. Examples of 'hosting services' include categories of services such as cloud computing, web hosting, paid referencing services or services enabling sharing information and content online, including file storage and sharing. Intermediary services may be provided in isolation, as a part of another type of intermediary service, or simultaneously with other intermediary services. Whether a specific service constitutes a 'mere conduit', 'caching' or 'hosting' service depends solely on its technical functionalities, which might evolve in time, and should be assessed on a case-by-case basis.",recital,"The Digital Services Act (DSA) covers a wide range of online services. These services, known as intermediary services, help to transmit information quickly, safely, and securely. They include things like internet access points, virtual private networks, domain name registries, and digital certificate issuers. They also include content delivery networks and reverse proxies. In addition, they cover hosting services like cloud computing, web hosting, and online file storage and sharing. These services can be provided on their own or as part of other services. The DSA classifies these services based on their technical functions, which can change over time. Each service is evaluated individually to determine its classification."
General Data Protection Regulation (GDPR) - Contextual Paragraph (23),0.730958879,"Details of the Contextual Paragraph (23) in the General Data Protection Regulation (GDPR): In order to ensure that natural persons are not deprived of the protection to which they are entitled under this Regulation, the processing of personal data of data subjects who are in the Union by a controller or a processor not established in the Union should be subject to this Regulation where the processing activities are related to offering goods or services to such data subjects irrespective of whether connected to a payment. In order to determine whether such a controller or processor is offering goods or services to data subjects who are in the Union, it should be ascertained whether it is apparent that the controller or processor envisages offering services to data subjects in one or more Member States in the Union. Whereas the mere accessibility of the controller's, processor's or an intermediary's website in the Union, of an email address or of other contact details, or the use of a language generally used in the third country where the controller is established, is insufficient to ascertain such intention, factors such as the use of a language or a currency generally used in one or more Member States with the possibility of ordering goods and services in that other language, or the mentioning of customers or users who are in the Union, may make it apparent that the controller envisages offering goods or services to data subjects in the Union.",recital,"The General Data Protection Regulation (GDPR) Paragraph 23 states that any company, regardless of where it is based, must follow GDPR rules if it collects or uses the personal data of people living in the European Union (EU). This applies even if the company is offering free goods or services. To determine if a company is targeting EU residents, factors such as the use of a language or currency common in the EU, or mentioning EU customers, will be considered. Simply having a website accessible in the EU or using a language common in the company's home country isn't enough to determine this."
General Data Protection Regulation (GDPR) - Contextual Paragraph (25),0.730932772,"Details of the Contextual Paragraph (25) in the General Data Protection Regulation (GDPR): Where Member State law applies by virtue of public international law, this Regulation should also apply to a controller not established in the Union, such as in a Member State's diplomatic mission or consular post.",recital,"The General Data Protection Regulation (GDPR) now includes a rule (Paragraph 25) stating that even if a data controller (a person or organization that determines the purposes for which and the manner in which any personal data are processed) is not based in the European Union, they still have to follow GDPR if they're operating in places like a country's embassy or consulate. This is because these places are subject to the laws of the member state due to public international law."
Digital Markets Act (DMA) - Contextual Paragraph (67),0.730902612,"Details of the Contextual Paragraph (67) in the Digital Markets Act (DMA): In exceptional circumstances, justified on the limited grounds of public health or public security laid down in Union law and interpreted by the Court of Justice, the Commission should be able to decide that a specific obligation does not apply to a specific core platform service. If harm is caused to such public interests that could indicate that the cost to society as a whole of enforcing a certain obligation is, in a specific exceptional case, too high and thus disproportionate. Where appropriate, the Commission should be able to facilitate compliance by assessing whether a limited and duly justified suspension or exemption is justified. This should ensure the proportionality of the obligations in this Regulation without undermining the intended ex ante effects on fairness and contestability. Where such an exemption is granted, the Commission should review its decision every year.",rectial,"The Digital Markets Act (DMA) includes a clause (Paragraph 67) that allows the Commission to waive certain obligations for a core platform service under special circumstances. These circumstances must be related to public health or security and be deemed exceptional by the Court of Justice. This could happen if enforcing the obligation would cause more harm to the public than good, making it too costly for society. The Commission can also help ensure compliance by considering a temporary suspension or exemption if it's justified. This is designed to maintain fairness and competition without compromising the obligations of the law. If an exemption is granted, the Commission must review its decision annually."
Artifical Inellegence Act (AI Act) - Overview paragraph 35,0.730881333,"Aritifical Intelligence Act (AI Act) overview paragraph (35): AI systems used in education or vocational training, notably for determining access or assigning persons to educational and vocational training institutions or to evaluate persons on tests as part of or as a precondition for their education should be considered high-risk, since they may determine the educational and professional course of a persons life and therefore affect their ability to secure their livelihood. When improperly designed and used, such systems may violate the right to education and training as well as the right not to be discriminated against and perpetuate historical patterns of discrimination.",recital,"The Artificial Intelligence Act (AI Act) classifies AI systems used in education or vocational training as high-risk. These systems, which determine access to or assign individuals to educational institutions or evaluate them on tests, can significantly impact a person's career path and livelihood. If poorly designed or misused, these systems could infringe on a person's right to education and non-discrimination, potentially perpetuating historical discrimination patterns."
Digital Services Act (DSA) - Contextual paragraph (142),0.730872452,"Details of the contextual paragraph (142) of the Digital Services Act (DSA): Interim measures can be an important tool to ensure that, while an investigation is ongoing, the infringement being investigated does not lead to the risk of serious damage for the recipients of the service. This tool is important to avoid developments that could be very difficult to reverse by a decision taken by the Commission at the end of the proceedings. The Commission should therefore have the power to impose interim measures by decision in the context of proceedings opened in view of the possible adoption of a decision of non-compliance. This power should apply in cases where the Commission has made a prima facie finding of infringement of obligations under this Regulation by the provider of very large online platform or of very large online search engine. A decision imposing interim measures should only apply for a specified period, either one ending with the conclusion of the proceedings by the Commission, or for a fixed period which can be renewed insofar as it is necessary and appropriate.",recital,"The Digital Services Act (DSA) includes a provision (paragraph 142) that allows for interim measures to be put in place during an ongoing investigation. This is to prevent potential harm to users of the service while the investigation is in progress. These measures might be necessary to stop things from happening that could be hard to undo later. The Commission has the power to impose these temporary measures if they find initial evidence of a violation by a large online platform or search engine. These measures are only in place for a certain period, either until the investigation ends or for a set time that can be extended if needed."
General Data Protection Regulation (GDPR) - Contextual Paragraph (108),0.730866671,"Details of the Contextual Paragraph (108) in the General Data Protection Regulation (GDPR): In the absence of an adequacy decision, the controller or processor should take measures to compensate for the lack of data protection in a third country by way of appropriate safeguards for the data subject. Such appropriate safeguards may consist of making use of binding corporate rules, standard data protection clauses adopted by the Commission, standard data protection clauses adopted by a supervisory authority or contractual clauses authorised by a supervisory authority. Those safeguards should ensure compliance with data protection requirements and the rights of the data subjects appropriate to processing within the Union, including the availability of enforceable data subject rights and of effective legal remedies, including to obtain effective administrative or judicial redress and to claim compensation, in the Union or in a third country. They should relate in particular to compliance with the general principles relating to personal data processing, the principles of data protection by design and by default. Transfers may also be carried out by public authorities or bodies with public authorities or bodies in third countries or with international organisations with corresponding duties or functions, including on the basis of provisions to be inserted into administrative arrangements, such as a memorandum of understanding, providing for enforceable and effective rights for data subjects. Authorisation by the competent supervisory authority should be obtained when the safeguards are provided for in administrative arrangements that are not legally binding.",recital,"The General Data Protection Regulation (GDPR) paragraph 108 states that if a country does not have adequate data protection, measures must be taken to protect individuals' data. This can be done through binding corporate rules, standard data protection clauses, or contractual clauses approved by a supervisory authority. These safeguards must ensure that data protection standards are met, including the principles of data protection by design and default. They should also provide individuals with enforceable rights and effective legal remedies, including the ability to claim compensation. Public authorities can also transfer data to third countries or international organizations, provided they have similar duties. However, if these safeguards are part of non-legally binding administrative arrangements, approval from a supervisory authority is required."
General Data Protection Regulation (GDPR) - Contextual Paragraph (119),0.730828643,"Details of the Contextual Paragraph (119) in the General Data Protection Regulation (GDPR): Where a Member State establishes several supervisory authorities, it should establish by law mechanisms for ensuring the effective participation of those supervisory authorities in the consistency mechanism. That Member State should in particular designate the supervisory authority which functions as a single contact point for the effective participation of those authorities in the mechanism, to ensure swift and smooth cooperation with other supervisory authorities, the Board and the Commission.",recital,"The General Data Protection Regulation (GDPR) contains a clause (Paragraph 119) that requires member states with multiple supervisory authorities to establish clear procedures for these authorities to effectively participate in the consistency mechanism. This mechanism ensures uniform application of GDPR across all member states. The law also requires each member state to appoint a single supervisory authority as the main contact point. This is meant to facilitate efficient cooperation with other supervisory authorities, the Board, and the Commission."
Digital Services Act (DSA) - Article 70 Interim measures,0.730816603,"Article 70 Interim measures in the Digital Services Act (DSA):  1.   In the context of proceedings which may lead to the adoption of a decision of non-compliance pursuant to Article 73(1), where there is an urgency due to the risk of serious damage for the recipients of the service, the Commission may, by decision, order interim measures against the provider of the very large online platform or of the very large online search engine concerned on the basis of a prima facie finding of an infringement.

2.   A decision under paragraph 1 shall apply for a specified period of time and may be renewed in so far this is necessary and appropriate.",article,The Digital Services Act (DSA) allows for temporary actions to be taken against large online platforms or search engines if they are suspected of breaking the rules. This can happen when there's an urgent risk of serious harm to the users of these services. The European Commission can order these temporary measures based on initial evidence of a violation. These measures are time-bound but can be extended if necessary and appropriate.
Digital Services Act (DSA) - Contextual paragraph (97),0.730813682,"Details of the contextual paragraph (97) of the Digital Services Act (DSA): This Regulation therefore provides a framework for compelling access to data from very large online platforms and very large online search engines to vetted researchers affiliated to a research organisation within the meaning of Article 2 of Directive (EU) 2019/790, which may include, for the purpose of this Regulation, civil society organisations that are conducting scientific research with the primary goal of supporting their public interest mission. All requests for access to data under that framework should be proportionate and appropriately protect the rights and legitimate interests, including the protection of personal data, trade secrets and other confidential information, of the very large online platform or of the very large online search engine and any other parties concerned, including the recipients of the service. However, to ensure that the objective of this Regulation is achieved, consideration of the commercial interests of providers should not lead to a refusal to provide access to data necessary for the specific research objective pursuant to a request under this Regulation. In this regard, whilst without prejudice to Directive (EU) 2016/943 of the European Parliament and of the Council (32), providers should ensure appropriate access for researchers, including, where necessary, by taking technical protections such as through data vaults. Data access requests could cover, for example, the number of views or, where relevant, other types of access to content by recipients of the service prior to its removal by the providers of very large online platforms or of very large online search engines.",recital,"The Digital Services Act (DSA) sets up a system where large online platforms and search engines must provide access to their data to approved researchers. These researchers could be from civil society organizations that are doing scientific research for public interest. The data access has to be fair and protect the rights and interests of the online platforms, including personal data and trade secrets. However, these platforms can't refuse access if the data is needed for research. They may need to use technical protections like data vaults. The data requested could include things like the number of views on content before it was removed by the platform."
General Data Protection Regulation (GDPR) - Contextual Paragraph (146),0.730795205,"Details of the Contextual Paragraph (146) in the General Data Protection Regulation (GDPR): The controller or processor should compensate any damage which a person may suffer as a result of processing that infringes this Regulation. The controller or processor should be exempt from liability if it proves that it is not in any way responsible for the damage. The concept of damage should be broadly interpreted in the light of the case-law of the Court of Justice in a manner which fully reflects the objectives of this Regulation. This is without prejudice to any claims for damage deriving from the violation of other rules in Union or Member State law. Processing that infringes this Regulation also includes processing that infringes delegated and implementing acts adopted in accordance with this Regulation and Member State law specifying rules of this Regulation. Data subjects should receive full and effective compensation for the damage they have suffered. Where controllers or processors are involved in the same processing, each controller or processor should be held liable for the entire damage. However, where they are joined to the same judicial proceedings, in accordance with Member State law, compensation may be apportioned according to the responsibility of each controller or processor for the damage caused by the processing, provided that full and effective compensation of the data subject who suffered the damage is ensured. Any controller or processor which has paid full compensation may subsequently institute recourse proceedings against other controllers or processors involved in the same processing.",recital,"The General Data Protection Regulation (GDPR) states that if a person suffers damage due to a company's misuse of their data, that company (known as the controller or processor) should compensate them. If the company can prove it's not at fault, it won't be liable. The law broadly defines ""damage"" and ensures that victims receive full compensation. If multiple companies are involved in the misuse, each can be held liable for the entire damage. However, they can split the compensation based on their individual responsibility, as long as the victim is fully compensated. A company that pays full compensation can later seek repayment from other involved companies."
Digital Services Act (DSA) - Contextual paragraph (154),0.730782,"Details of the contextual paragraph (154) of the Digital Services Act (DSA): Given the scope and impact of societal risks that may be caused by very large online platforms and very large online search engines, the need to address those risks as a matter of priority and the capacity to take the necessary measures, it is justified to limit the period after which this Regulation starts to apply to the providers of those services.",recital,The Digital Services Act (DSA) is a new law aimed at managing potential societal risks caused by large online platforms and search engines. It emphasizes the urgency to address these risks and the ability to implement necessary measures. The law also sets a limit on when it starts to apply to these service providers.
Digital Markets Act (DMA) - Contextual Paragraph (33),0.730778694,"Details of the Contextual Paragraph (33) in the Digital Markets Act (DMA): For the purpose of this Regulation, unfairness should relate to an imbalance between the rights and obligations of business users where the gatekeeper obtains a disproportionate advantage. Market participants, including business users of core platform services and alternative providers of services provided together with, or in support of, such core platform services, should have the ability to adequately capture the benefits resulting from their innovative or other efforts. Due to their gateway position and superior bargaining power, it is possible that gatekeepers engage in behaviour that does not allow others to capture fully the benefits of their own contributions, and unilaterally set unbalanced conditions for the use of their core platform services or services provided together with, or in support of, their core platform services. Such imbalance is not excluded by the fact that the gatekeeper offers a particular service free of charge to a specific group of users, and may also consist in excluding or discriminating against business users, in particular if the latter compete with the services provided by the gatekeeper. This Regulation should therefore impose obligations on gatekeepers addressing such behaviour.",rectial,"The Digital Markets Act (DMA) addresses unfair practices by large online platforms, known as gatekeepers. These gatekeepers may use their power to gain disproportionate advantages over other businesses, potentially preventing these businesses from fully benefiting from their own innovations. The DMA aims to correct this imbalance, even if the gatekeeper offers some services for free. The law also addresses situations where gatekeepers may exclude or discriminate against businesses, especially those that compete with them. Therefore, the DMA imposes obligations on gatekeepers to prevent such unfair behavior."
Digital Services Act (DSA) - Contextual paragraph (5),0.73076272,"Details of the contextual paragraph (5) of the Digital Services Act (DSA): This Regulation should apply to providers of certain information society services as defined in Directive (EU) 2015/1535 of the European Parliament and of the Council (5), that is, any service normally provided for remuneration, at a distance, by electronic means and at the individual request of a recipient. Specifically, this Regulation should apply to providers of intermediary services, and in particular intermediary services consisting of services known as 'mere conduit', 'caching' and 'hosting' services, given that the exponential growth of the use made of those services, mainly for legitimate and socially beneficial purposes of all kinds, has also increased their role in the intermediation and spread of unlawful or otherwise harmful information and activities.",recital,"The Digital Services Act (DSA) is a new law that applies to providers of certain online services, such as those who provide services from a distance, electronically, and at the request of a user. This includes intermediary services like 'mere conduit', 'caching', and 'hosting' services. The DSA was introduced because these services have grown exponentially, and while they are mainly used for legitimate and beneficial purposes, they have also played a role in spreading illegal or harmful information and activities."
Digital Services Act (DSA) - Contextual paragraph (132),0.730697453,"Details of the contextual paragraph (132) of the Digital Services Act (DSA): The Board should contribute to achieving a common Union perspective on the consistent application of this Regulation and to the cooperation among competent authorities, including by advising the Commission and the Digital Services Coordinators about appropriate investigation and enforcement measures, in particular vis  vis the providers of very large online platforms or of very large online search engines and having regard, in particular, to the freedom of the providers of intermediary services to provide services across the Union. The Board should also contribute to the drafting of relevant templates and codes of conduct and to the analysis of emerging general trends in the development of digital services in the Union, including by issuing opinions or recommendations on matters related to standards.",recital,"The Digital Services Act (DSA) establishes a board that will help ensure the law is applied consistently across the European Union. The board will advise on how to investigate and enforce the law, especially regarding large online platforms and search engines. It will also help create guidelines and codes of conduct, and analyze trends in digital services. The goal is to allow digital service providers to operate freely across the EU, while maintaining certain standards. The board will also issue opinions or recommendations on related matters."
Digital Services Act (DSA) - Contextual paragraph (138),0.730672538,"Details of the contextual paragraph (138) of the Digital Services Act (DSA): The Commission should be able to investigate infringements on its own initiative in accordance with the powers provided for in this Regulation, including by asking access to data, by requesting information or by performing inspections, as well as by relying on the support of the Digital Services Coordinators. Where supervision by the competent national authorities of individual alleged infringements by providers of very large online platforms or very large online search engines points to systemic issues, such as issues with a wide impact on collective interests of recipients of the service, the Digital Services Coordinators should be able to, on the basis of a duly reasoned request, refer such issues to the Commission. Such a request should contain, at least, all the necessary facts and circumstances supporting the alleged infringement and its systemic nature. Depending on the outcome of its own assessment, the Commission should be able to take the necessary investigative and enforcement measures pursuant to this Regulation, including, where relevant, launching an investigation or adopting interim measures.",recital,"The Digital Services Act (DSA) allows the Commission to investigate potential online violations independently. This can involve requesting data access, information, or conducting inspections, with the help of Digital Services Coordinators. If national authorities suspect large online platforms or search engines of systemic issues that broadly affect users, the Coordinators can refer these issues to the Commission. The referral should include all facts supporting the alleged violation and its systemic nature. Based on its evaluation, the Commission can then take necessary actions, including launching an investigation or implementing interim measures."
General Data Protection Regulation (GDPR) - Contextual Paragraph (9),0.730626941,"Details of the Contextual Paragraph (9) in the General Data Protection Regulation (GDPR): The objectives and principles of Directive 95/46/EC remain sound, but it has not prevented fragmentation in the implementation of data protection across the Union, legal uncertainty or a widespread public perception that there are significant risks to the protection of natural persons, in particular with regard to online activity. Differences in the level of protection of the rights and freedoms of natural persons, in particular the right to the protection of personal data, with regard to the processing of personal data in the Member States may prevent the free flow of personal data throughout the Union. Those differences may therefore constitute an obstacle to the pursuit of economic activities at the level of the Union, distort competition and impede authorities in the discharge of their responsibilities under Union law. Such a difference in levels of protection is due to the existence of differences in the implementation and application of Directive 95/46/EC.",recital,"The General Data Protection Regulation (GDPR) aims to address issues with the previous Directive 95/46/EC. Despite the Directive's good intentions, it led to inconsistent data protection across the European Union, legal uncertainty, and public concern over data protection risks, especially online. These inconsistencies hindered the free movement of personal data within the Union, potentially affecting economic activities, creating unfair competition, and obstructing authorities from fulfilling their duties under EU law. These protection level disparities were due to different interpretations and applications of Directive 95/46/EC. The GDPR seeks to rectify these issues."
Digital Services Act (DSA) - Article 79 Right to be heard and access to the file,0.730611384,"Article 79 Right to be heard and access to the file in the Digital Services Act (DSA):  1.   Before adopting a decision pursuant to Article 73(1), Article 74 or 76, the Commission shall give the provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1) the opportunity of being heard on:

(a) preliminary findings of the Commission, including any matter to which the Commission has taken objections; and
(b) measures that the Commission may intend to take in view of the preliminary findings referred to point (a).

2.   The provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1) may submit its observations on the Commission's preliminary findings within a reasonable period set by the Commission in its preliminary findings, which may not be less than 14 days.

3.   The Commission shall base its decisions only on objections on which the parties concerned have been able to comment.

4.   The rights of defence of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the Commission's file under the terms of a negotiated disclosure, subject to the legitimate interest of the provider of the very large online platform or of the very large online search engine or other person concerned in the protection of their business secrets. The Commission shall have the power to adopt decisions setting out such terms of disclosure in case of disagreement between the parties. The right of access to the file of the Commission shall not extend to confidential information and internal documents of the Commission, the Board, Digital Service Coordinators, other competent authorities or other public authorities of the Member States. In particular, the right of access shall not extend to correspondence between the Commission and those authorities. Nothing in this paragraph shall prevent the Commission from disclosing and using information necessary to prove an infringement.

5.   The information collected pursuant to Articles 67, 68 and 69 shall be used only for the purpose of this Regulation.",article,"The Digital Services Act (DSA) Article 79 outlines the right to be heard and access files. Before making a decision impacting a large online platform or search engine, the Commission must allow the provider to comment on preliminary findings and potential actions. The provider has a minimum of 14 days to respond to these findings. The Commission's final decision will only be based on issues that the provider had a chance to comment on. The provider's rights will be respected during proceedings, including access to the Commission's file, except for confidential information or internal documents. Any information gathered under the DSA can only be used for the purposes of this regulation."
Digital Services Act (DSA) - Contextual paragraph (59),0.730607688,"Details of the contextual paragraph (59) of the Digital Services Act (DSA): In addition, provision should be made for the possibility of engaging, in good faith, in the out-of-court dispute settlement of such disputes, including those that could not be resolved in a satisfactory manner through the internal complaint-handling systems, by certified bodies that have the requisite independence, means and expertise to carry out their activities in a fair, swift and cost-effective manner. The independence of the out-of-court dispute settlement bodies should be ensured also at the level of the natural persons in charge of resolving disputes, including through rules on conflict of interest. The fees charged by the out-of-court dispute settlement bodies should be reasonable, accessible, attractive, inexpensive for consumers and proportionate, and assessed on a case-by-case basis. Where an out-of-court dispute settlement body is certified by the competent Digital Services Coordinator, that certification should be valid in all Member States. Providers of online platforms should be able to refuse to engage in out-of-court dispute settlement procedures under this Regulation when the same dispute, in particular as regards the information concerned and the grounds for taking the contested decision, the effects of the decision and the grounds raised for contesting the decision, has already been resolved by or is already subject to an ongoing procedure before the competent court or before another competent out-of-court dispute settlement body. Recipients of the service should be able to choose between the internal complaint mechanism, an out-of-court dispute settlement and the possibility to initiate, at any stage, judicial proceedings. Since the outcome of the out-of-court dispute settlement procedure is not binding, the parties should not be prevented from initiating judicial proceedings in relation to the same dispute. The possibilities to contest decisions of providers of online platforms thus created should leave unaffected in all respects the possibility to seek judicial redress in accordance with the laws of the Member State concerned, and therefore should not affect the exercise of the right to an effective judicial remedy under Article 47 of the Charter. The provisions in this Regulation on out-of-court dispute settlement should not require Member States to establish such out-of-court settlement bodies.",recital,"The Digital Services Act (DSA) allows for out-of-court dispute resolution between online platforms and users. These disputes can be handled by certified, independent bodies that are efficient, fair, and cost-effective. The people resolving these disputes must also be independent and free from conflicts of interest. The fees for these services should be reasonable and assessed on a case-by-case basis. If a dispute resolution body is certified, it is valid in all member states. Online platforms can refuse to engage in this process if the dispute is already being handled elsewhere. Users can choose between internal complaints, out-of-court dispute resolution, or court proceedings. The outcome of the out-of-court process is not binding, so parties can still go to court over the same issue. This doesn't affect the right to seek legal redress under Article 47 of the Charter. Member states are not required to establish these bodies."
General Data Protection Regulation (GDPR) - Contextual Paragraph (110),0.730574608,"Details of the Contextual Paragraph (110) in the General Data Protection Regulation (GDPR): A group of undertakings, or a group of enterprises engaged in a joint economic activity, should be able to make use of approved binding corporate rules for its international transfers from the Union to organisations within the same group of undertakings, or group of enterprises engaged in a joint economic activity, provided that such corporate rules include all essential principles and enforceable rights to ensure appropriate safeguards for transfers or categories of transfers of personal data.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 110, that allows businesses or groups of businesses involved in joint economic activities to use approved corporate rules for transferring data internationally within their group. However, these corporate rules must include key principles and enforceable rights to ensure that any transfer or category of transfer of personal data is appropriately safeguarded."
General Data Protection Regulation (GDPR) - Article 85 Processing and freedom of expression and information,0.730463684,"Details of Article 85 Processing and freedom of expression and information in the General Data Protection Regulation (GDPR): 1. Member States shall by law reconcile the right to the protection of personal data pursuant to this Regulation with the right to freedom of expression and information, including processing for journalistic purposes and the purposes of academic, artistic or literary expression. 2. For processing carried out for journalistic purposes or the purpose of academic artistic or literary expression, Member States shall provide for exemptions or derogations from Chapter II (principles), Chapter III (rights of the data subject), Chapter IV (controller and processor), Chapter V (transfer of personal data to third countries or international organisations), Chapter VI (independent supervisory authorities), Chapter VII (cooperation and consistency) and Chapter IX (specific data processing situations) if they are necessary to reconcile the right to the protection of personal data with the freedom of expression and information. 3. Each Member State shall notify to the Commission the provisions of its law which it has adopted pursuant to paragraph 2 and, without delay, any subsequent amendment law or amendment affecting them.",article,"The General Data Protection Regulation (GDPR) Article 85 states that countries must balance the right to protect personal data with the right to freedom of expression and information. This includes data used for journalism, academia, art, or literature. Countries may create exceptions to data protection rules for these purposes if necessary to maintain this balance. Any laws or amendments made under this provision must be reported to the Commission promptly."
Digital Services Act (DSA) - Article 25 Online interface design and organisation,0.730459571,"Article 25 Online interface design and organisation in the Digital Services Act (DSA):  1.   Providers of online platforms shall not design, organise or operate their online interfaces in a way that deceives or manipulates the recipients of their service or in a way that otherwise materially distorts or impairs the ability of the recipients of their service to make free and informed decisions.

2.   The prohibition in paragraph 1 shall not apply to practices covered by Directive 2005/29/EC or Regulation (EU) 2016/679.

3.   The Commission may issue guidelines on how paragraph 1 applies to specific practices, notably:
(a) giving more prominence to certain choices when asking the recipient of the service for a decision;
(b) repeatedly requesting that the recipient of the service make a choice where that choice has already been made, especially by presenting pop-ups that interfere with the user experience;
(c) making the procedure for terminating a service more difficult than subscribing to it.",article,"The Digital Services Act (DSA) introduces Article 25, which requires online platforms to design their interfaces in a way that doesn't deceive or manipulate users, or hinder their ability to make informed decisions. This rule doesn't apply to practices covered by Directive 2005/29/EC or Regulation (EU) 2016/679. The Commission can provide guidelines on how this applies, such as not favoring certain choices, not repeatedly asking users to make a choice they've already made (like annoying pop-ups), and not making it harder to cancel a service than to subscribe to it."
Digital Services Act (DSA) - Contextual paragraph (7),0.730390728,"Details of the contextual paragraph (7) of the Digital Services Act (DSA): In order to ensure the effectiveness of the rules laid down in this Regulation and a level playing field within the internal market, those rules should apply to providers of intermediary services irrespective of their place of establishment or their location, in so far as they offer services in the Union, as evidenced by a substantial connection to the Union.",recital,"The Digital Services Act (DSA) is a new law that applies to all providers of intermediary services, no matter where they are based or located. The key point is that they offer services within the European Union. This law ensures that all these service providers follow the same rules, creating a fair competitive environment. The law applies to them as long as they have a significant connection to the European Union."
Digital Services Act (DSA) - Contextual paragraph (111),0.730322957,"Details of the contextual paragraph (111) of the Digital Services Act (DSA): The Digital Services Coordinator, as well as other competent authorities designated under this Regulation, play a crucial role in ensuring the effectiveness of the rights and obligations laid down in this Regulation and the achievement of its objectives. Accordingly, it is necessary to ensure that those authorities have the necessary means, including financial and human resources, to supervise all the providers of intermediary services falling within their competence, in the interest of all Union citizens. Given the variety of providers of intermediary services and their use of advanced technology in providing their services, it is also essential that the Digital Services Coordinator and the relevant competent authorities are equipped with the necessary number of staff and experts with specialised skills and advanced technical means, and that they autonomously manage financial resources to carry out their tasks. Furthermore, the level of resources should take into account the size, complexity and potential societal impact of the providers of intermediary services falling within their competence, as well as the reach of their services across the Union. This Regulation is without prejudice to the possibility for Member States to establish funding mechanisms based on a supervisory fee charged to providers of intermediary services under national law in compliance with Union law, to the extent that it is levied on providers of intermediary services having their main establishment in the Member State in question, that it is strictly limited to what is necessary and proportionate to cover the costs for the fulfilment of the tasks conferred upon the competent authorities pursuant to this Regulation, with the exclusion of the tasks conferred upon the Commission, and that adequate transparency is ensured regarding the levying and the use of such a supervisory fee.",recital,"The Digital Services Act (DSA) mandates that the Digital Services Coordinator and other relevant authorities have adequate resources to oversee all providers of intermediary services. This includes the necessary financial and human resources, as well as specialized staff and advanced technology. The resources allocated should consider the size, complexity, and societal impact of the service providers, as well as their reach across the Union. Member States can establish funding mechanisms through a supervisory fee charged to service providers, as long as it is transparent, necessary, proportionate, and in compliance with Union law. This fee should only cover the costs for the tasks of the competent authorities, excluding tasks conferred upon the Commission."
Digital Services Act (DSA) - Contextual paragraph (118),0.730320096,"Details of the contextual paragraph (118) of the Digital Services Act (DSA): In order to ensure effective enforcement of the obligations laid down in this Regulation, individuals or representative organisations should be able to lodge any complaint related to compliance with those obligations with the Digital Services Coordinator in the territory where they received the service, without prejudice to this Regulation's rules on allocation of competences and to the applicable rules on handling of complaints in accordance with national principles of good administration. Complaints could provide a faithful overview of concerns related to a particular intermediary service provider's compliance and could also inform the Digital Services Coordinator of any more cross-cutting issues. The Digital Services Coordinator should involve other national competent authorities as well as the Digital Services Coordinator of another Member State, and in particular the one of the Member State where the provider of intermediary services concerned is established, if the issue requires cross-border cooperation.",recital,"The Digital Services Act (DSA) allows individuals or organizations to file complaints about any violations of the rules set by the DSA. These complaints can be filed with the Digital Services Coordinator in the region where the service was received. These complaints not only help identify issues with specific service providers, but also help identify broader problems. If a complaint involves a service provider from another region, the local Digital Services Coordinator will collaborate with their counterpart in that region. This law ensures effective enforcement of the DSA's rules and promotes cross-border cooperation when needed."
Digital Markets Act (DMA) - Article 45 Review by the Court of Justice,0.730318129,"Details of Article 45 Review by the Court of Justice in the Digital Markets Act (DMA): In accordance with Article 261 TFEU, the Court of Justice has unlimited jurisdiction to review decisions by which the Commission has imposed fines or periodic penalty payments. It may cancel, reduce or increase the fine or periodic penalty payment imposed.",article,"The Digital Markets Act (DMA) includes Article 45, which gives the Court of Justice the power to review decisions made by the Commission, particularly those involving fines or ongoing penalty payments. The Court can either cancel, lessen, or increase these fines or penalties. This is in line with Article 261 of the Treaty on the Functioning of the European Union (TFEU)."
General Data Protection Regulation (GDPR) - Contextual Paragraph (46),0.730272591,"Details of the Contextual Paragraph (46) in the General Data Protection Regulation (GDPR): The processing of personal data should also be regarded to be lawful where it is necessary to protect an interest which is essential for the life of the data subject or that of another natural person. Processing of personal data based on the vital interest of another natural person should in principle take place only where the processing cannot be manifestly based on another legal basis. Some types of processing may serve both important grounds of public interest and the vital interests of the data subject as for instance when processing is necessary for humanitarian purposes, including for monitoring epidemics and their spread or in situations of humanitarian emergencies, in particular in situations of natural and man-made disasters.",recital,"The General Data Protection Regulation (GDPR) allows the use of personal data if it's necessary to protect someone's life. This could be the person whose data is being used, or someone else. However, this should only happen if there's no other legal way to use the data. In some cases, using personal data can be important for the public and for the individual. For example, it can be used for humanitarian reasons, like monitoring the spread of diseases or during emergencies and disasters."
General Data Protection Regulation (GDPR) - Contextual Paragraph (77),0.730268776,"Details of the Contextual Paragraph (77) in the General Data Protection Regulation (GDPR): Guidance on the implementation of appropriate measures and on the demonstration of compliance by the controller or the processor, especially as regards the identification of the risk related to the processing, their assessment in terms of origin, nature, likelihood and severity, and the identification of best practices to mitigate the risk, could be provided in particular by means of approved codes of conduct, approved certifications, guidelines provided by the Board or indications provided by a data protection officer. The Board may also issue guidelines on processing operations that are considered to be unlikely to result in a high risk to the rights and freedoms of natural persons and indicate what measures may be sufficient in such cases to address such risk.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 77) that guides businesses on how to protect personal data. It suggests using approved codes of conduct, certifications, and guidelines to identify and assess risks associated with data processing. These risks could be about the origin, nature, likelihood, and severity of potential data breaches. The GDPR also encourages businesses to find the best ways to reduce these risks. The Board can provide additional guidelines on data processing operations that are unlikely to pose a high risk to individuals' rights and freedoms, and suggest adequate measures to manage such risks."
Digital Services Act (DSA) - Contextual paragraph (120),0.730266869,"Details of the contextual paragraph (120) of the Digital Services Act (DSA): Such an order to restrict access should not go beyond what is necessary to achieve its objective. For that purpose, it should be temporary and be addressed in principle to a provider of intermediary services, such as the relevant hosting service provider, internet service provider or domain registry or registrar, which is in a reasonable position to achieve that objective without unduly restricting access to lawful information.",recital,"The Digital Services Act (DSA) includes a provision (paragraph 120) that allows for temporary restrictions on access to certain digital services. This could be applied to hosting service providers, internet service providers, or domain registries. However, these restrictions should only be as extensive as necessary to achieve a specific goal. They should not unnecessarily limit access to legal information. The providers targeted by these restrictions should be those reasonably capable of achieving the desired objective."
Digital Markets Act (DMA) - Contextual Paragraph (27),0.730262578,"Details of the Contextual Paragraph (27) in the Digital Markets Act (DMA): However, such early intervention should be limited to imposing only those obligations that are necessary and appropriate to ensure that the services in question remain contestable and enable the qualified risk of unfair conditions and practices to be avoided. Obligations that prevent the undertaking providing core platform services concerned from enjoying an entrenched and durable position in its operations, such as those preventing leveraging, and those that facilitate switching and multi-homing are more directly geared towards this purpose. To ensure proportionality, the Commission should moreover apply from that subset of obligations only those that are necessary and proportionate to achieve the objectives of this Regulation and should regularly review whether such obligations should be maintained, suppressed or adapted.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 27) that allows for early intervention in digital markets to prevent unfair practices and conditions. This intervention should only impose necessary obligations to keep the services competitive and prevent companies from gaining too much power. These obligations may include measures to prevent leveraging, and to facilitate switching and multi-homing. The Commission should only apply obligations that are necessary and proportionate to the DMA's objectives, and should regularly review and adjust these obligations as needed."
General Data Protection Regulation (GDPR) - Contextual Paragraph (145),0.730253041,"Details of the Contextual Paragraph (145) in the General Data Protection Regulation (GDPR): For proceedings against a controller or processor, the plaintiff should have the choice to bring the action before the courts of the Member States where the controller or processor has an establishment or where the data subject resides, unless the controller is a public authority of a Member State acting in the exercise of its public powers.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Contextual Paragraph (145), which allows individuals to sue a data controller or processor in two places: where the individual lives or where the controller/processor is based. However, if the controller is a public authority (like a government department) using its powers, this rule doesn't apply."
Digital Markets Act (DMA) - Contextual Paragraph (10),0.730245,"Details of the Contextual Paragraph (10) in the Digital Markets Act (DMA): At the same time, since this Regulation aims to complement the enforcement of competition law, it should apply without prejudice to Articles 101 and 102 TFEU, to the corresponding national competition rules and to other national competition rules regarding unilateral conduct that are based on an individualised assessment of market positions and behaviour, including its actual or potential effects and the precise scope of the prohibited behaviour, and which provide for the possibility of undertakings to make efficiency and objective justification arguments for the behaviour in question, and to national rules concerning merger control. However, the application of those rules should not affect the obligations imposed on gatekeepers under this Regulation and their uniform and effective application in the internal market.",rectial,"The Digital Markets Act (DMA) is a new law designed to work alongside existing competition laws. It does not replace or interfere with Articles 101 and 102 TFEU or any national competition rules. These rules typically assess market positions and behaviour, including potential effects and the exact scope of prohibited behaviour. They also allow businesses to justify their actions based on efficiency and objective reasoning. This includes national rules about controlling mergers. However, the DMA imposes additional obligations on gatekeepers (major digital companies) that must be followed uniformly and effectively across the internal market, regardless of the application of other competition rules."
General Data Protection Regulation (GDPR) - Contextual Paragraph (66),0.73018223,"Details of the Contextual Paragraph (66) in the General Data Protection Regulation (GDPR): To strengthen the right to be forgotten in the online environment, the right to erasure should also be extended in such a way that a controller who has made the personal data public should be obliged to inform the controllers which are processing such personal data to erase any links to, or copies or replications of those personal data. In doing so, that controller should take reasonable steps, taking into account available technology and the means available to the controller, including technical measures, to inform the controllers which are processing the personal data of the data subject's request.",recital,"The General Data Protection Regulation (GDPR) has a new rule (Paragraph 66) to enhance the ""right to be forgotten"" online. This means if a company has made your personal data public, they must tell any other companies using that data to delete it. This includes any links, copies, or replications of your data. The company is expected to take reasonable steps, considering the technology and resources they have, to inform the other companies about your request to have your data erased."
Digital Services Act (DSA) - Contextual paragraph (85),0.730159104,"Details of the contextual paragraph (85) of the Digital Services Act (DSA): In order to make it possible that subsequent risk assessments build on each other and show the evolution of the risks identified, as well as to facilitate investigations and enforcement actions, providers of very large online platforms and of very large online search engines should preserve all supporting documents relating to the risk assessments that they carried out, such as information regarding the preparation thereof, underlying data and data on the testing of their algorithmic systems.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to keep all documents related to their risk assessments. This includes information about how these assessments were prepared, the data used, and data on testing their algorithm systems. This is to ensure that future risk assessments can build on previous ones, showing how identified risks evolve over time. It also aids in investigations and enforcement actions."
General Data Protection Regulation (GDPR) - Contextual Paragraph (21),0.730151236,"Details of the Contextual Paragraph (21) in the General Data Protection Regulation (GDPR): This Regulation is without prejudice to the application of Directive 2000/31/EC of the European Parliament and of the Council ( 2 ), in particular of the liability rules of intermediary service providers in Articles 12 to 15 of that Directive. That Directive seeks to contribute to the proper functioning of the internal market by ensuring the free movement of information society services between Member States.",recital,"The Contextual Paragraph (21) in the General Data Protection Regulation (GDPR) states that the GDPR does not affect the application of Directive 2000/31/EC. This Directive, established by the European Parliament and Council, outlines the responsibilities of intermediary service providers in its Articles 12 to 15. The Directive's main aim is to ensure the smooth operation of the internal market by guaranteeing the free flow of information society services between EU Member States."
Digital Markets Act (DMA) - Contextual Paragraph (58),0.730127752,"Details of the Contextual Paragraph (58) in the Digital Markets Act (DMA): The conditions under which gatekeepers provide online advertising services to business users, including both advertisers and publishers, are often non-transparent and opaque. This often leads to a lack of information for advertisers and publishers about the effect of a given advertisement. To further enhance fairness, transparency and contestability of online advertising services listed in the designation decision, as well as those that are fully integrated with other core platform services of the same undertaking, gatekeepers should provide advertisers and publishers, and third parties authorised by advertisers and publishers, when requested, with free of charge access to the gatekeepers"" performance measuring tools and the data, including aggregated and non-aggregated data, necessary for advertisers, authorised third parties such as advertising agencies acting on behalf of a company placing advertising, as well as for publishers to carry out their own independent verification of the provision of the relevant online advertising services.",rectial,"The Digital Markets Act (DMA) includes a new rule (Paragraph 58) aimed at making online advertising more transparent and fair. Currently, the way big online platforms (gatekeepers) offer advertising services to businesses can be unclear. This can leave businesses unsure about how effective their ads are. To address this, under the new law, gatekeepers must provide businesses and their approved third parties with free access to data and tools to measure ad performance. This allows businesses to independently verify the success of their online ads."
Digital Markets Act (DMA) - Contextual Paragraph (70),0.730087757,"Details of the Contextual Paragraph (70) in the Digital Markets Act (DMA): Given the substantial economic power of gatekeepers, it is important that the obligations are applied effectively and are not circumvented. To that end, the rules in question should apply to any practice by a gatekeeper, irrespective of its form and irrespective of whether it is of a contractual, commercial, technical or any other nature, insofar as the practice corresponds to the type of practice that is the subject of one of the obligations laid down by this Regulation. Gatekeepers should not engage in behaviour that would undermine the effectiveness of the prohibitions and obligations laid down in this Regulation. Such behaviour includes the design used by the gatekeeper, the presentation of end-user choices in a non-neutral manner, or using the structure, function or manner of operation of a user interface or a part thereof to subvert or impair user autonomy, decision-making, or choice. Furthermore, the gatekeeper should not be allowed to engage in any behaviour undermining interoperability as required under this Regulation, such as for example by using unjustified technical protection measures, discriminatory terms of service, unlawfully claiming a copyright on application programming interfaces or providing misleading information. Gatekeepers should not be allowed to circumvent their designation by artificially segmenting, dividing, subdividing, fragmenting or splitting their core platform services to circumvent the quantitative thresholds laid down in this Regulation.",rectial,"The Digital Markets Act (DMA) aims to regulate the behavior of powerful online platforms, known as gatekeepers. The law applies to any action by these gatekeepers, regardless of its nature, as long as it involves practices mentioned in the DMA. Gatekeepers are prohibited from undermining the law's effectiveness by manipulating user choices, impairing user autonomy, or subverting interoperability requirements. This includes using unfair technical protections, discriminatory terms of service, false copyright claims, or providing misleading information. The law also prevents gatekeepers from avoiding regulation by artificially breaking down their services to bypass the law's thresholds."
Digital Services Act (DSA) - Contextual paragraph (1),0.730052173,"Details of the contextual paragraph (1) of the Digital Services Act (DSA): Information society services and especially intermediary services have become an important part of the Union's economy and the daily life of Union citizens. Twenty years after the adoption of the existing legal framework applicable to such services laid down in Directive 2000/31/EC of the European Parliament and of the Council (4), new and innovative business models and services, such as online social networks and online platforms allowing consumers to conclude distance contracts with traders, have allowed business users and consumers to impart and access information and engage in transactions in novel ways. A majority of Union citizens now uses those services on a daily basis. However, the digital transformation and increased use of those services has also resulted in new risks and challenges for individual recipients of the relevant service, companies and society as a whole.",recital,"The Digital Services Act (DSA) is a new law that recognizes the importance of online services, such as social networks and online platforms, in the European Union's economy and citizens' daily lives. These services have changed the way businesses and consumers interact and access information. However, the DSA also acknowledges that the digital transformation has brought new risks and challenges for individuals, businesses, and society. This law is an update to the existing legal framework from 20 years ago to better address these new developments and risks."
Artifical Inellegence Act (AI Act) - Overview paragraph 33,0.729936123,"Aritifical Intelligence Act (AI Act) overview paragraph (33): Technical inaccuracies of AI systems intended for the remote biometric identification of natural persons can lead to biased results and entail discriminatory effects. This is particularly relevant when it comes to age, ethnicity, sex or disabilities. Therefore, real-time and post remote biometric identification systems should be classified as high-risk.In view of the risks that they pose, both types of remote biometric identification systems should besubject to specific requirements on logging capabilities and human oversight.",recital,"The Artificial Intelligence Act (AI Act) recognizes that AI systems used for remote identification of individuals can be inaccurate and potentially discriminatory, particularly in relation to age, ethnicity, gender, or disabilities. The law classifies these systems, whether they operate in real-time or after the fact, as high-risk. As a result, these systems must meet specific requirements, including maintaining detailed records of their operations and being supervised by humans, to mitigate the risks they pose."
Digital Services Act (DSA) - Definition of 'to offer services in the Union',0.729922056,Definition of 'to offer services in the Union' in the Digital Services Act (DSA): enabling natural or legal persons in one or more Member States to use the services of a provider of intermediary services that has a substantial connection to the Union.,recital,"The Digital Services Act (DSA) defines 'to offer services in the Union' as allowing individuals or businesses in one or more European Union (EU) countries to use the services of an intermediary service provider that has a significant relationship with the EU. In simpler terms, it means if a company provides services that can be used by people or businesses in EU countries and has a strong connection to the EU, it is considered to be offering services in the Union under the DSA."
Digital Services Act (DSA) - Article 8 No general monitoring or active fact-finding obligations,0.729904771,"Article 8 No general monitoring or active fact-finding obligations in the Digital Services Act (DSA):  No general obligation to monitor the information which providers of intermediary services transmit or store, nor actively to seek facts or circumstances indicating illegal activity shall be imposed on those providers.",article,The new Digital Services Act (DSA) states that online service providers are not required to constantly monitor or actively search for evidence of illegal activity in the information they transmit or store. This means that these providers are not obliged to act as watchdogs over their users' activities.
Digital Services Act (DSA) - Contextual paragraph (145),0.729845881,"Details of the contextual paragraph (145) of the Digital Services Act (DSA): Given the potential significant societal effects of an infringement of the additional obligations to manage systemic risks that solely apply to very large online platforms and very large online search engines and in order to address those public policy concerns, it is necessary to provide for a system of enhanced supervision of any action undertaken to effectively terminate and remedy infringements of this Regulation. Therefore, once an infringement of one of the provisions of this Regulation that solely apply to very large online platforms or very large online search engines has been ascertained and, where necessary, sanctioned, the Commission should request the provider of such platform or of such search engine to draw a detailed action plan to remedy any effect of the infringement for the future and communicate such action plan within a timeline set by the Commission, to the Digital Services Coordinators, the Commission and the Board. The Commission, taking into account the opinion of the Board, should establish whether the measures included in the action plan are sufficient to address the infringement, taking also into account whether adherence to relevant code of conduct is included among the measures proposed. The Commission should also monitor any subsequent measure taken by the provider of a very large online platform or of a very large online search engine concerned as set out in its action plan, taking into account also an independent audit of the provider. If following the implementation of the action plan the Commission still considers that the infringement has not been fully remedied, or if the action plan has not been provided or is not considered suitable, it should be able to use any investigative or enforcement powers pursuant to this Regulation, including the power to impose periodic penalty payments and initiating the procedure to disable access to the infringing service.",recital,"The Digital Services Act (DSA) outlines stricter supervision for large online platforms and search engines that violate its rules. If an infringement is identified, the European Commission will require the platform or search engine to create an action plan to fix the issue and prevent future violations. This plan must be shared with the Digital Services Coordinators, the Commission, and the Board within a set timeframe. The Commission will then assess the plan, considering factors like adherence to relevant codes of conduct, and monitor its implementation. If the plan is insufficient or not provided, or if the violation continues, the Commission has the power to impose penalties, including blocking access to the offending service."
Artifical Inellegence Act (AI Act) - Overview paragraph 21,0.729810596,"Aritifical Intelligence Act (AI Act) overview paragraph (21): Each use of a real-time remote biometric identification system in publicly accessible spaces for the purpose of law enforcement should be subject toan express and specific authorisation by a judicial authority or by an independent administrative authority of a Member State. Such authorisation should in principle be obtained prior to the use, except in duly justified situations of urgency, that is, situations where the need to use the systems in question is such as to make it effectively and objectively impossible to obtain an authorisation before commencing the use. In such situations of urgency, the use should be restricted to the absolute minimum necessary and be subject to appropriate safeguards and conditions, as determined in national law and specified in the context of each individual urgent use case by the law enforcement authority itself. In addition, the law enforcement authority should in such situations seek to obtain an authorisation as soon as possible, whilst providing the reasons for not having been able to request it earlier.",recital,"The Artificial Intelligence Act (AI Act) requires that any use of real-time remote biometric identification (like facial recognition) by law enforcement in public spaces must be approved by a judicial or independent administrative authority. Normally, this approval should be obtained before use. However, in emergencies where getting approval beforehand is impossible, the system can be used minimally and with proper safeguards. The law enforcement must then seek approval as soon as they can, explaining why they couldn't get it earlier."
Digital Services Act (DSA) - Contextual paragraph (65),0.729763806,"Details of the contextual paragraph (65) of the Digital Services Act (DSA): In view of the particular responsibilities and obligations of providers of online platforms, they should be made subject to transparency reporting obligations, which apply in addition to the transparency reporting obligations applicable to all providers of intermediary services under this Regulation. For the purposes of determining whether online platforms and online search engines may be very large online platforms or very large online search engines, respectively, that are subject to certain additional obligations under this Regulation, the transparency reporting obligations for online platforms and online search engines should include certain obligations relating to the publication and communication of information on the average monthly active recipients of the service in the Union.",recital,"The Digital Services Act (DSA) introduces new rules for online platform providers. They now have to follow transparency reporting obligations, which are additional to those already applicable to all intermediary service providers. The DSA also introduces criteria to identify if an online platform or search engine is considered 'very large'. This is determined by their average monthly active users in the EU. If classified as 'very large', they will have to follow extra obligations under this law. These obligations include publishing and communicating information about their service's average monthly active recipients."
Digital Services Act (DSA) - Contextual paragraph (69),0.729711115,"Details of the contextual paragraph (69) of the Digital Services Act (DSA): When recipients of the service are presented with advertisements based on targeting techniques optimised to match their interests and potentially appeal to their vulnerabilities, this can have particularly serious negative effects. In certain cases, manipulative techniques can negatively impact entire groups and amplify societal harms, for example by contributing to disinformation campaigns or by discriminating against certain groups. Online platforms are particularly sensitive environments for such practices and they present a higher societal risk. Consequently, providers of online platforms should not present advertisements based on profiling as defined in Article 4, point (4), of Regulation (EU) 2016/679, using special categories of personal data referred to in Article 9(1) of that Regulation, including by using profiling categories based on those special categories. This prohibition is without prejudice to the obligations applicable to providers of online platforms or any other service provider or advertiser involved in the dissemination of the advertisements under Union law on protection of personal data.",recital,"The Digital Services Act (DSA) aims to protect users from harmful or manipulative online advertisements. These ads are often tailored to a user's interests and can exploit their vulnerabilities, potentially leading to misinformation or discrimination. The DSA specifically prohibits online platforms from showing ads based on profiling, especially using sensitive personal data. This rule applies to all online platforms and advertisers, and does not affect any other obligations they may have under EU data protection laws."
Artifical Inellegence Act (AI Act) - Article 23,0.7296983,"Aritifical Intelligence Act (AI Act) Article 23 Cooperation with competent authorities:

Providers of high-risk AI systems shall, upon request by a national competent authority, provide that authority with all the information and documentation necessary to demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title, in an official Union language determined by the Member State concerned. Upon a reasoned request from a national competent authority, providers shall also give that authority access to the logs automatically generated by the high-risk AI system, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law.",article,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems to cooperate with national authorities. If asked, they must provide all necessary information and documentation to prove that their AI system complies with the regulations outlined in Chapter 2 of this law. This information must be provided in the official language of the country making the request. Additionally, if an authority makes a justified request, providers must also grant access to the system's automatically generated logs, provided they have control over these logs either through a contract with the user or by law."
General Data Protection Regulation (GDPR) - Contextual Paragraph (112),0.7296803,"Details of the Contextual Paragraph (112) in the General Data Protection Regulation (GDPR): Those derogations should in particular apply to data transfers required and necessary for important reasons of public interest, for example in cases of international data exchange between competition authorities, tax or customs administrations, between financial supervisory authorities, between services competent for social security matters, or for public health, for example in the case of contact tracing for contagious diseases or in order to reduce and/or eliminate doping in sport. A transfer of personal data should also be regarded as lawful where it is necessary to protect an interest which is essential for the data subject's or another person's vital interests, including physical integrity or life, if the data subject is incapable of giving consent. In the absence of an adequacy decision, Union or Member State law may, for important reasons of public interest, expressly set limits to the transfer of specific categories of data to a third country or an international organisation. Member States should notify such provisions to the Commission. Any transfer to an international humanitarian organisation of personal data of a data subject who is physically or legally incapable of giving consent, with a view to accomplishing a task incumbent under the Geneva Conventions or to complying with international humanitarian law applicable in armed conflicts, could be considered to be necessary for an important reason of public interest or because it is in the vital interest of the data subject.",recital,"The General Data Protection Regulation (GDPR) allows for exceptions in data transfers for public interest reasons. This can include sharing data between tax administrations, financial authorities, social security services, or for public health, such as tracing contagious diseases. Personal data can also be lawfully transferred if it's necessary to protect someone's life or physical integrity, especially if they can't give consent. If there's no adequacy decision, the Union or Member State can set limits on transferring specific data types to a third country or international organization for public interest reasons. Member States must notify the Commission about such provisions. Data transfers to international humanitarian organizations can also be considered necessary if the individual can't give consent and it's in their vital interest or for a significant public interest reason."
General Data Protection Regulation (GDPR) - Article 80 Representation of data subjects,0.72967869,"Details of Article 80 Representation of data subjects in the General Data Protection Regulation (GDPR): 1. The data subject shall have the right to mandate a not-for-profit body, organisation or association which has been properly constituted in accordance with the law of a Member State, has statutory objectives which are in the public interest, and is active in the field of the protection of data subjects' rights and freedoms with regard to the protection of their personal data to lodge the complaint on his or her behalf, to exercise the rights referred to in Articles 77, 78 and 79 on his or her behalf, and to exercise the right to receive compensation referred to in Article 82 on his or her behalf where provided for by Member State law. 2. Member States may provide that any body, organisation or association referred to in paragraph 1 of this Article, independently of a data subject's mandate, has the right to lodge, in that Member State, a complaint with the supervisory authority which is competent pursuant to Article 77 and to exercise the rights referred to in Articles 78 and 79 if it considers that the rights of a data subject under this Regulation have been infringed as a result of the processing.",article,"Article 80 of the General Data Protection Regulation (GDPR) allows individuals to appoint a non-profit organization to represent them in matters related to the protection of their personal data. This organization can file complaints, exercise rights, and seek compensation on behalf of the individual, if allowed by the laws of the member state. Additionally, member states can permit these organizations to file complaints and exercise rights independently, if they believe the individual's data protection rights have been violated."
Digital Markets Act (DMA) - Contextual Paragraph (16),0.72966516,"Details of the Contextual Paragraph (16) in the Digital Markets Act (DMA): In order to ensure the effective application of this Regulation to undertakings providing core platform services which are most likely to satisfy those objective requirements, and where unfair practices weakening contestability are most prevalent and have the most impact, the Commission should be able to directly designate as gatekeepers those undertakings providing core platform services which meet certain quantitative thresholds. Such undertakings should in any event be subject to a fast designation process which should start once this Regulation becomes applicable.",rectial,"The Digital Markets Act (DMA) has a new rule, Paragraph 16, which aims to regulate big tech companies that provide core platform services. These companies, often called 'gatekeepers', can have a significant impact on the market and can sometimes use unfair practices. This new rule allows the Commission to identify and regulate these gatekeepers, especially those that meet certain size requirements. This process will be quick and will start as soon as the new DMA rules are in effect."
Digital Services Act (DSA) - Contextual paragraph (136),0.729658186,"Details of the contextual paragraph (136) of the Digital Services Act (DSA): In view of the need to ensure support for the Board's activities, the Board should be able to rely on the expertise and human resources of the Commission and of the competent national authorities. The specific operational arrangements for the internal functioning of the Board should be further specified in the rules of procedure of the Board.",recital,The Digital Services Act (DSA) includes a provision (paragraph 136) that allows the Board to utilize the expertise and staff of the Commission and national authorities to support its activities. The exact details of how the Board will operate internally will be outlined in its procedural rules.
Digital Services Act (DSA) - Article 29 Exclusion for micro and small enterprises,0.729648232,"Article 29 Exclusion for micro and small enterprises in the Digital Services Act (DSA):  1.   This Section shall not apply to providers of online platforms allowing consumers to conclude distance contracts with traders that qualify as micro or small enterprises as defined in Recommendation 2003/361/EC.

This Section shall not apply to providers of online platforms allowing consumers to conclude distance contracts with traders that previously qualified for the status of a micro or small enterprise as defined in Recommendation 2003/361/EC during the 12 months following their loss of that status pursuant to Article 4(2) thereof, except when they are very large online platforms in accordance with Article 33.

2.   By derogation from paragraph 1 of this Article, this Section shall apply to providers of online platforms allowing consumers to conclude distance contracts with traders that have been designated as very large online platforms in accordance with Article 33, irrespective of whether they qualify as micro or small enterprises.",article,"The Digital Services Act (DSA) has a new rule, Article 29, that exempts small and micro businesses from certain regulations. These are businesses that meet the criteria set out in the 2003/361/EC Recommendation. Even if these businesses lose their small or micro status, they will still be exempt from these rules for 12 months, unless they are classified as very large online platforms. However, if a business is designated as a very large online platform, it will have to follow these rules, regardless of whether it is a small or micro business."
Digital Services Act (DSA) - Contextual paragraph (50),0.729540408,"Details of the contextual paragraph (50) of the Digital Services Act (DSA): Providers of hosting services play a particularly important role in tackling illegal content online, as they store information provided by and at the request of the recipients of the service and typically give other recipients access thereto, sometimes on a large scale. It is important that all providers of hosting services, regardless of their size, put in place easily accessible and user-friendly notice and action mechanisms that facilitate the notification of specific items of information that the notifying party considers to be illegal content to the provider of hosting services concerned ('notice'), pursuant to which that provider can decide whether or not it agrees with that assessment and wishes to remove or disable access to that content ('action'). Such mechanisms should be clearly identifiable, located close to the information in question and at least as easy to find and use as notification mechanisms for content that violates the terms and conditions of the hosting service provider. Provided the requirements on notices are met, it should be possible for individuals or entities to notify multiple specific items of allegedly illegal content through a single notice in order to ensure the effective operation of notice and action mechanisms. The notification mechanism should allow, but not require, the identification of the individual or the entity submitting a notice. For some types of items of information notified, the identity of the individual or the entity submitting a notice might be necessary to determine whether the information in question constitutes illegal content, as alleged. The obligation to put in place notice and action mechanisms should apply, for instance, to file storage and sharing services, web hosting services, advertising servers and paste bins, in so far as they qualify as hosting services covered by this Regulation.",recital,"The Digital Services Act (DSA) requires all online hosting service providers, regardless of their size, to establish clear and user-friendly systems for reporting potentially illegal content. These systems should be easy to find and use, and should allow multiple pieces of content to be reported in one go. The person reporting the content can choose to remain anonymous, but in some cases, their identity may be necessary to determine if the content is indeed illegal. This law applies to various types of hosting services, including file storage and sharing services, web hosting services, advertising servers, and paste bins."
General Data Protection Regulation (GDPR) - Contextual Paragraph (172),0.72953862,Details of the Contextual Paragraph (172) in the General Data Protection Regulation (GDPR): The European Data Protection Supervisor was consulted in accordance with Article 28(2) of Regulation (EC) No 45/2001 and delivered an opinion on 7 March 2012 ( 1 ).,recital,"The new law being discussed here is the General Data Protection Regulation (GDPR). Paragraph 172 of this law states that the European Data Protection Supervisor was consulted as per the rules set out in Article 28(2) of Regulation (EC) No 45/2001. The Supervisor then gave an opinion on this matter on March 7, 2012. This law is part of the GDPR's efforts to protect personal data and privacy."
Digital Markets Act (DMA) - Contextual Paragraph (38),0.729476,"Details of the Contextual Paragraph (38) in the Digital Markets Act (DMA): Children merit specific protection with regard to their personal data, in particular as regards the use of their personal data for the purposes of commercial communication or creating user profiles. The protection of children online is an important objective of the Union and should be reflected in the relevant Union law. In this context, due regard should be given to a Regulation on a single market for digital services. Nothing in this Regulation exempts gatekeepers from the obligation to protect children laid down in applicable Union law.",rectial,"The Digital Markets Act (DMA) includes a specific clause (Paragraph 38) focusing on the protection of children's personal data. This law emphasizes that children need extra safeguards, particularly when their data is used for commercial messaging or creating user profiles. The law also states that the protection of children online is a key goal of the Union. It implies that all digital service providers, referred to as 'gatekeepers', must adhere to this law and ensure they protect children's data as per the Union's regulations."
General Data Protection Regulation (GDPR) - Article 82 Right to compensation and liability,0.729444385,"Details of Article 82 Right to compensation and liability in the General Data Protection Regulation (GDPR): 1. Any person who has suffered material or non-material damage as a result of an infringement of this Regulation shall have the right to receive compensation from the controller or processor for the damage suffered. 2. Any controller involved in processing shall be liable for the damage caused by processing which infringes this Regulation. A processor shall be liable for the damage caused by processing only where it has not complied with obligations of this Regulation specifically directed to processors or where it has acted outside or contrary to lawful instructions of the controller. 3. A controller or processor shall be exempt from liability under paragraph 2 if it proves that it is not in any way responsible for the event giving rise to the damage. 4. Where more than one controller or processor, or both a controller and a processor, are involved in the same processing and where they are, under paragraphs 2 and 3, responsible for any damage caused by processing, each controller or processor shall be held liable for the entire damage in order to ensure effective compensation of the data subject. 5. Where a controller or processor has, in accordance with paragraph 4, paid full compensation for the damage suffered, that controller or processor shall be entitled to claim back from the other controllers or processors involved in the same processing that part of the compensation corresponding to their part of responsibility for the damage, in accordance with the conditions set out in paragraph 2. 6. Court proceedings for exercising the right to receive compensation shall be brought before the courts competent under the law of the Member State referred to in Article 79(2).",article,"The General Data Protection Regulation (GDPR) Article 82 outlines the right to compensation and liability for data breaches. If a person suffers damage due to a violation of this law, they can claim compensation from the data controller or processor responsible. The data controller is always liable for any damage, while the processor is only liable if they didn't follow the law or acted against the controller's lawful instructions. If the controller or processor can prove they weren't responsible for the damage, they're not liable. If multiple parties are involved, each one is liable for the entire damage to ensure the victim is fully compensated. If one party pays the full compensation, they can claim back the portion of the compensation corresponding to the other parties' responsibility. Legal proceedings for compensation claims are handled by the courts of the member state referenced in Article 79(2)."
Digital Markets Act (DMA) - Contextual Paragraph (104),0.729424477,"Details of the Contextual Paragraph (104) in the Digital Markets Act (DMA): Consumers should be entitled to enforce their rights in relation to the obligations imposed on gatekeepers under this Regulation through representative actions in accordance with Directive (EU) 2020/1828 of the European Parliament and of the Council ( 21). For that purpose, this Regulation should provide that Directive (EU) 2020/1828 is applicable to the representative actions brought against infringements by gatekeepers of provisions of this Regulation that harm or can harm the collective interests of consumers. The Annex to that Directive should therefore be amended accordingly. It is for the Member States to ensure that that amendment is reflected in their transposition measures adopted in accordance with Directive (EU) 2020/1828, although the adoption of national transposition measures in this regard is not a condition for the applicability of that Directive to those representative actions. The applicability of Directive (EU) 2020/1828 to the representative actions brought against infringements by gatekeepers of provisions of this Regulation that harm or can harm the collective interests of consumers should start from the date of application of Member States"" laws, regulations and administrative provisions necessary to transpose that Directive, or from the date of application of this Regulation, whichever is the later.",rectial,"The Digital Markets Act (DMA) allows consumers to enforce their rights against digital gatekeepers (major tech companies) who violate the law. This can be done through representative actions, as detailed in Directive (EU) 2020/1828. This means that if a gatekeeper's actions harm or could harm a group of consumers, a representative can bring a case against them. The member states of the EU are responsible for making sure this is reflected in their national laws. This law applies from the date the member states implement the necessary laws, or from when the DMA comes into effect, whichever is later."
General Data Protection Regulation (GDPR) - Contextual Paragraph (126),0.729365587,Details of the Contextual Paragraph (126) in the General Data Protection Regulation (GDPR): The decision should be agreed jointly by the lead supervisory authority and the supervisory authorities concerned and should be directed towards the main or single establishment of the controller or processor and be binding on the controller and processor. The controller or processor should take the necessary measures to ensure compliance with this Regulation and the implementation of the decision notified by the lead supervisory authority to the main establishment of the controller or processor as regards the processing activities in the Union.,recital,"The General Data Protection Regulation (GDPR) Paragraph 126 states that decisions about data protection should be made together by the main supervisory authority and any other relevant authorities. These decisions should be focused on the main or only location of the data controller or processor, and must be followed by them. The data controller or processor must take steps to ensure they are following this regulation and any decisions made by the main supervisory authority about data processing activities within the European Union."
Digital Services Act (DSA) - Contextual paragraph (46),0.729357898,"Details of the contextual paragraph (46) of the Digital Services Act (DSA): Providers of intermediary services that are primarily directed at minors, for example through the design or marketing of the service, or which are used predominantly by minors, should make particular efforts to render the explanation of their terms and conditions easily understandable to minors.",recital,The Digital Services Act (DSA) has a new rule (paragraph 46) that is specifically aimed at online services mainly used by or marketed to young people. This rule requires these service providers to make extra efforts to ensure that their terms and conditions are easy for young people to understand.
Digital Services Act (DSA) - Contextual paragraph (44),0.729342699,"Details of the contextual paragraph (44) of the Digital Services Act (DSA): Providers of intermediary services that are established in a third country and that offer services in the Union should designate a sufficiently mandated legal representative in the Union and provide information relating to their legal representatives to the relevant authorities and make it publicly available. In order to comply with that obligation, such providers of intermediary services should ensure that the designated legal representative has the necessary powers and resources to cooperate with the relevant authorities. This could be the case, for example, where a provider of intermediary services appoints a subsidiary undertaking of the same group as the provider, or its parent undertaking, if that subsidiary or parent undertaking is established in the Union. However, it might not be the case, for instance, when the legal representative is subject to reconstruction proceedings, bankruptcy, or personal or corporate insolvency. That obligation should allow for the effective oversight and, where necessary, enforcement of this Regulation in relation to those providers. It should be possible for a legal representative to be mandated, in accordance with national law, by more than one provider of intermediary services. It should be possible for the legal representative to also function as a point of contact, provided the relevant requirements of this Regulation are complied with.",recital,"The Digital Services Act (DSA) requires companies from outside the EU, offering intermediary services within the EU, to appoint a legal representative in the EU. This representative should have the necessary authority and resources to cooperate with relevant authorities. The representative's information should be made public and available to these authorities. The representative could be a subsidiary or parent company of the service provider if it's based in the EU. However, if the representative is undergoing restructuring, bankruptcy, or insolvency, it may not fulfill the role. The law allows for one representative to represent multiple service providers and to serve as a point of contact, as long as they comply with the DSA's requirements. This is to ensure effective regulation and enforcement of the DSA."
Artifical Inellegence Act (AI Act) - Overview paragraph 7,0.729235709,"Aritifical Intelligence Act (AI Act) overview paragraph (7): The notion of biometric data used in this Regulation is in line with and should be interpreted consistently with the notion of biometric data as defined in Article 4(14) of Regulation (EU) 2016/679 of the European Parliament and of the Council35, Article 3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council36and Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the Council37.",recital,"The Artificial Intelligence Act (AI Act) provides guidelines on how biometric data (unique physical characteristics used for identification, like fingerprints) should be used. It aligns with previous European Union regulations and directives, specifically Regulation (EU) 2016/679, Regulation (EU) 2018/1725, and Directive (EU) 2016/680. The understanding and interpretation of biometric data in this act should be consistent with these existing laws."
General Data Protection Regulation (GDPR) - Contextual Paragraph (157),0.729233801,"Details of the Contextual Paragraph (157) in the General Data Protection Regulation (GDPR): By coupling information from registries, researchers can obtain new knowledge of great value with regard to widespread medical conditions such as cardiovascular disease, cancer and depression. On the basis of registries, research results can be enhanced, as they draw on a larger population. Within social science, research on the basis of registries enables researchers to obtain essential knowledge about the long-term correlation of a number of social conditions such as unemployment and education with other life conditions. Research results obtained through registries provide solid, high-quality knowledge which can provide the basis for the formulation and implementation of knowledge-based policy, improve the quality of life for a number of people and improve the efficiency of social services. In order to facilitate scientific research, personal data can be processed for scientific research purposes, subject to appropriate conditions and safeguards set out in Union or Member State law.",recital,"The General Data Protection Regulation (GDPR) allows researchers to use personal data from registries for scientific research, under certain conditions. This can help gain valuable insights into common medical conditions like heart disease, cancer, and depression, and social issues like unemployment and education. The large population data can improve research results, leading to better policies and improved quality of life. However, this data processing must comply with safeguards and conditions set by the Union or Member State law to ensure privacy and data protection."
General Data Protection Regulation (GDPR) - Article 25 Data protection by design and by default,0.729232192,"Details of Article 25 Data protection by design and by default in the General Data Protection Regulation (GDPR): 1. Taking into account the state of the art, the cost of implementation and the nature, scope, context and purposes of processing as well as the risks of varying likelihood and severity for rights and freedoms of natural persons posed by the processing, the controller shall, both at the time of the determination of the means for processing and at the time of the processing itself, implement appropriate technical and organisational measures, such as pseudonymisation, which are designed to implement data-protection principles, such as data minimisation, in an effective manner and to integrate the necessary safeguards into the processing in order to meet the requirements of this Regulation and protect the rights of data subjects. 2. The controller shall implement appropriate technical and organisational measures for ensuring that, by default, only personal data which are necessary for each specific purpose of the processing are processed. That obligation applies to the amount of personal data collected, the extent of their processing, the period of their storage and their accessibility. In particular, such measures shall ensure that by default personal data are not made accessible without the individual's intervention to an indefinite number of natural persons. 3. An approved certification mechanism pursuant to Article 42 may be used as an element to demonstrate compliance with the requirements set out in paragraphs 1 and 2 of this Article.",article,"Article 25 of the General Data Protection Regulation (GDPR) requires companies to incorporate data protection measures into their systems and processes. These measures should consider factors like technology, cost, and the type and purpose of data being processed. Companies must ensure they only collect and process necessary personal data, limit access to it, and not keep it longer than needed. They should also use techniques like pseudonymisation to protect data. The law also allows for the use of approved certification mechanisms to show they are complying with these requirements."
General Data Protection Regulation (GDPR) - Contextual Paragraph (79),0.729223609,"Details of the Contextual Paragraph (79) in the General Data Protection Regulation (GDPR): The protection of the rights and freedoms of data subjects as well as the responsibility and liability of controllers and processors, also in relation to the monitoring by and measures of supervisory authorities, requires a clear allocation of the responsibilities under this Regulation, including where a controller determines the purposes and means of the processing jointly with other controllers or where a processing operation is carried out on behalf of a controller.",recital,"The Contextual Paragraph (79) in the General Data Protection Regulation (GDPR) focuses on protecting the rights and freedoms of individuals whose data is being processed. It stresses the need for clear assignment of responsibilities, particularly when multiple entities are involved in determining how and why the data is processed, or when the processing is done on behalf of another entity. This is to ensure proper accountability and liability, and to facilitate monitoring and enforcement by regulatory authorities."
Digital Services Act (DSA) - Contextual paragraph (60),0.729208,"Details of the contextual paragraph (60) of the Digital Services Act (DSA): For contractual consumer-to-business disputes regarding the purchase of goods or services, Directive 2013/11/EU ensures that Union consumers and businesses in the Union have access to quality-certified alternative dispute resolution entities. In this regard, it should be clarified that the rules of this Regulation on out-of-court dispute settlement are without prejudice to that Directive, including the right of consumers under that Directive to withdraw from the procedure at any stage if they are dissatisfied with the performance or the operation of the procedure.",recital,"The Digital Services Act (DSA) includes a section (paragraph 60) that deals with disputes between consumers and businesses about purchases. This section reinforces the Directive 2013/11/EU, which ensures both consumers and businesses in the Union have access to certified alternative dispute resolution entities. This means there are specific rules for settling disputes outside of court. Importantly, consumers have the right to withdraw from this process at any point if they're unhappy with how it's going."
Artifical Inellegence Act (AI Act) - Overview paragraph 9,0.729189038,"Aritifical Intelligence Act (AI Act) overview paragraph (9): For the purposes of this Regulation the notion of publicly accessible space should be understood as referring to any physical place that is accessible to the public, irrespective of whether the place in question is privately or publicly owned. Therefore, the notion does not cover places that are private in nature and normally not freely accessible for third parties, including law enforcement authorities, unless those parties have been specifically invited or authorised, such as homes, private clubs, offices, warehouses and factories. Online spaces are not covered either, as they are not physical spaces. However, the mere fact that certain conditions for accessing aparticular space may apply, such as admission tickets or age restrictions, does not mean that the space is not publicly accessible within the meaning of this Regulation. Consequently, in addition to public spaces such as streets, relevant parts of government buildings and most transport infrastructure, spaces such as cinemas, theatres, shops and shopping centres are normally also publicly accessible. Whether a given space is accessible to the public should however be determined on a case-by-case basis, having regard to the specificities of the individual situation at hand.",recital,"The Artificial Intelligence Act (AI Act) defines a ""publicly accessible space"" as any physical location that the public can access, regardless of who owns it. This doesn't include private places like homes, offices, or factories, unless specific permission is given. It also doesn't include online spaces. Even if there are conditions to access a place, like tickets or age restrictions, it can still be considered publicly accessible. This includes places like streets, government buildings, transport infrastructure, cinemas, shops, and shopping centers. However, whether a place is publicly accessible should be decided on a case-by-case basis."
Digital Services Act (DSA) - Contextual paragraph (105),0.729053915,"Details of the contextual paragraph (105) of the Digital Services Act (DSA): The codes of conduct should facilitate the accessibility of very large online platforms and very large online search engines, in compliance with Union and national law, in order to facilitate their foreseeable use by persons with disabilities. In particular, the codes of conduct could ensure that the information is presented in a perceivable, operable, understandable and robust way and that forms and measures provided pursuant to this Regulation are made available in a manner that is easy to find and accessible to persons with disabilities.",recital,"The Digital Services Act (DSA) includes a new provision (paragraph 105) aimed at improving accessibility for people with disabilities on large online platforms and search engines. This law encourages these platforms to adopt codes of conduct that ensure their services are easy to use, understand, and navigate for individuals with disabilities. The information should be presented clearly and robustly, and any forms or measures related to this regulation should be easy to find and accessible. All these should be in compliance with both Union and national law."
California Consumer Privacy Act Regulations (CCPA) - Definition of Signed,0.729030192,"Details of Definition of Signed in the California Consumer Privacy Act Regulations (CCPA): Signed means that the written attestation, declaration, or permission has either been physically signed or provided electronically in accordance with the Uniform Electronic Transactions Act, Civil Code section 1633.1 et seq.",recital,"The California Consumer Privacy Act (CCPA) has a new definition for ""Signed"". This means that any written agreement, statement, or permission is considered ""signed"" if it has been either physically signed with pen and paper, or given electronically following the rules of the Uniform Electronic Transactions Act. This act allows electronic signatures to have the same legal standing as traditional signatures."
Artifical Inellegence Act (AI Act) - Overview paragraph 24,0.729024827,"Aritifical Intelligence Act (AI Act) overview paragraph (24): Any processing of biometric data and other personal data involved in the use of AI systems for biometric identification, other than in connection to the use of real-time remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement as regulated by this Regulation, including where those systems are used by competent authorities in publicly accessible spaces for other purposes than law enforcement, should continue to comply with all requirements resulting from Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.",recital,"The Artificial Intelligence Act (AI Act) states that any use of AI systems for identifying people through biometric data (like facial recognition) must comply with existing privacy laws, unless it's being used in real-time by law enforcement in public spaces. This includes when these systems are used by authorities in public spaces for non-law enforcement purposes. The relevant privacy laws are Article 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU) 2018/1725, and Article 10 of Directive (EU) 2016/680."
Digital Services Act (DSA) - Contextual paragraph (150),0.729015589,"Details of the contextual paragraph (150) of the Digital Services Act (DSA): In the interest of effectiveness and efficiency, the Commission should carry out a general evaluation of this Regulation. In particular, that general evaluation should address, inter alia, the scope of the services covered by this Regulation, the interplay with other legal acts, the impact of this Regulation on the functioning of the internal market, in particular regarding digital services, the implementation of codes of conduct, the obligation to designate a legal representative established in the Union, the effect of the obligations on small and micro enterprises, the effectiveness of the supervision and enforcement mechanism and the impact on the right to freedom of expression and of information. In addition, to avoid disproportionate burdens and ensure the continued effectiveness of this Regulation, the Commission should perform an evaluation of the impact of the obligations set out in this Regulation on small and medium-sized enterprises within three years from the start of its application and an evaluation on the scope of the services covered by this Regulation, particularly for very large online platforms and for very large online search engines, and the interplay with other legal acts within three years from its entry into force.",recital,"The Digital Services Act (DSA) is a new law that aims to regulate digital services. The law will be evaluated by the Commission to ensure it is effective and efficient. This evaluation will look at various aspects such as the services it covers, its interaction with other laws, its impact on the digital market, implementation of conduct codes, and its effect on small businesses. There will also be a focus on how the law affects freedom of expression and information. To avoid overburdening businesses, the Commission will assess the law's impact on small and medium businesses within three years of its application. It will also evaluate the law's scope, especially regarding large online platforms and search engines, within three years of its enforcement."
Digital Services Act (DSA) - Contextual paragraph (31),0.728960454,"Details of the contextual paragraph (31) of the Digital Services Act (DSA): Depending on the legal system of each Member State and the field of law at issue, national judicial or administrative authorities, including law enforcement authorities, may order providers of intermediary services to act against one or more specific items of illegal content or to provide certain specific information. The national laws on the basis of which such orders are issued differ considerably and the orders are increasingly addressed in cross-border situations. In order to ensure that those orders can be complied with in an effective and efficient manner, in particular in a cross-border context, so that the public authorities concerned can carry out their tasks and the providers are not subject to any disproportionate burdens, without unduly affecting the rights and legitimate interests of any third parties, it is necessary to set certain conditions that those orders should meet and certain complementary requirements relating to the processing of those orders. Consequently, this Regulation should harmonise only certain specific minimum conditions that such orders should fulfil in order to give rise to the obligation of providers of intermediary services to inform the relevant authorities about the effect given to those orders. Therefore, this Regulation does not provide the legal basis for the issuing of such orders, nor does it regulate their territorial scope or cross-border enforcement.",recital,"The Digital Services Act (DSA) allows national authorities in EU member states to order online service providers to remove illegal content or provide specific information. However, as these orders are based on national laws that vary greatly, the DSA aims to establish minimum conditions for these orders to ensure they can be effectively carried out, especially in cross-border situations. The conditions are meant to prevent undue burdens on providers and protect third-party rights. It's important to note that the DSA doesn't provide the legal basis for issuing these orders, nor does it regulate their territorial scope or cross-border enforcement."
Digital Services Act (DSA) - Contextual paragraph (4),0.728952646,"Details of the contextual paragraph (4) of the Digital Services Act (DSA): Therefore, in order to safeguard and improve the functioning of the internal market, a targeted set of uniform, effective and proportionate mandatory rules should be established at Union level. This Regulation provides the conditions for innovative digital services to emerge and to scale up in the internal market. The approximation of national regulatory measures at Union level concerning the requirements for providers of intermediary services is necessary to avoid and put an end to fragmentation of the internal market and to ensure legal certainty, thus reducing uncertainty for developers and fostering interoperability. By using requirements that are technology neutral, innovation should not be hampered but instead be stimulated.",recital,"The Digital Services Act (DSA) is a new law aimed at enhancing the functioning of the digital market within the Union. It establishes a set of mandatory rules that are uniform, effective, and proportionate to ensure innovative digital services can grow. The DSA also standardizes national regulations for intermediary service providers to prevent market fragmentation and provide legal certainty. This will reduce uncertainty for developers and promote interoperability. The law is technology-neutral, meaning it doesn't favor any particular technology, thereby encouraging innovation."
Digital Services Act (DSA) - Contextual paragraph (36),0.728874803,"Details of the contextual paragraph (36) of the Digital Services Act (DSA): The territorial scope of such orders to act against illegal content should be clearly set out on the basis of the applicable Union or national law enabling the issuance of the order and should not exceed what is strictly necessary to achieve its objectives. In that regard, the national judicial or administrative authority, which might be a law enforcement authority, issuing the order should balance the objective that the order seeks to achieve, in accordance with the legal basis enabling its issuance, with the rights and legitimate interests of all third parties that may be affected by the order, in particular their fundamental rights under the Charter. In particular in a cross-border context, the effect of the order should in principle be limited to the territory of the issuing Member State, unless the illegality of the content derives directly from Union law or the issuing authority considers that the rights at stake require a wider territorial scope, in accordance with Union and international law, while taking into account the interests of international comity.",recital,"The Digital Services Act (DSA) states that any orders to remove illegal content should only be as extensive as necessary to achieve their goals. These orders should be based on EU or national law. The authority issuing the order must balance its objectives with the rights and interests of any third parties affected, especially their fundamental rights. If the order is issued across borders, its effect should generally be limited to the country issuing it, unless the content's illegality is based on EU law or the authority believes wider action is necessary. This should be in line with EU and international law, and respect international relations."
"Digital Services Act (DSA) - Article 11 Points of contact for Member States' authorities, the Commission and the Board",0.728873849,"Article 11 Points of contact for Member States' authorities, the Commission and the Board in the Digital Services Act (DSA):  1.   Providers of intermediary services shall designate a single point of contact to enable them to communicate directly, by electronic means, with Member States' authorities, the Commission and the Board referred to in Article 61 for the application of this Regulation.
2.   Providers of intermediary services shall make public the information necessary to easily identify and communicate with their single points of contact. That information shall be easily accessible, and shall be kept up to date.
3.   Providers of intermediary services shall specify in the information referred to in paragraph 2 the official language or languages of the Member States which, in addition to a language broadly understood by the largest possible number of Union citizens, can be used to communicate with their points of contact, and which shall include at least one of the official languages of the Member State in which the provider of intermediary services has its main establishment or where its legal representative resides or is established.",article,"The Digital Services Act (DSA) requires online service providers to have a designated point of contact for communication with authorities from Member States, the Commission, and the Board. This contact must be easily identifiable and accessible, with up-to-date information available publicly. The service providers must also specify which languages can be used for communication with this contact. These languages should include at least one official language of the Member State where the service provider is primarily established or where its legal representative resides."
Digital Services Act (DSA) - Contextual paragraph (58),0.728849411,"Details of the contextual paragraph (58) of the Digital Services Act (DSA): Recipients of the service should be able to easily and effectively contest certain decisions of providers of online platforms concerning the illegality of content or its incompatibility with the terms and conditions that negatively affect them. Therefore, providers of online platforms should be required to provide for internal complaint-handling systems, which meet certain conditions that aim to ensure that the systems are easily accessible and lead to swift, non-discriminatory, non-arbitrary and fair outcomes, and are subject to human review where automated means are used. Such systems should enable all recipients of the service to lodge a complaint and should not set formal requirements, such as referral to specific, relevant legal provisions or elaborate legal explanations. Recipients of the service who submitted a notice through the notice and action mechanism provided for in this Regulation or through the notification mechanism for content that violate the terms and conditions of the provider of online platforms should be entitled to use the complaint mechanism to contest the decision of the provider of online platforms on their notices, including when they consider that the action taken by that provider was not adequate. The possibility to lodge a complaint for the reversal of the contested decisions should be available for at least six months, to be calculated from the moment at which the provider of online platforms informed the recipient of the service of the decision.",recital,"The Digital Services Act (DSA) requires online platforms to have a user-friendly system for handling complaints about content that's been deemed illegal or against the platform's rules. This system should be easily accessible, quick, fair, and not biased. It should also involve human review if automated methods are used. Users should be able to file a complaint without needing to refer to specific laws or provide complex legal explanations. Users who have reported content or who disagree with the platform's response to their report can use this complaint system. They can also ask for a decision to be reversed up to six months after being informed of the decision by the platform."
General Data Protection Regulation (GDPR) - Contextual Paragraph (41),0.728827894,"Details of the Contextual Paragraph (41) in the General Data Protection Regulation (GDPR): Where this Regulation refers to a legal basis or a legislative measure, this does not necessarily require a legislative act adopted by a parliament, without prejudice to requirements pursuant to the constitutional order of the Member State concerned. However, such a legal basis or legislative measure should be clear and precise and its application should be foreseeable to persons subject to it, in accordance with the case-law of the Court of Justice of the European Union (the ""Court of Justice"") and the European Court of Human Rights.",recital,"The General Data Protection Regulation (GDPR) Paragraph 41 states that when the law mentions a legal basis or legislative measure, it doesn't always mean an act passed by parliament. However, it should be clear, precise and predictable for those it applies to. This should align with the rulings of the Court of Justice of the European Union and the European Court of Human Rights. The requirements may vary based on the constitutional order of the member state."
General Data Protection Regulation (GDPR) - Article 86 Processing and public access to official documents,0.728816152,Details of Article 86 Processing and public access to official documents in the General Data Protection Regulation (GDPR): Personal data in official documents held by a public authority or a public body or a private body for the performance of a task carried out in the public interest may be disclosed by the authority or body in accordance with Union or Member State law to which the public authority or body is subject in order to reconcile public access to official documents with the right to the protection of personal data pursuant to this Regulation.,article,"Article 86 of the General Data Protection Regulation (GDPR) states that personal data in official documents can be disclosed by public or private bodies if they are performing a task in the public interest. However, this must be done in accordance with the laws of the European Union or the member state the body is subject to. The aim is to balance public access to official documents with the right to protect personal data under GDPR."
Digital Services Act (DSA) - Contextual paragraph (57),0.728814483,"Details of the contextual paragraph (57) of the Digital Services Act (DSA): To avoid disproportionate burdens, the additional obligations imposed under this Regulation on providers of online platforms, including platforms allowing consumers to conclude distance contracts with traders, should not apply to providers that qualify as micro or small enterprises as defined in Recommendation 2003/361/EC. For the same reason, those additional obligations should also not apply to providers of online platforms that previously qualified as micro or small enterprises during a period of 12 months after they lose that status. Such providers should not be excluded from the obligation to provide information on the average monthly active recipients of the service at the request of the Digital Services Coordinator of establishment or the Commission. However, considering that very large online platforms or very large online search engines have a larger reach and a greater impact in influencing how recipients of the service obtain information and communicate online, such providers should not benefit from that exclusion, irrespective of whether they qualify or recently qualified as micro or small enterprises. The consolidation rules laid down in Recommendation 2003/361/EC help ensure that any circumvention of those additional obligations is prevented. Nothing in this Regulation precludes providers of online platforms that are covered by that exclusion from setting up, on a voluntary basis, a system that complies with one or more of those obligations.",recital,"The Digital Services Act (DSA) introduces new obligations for online platform providers. However, to avoid overburdening small businesses, these obligations won't apply to providers classified as micro or small enterprises under Recommendation 2003/361/EC. Even if these businesses grow and lose their small status, they'll still be exempt from these obligations for a year. However, they must still provide information about their average monthly users if asked by the DSA Coordinator or the Commission. Large online platforms and search engines, due to their influence and reach, won't be exempt, regardless of their size. The rules in Recommendation 2003/361/EC ensure these obligations can't be avoided. Online platforms exempt from these obligations can still voluntarily comply if they choose to do so."
General Data Protection Regulation (GDPR) - Contextual Paragraph (168),0.72878617,"Details of the Contextual Paragraph (168) in the General Data Protection Regulation (GDPR): The examination procedure should be used for the adoption of implementing acts on standard contractual clauses between controllers and processors and between processors; codes of conduct; technical standards and mechanisms for certification; the adequate level of protection afforded by a third country, a territory or a specified sector within that third country, or an international organisation; standard protection clauses; formats and procedures for the exchange of information by electronic means between controllers, processors and supervisory authorities for binding corporate rules; mutual assistance; and arrangements for the exchange of information by electronic means between supervisory authorities, and between supervisory authorities and the Board.",recital,"The General Data Protection Regulation (GDPR) includes a new rule, Paragraph 168, that outlines how certain procedures and standards should be adopted. These include standard contracts between data controllers and processors, codes of conduct, technical standards, certification mechanisms, and data protection clauses. It also covers how to determine if a third country or international organization provides adequate data protection. Additionally, it specifies formats and procedures for electronic information exchange between controllers, processors, and supervisory authorities. It also addresses mutual assistance and information exchange arrangements between supervisory authorities and the Board."
Digital Markets Act (DMA) - Contextual Paragraph (97),0.72876358,"Details of the Contextual Paragraph (97) in the Digital Markets Act (DMA): In order to ensure contestable and fair markets in the digital sector across the Union where gatekeepers are present, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission in respect of amending the methodology for determining whether the quantitative thresholds regarding active end users and active business users for the designation of gatekeepers are met, which is contained in an Annex to this Regulation, in respect of further specifying the additional elements of the methodology not falling in that Annex for determining whether the quantitative thresholds regarding the designation of gatekeepers are met, and in respect of supplementing the existing obligations laid down in this Regulation where, based on a market investigation, the Commission has identified the need for updating the obligations addressing practices that limit the contestability of core platform services or are unfair, and the update considered falls within the scope of the empowerment set out for such delegated acts in this Regulation.",rectial,"The Digital Markets Act (DMA) allows the European Commission to make changes to how they determine if a digital company is a ""gatekeeper"" - a dominant player in the market. This includes adjusting the criteria for how many active users a company must have to be considered a gatekeeper. The Commission can also add to the existing rules if they find, through a market investigation, that a company is limiting competition or acting unfairly. These changes are made to ensure fair and competitive digital markets across the European Union."
General Data Protection Regulation (GDPR) - Article 79 Right to an effective judicial remedy against a controller or processor,0.728739679,"Details of Article 79 Right to an effective judicial remedy against a controller or processor in the General Data Protection Regulation (GDPR): 1. Without prejudice to any available administrative or non-judicial remedy, including the right to lodge a complaint with a supervisory authority pursuant to Article 77, each data subject shall have the right to an effective judicial remedy where he or she considers that his or her rights under this Regulation have been infringed as a result of the processing of his or her personal data in non-compliance with this Regulation. 2. Proceedings against a controller or a processor shall be brought before the courts of the Member State where the controller or processor has an establishment. Alternatively, such proceedings may be brought before the courts of the Member State where the data subject has his or her habitual residence, unless the controller or processor is a public authority of a Member State acting in the exercise of its public powers.",article,"The General Data Protection Regulation (GDPR) Article 79 states that individuals have the right to take legal action if they believe their rights have been violated due to improper handling of their personal data. This can be done in addition to any other remedies available, like filing a complaint with a supervisory authority. Legal action can be taken in the country where the organization handling the data is located or where the individual lives, unless the organization is a public authority exercising its public powers."
General Data Protection Regulation (GDPR) - Contextual Paragraph (122),0.728732467,"Details of the Contextual Paragraph (122) in the General Data Protection Regulation (GDPR): Each supervisory authority should be competent on the territory of its own Member State to exercise the powers and to perform the tasks conferred on it in accordance with this Regulation. This should cover in particular the processing in the context of the activities of an establishment of the controller or processor on the territory of its own Member State, the processing of personal data carried out by public authorities or private bodies acting in the public interest, processing affecting data subjects on its territory or processing carried out by a controller or processor not established in the Union when targeting data subjects residing on its territory. This should include handling complaints lodged by a data subject, conducting investigations on the application of this Regulation and promoting public awareness of the risks, rules, safeguards and rights in relation to the processing of personal data.",recital,"The General Data Protection Regulation (GDPR) Paragraph 122 states that each country's data protection authority is responsible for enforcing GDPR within its own borders. This includes overseeing the use of personal data by both public and private entities, whether they are based in that country or not. The authority's duties include handling complaints from individuals, investigating potential GDPR violations, and educating the public about their data protection rights and risks."
Digital Markets Act (DMA) - Article 34 Right to be heard and access to the file,0.728677452,"Details of Article 34 Right to be heard and access to the file in the Digital Markets Act (DMA): 1. Before adopting a decision pursuant to Article 8, Article 9(1), Article 10(1), Articles 17, 18, 24, 25, 29 and 30 and Article 31(2), the Commission shall give the gatekeeper or undertaking or association of undertakings concerned the opportunity of being heard on: (a) preliminary findings of the Commission, including any matter to which the Commission has taken objection; and (b) measures that the Commission may intend to take in view of the preliminary findings pursuant to point (a) of this paragraph. 2. Gatekeepers, undertakings and associations of undertakings concerned may submit their observations to the Commission concerning the Commission""s preliminary findings within a time limit set by the Commission in its preliminary findings which may not be less than 14 days. 3. The Commission shall base its decisions only on preliminary findings, including any matter to which the Commission has taken objection, on which gatekeepers, undertakings and associations of undertakings concerned have been able to comment. 4. The rights of defence of the gatekeeper, undertaking or association of undertakings concerned shall be fully respected in any proceedings. The gatekeeper, undertaking or association of undertakings concerned shall be entitled to have access to the Commission's file under terms of disclosure, subject to the legitimate interest of undertakings in the protection of their business secrets. In the case of disagreement between the parties, the Commission may adopt decisions setting out those terms of disclosure. The right of access to the file of the Commission shall not extend to confidential information and internal documents of the Commission or the competent authorities of the Member States. In particular, the right of access shall not extend to correspondence between the Commission and the competent authorities of the Member States. Nothing in this paragraph shall prevent the Commission from disclosing and using information necessary to prove an infringement.",article,"The Digital Markets Act (DMA) Article 34 provides a right to be heard and access to the file. Before the Commission makes a decision that affects a gatekeeper or business, it must give them a chance to comment on preliminary findings or proposed measures. They can submit their observations within a minimum of 14 days. The Commission's decisions will only be based on these preliminary findings that the affected parties have had a chance to comment on. The rights of the gatekeeper or business will be fully respected, and they will have access to the Commission's file, except for confidential information and internal documents. If there's a disagreement about what should be disclosed, the Commission can make the final decision. The Commission can still disclose and use necessary information to prove an infringement."
Digital Markets Act (DMA) - Contextual Paragraph (88),0.72865206,"Details of the Contextual Paragraph (88) in the Digital Markets Act (DMA): In the context of proceedings carried out under this Regulation, the undertaking concerned should be accorded the right to be heard by the Commission and the decisions taken should be widely publicised. While ensuring the rights to good administration, the right of access to the file and the right to be heard, it is essential to protect confidential information. Furthermore, while respecting the confidentiality of the information, the Commission should ensure that any information on which the decision is based is disclosed to an extent that allows the addressee of the decision to understand the facts and considerations that led to the decision. It is also necessary to ensure that the Commission only uses information collected pursuant to this Regulation for the purposes of this Regulation, except where specifically envisaged otherwise. Finally, it should be possible, under certain conditions, for certain business records, such as communication between lawyers and their clients, to be considered confidential if the relevant conditions are met.",rectial,"The Digital Markets Act (DMA) states that during proceedings, the involved party has the right to be heard by the Commission and any decisions made will be widely publicized. The law emphasizes the importance of protecting confidential information while also ensuring the party understands the facts and reasoning behind any decisions. The Commission can only use the collected information for the purposes of this law, unless otherwise specified. Certain business records, such as lawyer-client communications, may be considered confidential under specific conditions."
Digital Services Act (DSA) - Contextual paragraph (84),0.728641391,"Details of the contextual paragraph (84) of the Digital Services Act (DSA): When assessing such systemic risks, providers of very large online platforms and of very large online search engines should focus on the systems or other elements that may contribute to the risks, including all the algorithmic systems that may be relevant, in particular their recommender systems and advertising systems, paying attention to the related data collection and use practices. They should also assess whether their terms and conditions and the enforcement thereof are appropriate, as well as their content moderation processes, technical tools and allocated resources. When assessing the systemic risks identified in this Regulation, those providers should also focus on the information which is not illegal, but contributes to the systemic risks identified in this Regulation. Such providers should therefore pay particular attention on how their services are used to disseminate or amplify misleading or deceptive content, including disinformation. Where the algorithmic amplification of information contributes to the systemic risks, those providers should duly reflect this in their risk assessments. Where risks are localised or there are linguistic differences, those providers should also account for this in their risk assessments. Providers of very large online platforms and of very large online search engines should, in particular, assess how the design and functioning of their service, as well as the intentional and, oftentimes, coordinated manipulation and use of their services, or the systemic infringement of their terms of service, contribute to such risks. Such risks may arise, for example, through the inauthentic use of the service, such as the creation of fake accounts, the use of bots or deceptive use of a service, and other automated or partially automated behaviours, which may lead to the rapid and widespread dissemination to the public of information that is illegal content or incompatible with an online platform's or online search engine's terms and conditions and that contributes to disinformation campaigns.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to assess potential risks posed by their systems, including algorithms, data collection, and advertising. They must evaluate whether their terms of service, content moderation processes, and resources are sufficient. The DSA also mandates these providers to examine non-illegal information that could contribute to systemic risks, such as the spread of misleading or deceptive content. The law also requires these providers to consider how their services' design and misuse can contribute to such risks, including fake accounts and bot usage. If systemic risks are identified, they must be reflected in their risk assessments. The DSA also requires providers to consider local or linguistic differences in their risk assessments."
Digital Markets Act (DMA) - Contextual Paragraph (29),0.728628218,"Details of the Contextual Paragraph (29) in the Digital Markets Act (DMA): Gatekeepers should comply with the obligations laid down in this Regulation in respect of each of the core platform services listed in the relevant designation decision. The obligations should apply taking into account the conglomerate position of gatekeepers, where applicable. Furthermore, it should be possible for the Commission to impose implementing measures on the gatekeeper by decision. Those implementing measures should be designed in an effective manner, having regard to the features of core platform services and the possible circumvention risks, and in compliance with the principle of proportionality and the fundamental rights of the undertakings concerned, as well as those of third parties.",rectial,"The Digital Markets Act (DMA) requires digital gatekeepers to follow specific rules for each of their core platform services. The DMA takes into account if these gatekeepers are part of larger conglomerates. The Commission can enforce these rules by making decisions on implementing measures. These measures should be effective, considering the characteristics of the services and potential risks of circumvention. They should also respect the principle of proportionality and the fundamental rights of the businesses involved and third parties."
General Data Protection Regulation (GDPR) - Contextual Paragraph (163),0.728621,"Details of the Contextual Paragraph (163) in the General Data Protection Regulation (GDPR): The confidential information which the Union and national statistical authorities collect for the production of official European and official national statistics should be protected. European statistics should be developed, produced and disseminated in accordance with the statistical principles as set out in Article 338(2) TFEU, while national statistics should also comply with Member State law. Regulation (EC) No 223/2009 of the European Parliament and of the Council ( 2 ) provides further specifications on statistical confidentiality for European statistics.",recital,"The General Data Protection Regulation (GDPR) has a new provision, Paragraph 163, which emphasizes the protection of confidential information collected by the Union and national statistical authorities for official European and national statistics. This law states that European statistics should be produced and shared according to the principles in Article 338(2) TFEU, and national statistics must comply with Member State law. The law also refers to Regulation (EC) No 223/2009 for further details on maintaining confidentiality in European statistics."
Digital Services Act (DSA) - Article 18 Notification of suspicions of criminal offences,0.728603721,"Article 18 Notification of suspicions of criminal offences in the Digital Services Act (DSA):  1.   Where a provider of hosting services becomes aware of any information giving rise to a suspicion that a criminal offence involving a threat to the life or safety of a person or persons has taken place, is taking place or is likely to take place, it shall promptly inform the law enforcement or judicial authorities of the Member State or Member States concerned of its suspicion and provide all relevant information available.
2.   Where the provider of hosting services cannot identify with reasonable certainty the Member State concerned, it shall inform the law enforcement authorities of the Member State in which it is established or where its legal representative resides or is established or inform Europol, or both.
For the purpose of this Article, the Member State concerned shall be the Member State in which the offence is suspected to have taken place, to be taking place or to be likely to take place, or the Member State where the suspected offender resides or is located, or the Member State where the victim of the suspected offence resides or is located.",article,"The Digital Services Act (DSA) requires online service providers to promptly report any suspicion of a crime threatening someone's life or safety to the law enforcement or judicial authorities of the relevant EU Member State. The service provider should provide all relevant information available. If the service provider cannot confidently identify the relevant Member State, they should report to the law enforcement of the state where they are established, where their legal representative resides, or to Europol. The relevant Member State is defined as the state where the crime is suspected to have occurred, where the suspected offender resides, or where the victim resides."
Digital Services Act (DSA) - Contextual paragraph (123),0.728563607,"Details of the contextual paragraph (123) of the Digital Services Act (DSA): In the interest of clarity, simplicity and effectiveness, the powers to supervise and enforce the obligations under this Regulation should be conferred to the competent authorities in the Member State where the main establishment of the provider of intermediary services is located, that is, where the provider has its head office or registered office within which the principal financial functions and operational control are exercised. In respect of providers that are not established in the Union, but that offer services in the Union and therefore fall within the scope of this Regulation, the Member State where those providers appointed their legal representative should have competence, considering the function of legal representatives under this Regulation. In the interest of the effective application of this Regulation, all Member States or the Commission, where applicable, should, however, have competence in respect of providers that failed to designate a legal representative. That competence may be exercised by any of the competent authorities or the Commission, provided that the provider is not subject to enforcement proceedings for the same facts by another competent authority or the Commission. In order to ensure that the principle of ne bis in idem is respected, and in particular to avoid that the same infringement of the obligations laid down in this Regulation is sanctioned more than once, each Member State that intends to exercise its competence in respect of such providers should, without undue delay, inform all other authorities, including the Commission, through the information sharing system established for the purpose of this Regulation.",recital,"The Digital Services Act (DSA) states that the primary authority for overseeing and enforcing this law falls to the country where the main office of the digital service provider is located. If the provider is not based in the European Union (EU) but offers services there, the authority goes to the country where their legal representative is based. If a provider doesn't have a legal representative, any EU country or the EU Commission can enforce the law. However, they must ensure that the provider isn't already facing enforcement for the same issue elsewhere, to avoid punishing the same violation twice. If a country plans to enforce the law, they must inform all other authorities promptly."
General Data Protection Regulation (GDPR) - Contextual Paragraph (152),0.728554368,"Details of the Contextual Paragraph (152) in the General Data Protection Regulation (GDPR): Where this Regulation does not harmonise administrative penalties or where necessary in other cases, for example in cases of serious infringements of this Regulation, Member States should implement a system which provides for effective, proportionate and dissuasive penalties. The nature of such penalties, criminal or administrative, should be determined by Member State law",recital,"The General Data Protection Regulation (GDPR) has a section (Paragraph 152) that advises countries to set up systems for penalties if the GDPR rules are broken. These penalties should be effective, fair, and strong enough to deter people from breaking the rules. The type of penalty (criminal or administrative) should be decided by each country's own laws. This is especially important in cases of serious violations of the GDPR."
Digital Markets Act (DMA) - Contextual Paragraph (105),0.728552222,"Details of the Contextual Paragraph (105) in the Digital Markets Act (DMA): The Commission should periodically evaluate this Regulation and closely monitor its effects on the contestability and fairness of commercial relationships in the online platform economy, in particular with a view to determining the need for amendments in light of relevant technological or commercial developments. That evaluation should include the regular review of the list of core platform services and the obligations addressed to gatekeepers, as well as their enforcement, in view of ensuring that digital markets across the Union are contestable and fair. In that context, the Commission should also evaluate the scope of the obligation concerning the interoperability of number-independent electronic communications services. In order to obtain a broad view of developments in the digital sector, the evaluation should take into account the experiences of Member States and relevant stakeholders. It should be possible for the Commission in this regard also to consider the opinions and reports presented to it by the Observatory on the Online Platform Economy that was first established by Commission Decision C(2018)2393 of 26 April 2018. Following the evaluation, the Commission should take appropriate measures. The Commission should maintain a high level of protection and respect for the common rights and values, particularly equality and non-discrimination, as an objective when conducting the assessments and reviews of the practices and obligations provided in this Regulation.",rectial,"The Digital Markets Act (DMA) requires the European Commission to regularly review and evaluate the regulation's impact on online platform economy's fairness and competitiveness. This includes assessing the list of core platform services, the obligations of gatekeepers, and their enforcement. The Commission also needs to evaluate the interoperability of independent electronic communication services. The assessment should consider the experiences of Member States and relevant stakeholders, and may include opinions from the Observatory on the Online Platform Economy. After the evaluation, the Commission will take necessary measures. Throughout this process, the Commission must ensure high protection and respect for common rights and values, such as equality and non-discrimination."
Digital Services Act (DSA) - Contextual paragraph (133),0.728552,"Details of the contextual paragraph (133) of the Digital Services Act (DSA): For that purpose, the Board should be able to adopt opinions, requests and recommendations addressed to Digital Services Coordinators or other competent national authorities. While not legally binding, the decision to deviate therefrom should be properly explained and could be taken into account by the Commission in assessing the compliance of the Member State concerned with this Regulation.",recital,"The Digital Services Act (DSA) includes a provision (paragraph 133) that allows a governing body to provide opinions, requests, and recommendations to Digital Services Coordinators or other relevant national authorities. These aren't legally mandatory, but if a member state chooses not to follow them, they must provide a valid explanation. The European Commission can consider this when evaluating if the member state is following the DSA rules."
Digital Markets Act (DMA) - Contextual Paragraph (107),0.72849828,"Details of the Contextual Paragraph (107) in the Digital Markets Act (DMA): Since the objective of this Regulation, namely to ensure a contestable and fair digital sector in general and core platform services in particular, with a view to promoting innovation, high quality of digital products and services, fair and competitive prices, as well as a high quality and choice for end users in the digital sector, cannot be sufficiently achieved by the Member States, but can rather, by reason of the business model and operations of the gatekeepers and the scale and effects of their operations, be better achieved at Union level, the Union may adopt measures, in accordance with the principle of subsidiarity as set out in Article 5 TEU. In accordance with the principle of proportionality, as set out in that Article, this Regulation does not go beyond what is necessary in order to achieve that objective.",rectial,"The Digital Markets Act (DMA) aims to ensure fairness and competition in the digital sector, particularly in core platform services. It aims to promote innovation, high-quality digital products and services, competitive pricing, and a wide range of choices for end users. The DMA believes that these goals can be better achieved at the Union level, rather than by individual Member States, due to the business model and operations of the digital gatekeepers. The DMA will adopt measures following the principle of subsidiarity, meaning it will only intervene when necessary. It also follows the principle of proportionality, ensuring it doesn't exceed what is necessary to achieve its objective."
General Data Protection Regulation (GDPR) - Contextual Paragraph (101),0.728448808,"Details of the Contextual Paragraph (101) in the General Data Protection Regulation (GDPR): Flows of personal data to and from countries outside the Union and international organisations are necessary for the expansion of international trade and international cooperation. The increase in such flows has raised new challenges and concerns with regard to the protection of personal data. However, when personal data are transferred from the Union to controllers, processors or other recipients in third countries or to international organisations, the level of protection of natural persons ensured in the Union by this Regulation should not be undermined, including in cases of onward transfers of personal data from the third country or international organisation to controllers, processors in the same or another third country or international organisation. In any event, transfers to third countries and international organisations may only be carried out in full compliance with this Regulation. A transfer could take place only if, subject to the other provisions of this Regulation, the conditions laid down in the provisions of this Regulation relating to the transfer of personal data to third countries or international organisations are complied with by the controller or processor.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph (101), regarding the international transfer of personal data. This rule acknowledges that sharing personal data globally is crucial for international trade and cooperation. However, it also recognizes the challenges and concerns this raises for data protection. The rule stipulates that when data is transferred from the EU to other countries or international organizations, it must still uphold the same level of protection for individuals as within the EU. This includes any further transfers of that data. Any data transfers must fully comply with the GDPR, and can only occur if the controller or processor meets all conditions set out in the GDPR for international data transfers."
Digital Markets Act (DMA) - Contextual Paragraph (73),0.728406549,"Details of the Contextual Paragraph (73) in the Digital Markets Act (DMA): In order to ensure the full and lasting achievement of the objectives of this Regulation, the Commission should be able to assess whether an undertaking providing core platform services should be designated as a gatekeeper without meeting the quantitative thresholds laid down in this Regulation; whether systematic non-compliance by a gatekeeper warrants imposing additional remedies; whether more services within the digital sector should be added to the list of core platform services; and whether additional practices that are similarly unfair and limiting the contestability of digital markets need to be investigated. Such assessment should be based on market investigations to be carried out in an appropriate timeframe, by using clear procedures and deadlines, in order to support the ex ante effect of this Regulation on contestability and fairness in the digital sector, and to provide the requisite degree of legal certainty.",rectial,"The Digital Markets Act (DMA) sets new rules for digital platforms. The law allows the Commission to decide if a company providing core digital services should be considered a ""gatekeeper,"" even if it doesn't meet certain size requirements. The Commission can also determine if a gatekeeper is not following the rules and needs further regulation. It can decide if more digital services should be considered ""core"" services, and if there are other unfair practices that need to be investigated. These decisions will be based on market investigations done in a timely manner, with clear procedures and deadlines. This is to ensure fairness in the digital market and provide legal certainty."
Digital Markets Act (DMA) - Contextual Paragraph (1),0.728394,"Details of the Contextual Paragraph (1) in the Digital Markets Act (DMA): Digital services in general and online platforms in particular play an increasingly important role in the economy, in particular in the internal market, by enabling businesses to reach users throughout the Union, by facilitating crossborder trade and by opening entirely new business opportunities to a large number of companies in the Union to the benefit of consumers in the Union",rectial,"The Digital Markets Act (DMA) acknowledges that digital services, especially online platforms, have become crucial in the economy. These platforms help businesses reach customers all over the European Union, assist in cross-border trade, and create new opportunities for many companies. This benefits consumers throughout the Union."
Digital Markets Act (DMA) - Contextual Paragraph (61),0.728382885,"Details of the Contextual Paragraph (61) in the Digital Markets Act (DMA): The value of online search engines to their respective business users and end users increases as the total number of such users increases. Undertakings providing online search engines collect and store aggregated datasets containing information about what users searched for, and how they interacted with, the results with which they were provided. Undertakings providing online search engines collect these data from searches undertaken on their own online search engine and, where applicable, searches undertaken on the platforms of their downstream commercial partners. Access by gatekeepers to such ranking, query, click and view data constitutes an important barrier to entry and expansion, which undermines the contestability of online search engines. Gatekeepers should therefore be required to provide access, on fair, reasonable and non-discriminatory terms, to those ranking, query, click and view data in relation to free and paid search generated by consumers on online search engines to other undertakings providing such services, so that those third-party undertakings can optimise their services and contest the relevant core platform services. Such access should also be given to third parties contracted by a provider of an online search engine, who are acting as processors of this data for that online search engine. When providing access to its search data, a gatekeeper should ensure the protection of the personal data of end users, including against possible re-identification risks, by appropriate means, such as anonymisation of such personal data, without substantially degrading the quality or usefulness of the data. The relevant data is anonymised if personal data is irreversibly altered in such a way that information does not relate to an identified or identifiable natural person or where personal data is rendered anonymous in such a manner that the data subject is not or is no longer identifiable.",rectial,"The Digital Markets Act (DMA) outlines new rules for online search engines. These companies collect data about user searches and interactions, which is valuable for their business and increases with more users. This data, however, can create a barrier for new companies entering the market. The DMA requires these 'gatekeeper' companies to share this data with other companies in a fair and non-discriminatory way, allowing them to improve their services and compete more effectively. This also applies to third parties working for the search engine company. However, these gatekeepers must ensure user personal data is protected, including from potential re-identification, by anonymizing it without reducing its usefulness. Anonymized data is data that has been altered so it can't be linked to an identifiable person."
Digital Markets Act (DMA) - Contextual Paragraph (43),0.728356481,"Details of the Contextual Paragraph (43) in the Digital Markets Act (DMA): Certain services provided together with, or in support of, relevant core platform services of the gatekeeper, such as identification services, web browser engines, payment services or technical services that support the provision of payment services, such as payment systems for in-app purchases, are crucial for business users to conduct their business and allow them to optimise services. In particular, each browser is built on a web browser engine, which is responsible for key browser functionality such as speed, reliability and web compatibility. When gatekeepers operate and impose web browser engines, they are in a position to determine the functionality and standards that will apply not only to their own web browsers, but also to competing web browsers and, in turn, to web software applications. Gatekeepers should therefore not use their position to require their dependent business users to use any of the services provided together with, or in support of, core platform services by the gatekeeper itself as part of the provision of services or products by those business users. In order to avoid a situation in which gatekeepers indirectly impose on business users their own services provided together with, or in support of, core platform services, gatekeepers should also be prohibited from requiring end users to use such services, when that requirement would be imposed in the context of the service provided to end users by the business user using the core platform service of the gatekeeper. That prohibition aims to protect the freedom of the business user to choose alternative services to the ones of the gatekeeper, but should not be construed as obliging the business user to offer such alternatives to its end users.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 43) aimed at protecting businesses from potential monopolistic practices by digital platform providers, often referred to as ""gatekeepers"". The law focuses on services that are essential for businesses to operate, such as identification, payment, and web browser services. Gatekeepers often provide these services and can potentially control their functionality and standards. The DMA prohibits gatekeepers from forcing businesses to use these services as part of their own offerings. This rule also extends to end users, preventing gatekeepers from requiring them to use these services. The goal is to protect business' freedom to choose alternative services, but it doesn't obligate businesses to offer such alternatives to their customers."
General Data Protection Regulation (GDPR) - Contextual Paragraph (16),0.728323638,"Details of the Contextual Paragraph (16) in the General Data Protection Regulation (GDPR): This Regulation does not apply to issues of protection of fundamental rights and freedoms or the free flow of personal data related to activities which fall outside the scope of Union law, such as activities concerning national security. This Regulation does not apply to the processing of personal data by the Member States when carrying out activities in relation to the common foreign and security policy of the Union.",recital,"The General Data Protection Regulation (GDPR) has a clause known as Paragraph (16) that states the regulation doesn't apply to certain activities. These include activities outside the scope of Union law, like those related to national security, or when Member States are handling personal data related to the Union's common foreign and security policy. In simpler terms, GDPR rules don't apply to everything - especially not matters of national security or foreign policy."
Artifical Inellegence Act (AI Act) - Overview paragraph 25,0.728268147,"Aritifical Intelligence Act (AI Act) overview paragraph (25): In accordance with Article 6a of Protocol No 21 on the position of the United Kingdom and Ireland in respect of the area of freedom, security and justice, as annexed to the TEU and to the TFEU, Ireland is not bound by the rules laid down in Article 5(1), point (d), (2) and (3) of this Regulation adopted on the basis of Article 16 of the TFEU which relate to the processing of personal data by the Member States when carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title V of Part Three of the TFEU, where Ireland is not bound by the rules governing the forms of judicial cooperation in criminal matters or police cooperation which require compliance with the provisions laid down on the basis of Article 16 of the TFEU.",recital,"The Artificial Intelligence Act (AI Act) has new rules about how personal data is processed. However, these rules don't apply to Ireland due to the specifics of its relationship with the United Kingdom and the rest of the European Union. Specifically, Ireland isn't required to follow these rules when conducting activities under certain chapters of the Treaty on the Functioning of the European Union (TFEU). This is because Ireland isn't bound by certain rules about cooperation in criminal matters or police cooperation that require compliance with provisions based on Article 16 of the TFEU."
Digital Services Act (DSA) - Contextual paragraph (13),0.72822994,"Details of the contextual paragraph (13) of the Digital Services Act (DSA): Considering the particular characteristics of the services concerned and the corresponding need to make the providers thereof subject to certain specific obligations, it is necessary to distinguish, within the broader category of providers of hosting services as defined in this Regulation, the subcategory of online platforms. Online platforms, such as social networks or online platforms allowing consumers to conclude distance contracts with traders, should be defined as providers of hosting services that not only store information provided by the recipients of the service at their request, but that also disseminate that information to the public at the request of the recipients of the service. However, in order to avoid imposing overly broad obligations, providers of hosting services should not be considered as online platforms where the dissemination to the public is merely a minor and purely ancillary feature that is intrinsically linked to another service, or a minor functionality of the principal service, and that feature or functionality cannot, for objective technical reasons, be used without that other or principal service, and the integration of that feature or functionality is not a means to circumvent the applicability of the rules of this Regulation applicable to online platforms. For example, the comments section in an online newspaper could constitute such a feature, where it is clear that it is ancillary to the main service represented by the publication of news under the editorial responsibility of the publisher. In contrast, the storage of comments in a social network should be considered an online platform service where it is clear that it is not a minor feature of the service offered, even if it is ancillary to publishing the posts of recipients of the service. For the purposes of this Regulation, cloud computing or web-hosting services should not be considered to be an online platform where dissemination of specific information to the public constitutes a minor and ancillary feature or a minor functionality of such services.
Moreover, cloud computing services and web-hosting services, when serving as infrastructure, such as the underlying infrastructural storage and computing services of an internet-based application, website or online platform, should not in themselves be considered as disseminating to the public information stored or processed at the request of a recipient of the application, website or online platform which they host.",recital,"The Digital Services Act (DSA) differentiates between online platforms and other hosting service providers. Online platforms, like social networks or e-commerce sites, not only store user information but also share it publicly. However, if sharing is a minor feature linked to another service, the provider isn't considered an online platform. An example is a comments section in an online newspaper, which is secondary to the main news service. But if comments are a significant part of a service, like on social networks, it's considered an online platform. Cloud computing or web-hosting services aren't considered online platforms if public sharing is a minor feature. They also aren't responsible for public dissemination of information they host for apps, websites, or online platforms."
General Data Protection Regulation (GDPR) - Contextual Paragraph (165),0.728229105,"Details of the Contextual Paragraph (165) in the General Data Protection Regulation (GDPR): This Regulation respects and does not prejudice the status under existing constitutional law of churches and religious associations or communities in the Member States, as recognised in Article 17 TFEU.",recital,"The General Data Protection Regulation (GDPR) is a new law that protects personal data. Paragraph 165 of the GDPR specifically states that this law respects the current legal status of churches and religious communities in the member states, as recognized in Article 17 TFEU. This means that the GDPR does not affect or change the existing rights and position of these religious organizations under constitutional law."
Digital Markets Act (DMA) - Contextual Paragraph (8),0.728148282,"Details of the Contextual Paragraph (8) in the Digital Markets Act (DMA): By approximating diverging national laws, it is possible to eliminate obstacles to the freedom to provide and receive services, including retail services, within the internal market. A targeted set of harmonised legal obligations should therefore be established at Union level to ensure contestable and fair digital markets featuring the presence of gatekeepers within the internal market to the benefit of the Union""s economy as a whole and ultimately of the Union""s consumers.",rectial,"The Digital Markets Act (DMA) aims to standardize different national laws to remove barriers to providing and receiving services, including retail, within the internal market. This law introduces a specific set of legal obligations at the Union level to ensure fair competition in digital markets. This is done by regulating the presence of gatekeepers, or dominant market players. The DMA is intended to benefit the Union's economy and consumers."
Digital Services Act (DSA) - Article 32 Right to information,0.728140712,"Article 32 Right to information in the Digital Services Act (DSA):  1.   Where a provider of an online platform allowing consumers to conclude distance contracts with traders becomes aware, irrespective of the means used, that an illegal product or service has been offered by a trader to consumers located in the Union through its services, that provider shall inform, insofar as it has their contact details, consumers who purchased the illegal product or service through its services of the following:

(a) the fact that the product or service is illegal;
(b) the identity of the trader; and
(c) any relevant means of redress.

The obligation laid down in the first subparagraph shall be limited to purchases of illegal products or services made within the six months preceding the moment that the provider became aware of the illegality.

2.   Where, in the situation referred to in paragraph 1, the provider of the online platform allowing consumers to conclude distance contracts with traders does not have the contact details of all consumers concerned, that provider shall make publicly available and easily accessible on its online interface the information concerning the illegal product or service, the identity of the trader and any relevant means of redress.",article,"The Digital Services Act (DSA) Article 32 requires online platforms to inform customers if they have unknowingly purchased an illegal product or service. This rule applies if the purchase was made within the past six months and the platform has the customer's contact details. The platform must provide information about the illegality of the product or service, the identity of the seller, and possible ways to seek redress. If the platform doesn't have the contact details of the affected customers, it must publicly display this information on its website."
Digital Markets Act (DMA) - Contextual Paragraph (40),0.728083372,"Details of the Contextual Paragraph (40) in the Digital Markets Act (DMA): To prevent further reinforcing their dependence on the core platform services of gatekeepers, and in order to promote multi-homing, the business users of those gatekeepers should be free to promote and choose the distribution channel that they consider most appropriate for the purpose of interacting with any end users that those business users have already acquired through core platform services provided by the gatekeeper or through other channels. This should apply to the promotion of offers, including through a software application of the business user, and any form of communication and conclusion of contracts between business users and end users. An acquired end user is an end user who has already entered into a commercial relationship with the business user and, where applicable, the gatekeeper has been directly or indirectly remunerated by the business user for facilitating the initial acquisition of the end user by the business user. Such commercial relationships can be on either a paid or a free basis, such as free trials or free service tiers, and can have been entered into either on the core platform service of the gatekeeper or through any other channel. Conversely, end users should also be free to choose offers of such business users and to enter into contracts with them either through core platform services of the gatekeeper, if applicable, or from a direct distribution channel of the business user or another indirect channel that such business user uses.",rectial,"The Digital Markets Act (DMA) Paragraph 40 aims to reduce businesses' reliance on dominant online platforms (gatekeepers) for reaching their customers. It allows businesses to freely choose and promote their preferred distribution channels for interacting with existing customers, whether they were originally acquired through the gatekeeper's platform or elsewhere. This applies to all forms of promotion, communication, and contract agreements. Customers, who may have been introduced to the business through a paid or free service from the gatekeeper, should also have the freedom to choose how they engage with businesses, either through the gatekeeper's platform or directly from the business or another platform."
Digital Services Act (DSA) - Article 19 Exclusion for micro and small enterprises,0.728043,"Article 19 Exclusion for micro and small enterprises in the Digital Services Act (DSA):  1.   This Section, with the exception of Article 24(3) thereof, shall not apply to providers of online platforms that qualify as micro or small enterprises as defined in Recommendation 2003/361/EC.
This Section, with the exception of Article 24(3) thereof, shall not apply to providers of online platforms that previously qualified for the status of a micro or small enterprise as defined in Recommendation 2003/361/EC during the 12 months following their loss of that status pursuant to Article 4(2) thereof, except when they are very large online platforms in accordance with Article 33.
2.   By derogation from paragraph 1 of this Article, this Section shall apply to providers of online platforms that have been designated as very large online platforms in accordance with Article 33, irrespective of whether they qualify as micro or small enterprises.",article,"The Digital Services Act (DSA) includes a provision, Article 19, that exempts small and micro online platform providers from certain regulations. These providers are defined by Recommendation 2003/361/EC. Even if a company loses its status as a small or micro enterprise, it is still exempt for 12 months, unless it's classified as a very large online platform. However, if an online platform is designated as a very large online platform under Article 33, it must follow the regulations in this section, regardless of its size."
Digital Markets Act (DMA) - Contextual Paragraph (74),0.728001177,"Details of the Contextual Paragraph (74) in the Digital Markets Act (DMA): The Commission should be able to find, following a market investigation, that an undertaking providing a core platform service fulfils all of the overarching qualitative criteria for being identified as a gatekeeper. That undertaking should then, in principle, comply with all of the relevant obligations laid down by this Regulation. However, for gatekeepers that have been designated by the Commission because it is foreseeable that they will enjoy an entrenched and durable position in the near future, the Commission should only impose those obligations that are necessary and appropriate to prevent that the gatekeeper concerned achieves an entrenched and durable position in its operations. With respect to such emerging gatekeepers, the Commission should take into account that this status is in principle of a temporary nature, and it should therefore be decided at a given moment whether such an undertaking providing core platform services should be subjected to the full set of gatekeeper obligations because it has acquired an entrenched and durable position, or the conditions for designation are ultimately not met and therefore all previously imposed obligations should be waived.",rectial,"The Digital Markets Act (DMA) allows the Commission to identify a company providing core platform services as a ""gatekeeper"" if it meets certain criteria. Once identified, the company must follow all obligations set by this law. However, if the Commission predicts that a company will soon have a strong, long-lasting position in the market, it can only enforce necessary obligations to prevent the company from gaining too much power. This status is usually temporary. At a certain point, the Commission will decide if the company has gained a strong, long-lasting position and should follow all gatekeeper obligations, or if it doesn't meet the criteria and all obligations should be removed."
General Data Protection Regulation (GDPR) - Contextual Paragraph (84),0.727974951,"Details of the Contextual Paragraph (84) in the General Data Protection Regulation (GDPR): In order to enhance compliance with this Regulation where processing operations are likely to result in a high risk to the rights and freedoms of natural persons, the controller should be responsible for the carrying-out of a data protection impact assessment to evaluate, in particular, the origin, nature, particularity and severity of that risk. The outcome of the assessment should be taken into account when determining the appropriate measures to be taken in order to demonstrate that the processing of personal data complies with this Regulation. Where a data-protection impact assessment indicates that processing operations involve a high risk which the controller cannot mitigate by appropriate measures in terms of available technology and costs of implementation, a consultation of the supervisory authority should take place prior to the processing.",recital,"The General Data Protection Regulation (GDPR) requires companies to conduct a data protection impact assessment if their data processing activities might pose a high risk to individual rights and freedoms. This assessment should consider the source, nature, and severity of the risk. The results of this assessment will guide the company in taking necessary steps to ensure they're handling personal data in compliance with GDPR. If the assessment shows a high risk that the company can't mitigate with available technology or without incurring excessive costs, they must consult with a supervisory authority before proceeding with the data processing."
Digital Services Act (DSA) - Contextual paragraph (56),0.727973044,"Details of the contextual paragraph (56) of the Digital Services Act (DSA): A provider of hosting services may in some instances become aware, such as through a notice by a notifying party or through its own voluntary measures, of information relating to certain activity of a recipient of the service, such as the provision of certain types of illegal content, that reasonably justify, having regard to all relevant circumstances of which the provider of hosting services is aware, the suspicion that that recipient may have committed, may be committing or is likely to commit a criminal offence involving a threat to the life or safety of person or persons, such as offences specified in Directive 2011/36/EU of the European Parliament and of the Council (27), Directive 2011/93/EU or Directive (EU) 2017/541 of the European Parliament and of the Council (28). For example, specific items of content could give rise to a suspicion of a threat to the public, such as incitement to terrorism within the meaning of Article 21 of Directive (EU) 2017/541. In such instances, the provider of hosting services should inform without delay the competent law enforcement authorities of such suspicion. The provider of hosting services should provide all relevant information available to it, including, where relevant, the content in question and, if available, the time when the content was published, including the designated time zone, an explanation of its suspicion and the information necessary to locate and identify the relevant recipient of the service. This Regulation does not provide the legal basis for profiling of recipients of the services with a view to the possible identification of criminal offences by providers of hosting services. Providers of hosting services should also respect other applicable rules of Union or national law for the protection of the rights and freedoms of individuals when informing law enforcement authorities.",recital,"The Digital Services Act (DSA) states that if a hosting service provider suspects that a user is involved in illegal activities that could threaten lives or safety, they should inform law enforcement immediately. This suspicion might arise from a user sharing illegal content or from a notice by a third party. The hosting service provider should provide all relevant information, such as the content in question, when it was posted, and any information that could help identify the user. However, the DSA does not allow providers to profile users to identify potential criminal activity. The providers must still respect individuals' rights and freedoms when informing law enforcement."
Digital Services Act (DSA) - Contextual paragraph (130),0.727971911,"Details of the contextual paragraph (130) of the Digital Services Act (DSA): In order to facilitate cross-border supervision and investigations of obligations laid down in this Regulation involving several Member States, the Digital Services Coordinators of establishment should be able, through the information sharing system, to invite other Digital Services Coordinators to a joint investigation concerning an alleged infringement of this Regulation. Other Digital Services Coordinators, and other competent authorities, where appropriate, should be able to join the investigation proposed by the Digital Services Coordinator of establishment, unless the latter considers that an excessive number of participating authorities may affect the effectiveness of the investigation taking into account the features of the alleged infringement and the lack of direct effects on the recipients of the service in those Member States. Joint investigation activities may include a variety of actions to be coordinated by the Digital Services Coordinator of establishment in accordance with the availabilities of the participating authorities, such as coordinated data gathering exercises, pooling of resources, task forces, coordinated requests for information or common inspections of premises. All competent authorities participating in a joint investigation should cooperate with the Digital Services Coordinator of establishment, including by exercising their powers of investigation within their territory, in accordance with the applicable national procedures. The joint investigation should be concluded within a given timeframe with a final report taking into account the contribution of all participating competent authorities. Also the Board, where this is requested by at least three Digital Services Coordinators of destination, may recommend to a Digital Services Coordinator of establishment to launch such joint investigation and give indications on its organisation. In order to avoid deadlocks, the Board should be able to refer the matter to the Commission in specific cases, including where the Digital Services Coordinator of establishment refuses to launch the investigation and the Board does not agree with the justification given.",recital,"The Digital Services Act (DSA) allows for cross-border investigations into potential violations of the regulation. This means that Digital Services Coordinators from different countries can work together to investigate alleged infringements. These joint investigations can include various coordinated actions, such as data gathering and inspections. If at least three Coordinators request it, the Board can recommend launching a joint investigation. If a Coordinator refuses to start an investigation and the Board disagrees with their reasoning, the Board can refer the issue to the Commission. The aim of these provisions is to ensure effective and cooperative investigations into potential violations of the DSA."
General Data Protection Regulation (GDPR) - Contextual Paragraph (111),0.727929354,"Details of the Contextual Paragraph (111) in the General Data Protection Regulation (GDPR): Provisions should be made for the possibility for transfers in certain circumstances where the data subject has given his or her explicit consent, where the transfer is occasional and necessary in relation to a contract or a legal claim, regardless of whether in a judicial procedure or whether in an administrative or any out-of-court procedure, including procedures before regulatory bodies. Provision should also be made for the possibility for transfers where important grounds of public interest laid down by Union or Member State law so require or where the transfer is made from a register established by law and intended for consultation by the public or persons having a legitimate interest. In the latter case, such a transfer should not involve the entirety of the personal data or entire categories of the data contained in the register and, when the register is intended for consultation by persons having a legitimate interest, the transfer should be made only at the request of those persons or, if they are to be the recipients, taking into full account the interests and fundamental rights of the data subject.",recital,"The General Data Protection Regulation (GDPR) allows for the transfer of personal data under certain conditions. These include when the person has given clear consent, the transfer is occasional and necessary for a contract or legal claim, or if there are significant public interest reasons. Transfers can also be made from a public register, but not all personal data or categories of data can be transferred. If the register is for those with a legitimate interest, the transfer should only be made at their request, considering the interests and rights of the person whose data is being transferred."
Digital Services Act (DSA) - Article 50 Competent authorities,0.727919281,"Article 50 Competent authorities and Digital Services Coordinators in the Digital Services Act (DSA):  1.   Member States shall ensure that their Digital Services Coordinators perform their tasks under this Regulation in an impartial, transparent and timely manner. Member States shall ensure that their Digital Services Coordinators have all necessary resources to carry out their tasks, including sufficient technical, financial and human resources to adequately supervise all providers of intermediary services falling within their competence. Each Member State shall ensure that its Digital Services Coordinator has sufficient autonomy in managing its budget within the budget's overall limits, in order not to adversely affect the independence of the Digital Services Coordinator.

2.   When carrying out their tasks and exercising their powers in accordance with this Regulation, the Digital Services Coordinators shall act with complete independence. They shall remain free from any external influence, whether direct or indirect, and shall neither seek nor take instructions from any other public authority or any private party.

3.   Paragraph 2 of this Article is without prejudice to the tasks of Digital Services Coordinators within the system of supervision and enforcement provided for in this Regulation and the cooperation with other competent authorities in accordance with Article 49(2). Paragraph 2 of this Article shall not prevent the exercise of judicial review and shall also be without prejudice to proportionate accountability requirements regarding the general activities of the Digital Services Coordinators, such as financial expenditure or reporting to national parliaments, provided that those requirements do not undermine the achievement of the objectives of this Regulation.",article,"The Digital Services Act (DSA) requires each member state to have a Digital Services Coordinator who operates impartially, transparently, and promptly. These coordinators must have enough resources, including technical, financial, and human, to supervise all intermediary service providers effectively. They should also have autonomy in managing their budget. 

The DSA insists that these coordinators must act independently, free from any external influence or instructions from any public authority or private party. 

However, this independence does not interfere with their supervisory and enforcement tasks under the DSA or their cooperation with other authorities. It also doesn't prevent judicial review or accountability requirements, such as financial expenditure or reporting to national parliaments, as long as these don't hinder the DSA's objectives."
General Data Protection Regulation (GDPR) - Contextual Paragraph (12),0.727894783,Details of the Contextual Paragraph (12) in the General Data Protection Regulation (GDPR): Article 16(2) TFEU mandates the European Parliament and the Council to lay down the rules relating to the protection of natural persons with regard to the processing of personal data and the rules relating to the free movement of personal data.,recital,"The General Data Protection Regulation (GDPR) is a new law that mandates the European Parliament and the Council to establish rules about the protection of individual's personal data. This includes how personal data is processed and how it can be freely moved. Essentially, it's a law designed to protect your personal information and control how it's used."
Artifical Inellegence Act (AI Act) - Overview paragraph 19,0.727873504,"Aritifical Intelligence Act (AI Act) overview paragraph (19): The use of those systems for the purpose of law enforcement should therefore be prohibited, except in three exhaustively listed and narrowly defined situations, wherethe use is strictly necessary to achieve a substantial public interest, the importance of which outweighs the risks. Those situations involve the search for potential victims of crime, including missing children; certain threats to the life or physical safety of natural persons or of a terrorist attack; and the detection, localisation, identification or prosecution of perpetrators or suspects of the criminal offences referred to in Council Framework Decision 2002/584/JHA38if those criminal offences are punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least three years and as they are defined in the law of that Member State. Such threshold for the custodial sentence or detention order in accordance with national law contributes to ensure that the offence should be serious enough to potentially justify the use of real-time remote biometric identification systems. Moreover,of the 32 criminal offences listed in the Council Framework Decision 2002/584/JHA, some are in practice likely to be more relevant than others, in that the recourse toreal-time remote biometric identificationwill foreseeably be necessary and proportionate to highly varying degrees for the practical pursuit of the detection, localisation, identification or prosecution of a perpetrator or suspect of the different criminal offences listed and having regard to the likely differences inthe seriousness, probability and scale of the harm or possible negative consequences.",recital,"The Artificial Intelligence Act (AI Act) restricts the use of AI systems in law enforcement, except in three specific, narrowly defined situations. These include searching for potential crime victims, such as missing children; dealing with threats to life or safety, including terrorism; and identifying or prosecuting suspects of serious crimes. Serious crimes are defined as those punishable by at least a three-year custodial sentence or detention order in the relevant Member State. The law aims to ensure that the use of real-time remote biometric identification systems is justified by the seriousness of the crime. The relevance of these systems will vary depending on the nature and severity of the crime, as well as the potential harm or negative consequences."
Digital Services Act (DSA) - Contextual paragraph (70),0.727826178,"Details of the contextual paragraph (70) of the Digital Services Act (DSA): A core part of the online platform's business is the manner in which information is prioritised and presented on its online interface to facilitate and optimise access to information for the recipients of the service. This is done, for example, by algorithmically suggesting, ranking and prioritising information, distinguishing through text or other visual representations, or otherwise curating information provided by recipients. Such recommender systems can have a significant impact on the ability of recipients to retrieve and interact with information online, including to facilitate the search of relevant information for recipients of the service and contribute to an improved user experience. They also play an important role in the amplification of certain messages, the viral dissemination of information and the stimulation of online behaviour. Consequently, online platforms should consistently ensure that recipients of their service are appropriately informed about how recommender systems impact the way information is displayed, and can influence how information is presented to them. They should clearly present the parameters for such recommender systems in an easily comprehensible manner to ensure that the recipients of the service understand how information is prioritised for them. Those parameters should include at least the most important criteria in determining the information suggested to the recipient of the service and the reasons for their respective importance, including where information is prioritised based on profiling and their online behaviour.",recital,"The Digital Services Act (DSA) requires online platforms to be more transparent about how they rank and present information to users. This includes how algorithms suggest, rank, and prioritize information. These systems can greatly influence what information users see and interact with online. Therefore, platforms must clearly explain how these systems work and how they can affect what information is shown to users. They must also explain the key factors used in determining what information is suggested to users, including if it's based on their online behavior or profiling. This is to ensure users understand how information is prioritized for them."
Digital Services Act (DSA) - Contextual paragraph (9),0.727769315,"Details of the contextual paragraph (9) of the Digital Services Act (DSA): This Regulation fully harmonises the rules applicable to intermediary services in the internal market with the objective of ensuring a safe, predictable and trusted online environment, addressing the dissemination of illegal content online and the societal risks that the dissemination of disinformation or other content may generate, and within which fundamental rights enshrined in the Charter are effectively protected and innovation is facilitated. Accordingly, Member States should not adopt or maintain additional national requirements relating to the matters falling within the scope of this Regulation, unless explicitly provided for in this Regulation, since this would affect the direct and uniform application of the fully harmonised rules applicable to providers of intermediary services in accordance with the objectives of this Regulation. This should not preclude the possibility of applying other national legislation applicable to providers of intermediary services, in compliance with Union law, including Directive 2000/31/EC, in particular its Article 3, where the provisions of national law pursue other legitimate public interest objectives than those pursued by this Regulation.",recital,"The Digital Services Act (DSA) is a new law that standardizes rules for online intermediary services across the internal market. The goal is to create a safe, predictable, and trustworthy online environment by addressing the spread of illegal content and disinformation. It also aims to protect fundamental rights and encourage innovation. Member States should not impose additional national requirements unless explicitly stated in this law, to ensure uniform application of these rules. However, this does not prevent the application of other national laws that comply with Union law, as long as they pursue legitimate public interest objectives."
General Data Protection Regulation (GDPR) - Article 81 Suspension of proceedings,0.727757514,"Details of Article 81 Suspension of proceedings in the General Data Protection Regulation (GDPR): 1. Where a competent court of a Member State has information on proceedings, concerning the same subject matter as regards processing by the same controller or processor, that are pending in a court in another Member State, it shall contact that court in the other Member State to confirm the existence of such proceedings. 2. Where proceedings concerning the same subject matter as regards processing of the same controller or processor are pending in a court in another Member State, any competent court other than the court first seized may suspend its proceedings. 3. Where those proceedings are pending at first instance, any court other than the court first seized may also, on the application of one of the parties, decline jurisdiction if the court first seized has jurisdiction over the actions in question and its law permits the consolidation thereof.",article,"Article 81 of the General Data Protection Regulation (GDPR) addresses how courts handle cases involving the same data processing issue in different EU member states. If a court realizes another court in a different state is handling a similar case, it must contact that court to confirm. If confirmed, any court, except the first one to handle the case, can pause their proceedings. Additionally, if a party involved in the case requests it and the first court's laws allow, any other court can decline jurisdiction over the case."
Digital Markets Act (DMA) - Contextual Paragraph (95),0.727710247,Details of the Contextual Paragraph (95) in the Digital Markets Act (DMA): It should be possible for the Commission to develop guidelines to provide further guidance on different aspects of this Regulation or to assist undertakings providing core platform services in the implementation of the obligations under this Regulation. It should be possible for such guidance to be based in particular on the experience that the Commission obtains through the monitoring of compliance with this Regulation. The issuing of any guidelines under this Regulation is a prerogative and at the sole discretion of the Commission and should not be considered to be a constitutive element in ensuring that the undertakings or associations of undertakings concerned comply with the obligations under this Regulation.,rectial,"The Digital Markets Act (DMA) allows the Commission to create guidelines to help businesses that provide core platform services understand and follow the rules of the Act. These guidelines can be based on the Commission's experiences in monitoring compliance with the Act. However, creating these guidelines is entirely up to the Commission and they are not a mandatory part of ensuring businesses comply with the Act's obligations."
Digital Services Act (DSA) - Contextual paragraph (156),0.727608919,"Details of the contextual paragraph (156) of the Digital Services Act (DSA): The European Data Protection Supervisor was consulted in accordance with Article 42(1) of Regulation (EU) 2018/1725 of the European Parliament and of the Council (36) and delivered an opinion on 10 February 2021 (37),",recital,"The Digital Services Act (DSA) is a new law that involves the European Data Protection Supervisor. This official was asked for their opinion on the law, as required by another law, Regulation (EU) 2018/1725. This consultation took place on 10 February 2021. The DSA is designed to regulate digital services in the European Union, with input from data protection authorities to ensure privacy and data rights are respected."
General Data Protection Regulation (GDPR) - Contextual Paragraph (68),0.727587402,"Details of the Contextual Paragraph (68) in the General Data Protection Regulation (GDPR): To further strengthen the control over his or her own data, where the processing of personal data is carried out by automated means, the data subject should also be allowed to receive personal data concerning him or her which he or she has provided to a controller in a structured, commonly used, machine-readable and interoperable format, and to transmit it to another controller. Data controllers should be encouraged to develop interoperable formats that enable data portability. That right should apply where the data subject provided the personal data on the basis of his or her consent or the processing is necessary for the performance of a contract. It should not apply where processing is based on a legal ground other than consent or contract. By its very nature, that right should not be exercised against controllers processing personal data in the exercise of their public duties. It should therefore not apply where the processing of the personal data is necessary for compliance with a legal obligation to which the controller is subject or for the performance of a task carried out in the public interest or in the exercise of an official authority vested in the controller. The data subject's right to transmit or receive personal data concerning him or her should not create an obligation for the controllers to adopt or maintain processing systems which are technically compatible. Where, in a certain set of personal data, more than one data subject is concerned, the right to receive the personal data should be without prejudice to the rights and freedoms of other data subjects in accordance with this Regulation. Furthermore, that right should not prejudice the right of the data subject to obtain the erasure of personal data and the limitations of that right as set out in this Regulation and should, in particular, not imply the erasure of personal data concerning the data subject which have been provided by him or her for the performance of a contract to the extent that and for as long as the personal data are necessary for the performance of that contract. Where technically feasible, the data subject should have the right to have the personal data transmitted directly from one controller to another.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 68) that allows individuals to have more control over their personal data. If the data is processed automatically, individuals have the right to receive their data in a commonly used, machine-readable format, and can transfer it to another data controller. This right only applies if the individual provided the data through consent or for a contract. It doesn't apply if the data is processed for legal reasons or public duties. The law doesn't require data controllers to have compatible systems. If multiple individuals are involved, their rights are not affected. The right to transfer data doesn't affect the right to erase data, unless it's needed for a contract. If possible, individuals can have their data transferred directly from one controller to another."
General Data Protection Regulation (GDPR) - Contextual Paragraph (64),0.727583349,"Details of the Contextual Paragraph (64) in the General Data Protection Regulation (GDPR): The controller should use all reasonable measures to verify the identity of a data subject who requests access, in particular in the context of online services and online identifiers. A controller should not retain personal data for the sole purpose of being able to react to potential requests.",recital,"The General Data Protection Regulation (GDPR) requires companies (controllers) to make sure they know who you are before they give you access to your data, especially online. However, they can't keep your personal data just in case you might make a request in the future."
Digital Services Act (DSA) - Article 69 Power to conduct inspections,0.727581799,"Article 69 Power to conduct inspections in the Digital Services Act (DSA):  1.   In order to carry out the tasks assigned to it under this Section, the Commission may conduct all necessary inspections at the premises of the provider of the very large online platform or of the very large online search engine concerned or of another person referred to in Article 67(1).

2.   The officials and other accompanying persons authorised by the Commission to conduct an inspection shall be empowered to:

(a) enter any premises, land and means of transport of the provider of the very large online platform or of the very large online search engine concerned or of the other person concerned;
(b) examine the books and other records related to the provision of the service concerned, irrespective of the medium on which they are stored;
(c) take or obtain in any form copies of or extracts from such books or other records;
(d) require the provider of the very large online platform or of the very large online search engine or the other person concerned to provide access to and explanations on its organisation, functioning, IT system, algorithms, data-handling and business practices and to record or document the explanations given;
(e) seal any premises used for purposes related to the trade, business, craft or profession of the provider of the very large online platform or of the very large online search engine or of the other person concerned, as well as books or other records, for the period and to the extent necessary for the inspection;
(f) ask any representative or member of staff of the provider of the very large online platform or of the very large online search engine or the other person concerned for explanations on facts or documents relating to the subject-matter and purpose of the inspection and to record the answers;
(g) address questions to any such representative or member of staff relating to the subject-matter and purpose of the inspection and to record the answers.

3.   Inspections may be carried out with the assistance of auditors or experts appointed by the Commission pursuant to Article 72(2), and of Digital Services Coordinator or other competent national authorities of the Member State in the territory of which the inspection is conducted.

4.   Where the production of required books or other records related to the provision of the service concerned is incomplete or where the answers to questions asked under paragraph 2 of this Article are incorrect, incomplete or misleading, the officials and other accompanying persons authorised by the Commission to conduct an inspection shall exercise their powers upon production of a written authorisation specifying the subject matter and purpose of the inspection and the penalties provided for in Articles 74 and 76. In good time before the inspection, the Commission shall inform the Digital Services Coordinator of the Member State in the territory in which the inspection is to be conducted thereof.

5.   During inspections, the officials and other accompanying persons authorised by the Commission, the auditors and experts appointed by the Commission, the Digital Services Coordinator or the other competent authorities of the Member State in the territory of which the inspection is conducted may require the provider of the very large online platform or of the very large online search engine or other person concerned to provide explanations on its organisation, functioning, IT system, algorithms, data-handling and business conducts, and may address questions to its key personnel.

6.   The provider of the very large online platform or of the very large online search engine or other natural or legal person concerned shall be required to submit to an inspection ordered by decision of the Commission. The decision shall specify the subject matter and purpose of the inspection, set the date on which it is to begin and indicate the penalties provided for in Articles 74 and 76 and the right to have the decision reviewed by the Court of Justice of the European Union. The Commission shall consult the Digital Services Coordinator of the Member State on territory of which the inspection is to be conducted prior to taking that decision.

7.   Officials of, and other persons authorised or appointed by, the Digital Services Coordinator of the Member State on the territory of which the inspection is to be conducted shall, at the request of that Digital Services Coordinator or of the Commission, actively assist the officials and other accompanying persons authorised by the Commission in relation to the inspection. To this end, they shall have the powers listed in paragraph 2.

8.   Where the officials and other accompanying persons authorised by the Commission find that the provider of the very large online platform or of the very large online search engine or the other person concerned opposes an inspection ordered pursuant to this Article, the Member State in the territory of which the inspection is to be conducted shall, at the request of those officials or other accompanying persons and in accordance with the national law of the Member State, afford them necessary assistance, including, where appropriate under that national law, in the form of coercive measures taken by a competent law enforcement authority, so as to enable them to conduct the inspection.

9.   If the assistance provided for in paragraph 8 requires authorisation from a national judicial authority in accordance with the national law of the Member State concerned, such authorisation shall be applied for by the Digital Services Coordinator of that Member State at the request of the officials and other accompanying persons authorised by the Commission. Such authorisation may also be applied for as a precautionary measure.

10.   Where the authorisation referred to in paragraph 9 is applied for, the national judicial authority before which a case has been brought shall verify that the Commission decision ordering the inspection is authentic and that the coercive measures envisaged are neither arbitrary nor excessive having regard to the subject matter of the inspection. When conducting such verification, the national judicial authority may ask the Commission, directly or through the Digital Services Coordinators of the Member State concerned, for detailed explanations, in particular those concerning the grounds on which the Commission suspects an infringement of this Regulation, concerning the seriousness of the suspected infringement and concerning the nature of the involvement of the provider of the very large online platform or of the very large online search engine or of the other person concerned. However, the national judicial authority shall not call into question the necessity for the inspection nor demand information from the case file of the Commission. The lawfulness of the Commission decision shall be subject to review only by the Court of Justice of the European Union.",article,"The Digital Services Act (DSA) allows the Commission to inspect large online platforms and search engines. The Commission can enter any premises, examine records, ask for explanations about the organization and its practices, and seal off areas if necessary for the inspection. If the company doesn't provide complete or accurate information, the Commission can enforce penalties. The company must comply with the inspection, and the Commission will inform them of the purpose, start date, and potential penalties. If the company resists the inspection, the Commission can request assistance from the local law enforcement. If judicial authorization is required, it must be sought by the Digital Services Coordinator of the Member State. The national judicial authority can verify the authenticity of the inspection order and ensure it's not arbitrary or excessive. The lawfulness of the Commission's decision can only be reviewed by the Court of Justice of the European Union."
General Data Protection Regulation (GDPR) - Article 31 Cooperation with the supervisory authority,0.727578104,"Details of Article 31 Cooperation with the supervisory authority in the General Data Protection Regulation (GDPR): The controller and the processor and, where applicable, their representatives, shall cooperate, on request, with the supervisory authority in the performance of its tasks.",article,"Article 31 of the General Data Protection Regulation (GDPR) requires that those who control and process data (and their representatives, if applicable) must work together with the supervisory authority when asked. This cooperation is needed for the authority to carry out its duties effectively."
General Data Protection Regulation (GDPR) - Article 53 General conditions for the members of the supervisory authority,0.72757715,"Details of Article 53 General conditions for the members of the supervisory authority in the General Data Protection Regulation (GDPR): 1. Member States shall provide for each member of their supervisory authorities to be appointed by means of a transparent procedure by:  their parliament;  their government;  their head of State; or  an independent body entrusted with the appointment under Member State law. 2. Each member shall have the qualifications, experience and skills, in particular in the area of the protection of personal data, required to perform its duties and exercise its powers. 3. The duties of a member shall end in the event of the expiry of the term of office, resignation or compulsory retirement, in accordance with the law of the Member State concerned. 4. A member shall be dismissed only in cases of serious misconduct or if the member no longer fulfils the conditions required for the performance of the duties.",article,"The General Data Protection Regulation (GDPR) Article 53 outlines rules for appointing members to data protection authorities. Each member must be chosen through a transparent process by the country's parliament, government, head of state, or an independent body. These members need to have the necessary qualifications, experience, and skills, especially in personal data protection. Their term ends when their tenure expires, they resign, or they retire. They can only be dismissed for serious misconduct or if they can no longer fulfill their duties."
General Data Protection Regulation (GDPR) - Contextual Paragraph (109),0.727553785,"Details of the Contextual Paragraph (109) in the General Data Protection Regulation (GDPR): The possibility for the controller or processor to use standard data-protection clauses adopted by the Commission or by a supervisory authority should prevent controllers or processors neither from including the standard data-protection clauses in a wider contract, such as a contract between the processor and another processor, nor from adding other clauses or additional safeguards provided that they do not contradict, directly or indirectly, the standard contractual clauses adopted by the Commission or by a supervisory authority or prejudice the fundamental rights or freedoms of the data subjects. Controllers and processors should be encouraged to provide additional safeguards via contractual commitments that supplement standard protection clauses.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 109) that allows for the use of standard data-protection clauses in contracts by data controllers or processors. These clauses can be part of larger contracts and can be supplemented with additional clauses or safeguards, as long as they don't contradict the standard clauses or infringe on the rights of the individuals whose data is being processed. The GDPR encourages the addition of extra safeguards through contractual commitments."
Digital Services Act (DSA) - Contextual paragraph (64),0.727546394,"Details of the contextual paragraph (64) of the Digital Services Act (DSA): Under certain conditions, providers of online platforms should temporarily suspend their relevant activities in respect of the person engaged in abusive behaviour. This is without prejudice to the freedom by providers of online platforms to determine their terms and conditions and establish stricter measures in the case of manifestly illegal content related to serious crimes, such as child sexual abuse material. For reasons of transparency, this possibility should be set out, clearly and in sufficient detail, in the terms and conditions of the online platforms. Redress should always be open to the decisions taken in this regard by providers of online platforms and they should be subject to oversight by the competent Digital Services Coordinator. Providers of online platforms should send a prior warning before deciding on the suspension, which should include the reasons for the possible suspension and the means of redress against the decision of the providers of the online platform. When deciding on the suspension, providers of online platforms should send the statement of reasons in accordance with the rules set out in this Regulation. The rules of this Regulation on misuse should not prevent providers of online platforms from taking other measures to address the provision of illegal content by recipients of their service or other misuse of their services, including through the violation of their terms and conditions, in accordance with the applicable Union and national law. Those rules are without prejudice to any possibility to hold the persons engaged in misuse liable, including for damages, provided for in Union or national law.",recital,"The Digital Services Act (DSA) allows online platforms to temporarily suspend users who engage in abusive behavior. While platforms can set their own rules, they can also take stricter actions against clearly illegal content, like child sexual abuse material. These rules must be clearly stated in the platform's terms and conditions. Users should be warned before they are suspended and given reasons for the suspension, as well as ways to appeal the decision. The DSA also doesn't stop platforms from taking other actions against illegal content or misuse of their services, in line with their terms and conditions and the law. Users who misuse the platform can be held accountable, including for damages, under the law. The DSA also requires oversight by a competent Digital Services Coordinator."
General Data Protection Regulation (GDPR) - Contextual Paragraph (14),0.72751534,"Details of the Contextual Paragraph (14) in the General Data Protection Regulation (GDPR): The protection afforded by this Regulation should apply to natural persons, whatever their nationality or place of residence, in relation to the processing of their personal data. This Regulation does not cover the processing of personal data which concerns legal persons and in particular undertakings established as legal persons, including the name and the form of the legal person and the contact details of the legal person.",recital,"The General Data Protection Regulation (GDPR) is a new law that protects the personal data of individuals, regardless of their nationality or residence. It applies to the processing of personal data, but does not cover data related to legal entities such as businesses. This means the GDPR is not concerned with information about a company, including its name, structure, or contact details."
Artifical Inellegence Act (AI Act) - Overview paragraph 83,0.727478445,"Aritifical Intelligence Act (AI Act) overview paragraph (83): In order to ensure trustful and constructive cooperation of competent authorities on Union and national level, all parties involved in the application of this Regulation should respect the confidentiality of information and data obtained in carrying out their tasks.",recital,"The Artificial Intelligence Act (AI Act) requires that all parties involved in implementing this law, whether at the national or Union level, must maintain the confidentiality of any information or data they acquire while doing their jobs. This is to promote trust and effective collaboration among the authorities."
Digital Markets Act (DMA) - Contextual Paragraph (100),0.727476478,"Details of the Contextual Paragraph (100) in the Digital Markets Act (DMA): The examination procedure should be used for the adoption of an implementing act on the practical arrangements for the cooperation and coordination between the Commission and Member States. The advisory procedure should be used for the remaining implementing acts envisaged by this Regulation. This is justified by the fact that those remaining implementing acts relate to practical aspects of the procedures laid down in this Regulation, such as form, content and other details of various procedural steps, to practical arrangements of different procedural steps, such as, for example, extension of procedural deadlines or right to be heard, as well as to individual implementing decisions addressed to a gatekeeper.",rectial,"The Digital Markets Act (DMA) introduces new procedures for cooperation between the Commission and Member States. The examination procedure is for implementing acts on practical arrangements for this cooperation. The advisory procedure is for other implementing acts related to the practical aspects of the DMA, such as the form, content, and details of procedural steps. This also includes arrangements for procedural steps like extending deadlines or the right to be heard, as well as individual decisions directed at a gatekeeper."
General Data Protection Regulation (GDPR) - Contextual Paragraph (8),0.727474689,"Details of the Contextual Paragraph (8) in the General Data Protection Regulation (GDPR): Where this Regulation provides for specifications or restrictions of its rules by Member State law, Member States may, as far as necessary for coherence and for making the national provisions comprehensible to the persons to whom they apply, incorporate elements of this Regulation into their national law.",recital,"The General Data Protection Regulation (GDPR) allows member states to adapt its rules into their national laws. This is to ensure consistency and make the laws easier to understand for the people they apply to. This means that countries can tweak the GDPR rules to fit their specific needs, as long as they maintain the overall purpose and principles of the regulation."
General Data Protection Regulation (GDPR) - Article 10 Processing of personal data relating to criminal convictions and offences,0.727414727,Details of Article 10 Processing of personal data relating to criminal convictions and offences in the General Data Protection Regulation (GDPR): Processing of personal data relating to criminal convictions and offences or related security measures based on Article 6(1) shall be carried out only under the control of official authority or when the processing is authorised by Union or Member State law providing for appropriate safeguards for the rights and freedoms of data subjects. Any comprehensive register of criminal convictions shall be kept only under the control of official authority.,article,"Article 10 of the General Data Protection Regulation (GDPR) deals with the handling of personal data related to criminal convictions and offences. This data can only be processed under the supervision of an official authority or when allowed by Union or Member State law, ensuring proper protections for individuals' rights and freedoms. A complete register of criminal convictions must also be maintained under the control of an official authority."
Digital Markets Act (DMA) - Contextual Paragraph (99),0.727395773,"Details of the Contextual Paragraph (99) in the Digital Markets Act (DMA): In order to ensure uniform conditions for the implementation of this Regulation, implementing powers should be conferred on the Commission to specify measures to be implemented by gatekeepers in order to effectively comply with the obligations under this Regulation; to suspend, in whole or in part, a specific obligation imposed on a gatekeeper; to exempt a gatekeeper, in whole or in part, from a specific obligation; to specify the measures to be implemented by a gatekeeper when it circumvents the obligations under this Regulation; to conclude a market investigation for designating gatekeepers; to impose remedies in the case of systematic non-compliance; to order interim measures against a gatekeeper; to make commitments binding on a gatekeeper; to set out its finding of a non-compliance; to set the definitive amount of the periodic penalty payment; to determine the form, content and other details of notifications, submissions of information, reasoned requests and regulatory reports transmitted by gatekeepers; to lay down operational and technical arrangements in view of implementing interoperability and the methodology and procedure for the audited description of techniques used for profiling consumers; to provide for practical arrangements for proceedings, extensions of deadlines, exercising rights during proceedings, terms of disclosure, as well as for the cooperation and coordination between the Commission and national authorities. Those powers should be exercised in accordance with Regulation (EU) No 182/2011.",rectial,"The Digital Markets Act (DMA) gives the European Commission the power to ensure that large online platforms, known as ""gatekeepers"", comply with new regulations. The Commission can specify how these gatekeepers should meet their obligations, suspend or exempt them from certain obligations, and impose penalties for non-compliance. The Commission can also order interim measures against a gatekeeper, make commitments binding, and determine the amount of a penalty payment. The DMA also allows the Commission to set the rules for how gatekeepers notify the Commission and submit information. Additionally, the Commission can establish procedures for implementing interoperability and profiling consumers. All these powers should be exercised in line with Regulation (EU) No 182/2011."
General Data Protection Regulation (GDPR) - Contextual Paragraph (147),0.72739166,"Details of the Contextual Paragraph (147) in the General Data Protection Regulation (GDPR): Where specific rules on jurisdiction are contained in this Regulation, in particular as regards proceedings seeking a judicial remedy including compensation, against a controller or processor, general jurisdiction rules such as those of Regulation (EU) No 1215/2012 of the European Parliament and of the Council ( 1 ) should not prejudice the application of such specific rules.",recital,"The General Data Protection Regulation (GDPR) Paragraph 147 states that if there are specific rules about who has the authority to hear certain cases, especially those related to seeking legal remedies or compensation against a data controller or processor, these rules should be followed. This is the case even if there are general jurisdiction rules, like those in Regulation (EU) No 1215/2012. The specific rules in the GDPR override these general ones."
General Data Protection Regulation (GDPR) - Contextual Paragraph (11),0.727358222,"Details of the Contextual Paragraph (11) in the General Data Protection Regulation (GDPR): Effective protection of personal data throughout the Union requires the strengthening and setting out in detail of the rights of data subjects and the obligations of those who process and determine the processing of personal data, as well as equivalent powers for monitoring and ensuring compliance with the rules for the protection of personal data and equivalent sanctions for infringements in the Member States.",recital,"The General Data Protection Regulation (GDPR) is a new law designed to protect personal data across the European Union. It aims to enhance the rights of individuals (data subjects) and outlines specific obligations for those who handle and decide how personal data is processed. The law also provides authorities with powers to monitor and ensure that these rules are followed. If these rules are broken, the GDPR allows for equal penalties across all member states."
General Data Protection Regulation (GDPR) - Contextual Paragraph (99),0.727342427,"Details of the Contextual Paragraph (99) in the General Data Protection Regulation (GDPR): When drawing up a code of conduct, or when amending or extending such a code, associations and other bodies representing categories of controllers or processors should consult relevant stakeholders, including data subjects where feasible, and have regard to submissions received and views expressed in response to such consultations.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 99) that guides organizations on creating or changing their data handling rules. It advises them to consult with relevant parties, including, if possible, the individuals whose data they hold. They should also consider feedback and opinions received during these consultations."
General Data Protection Regulation (GDPR) - Contextual Paragraph (17),0.727336109,"Details of the Contextual Paragraph (17) in the General Data Protection Regulation (GDPR): Regulation (EC) No 45/2001 of the European Parliament and of the Council ( 2 ) applies to the processing of personal data by the Union institutions, bodies, offices and agencies. Regulation (EC) No 45/2001 and other Union legal acts applicable to such processing of personal data should be adapted to the principles and rules established in this Regulation and applied in the light of this Regulation. In order to provide a strong and coherent data protection framework in the Union, the necessary adaptations of Regulation (EC) No 45/2001 should follow after the adoption of this Regulation, in order to allow application at the same time as this Regulation.",recital,"The General Data Protection Regulation (GDPR) Paragraph 17 states that the existing European law, Regulation (EC) No 45/2001, which governs how personal data is handled by EU institutions, must be updated to align with the new rules and principles established in the GDPR. The aim is to create a strong, consistent data protection framework across the EU. Changes to Regulation (EC) No 45/2001 should be made after the GDPR is adopted, so both regulations can be applied simultaneously."
General Data Protection Regulation (GDPR) - Contextual Paragraph (82),0.727326393,"Details of the Contextual Paragraph (82) in the General Data Protection Regulation (GDPR): In order to demonstrate compliance with this Regulation, the controller or processor should maintain records of processing activities under its responsibility. Each controller and processor should be obliged to cooperate with the supervisory authority and make those records, on request, available to it, so that it might serve for monitoring those processing operations.",recital,"The General Data Protection Regulation (GDPR) requires companies (controllers or processors) to keep records of their data processing activities. This is to prove they're following the law. These companies must also cooperate with the supervisory authority overseeing data protection. If asked, they must provide these records for review to ensure they're handling data correctly."
Digital Services Act (DSA) - Article 84 Professional secrecy,0.727324,"Article 84 Professional secrecy in the Digital Services Act (DSA):  Without prejudice to the exchange and to the use of information referred to in this Chapter, the Commission, the Board, Member States' competent authorities and their respective officials, servants and other persons working under their supervision, and any other natural or legal person involved, including auditors and experts appointed pursuant to Article 72(2), shall not disclose information acquired or exchanged by them pursuant to this Regulation and of the kind covered by the obligation of professional secrecy.",article,"The Digital Services Act (DSA) includes a clause, Article 84, about professional secrecy. This means that any information gathered or shared under this law must be kept confidential. This applies to the Commission, the Board, authorities in Member States, their employees, and anyone else involved, like auditors and experts. They can't disclose any information that's protected by this professional secrecy obligation."
Digital Markets Act (DMA) - Contextual Paragraph (9),0.727225423,"Details of the Contextual Paragraph (9) in the Digital Markets Act (DMA): Fragmentation of the internal market can only effectively be averted if Member States are prevented from applying national rules which are within the scope of and pursue the same objectives as this Regulation. That does not preclude the possibility of applying to gatekeepers within the meaning of this Regulation other national rules which pursue other legitimate public interest objectives as set out in the TFEU or which pursue overriding reasons of public interest as recognised by the case law of the Court of Justice of the European Union (""the Court of Justice"").",rectial,"The Digital Markets Act (DMA) aims to prevent fragmentation in the internal market by stopping Member States from applying national rules that have the same objectives as this regulation. However, this doesn't stop the application of other national rules to gatekeepers (major players in the digital market), as long as these rules pursue different public interest objectives, as outlined in the Treaty on the Functioning of the European Union (TFEU), or are driven by overriding public interest reasons recognized by the Court of Justice of the European Union."
Artifical Inellegence Act (AI Act) - Overview paragraph 70,0.727202117,"Aritifical Intelligence Act (AI Act) overview paragraph (70): Certain AI systems intended to interact with natural persons or to generate content may pose specific risks of impersonation or deception irrespective of whether they qualify as high-risk or not. In certain circumstances, the use of these systems should therefore be subject to specific transparency obligations without prejudice to the requirements and obligations for high-risk AI systems. In particular, natural persons should be notified that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. Moreover, natural persons should be notified when they are exposed to an emotion recognition system or a biometric categorisation system. Such information and notifications should be provided in accessible formats for persons with disabilities. Further, users, who use an AI system to generate or manipulate image, audio or video content that appreciably resembles existing persons, places or events and would falsely appear to a person to be authentic, should disclose that the content has been artificially created or manipulated by labelling the artificial intelligence output accordingly and disclosing its artificial origin.",recital,"The Artificial Intelligence Act (AI Act) requires certain AI systems to be transparent about their use. If an AI system is designed to interact with humans or create content, it must make it clear that it's an AI, unless it's already obvious. This includes AI systems that recognize emotions or categorize biometrics. The information should be accessible to those with disabilities. Additionally, if an AI system creates or alters images, audio, or video that closely resembles real people, places, or events, it must disclose that the content is artificially created or manipulated."
General Data Protection Regulation (GDPR) - Contextual Paragraph (32),0.727137804,"Details of the Contextual Paragraph (32) in the General Data Protection Regulation (GDPR): Consent should be given by a clear affirmative act establishing a freely given, specific, informed and unambiguous indication of the data subject's agreement to the processing of personal data relating to him or her, such as by a written statement, including by electronic means, or an oral statement. This could include ticking a box when visiting an internet website, choosing technical settings for information society services or another statement or conduct which clearly indicates in this context the data subject's acceptance of the proposed processing of his or her personal data. Silence, pre-ticked boxes or inactivity should not therefore constitute consent. Consent should cover all processing activities carried out for the same purpose or purposes. When the processing has multiple purposes, consent should be given for all of them. If the data subject's consent is to be given following a request by electronic means, the request must be clear, concise and not unnecessarily disruptive to the use of the service for which it is provided.",recital,"The General Data Protection Regulation (GDPR) requires that a person's consent to use their personal data must be clearly and freely given, specific, informed, and unambiguous. This could be a written or oral statement, or an action like ticking a box on a website. It must be clear that the person agrees to their data being used. Silence or pre-ticked boxes don't count as consent. If data is being used for multiple purposes, the person must give consent for each purpose. If consent is asked for electronically, the request must be clear, concise and not disruptive to the service being provided."
General Data Protection Regulation (GDPR) - Contextual Paragraph (62),0.727131,"Details of the Contextual Paragraph (62) in the General Data Protection Regulation (GDPR): However, it is not necessary to impose the obligation to provide information where the data subject already possesses the information, where the recording or disclosure of the personal data is expressly laid down by law or where the provision of information to the data subject proves to be impossible or would involve a disproportionate effort. The latter could in particular be the case where processing is carried out for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes. In that regard, the number of data subjects, the age of the data and any appropriate safeguards adopted should be taken into consideration.",recital,"The General Data Protection Regulation (GDPR) includes a clause (Paragraph 62) that states you don't have to provide personal data information if the person already has the information, if the law requires the data to be recorded or disclosed, or if providing the information is impossible or would require too much effort. This could be the case for data used for public archives, scientific research, historical research, or statistics. When deciding whether providing information is too much effort, consider the number of people involved, the age of the data, and any safety measures in place."
General Data Protection Regulation (GDPR) - Article 90 Obligations of secrecy,0.727099776,"Details of Article 90 Obligations of secrecy in the General Data Protection Regulation (GDPR): 1. Member States may adopt specific rules to set out the powers of the supervisory authorities laid down in points (e) and (f) of Article 58(1) in relation to controllers or processors that are subject, under Union or Member State law or rules established by national competent bodies, to an obligation of professional secrecy or other equivalent obligations of secrecy where this is necessary and proportionate to reconcile the right of the protection of personal data with the obligation of secrecy. Those rules shall apply only with regard to personal data which the controller or processor has received as a result of or has obtained in an activity covered by that obligation of secrecy. 2. Each Member State shall notify to the Commission the rules adopted pursuant to paragraph 1, by 25 May 2018 and, without delay, any subsequent amendment affecting them.",article,"The General Data Protection Regulation (GDPR) Article 90, ""Obligations of secrecy,"" allows member states to create specific rules for data controllers or processors who are under a professional secrecy obligation. These rules are meant to balance the protection of personal data with the obligation of secrecy. They only apply to personal data received or obtained under that secrecy obligation. Member states must inform the Commission about these rules by 25 May 2018 and promptly report any changes."
Digital Markets Act (DMA) - Article 22 Power to carry out interviews and take statements,0.727080107,"Details of Article 22 Power to carry out interviews and take statements in the Digital Markets Act (DMA): 1. In order to carry out its duties under this Regulation, the Commission may interview any natural or legal person which consents to being interviewed, for the purpose of collecting information, relating to the subject-matter of an investigation. The Commission shall be entitled to record such interviews by any technical means. 2. Where an interview pursuant to paragraph 1 of this Article is conducted on the premises of an undertaking, the Commission shall inform the national competent authority of the Member State that is enforcing the rules referred to in Article 1(6) and in whose territory the interview takes place thereof. If that authority so requests, its officials may assist the officials and other accompanying persons authorised by the Commission to conduct the interview.",article,"The Digital Markets Act (DMA) Article 22 allows the Commission to interview anyone who agrees to it, in order to gather information for an investigation. These interviews can be recorded. If an interview happens at a business location, the Commission must inform the national authority of the country where the interview is taking place. If requested, officials from that authority can assist the Commission in conducting the interview."
Digital Markets Act (DMA) - Contextual Paragraph (24),0.727070391,"Details of the Contextual Paragraph (24) in the Digital Markets Act (DMA): Provision should also be made for the assessment of the gatekeeper role of undertakings providing core platform services which do not satisfy all of the quantitative thresholds, in light of the overall objective requirements that they have a significant impact on the internal market, act as an important gateway for business users to reach end users and benefit from an entrenched and durable position in their operations or it is foreseeable that they will do so in the near future. When the undertaking providing core platform services is a medium-sized, small or micro enterprise, the assessment should carefully take into account whether such an undertaking would be able to substantially undermine the contestability of the core platform services, since this Regulation primarily targets large undertakings with considerable economic power rather than medium-sized, small or micro enterprises.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 24) to assess the control certain companies have over core online services, even if they don't meet all the size requirements usually considered. The law checks if these companies significantly affect the market, act as a crucial link for businesses to reach customers, and have a strong, lasting position in their field. If they're expected to gain such a position soon, that's also considered. However, when evaluating smaller businesses, the law considers whether they could seriously challenge the core online services. The DMA mainly targets large, powerful companies, not small or medium-sized businesses."
Digital Services Act (DSA) - Article 39 Additional online advertising transparency,0.727057159,"Article 39 Additional online advertising transparency in the Digital Services Act (DSA):  1.   Providers of very large online platforms or of very large online search engines that present advertisements on their online interfaces shall compile and make publicly available in a specific section of their online interface, through a searchable and reliable tool that allows multicriteria queries and through application programming interfaces, a repository containing the information referred to in paragraph 2, for the entire period during which they present an advertisement and until one year after the advertisement was presented for the last time on their online interfaces. They shall ensure that the repository does not contain any personal data of the recipients of the service to whom the advertisement was or could have been presented, and shall make reasonable efforts to ensure that the information is accurate and complete.

2.   The repository shall include at least all of the following information:

(a) the content of the advertisement, including the name of the product, service or brand and the subject matter of the advertisement;
(b) the natural or legal person on whose behalf the advertisement is presented;
(c) the natural or legal person who paid for the advertisement, if that person is different from the person referred to in point (b);
(d) the period during which the advertisement was presented;
(e) whether the advertisement was intended to be presented specifically to one or more particular groups of recipients of the service and if so, the main parameters used for that purpose including where applicable the main parameters used to exclude one or more of such particular groups;
(f) the commercial communications published on the very large online platforms and identified pursuant to Article 26(2);
(g) the total number of recipients of the service reached and, where applicable, aggregate numbers broken down by Member State for the group or groups of recipients that the advertisement specifically targeted.

3.   As regards paragraph 2, points (a), (b) and (c), where a provider of very large online platform or of very large online search engine has removed or disabled access to a specific advertisement based on alleged illegality or incompatibility with its terms and conditions, the repository shall not include the information referred to in those points. In such case, the repository shall include, for the specific advertisement concerned, the information referred to in Article 17(3), points (a) to (e), or Article 9(2), point (a)(i), as applicable.

The Commission may, after consultation of the Board, the relevant vetted researchers referred to in Article 40 and the public, issue guidelines on the structure, organisation and functionalities of the repositories referred to in this Article.",article,"The Digital Services Act (DSA) requires large online platforms and search engines to create a public, searchable database of all advertisements shown on their sites for a period of one year. This database must not include any personal data of the ad recipients. It should include details such as the ad content, who it's for, who paid for it, when it was shown, its target audience, and how many people it reached. If an ad is removed due to illegal content or violation of terms, certain information won't be included in the database. The Commission may issue guidelines on how these databases should be structured and organized."
General Data Protection Regulation (GDPR) - Article 26 Joint controllers,0.727050781,"Details of Article 26 Joint controllers in the General Data Protection Regulation (GDPR): 1. Where two or more controllers jointly determine the purposes and means of processing, they shall be joint controllers. They shall in a transparent manner determine their respective responsibilities for compliance with the obligations under this Regulation, in particular as regards the exercising of the rights of the data subject and their respective duties to provide the information referred to in Articles 13 and 14, by means of an arrangement between them unless, and in so far as, the respective responsibilities of the controllers are determined by Union or Member State law to which the controllers are subject. The arrangement may designate a contact point for data subjects. 2. The arrangement referred to in paragraph 1 shall duly reflect the respective roles and relationships of the joint controllers vis--vis the data subjects. The essence of the arrangement shall be made available to the data subject. 3. Irrespective of the terms of the arrangement referred to in paragraph 1, the data subject may exercise his or her rights under this Regulation in respect of and against each of the controllers.",article,"Article 26 of the General Data Protection Regulation (GDPR) states that when two or more entities (controllers) jointly decide how and why to process data, they are considered joint controllers. They must clearly define their individual responsibilities for complying with the regulation, including respecting data subjects' rights and providing necessary information. This can be done through an agreement between them, unless specific laws dictate their responsibilities. The agreement can also specify a contact point for data subjects. The agreement must reflect the roles and relationships of the controllers towards the data subjects and be made available to them. Regardless of the agreement's terms, data subjects can exercise their rights under the GDPR against any of the controllers."
Digital Markets Act (DMA) - Contextual Paragraph (91),0.72703588,"Details of the Contextual Paragraph (91) in the Digital Markets Act (DMA): The Commission is the sole authority empowered to enforce this Regulation. In order to support the Commission, it should be possible for Member States to empower their national competent authorities enforcing competition rules to conduct investigations into possible non-compliance by gatekeepers with certain obligations under this Regulation. This could in particular be relevant for cases where it cannot be determined from the outset whether a gatekeeper""s behaviour is capable of infringing this Regulation, the competition rules which the national competent authority is empowered to enforce, or both. The national competent authority enforcing competition rules should report on its findings on possible non-compliance by gatekeepers with certain obligations under this Regulation to the Commission in view of the Commission opening proceedings to investigate any non-compliance as the sole enforcer of the provisions laid down by this Regulation. The Commission should have full discretion to decide whether to open such proceedings. In order to avoid overlapping investigations under this Regulation, the national competent authority concerned should inform the Commission before taking its first investigative measure into a possible non-compliance by gatekeepers with certain obligations under this Regulation. The national competent authorities should also closely cooperate and coordinate with the Commission when enforcing national competition rules against gatekeepers, including with regard to the setting of fines. To that end, they should inform the Commission when initiating proceedings based on national competition rules against gatekeepers, as well as prior to imposing obligations on gatekeepers in such proceedings. In order to avoid duplication, it should be possible for information of the draft decision pursuant to Article 11 of Regulation (EC) No 1/2003, where applicable, to serve as notification under this Regulation.",rectial,"The Digital Markets Act (DMA) gives the European Commission the sole power to enforce its rules. However, individual EU countries can allow their national authorities to investigate if ""gatekeepers"" (major tech companies) are breaking these rules. If a national authority finds potential non-compliance, it must report to the Commission, which can then decide whether to conduct its own investigation. To avoid duplicate investigations, national authorities must inform the Commission before starting their first investigation. They must also work closely with the Commission when enforcing national competition rules against gatekeepers, including when setting fines. They should inform the Commission when they start proceedings based on national competition rules against gatekeepers, and before imposing obligations on them. Information from a draft decision can be used as notification under this regulation to avoid duplication."
General Data Protection Regulation (GDPR) - Contextual Paragraph (167),0.726979375,"Details of the Contextual Paragraph (167) in the General Data Protection Regulation (GDPR): In order to ensure uniform conditions for the implementation of this Regulation, implementing powers should be conferred on the Commission when provided for by this Regulation. Those powers should be exercised in accordance with Regulation (EU) No 182/2011. In that context, the Commission should consider specific measures for micro, small and medium-sized enterprises.",recital,"The General Data Protection Regulation (GDPR) Paragraph 167 states that the Commission should ensure consistent implementation of this regulation. The Commission must follow the guidelines set by Regulation (EU) No 182/2011. Additionally, the Commission should consider special measures for micro, small and medium-sized businesses when implementing the GDPR."
General Data Protection Regulation (GDPR) - Contextual Paragraph (28),0.726927757,"Details of the Contextual Paragraph (28) in the General Data Protection Regulation (GDPR): The application of pseudonymisation to personal data can reduce the risks to the data subjects concerned and help controllers and processors to meet their data-protection obligations. The explicit introduction of ""pseudonymisation"" in this Regulation is not intended to preclude any other measures of data protection.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 28, which encourages the use of ""pseudonymisation"" for personal data. This means replacing identifying details with artificial identifiers to protect people's privacy. This can lower the risk of personal data being misused and help those who handle data (controllers and processors) to fulfill their privacy responsibilities. The law makes it clear that introducing ""pseudonymisation"" doesn't mean other data protection measures should be ignored."
Digital Markets Act (DMA) - Article 24 Interim measures,0.726892,"Details of Article 24 Interim measures in the Digital Markets Act (DMA): In case of urgency due to the risk of serious and irreparable damage for business users or end users of gatekeepers, the Commission may adopt an implementing act ordering interim measures against a gatekeeper on the basis of a prima facie finding of an infringement of Article 5, 6 or 7. That implementing act shall be adopted only in the context of proceedings opened with a view to the possible adoption of a non-compliance decision pursuant to Article 29(1). It shall apply only for a specified period of time and may be renewed in so far this is necessary and appropriate. That implementing act shall be adopted in accordance with the advisory procedure referred to in Article 50(2).",article,"The Digital Markets Act (DMA) includes a provision (Article 24) that allows the Commission to take immediate action against a gatekeeper (a dominant digital company) if there's a risk of serious harm to business or end users. This action, called an implementing act, can be taken if there's strong initial evidence of a violation of certain articles in the law. This act is temporary and can be renewed if necessary. It's only used during ongoing proceedings that could lead to a decision of non-compliance with the law. The act is adopted following an advisory procedure as outlined in another part of the law (Article 50(2))."
Artifical Inellegence Act (AI Act) - Article 34,0.72689,"Aritifical Intelligence Act (AI Act) Article 34 Subsidiaries of and subcontracting by notified bodies:

1.Where a notified body subcontracts specific tasks connected with the conformity assessment or has recourse to a subsidiary, it shall ensure that the subcontractor or the subsidiary meets the requirements laid down in Article 33 and shall inform the notifying authority accordingly.

2.Notified bodies shall take full responsibility for the tasks performed by subcontractors or subsidiaries wherever these are established.

3.Activities may be subcontracted or carried out by a subsidiary only with the agreement of the provider.

4.Notified bodies shall keep at the disposal of the notifying authority the relevant documents concerning the assessment of the qualifications of the subcontractor or the subsidiary and the work carried out by them under this Regulation.",article,"The Artificial Intelligence Act (AI Act) Article 34 clarifies rules for subcontractors and subsidiaries working under a notified body. If a notified body hires a subcontractor or uses a subsidiary, they must ensure these parties meet the requirements outlined in Article 33 and inform the relevant authority. The notified body is fully responsible for the tasks performed by these parties, regardless of their location. These tasks can only be subcontracted or performed by a subsidiary with the provider's agreement. The notified body must also keep all relevant documents related to the subcontractor or subsidiary's qualifications and work for the notifying authority to review."
Artifical Inellegence Act (AI Act) - Overview paragraph 11,0.726863146,"Aritifical Intelligence Act (AI Act) overview paragraph (11): Inlightof their digital nature, certain AI systems should fall within the scope of this Regulation even when they are neither placed on the market, nor put into service, nor used in the Union. This is the case for example of an operator established in the Union that contracts certain services to an operator established outside the Union in relation to an activity to be performed by an AI system that would qualify as high-risk and whose effects impact natural persons located in the Union. In those circumstances, the AI system used by the operator outside the Union could process data lawfully collected in and transferred from the Union, and provide to the contracting operator in the Union the output of that AI system resulting from that processing, without that AI system being placed on the market, put into service or used in the Union. To prevent the circumvention of this Regulation and to ensure an effective protection of natural persons located in the Union, this Regulation should also apply to providers and users of AI systems that are established in a third country, to the extent the output produced by those systems is used in the Union. Nonetheless, to take into account existing arrangements and special needs for cooperation with foreign partners with whom information and evidence is exchanged, this Regulation should not apply to public authorities of a third country and international organisations when acting in the framework of international agreementsconcluded at national or European levelfor law enforcement and judicial cooperation with the Union or with its Member States. Such agreements have been concluded bilaterally between Member States and third countries or between the European Union, Europol and other EU agencies and third countries and international organisations.",recital,"The Artificial Intelligence Act (AI Act) applies to certain AI systems, even if they are not marketed, used, or put into service in the EU. This includes cases where an EU-based operator contracts services from a non-EU operator for a high-risk AI system that impacts individuals in the EU. The AI system can process data legally collected and transferred from the EU and provide the results to the EU operator. To prevent loopholes and protect individuals in the EU, the law also applies to AI system providers and users in non-EU countries if the system's results are used in the EU. However, the law does not apply to public authorities of non-EU countries and international organizations acting under international agreements for law enforcement and judicial cooperation with the EU or its member states."
Digital Markets Act (DMA) - Contextual Paragraph (51),0.72685951,"Details of the Contextual Paragraph (51) in the Digital Markets Act (DMA): Gatekeepers are often vertically integrated and offer certain products or services to end users through their own core platform services, or through a business user over which they exercise control which frequently leads to conflicts of interest. This can include the situation whereby a gatekeeper provides its own online intermediation services through an online search engine. When offering those products or services on the core platform service, gatekeepers can reserve a better position, in terms of ranking, and related indexing and crawling, for their own offering than that of the products or services of third parties also operating on that core platform service. This can occur for instance with products or services, including other core platform services, which are ranked in the results communicated by online search engines, or which are partly or entirely embedded in online search engines results, groups of results specialised in a certain topic, displayed along with the results of an online search engine, which are considered or used by certain end users as a service distinct or additional to the online search engine. Other instances are those of software applications which are distributed through software application stores, or videos distributed through a video-sharing platform, or products or services that are given prominence and display in the newsfeed of an online social networking service, or products or services ranked in search results or displayed on an online marketplace, or products or services offered through a virtual assistant. Such reserving of a better position of gatekeeper""s own offering can take place even before ranking following a query, such as during crawling and indexing. For example, already during crawling, as a discovery process by which new and updated content is being found, as well as indexing, which entails storing and organising of the content found during the crawling process, the gatekeeper can favour its own content over that of third parties. In those circumstances, the gatekeeper is in a dual-role position as intermediary for third-party undertakings and as undertaking directly providing products or services. Consequently, such gatekeepers have the ability to undermine directly the contestability for those products or services on those core platform services, to the detriment of business users which are not controlled by the gatekeeper.",rectial,"The Digital Markets Act (DMA) addresses the issue of gatekeepers, or large tech companies, who control access to online platforms and often favor their own products or services over others. This creates a conflict of interest and can limit competition. For example, a gatekeeper might rank its own products higher in search engine results, or give them more visibility on social media feeds or online marketplaces. This can happen at any stage, from the initial discovery of content to its organization and display. The DMA is concerned that this practice harms businesses that aren't controlled by the gatekeeper, as they struggle to compete on these platforms."
General Data Protection Regulation (GDPR) - Article 48 Transfers or disclosures not authorised by Union law,0.726838887,"Details of Article 48 Transfers or disclosures not authorised by Union law in the General Data Protection Regulation (GDPR): Any judgment of a court or tribunal and any decision of an administrative authority of a third country requiring a controller or processor to transfer or disclose personal data may only be recognised or enforceable in any manner if based on an international agreement, such as a mutual legal assistance treaty, in force between the requesting third country and the Union or a Member State, without prejudice to other grounds for transfer pursuant to this Chapter.",article,"Article 48 of the General Data Protection Regulation (GDPR) states that any foreign court or authority can only require a data controller or processor to share personal data if there's an international agreement, like a mutual legal assistance treaty, between the foreign country and the EU or its member state. This rule doesn't affect other legal reasons for data transfer mentioned in the GDPR."
General Data Protection Regulation (GDPR) - Contextual Paragraph (92),0.726811409,"Details of the Contextual Paragraph (92) in the General Data Protection Regulation (GDPR): There are circumstances under which it may be reasonable and economical for the subject of a data protection impact assessment to be broader than a single project, for example where public authorities or bodies intend to establish a common application or processing platform or where several controllers plan to introduce a common application or processing environment across an industry sector or segment or for a widely used horizontal activity.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 92) that allows for a broader scope in assessing the impact on data protection. Instead of focusing on a single project, the assessment can cover a larger initiative. This could be useful when public organizations want to create a shared application or processing platform, or when multiple companies in the same industry or sector want to introduce a common processing environment. This provision is designed to make the process more efficient and cost-effective."
Digital Services Act (DSA) - Contextual paragraph (42),0.726724446,"Details of the contextual paragraph (42) of the Digital Services Act (DSA): In order to facilitate smooth and efficient two-way communications, including, where relevant, by acknowledging the receipt of such communications, relating to matters covered by this Regulation, providers of intermediary services should be required to designate a single electronic point of contact and to publish and update relevant information relating to that point of contact, including the languages to be used in such communications. The electronic point of contact can also be used by trusted flaggers and by professional entities which are under a specific relationship with the provider of intermediary services. In contrast to the legal representative, the electronic point of contact should serve operational purposes and should not be required to have a physical location. Providers of intermediary services can designate the same single point of contact for the requirements of this Regulation as well as for the purposes of other acts of Union law. When specifying the languages of communication, providers of intermediary services are encouraged to ensure that the languages chosen do not in themselves constitute an obstacle to communication. Where necessary, it should be possible for providers of intermediary services and Member States' authorities to reach a separate agreement on the language of communication, or to seek alternative means to overcome the language barrier, including by using all available technological means or internal and external human resources.",recital,"The Digital Services Act (DSA) requires online service providers to establish a single electronic point of contact to facilitate communication. This includes acknowledging received messages and publishing updates. This point of contact can be used by trusted flaggers and professional entities associated with the service provider. Unlike a legal representative, this point of contact doesn't need a physical location. The same contact point can be used for other legal requirements. The service provider should ensure the chosen languages for communication don't hinder communication. If necessary, the service provider and authorities can agree on a communication language or find ways to overcome language barriers, such as using technology or human resources."
Artifical Inellegence Act (AI Act) - Overview paragraph 23,0.726688,"Aritifical Intelligence Act (AI Act) overview paragraph (23): The use of AI systems for real-time remote biometric identification of natural persons in publicly accessible spaces for the purpose of law enforcement necessarily involves the processing of biometric data. The rules of this Regulation that prohibit, subject to certain exceptions, such use, which are based on Article 16 TFEU, should apply aslex specialisin respect of the rules on the processing of biometric data contained in Article 10 of Directive (EU) 2016/680, thus regulating such use and the processing of biometric data involved in an exhaustive manner. Therefore, such use and processing should only be possible in as far as it is compatible with the framework set by this Regulation, without there being scope, outside that framework, for the competent authorities, where they act for purpose of law enforcement, to use such systems and process such data in connection thereto on the grounds listed in Article 10 of Directive (EU) 2016/680. In this context, this Regulation is not intended to provide the legal basis for the processing of personal dataunder Article 8 of Directive 2016/680.However, the use of real-time remote biometric identification systems in publicly accessible spaces for purposes other than law enforcement, including by competent authorities, should not be covered by thespecific framework regarding such use for the purpose of law enforcementset by this Regulation. Such use for purposes other than law enforcementshouldtherefore not be subject to the requirement of an authorisation under this Regulationand the applicable detailed rules of national law that may give effect to it.",recital,"The Artificial Intelligence Act (AI Act) states that the use of AI for real-time biometric identification (like facial recognition) in public spaces for law enforcement is generally prohibited, unless certain exceptions apply. This rule is based on Article 16 TFEU and supersedes the rules in Article 10 of Directive (EU) 2016/680. The use of such systems should only be allowed if it aligns with the rules set by this Act. Law enforcement authorities cannot use these systems outside the framework provided by this Act. However, the Act does not cover the use of real-time biometric identification systems for non-law enforcement purposes. Such uses are not subject to the authorization requirement of this Act and may be governed by national law."
Digital Services Act (DSA) - Article 64 Development of expertise and capabilities,0.726673841,"Article 64 Development of expertise and capabilities in the Digital Services Act (DSA):  1.   The Commission, in cooperation with the Digital Services Coordinators and the Board, shall develop Union expertise and capabilities, including, where appropriate, through the secondment of Member States' personnel.

2.   In addition, the Commission, in cooperation with the Digital Services Coordinators and the Board, shall coordinate the assessment of systemic and emerging issues across the Union in relation to very large online platforms or very large online search engines with regard to matters covered by this Regulation.

3.   The Commission may ask the Digital Services Coordinators, the Board and other Union bodies, offices and agencies with relevant expertise to support the assessment of systemic and emerging issues across the Union under this Regulation.

4.   Member States shall cooperate with the Commission, in particular through their respective Digital Services Coordinators and other competent authorities, where applicable, including by making available their expertise and capabilities.",article,"The Digital Services Act (DSA) aims to enhance the European Union's digital expertise and capabilities. The Commission will work with the Digital Services Coordinators and the Board, using staff from member states as needed. They will also assess large online platforms and search engines for any systemic or emerging issues. The Commission can request support from other Union bodies and agencies with relevant expertise for this assessment. Member states are required to cooperate with the Commission, particularly through their Digital Services Coordinators, and share their expertise and capabilities."
General Data Protection Regulation (GDPR) - Contextual Paragraph (164),0.726630449,"Details of the Contextual Paragraph (164) in the General Data Protection Regulation (GDPR): As regards the powers of the supervisory authorities to obtain from the controller or processor access to personal data and access to their premises, Member States may adopt by law, within the limits of this Regulation, specific rules in order to safeguard the professional or other equivalent secrecy obligations, in so far as necessary to reconcile the right to the protection of personal data with an obligation of professional secrecy. This is without prejudice to existing Member State obligations to adopt rules on professional secrecy where required by Union law.",recital,"The General Data Protection Regulation (GDPR) allows supervisory authorities to access personal data from controllers or processors, as well as their premises. However, individual Member States can create specific laws to protect professional secrecy, as long as it doesn't violate the GDPR. This is to balance the right to data protection with the need for professional secrecy. Member States are also required to adopt rules on professional secrecy if mandated by Union law."
Digital Services Act (DSA) - Contextual paragraph (143),0.726628602,"Details of the contextual paragraph (143) of the Digital Services Act (DSA): The Commission should be able to take the necessary actions to monitor the effective implementation of and compliance with the obligations laid down in this Regulation. Such actions should include the ability to appoint independent external experts and auditors to assist the Commission in this process, including where applicable from competent authorities of the Member States, such as data or consumer protection authorities. When appointing auditors, the Commission should ensure sufficient rotation.",recital,"The Digital Services Act (DSA) allows the Commission to monitor and ensure compliance with the law's obligations. This includes hiring independent external experts and auditors, possibly from Member State authorities like data or consumer protection agencies, to help with this process. The Commission should also rotate auditors regularly for fairness and transparency."
Digital Markets Act (DMA) - Article 39 Cooperation with national courts,0.726625919,"Details of Article 39 Cooperation with national courts in the Digital Markets Act (DMA): 1. In proceedings for the application of this Regulation, national courts may ask the Commission to transmit to them information in its possession or its opinion on questions concerning the application of this Regulation. 2. Member States shall forward to the Commission a copy of any written judgment of national courts deciding on the application of this Regulation. Such copy shall be forwarded without delay after the full written judgment is notified to the parties. 3. Where the coherent application of this Regulation so requires, the Commission, acting on its own initiative, may submit written observations to national courts. With the permission of the court in question, it may also make oral observations. 4. For the purpose of the preparation of their observations only, the Commission may request the relevant national court to transmit or ensure the transmission to the Commission of any documents necessary for the assessment of the case. 5. National courts shall not give a decision which runs counter to a decision adopted by the Commission under this Regulation. They shall also avoid giving decisions which would conflict with a decision contemplated by the Commission in proceedings it has initiated under this Regulation. To that effect, the national court may assess whether it is necessary to stay its proceedings. This is without prejudice to the possibility for national courts to request a preliminary ruling under Article 267 TFEU.",article,"The Digital Markets Act (DMA) Article 39 allows national courts to request information or opinions from the Commission regarding the application of this law. Member states must send the Commission copies of any judgments related to the DMA. The Commission can also provide written or oral observations to national courts to ensure the law is applied consistently. The Commission can request necessary documents from the national court for preparing their observations. National courts must not make decisions that contradict those made by the Commission under the DMA, and should avoid decisions conflicting with potential Commission decisions. Courts can pause proceedings to ensure this, and can request a preliminary ruling under Article 267 TFEU."
Digital Markets Act (DMA) - Contextual Paragraph (52),0.72661835,"Details of the Contextual Paragraph (52) in the Digital Markets Act (DMA): In such situations, the gatekeeper should not engage in any form of differentiated or preferential treatment in ranking on the core platform service, and related indexing and crawling, whether through legal, commercial or technical means, in favour of products or services it offers itself or through a business user which it controls. To ensure that this obligation is effective, the conditions that apply to such ranking should also be generally fair and transparent. Ranking should in this context cover all forms of relative prominence, including display, rating, linking or voice results and should also include instances where a core platform service presents or communicates only one result to the end user. To ensure that this obligation is effective and cannot be circumvented, it should also apply to any measure that has an equivalent effect to the differentiated or preferential treatment in ranking. The guidelines adopted pursuant to Article 5 of Regulation (EU) 2019/1150 should also facilitate the implementation and enforcement of this obligation.",rectial,"The Digital Markets Act (DMA) includes a clause (Paragraph 52) that prevents digital ""gatekeepers"" from favoring their own products or services in search rankings. This means they can't use legal, commercial, or technical methods to give their own offerings an unfair advantage. The law also requires that the rules for these rankings be fair and transparent. This applies to all forms of prominence, including how products are displayed, rated, linked, or mentioned in voice results. Even if only one result is shown to the user, it must not favor the gatekeeper's own products. The law also covers any other measures that could have a similar effect. Guidelines from a 2019 regulation (EU 2019/1150) will help enforce this rule."
General Data Protection Regulation (GDPR) - Article 96 Relationship with previously concluded Agreements,0.72660768,"Details of Article 96 Relationship with previously concluded Agreements in the General Data Protection Regulation (GDPR): International agreements involving the transfer of personal data to third countries or international organisations which were concluded by Member States prior to 24 May 2016, and which comply with Union law as applicable prior to that date, shall remain in force until amended, replaced or revoked.",article,"The General Data Protection Regulation (GDPR) has a clause, Article 96, that deals with agreements made before May 24, 2016. If these agreements involve transferring personal data to countries or organizations outside the EU, and they followed EU law at the time they were made, they can continue to be in effect. These agreements will remain valid until they are changed, replaced, or cancelled."
General Data Protection Regulation (GDPR) - Article 20 Right to data portability,0.726588666,"Details of Article 20 Right to data portability in the General Data Protection Regulation (GDPR): 1. The data subject shall have the right to receive the personal data concerning him or her, which he or she has provided to a controller, in a structured, commonly used and machine-readable format and have the right to transmit those data to another controller without hindrance from the controller to which the personal data have been provided, where: (a) the processing is based on consent pursuant to point (a) of Article 6(1) or point (a) of Article 9(2) or on a contract pursuant to point (b) of Article 6(1); and (b) the processing is carried out by automated means. 2. In exercising his or her right to data portability pursuant to paragraph 1, the data subject shall have the right to have the personal data transmitted directly from one controller to another, where technically feasible. 3. The exercise of the right referred to in paragraph 1 of this Article shall be without prejudice to Article 17. That right shall not apply to processing necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller. 4. The right referred to in paragraph 1 shall not adversely affect the rights and freedoms of others.",article,"The General Data Protection Regulation (GDPR) Article 20, Right to data portability, allows individuals to access their personal data held by a company in a common, machine-readable format. They can also request this data to be transferred to another company without any hindrance, provided the data processing is based on their consent or a contract and is done by automated means. However, this right doesn't apply when data processing is necessary for public interest or official authority. Furthermore, exercising this right should not negatively impact the rights and freedoms of others."
General Data Protection Regulation (GDPR) - Article 62 Joint operations of supervisory authorities,0.726581573,"Details of Article 62 Joint operations of supervisory authorities in the General Data Protection Regulation (GDPR): 1. The supervisory authorities shall, where appropriate, conduct joint operations including joint investigations and joint enforcement measures in which members or staff of the supervisory authorities of other Member States are involved. 2. Where the controller or processor has establishments in several Member States or where a significant number of data subjects in more than one Member State are likely to be substantially affected by processing operations, a supervisory authority of each of those Member States shall have the right to participate in joint operations. The supervisory authority which is competent pursuant to Article 56(1) or (4) shall invite the supervisory authority of each of those Member States to take part in the joint operations and shall respond without delay to the request of a supervisory authority to participate. 3. A supervisory authority may, in accordance with Member State law, and with the seconding supervisory authority's authorisation, confer powers, including investigative powers on the seconding supervisory authority's members or staff involved in joint operations or, in so far as the law of the Member State of the host supervisory authority permits, allow the seconding supervisory authority's members or staff to exercise their investigative powers in accordance with the law of the Member State of the seconding supervisory authority. Such investigative powers may be exercised only under the guidance and in the presence of members or staff of the host supervisory authority. The seconding supervisory authority's members or staff shall be subject to the Member State law of the host supervisory authority. 4. Where, in accordance with paragraph 1, staff of a seconding supervisory authority operate in another Member State, the Member State of the host supervisory authority shall assume responsibility for their actions, including liability, for any damage caused by them during their operations, in accordance with the law of the Member State in whose territory they are operating. 5. The Member State in whose territory the damage was caused shall make good such damage under the conditions applicable to damage caused by its own staff. The Member State of the seconding supervisory authority whose staff has caused damage to any person in the territory of another Member State shall reimburse that other Member State in full any sums it has paid to the persons entitled on their behalf. 6. Without prejudice to the exercise of its rights vis--vis third parties and with the exception of paragraph 5, each Member State shall refrain, in the case provided for in paragraph 1, from requesting reimbursement from another Member State in relation to damage referred to in paragraph 4. 7. Where a joint operation is intended and a supervisory authority does not, within one month, comply with the obligation laid down in the second sentence of paragraph 2 of this Article, the other supervisory authorities may adopt a provisional measure on the territory of its Member State in accordance with Article 55. In that case, the urgent need to act under Article 66(1) shall be presumed to be met and require an opinion or an urgent binding decision from the Board pursuant to Article 66(2).",article,"The General Data Protection Regulation (GDPR) Article 62 allows for joint operations between supervisory authorities from different Member States. This can include investigations and enforcement measures. If a company has establishments in multiple Member States, or its data processing activities significantly affect individuals in more than one Member State, all relevant supervisory authorities have the right to participate in joint operations. The authority leading the operation can delegate powers to others, including investigative powers, but only under their guidance and in their presence. If any damage is caused during these operations, the host Member State is responsible for the actions of the seconding authority's staff. They must compensate for any damage caused, and the seconding Member State must reimburse the host. If a supervisory authority fails to participate in a joint operation, other authorities can take provisional measures in their own territory."
Artifical Inellegence Act (AI Act) - Overview paragraph 87,0.726576209,"Aritifical Intelligence Act (AI Act) overview paragraph (87): Since the objective of this Regulation cannot be sufficiently achieved by the Member States and can rather, by reason of the scale or effects of the action, be better achievedat Union level, the Union may adopt measures in accordance with the principle of subsidiarity as set out in Article 5 TEU. In accordance with the principle of proportionality as set out in that Article, this Regulation does not go beyond what is necessary in order to achieve that objective.",recital,"The Artificial Intelligence Act (AI Act) is a new law that has been introduced because it's believed that the goals of the act can be better achieved on a Union level, rather than by individual Member States. This is due to the scale and impact of the act. The law follows the principle of subsidiarity, as outlined in Article 5 TEU, meaning the Union can adopt measures if they're more effective at that level. The law also follows the principle of proportionality, meaning it only includes what is necessary to achieve its goals."
Digital Markets Act (DMA) - Contextual Paragraph (45),0.726572037,"Details of the Contextual Paragraph (45) in the Digital Markets Act (DMA): The conditions under which gatekeepers provide online advertising services to business users, including both advertisers and publishers, are often non-transparent and opaque. This opacity is partly linked to the practices of a few platforms, but is also due to the sheer complexity of modern day programmatic advertising. That sector is considered to have become less transparent after the introduction of new privacy legislation. This often leads to a lack of information and knowledge for advertisers and publishers about the conditions of the online advertising services they purchase and undermines their ability to switch between undertakings providing online advertising services. Furthermore, the costs of online advertising services under these conditions are likely to be higher than they would be in a fairer, more transparent and contestable platform environment. Those higher costs are likely to be reflected in the prices that end users pay for many daily products and services relying on the use of online advertising services. Transparency obligations should therefore require gatekeepers to provide advertisers and publishers to whom they supply online advertising services, when requested, with free of charge information that allows both sides to understand the price paid for each of the different online advertising services provided as part of the relevant advertising value chain. This information should be provided, upon request, to an advertiser at the level of an individual advertisement in relation to the price and fees charged to that advertiser and, subject to an agreement by the publisher owning the inventory where the advertisement is displayed, the remuneration received by that consenting publisher. The provision of this information on a daily basis will allow advertisers to receive information that has a sufficient level of granularity necessary to compare the costs of using the online advertising services of gatekeepers with the costs of using online advertising services of alternative undertakings. Where some publishers do not provide their consent to the sharing of the relevant information with the advertiser, the gatekeeper should provide the advertiser with the information about the daily average remuneration received by those publishers for the relevant advertisements. The same obligation and principles of sharing the relevant information concerning the provision of online advertising services should apply in respect of requests by publishers. Since gatekeepers can use different pricing models for the provision of online advertising services to advertisers and publishers, for instance a price per impression, per view or any other criterion, gatekeepers should also provide the method with which each of the prices and remunerations are calculated.",rectial,"The Digital Markets Act (DMA) addresses the issue of non-transparency in online advertising services provided by gatekeepers (large platforms) to businesses. The DMA suggests that this lack of clarity can lead to higher costs for businesses and, in turn, for consumers. To combat this, the DMA proposes that gatekeepers should be required to provide businesses with clear, free information about the cost of their advertising services, including the price of individual advertisements and the remuneration received by publishers. This information should be provided daily and in a detailed manner to allow businesses to compare costs between different providers. The DMA also requires gatekeepers to explain their pricing models. This law aims to make the online advertising market fairer and more transparent."
Artifical Inellegence Act (AI Act) - Overview paragraph 15,0.726570666,"Aritifical Intelligence Act (AI Act) overview paragraph (15): Aside from the many beneficial uses of artificial intelligence, that technology can also be misused and provide novel and powerful tools for manipulative, exploitative and social control practices. Such practices are particularly harmful and should be prohibited because they contradict Union values of respect for human dignity, freedom, equality, democracy and the rule of law and Union fundamental rights, including the right to non-discrimination, data protection and privacyand the rights of the child.",recital,"The Artificial Intelligence Act (AI Act) is a new law designed to prevent the misuse of artificial intelligence (AI) technology. The law is in place to stop AI from being used in manipulative, exploitive, or controlling ways, which can be harmful and go against the values of the Union. These values include respect for human dignity, freedom, equality, democracy, and the rule of law. The AI Act also protects fundamental rights like non-discrimination, data protection, privacy, and children's rights."
Artifical Inellegence Act (AI Act) - Overview paragraph 78,0.726559579,"Aritifical Intelligence Act (AI Act) overview paragraph (78): In order to ensure that providers of high-risk AI systems can take into account the experience on the use of high-risk AI systems for improving their systems and thedesign and development process or can take any possible corrective action in a timely manner, all providers should have a post-market monitoring system in place. This system is also key to ensure that the possible risks emerging from AI systems which continue to learn after being placed on the market or put into service can be more efficiently and timely addressed. In this context, providers should also be required to have a system in place to report to the relevant authorities any serious incidents or any breaches to national and Union law protecting fundamental rights resulting from the use of their AI systems.",recital,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems to implement a post-market monitoring system. This system is crucial for providers to learn from their experiences, improve their systems, and take corrective actions promptly. It also helps manage risks from AI systems that continue to evolve after being launched. Furthermore, providers must have a system to report serious incidents or violations of national and Union laws protecting fundamental rights caused by their AI systems to the relevant authorities."
General Data Protection Regulation (GDPR) - Contextual Paragraph (155),0.7265504,"Details of the Contextual Paragraph (155) in the General Data Protection Regulation (GDPR): Member State law or collective agreements, including ""works agreements"", may provide for specific rules on the processing of employees' personal data in the employment context, in particular for the conditions under which personal data in the employment context may be processed on the basis of the consent of the employee, the purposes of the recruitment, the performance of the contract of employment, including discharge of obligations laid down by law or by collective agreements, management, planning and organisation of work, equality and diversity in the workplace, health and safety at work, and for the purposes of the exercise and enjoyment, on an individual or collective basis, of rights and benefits related to employment, and for the purpose of the termination of the employment relationship.",recital,"The General Data Protection Regulation (GDPR) Paragraph 155 allows member states or collective agreements to set specific rules for handling employees' personal data in the workplace. This could include when and how an employee's consent is needed to process their data, how data is used in hiring, contract fulfillment, legal obligations, work management, promoting equality and diversity, ensuring health and safety, and managing employment rights and benefits. The law also covers data use when ending an employment relationship."
Artifical Inellegence Act (AI Act) - Overview paragraph 20,0.726536155,"Aritifical Intelligence Act (AI Act) overview paragraph (20): In order to ensure that those systems are used in a responsible and proportionate manner, it is also important to establish that, in each of those three exhaustively listed and narrowly defined situations, certain elements should be taken into account, in particular as regards the nature of thesituation giving rise to the request and the consequences of the use for the rights and freedoms of all persons concernedand thesafeguards and conditions provided for with the use. In addition, the use of real-time remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement should be subject to appropriate limits in time and space, having regard in particular to the evidence or indications regarding the threats, the victims orperpetrator.The reference database of persons should be appropriate for each use case in each of the three situations mentioned above.",recital,"The Artificial Intelligence Act (AI Act) is a new law meant to ensure that AI systems are used responsibly and proportionately. It focuses on three specific situations, all of which require careful consideration of the circumstances, the potential impact on people's rights and freedoms, and the safeguards in place. The law also limits the use of real-time remote biometric identification (like facial recognition) in public places by law enforcement, with restrictions based on time, space, and the nature of the threat. The law also states that the database of persons used for identification should be suitable for each specific situation."
Digital Markets Act (DMA) - Contextual Paragraph (11),0.726531863,"Details of the Contextual Paragraph (11) in the Digital Markets Act (DMA): Articles 101 and 102 TFEU and the corresponding national competition rules concerning anticompetitive multilateral and unilateral conduct as well as merger control have as their objective the protection of undistorted competition on the market. This Regulation pursues an objective that is complementary to, but different from that of protecting undistorted competition on any given market, as defined in competition-law terms, which is to ensure that markets where gatekeepers are present are and remain contestable and fair, independently from the actual, potential or presumed effects of the conduct of a given gatekeeper covered by this Regulation on competition on a given market. This Regulation therefore aims to protect a different legal interest from that protected by those rules and it should apply without prejudice to their application.",rectial,"The Digital Markets Act (DMA) introduces new regulations to maintain fair competition in markets dominated by major tech companies, known as gatekeepers. This law is different from existing competition laws, which aim to prevent anti-competitive behavior and control mergers. Instead, the DMA aims to ensure that these markets remain open and fair, regardless of the behavior of these gatekeepers. This new law will work alongside existing competition laws and does not replace them."
Artifical Inellegence Act (AI Act) - Overview paragraph 38,0.726524889,"Aritifical Intelligence Act (AI Act) overview paragraph (38): Actions by law enforcement authorities involving certain uses of AI systems are characterised by a significant degree of power imbalance and may lead to surveillance, arrest or deprivation of a natural persons liberty as well as other adverse impacts on fundamental rights guaranteed in the Charter. In particular, if the AI system is not trained with high quality data, does not meet adequate requirements in terms of its accuracy or robustness, or is not properly designed and tested before being put on the market or otherwise put into service, it may single out people in a discriminatory or otherwise incorrect or unjust manner. Furthermore, the exercise of important procedural fundamental rights, such as the right to an effective remedy and to a fair trial as well as the right of defence and the presumption of innocence, could be hampered, in particular, where such AI systems are not sufficiently transparent, explainable and documented.It is therefore appropriate to classify as high-risk a number of AI systems intended to be used in the law enforcement context where accuracy, reliability and transparency is particularly important to avoid adverse impacts, retain public trust and ensure accountability and effective redress. In view of the nature of the activities in question and the risks relating thereto, those high-risk AI systems should include in particular AI systems intended to be used by lawenforcement authorities for individual risk assessments,polygraphs and similar tools or to detect the emotional state of natural person, to detect deep fakes,for the evaluation of the reliability of evidence in criminal proceedings,for predicting the occurrence or reoccurrence of an actual or potential criminal offence based onprofiling of natural persons,or assessing personality traits and characteristics or past criminal behaviour of natural persons or groups, for profiling in the course of detection, investigation or prosecution of criminal offences, as well as forcrime analytics regarding natural persons.AI systems specifically intended to be used for administrative proceedings by tax and customs authorities should not be considered high-risk AI systems used by law enforcement authorities for the purposes of prevention, detection, investigation and prosecution of criminal offences.",recital,"The Artificial Intelligence Act (AI Act) addresses the use of AI systems by law enforcement. The law recognizes that misuse of AI can lead to unjust or discriminatory actions, particularly if the AI isn't properly trained, tested, and transparent. This could negatively impact fundamental rights, such as the right to a fair trial and presumption of innocence. Therefore, the law classifies certain AI systems as ""high-risk"" when used in law enforcement, including those used for risk assessments, polygraphs, detecting 'deep fakes', evaluating evidence, predicting criminal behavior, and profiling. The law emphasizes the importance of accuracy, reliability, and transparency in these systems to maintain public trust and accountability. However, AI systems used by tax and customs authorities for administrative proceedings are not considered high-risk."
General Data Protection Regulation (GDPR) - Contextual Paragraph (58),0.726497769,"Details of the Contextual Paragraph (58) in the General Data Protection Regulation (GDPR): The principle of transparency requires that any information addressed to the public or to the data subject be concise, easily accessible and easy to understand, and that clear and plain language and, additionally, where appropriate, visualisation be used. Such information could be provided in electronic form, for example, when addressed to the public, through a website. This is of particular relevance in situations where the proliferation of actors and the technological complexity of practice make it difficult for the data subject to know and understand whether, by whom and for what purpose personal data relating to him or her are being collected, such as in the case of online advertising. Given that children merit specific protection, any information and communication, where processing is addressed to a child, should be in such a clear and plain language that the child can easily understand.",recital,"The General Data Protection Regulation (GDPR) includes a principle of transparency, which states that any public information or data must be concise, easily accessible, and understandable. It should use clear language and visuals where necessary. This information can be provided electronically, like on a website. This is especially important when there are many involved parties and complex technology that may make it hard for individuals to understand how and why their personal data is being collected, such as in online advertising. The law also states that any information aimed at children must be clear and simple enough for them to understand."
General Data Protection Regulation (GDPR) - Contextual Paragraph (173),0.726479,"Details of the Contextual Paragraph (173) in the General Data Protection Regulation (GDPR): This Regulation should apply to all matters concerning the protection of fundamental rights and freedoms vis-vis the processing of personal data which are not subject to specific obligations with the same objective set out in Directive 2002/58/EC of the European Parliament and of the Council ( 2 ), including the obligations on the controller and the rights of natural persons. In order to clarify the relationship between this Regulation and Directive 2002/58/EC, that Directive should be amended accordingly. Once this Regulation is adopted, Directive 2002/58/EC should be reviewed in particular in order to ensure consistency with this Regulation.",recital,"The General Data Protection Regulation (GDPR) is a new law that applies to all matters related to the protection of individual rights and freedoms in the context of personal data processing. It covers areas not specifically addressed by the older law, Directive 2002/58/EC. This includes obligations of the data controller and the rights of individuals. To ensure both laws work together, the older Directive will be amended. Once the GDPR is in effect, the Directive will be reviewed to ensure it aligns with the new regulation."
General Data Protection Regulation (GDPR) - Article 92 Exercise of the delegation,0.726452351,"Details of Article 92 Exercise of the delegation in the General Data Protection Regulation (GDPR): 1. The power to adopt delegated acts is conferred on the Commission subject to the conditions laid down in this Article. 2. The delegation of power referred to in Article 12(8) and Article 43(8) shall be conferred on the Commission for an indeterminate period of time from 24 May 2016. 3. The delegation of power referred to in Article 12(8) and Article 43(8) may be revoked at any time by the European Parliament or by the Council. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force. 4. As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council. 5. A delegated act adopted pursuant to Article 12(8) and Article 43(8) shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.",article,"The General Data Protection Regulation (GDPR) Article 92 allows the Commission to adopt new rules, but these must follow certain conditions. The Commission has been given this power indefinitely from May 24, 2016. However, the European Parliament or the Council can take back this power at any time, which would end the Commission's ability to make new rules. If this happens, it won't affect any rules that are already in place. When the Commission makes a new rule, they must tell the European Parliament and the Council. The new rule will only become law if neither the Parliament nor the Council object within three months. This period can be extended by another three months if needed."
General Data Protection Regulation (GDPR) - Contextual Paragraph (34),0.726394176,"Details of the Contextual Paragraph (34) in the General Data Protection Regulation (GDPR): Genetic data should be defined as personal data relating to the inherited or acquired genetic characteristics of a natural person which result from the analysis of a biological sample from the natural person in question, in particular chromosomal, deoxyribonucleic acid (DNA) or ribonucleic acid (RNA) analysis, or from the analysis of another element enabling equivalent information to be obtained.",recital,"The General Data Protection Regulation (GDPR) has a new provision, Contextual Paragraph (34), which clarifies the definition of genetic data. This refers to any personal data about your inherited or acquired genetic traits. This information is usually obtained from analyzing a biological sample like your DNA, RNA, or chromosomes. It could also come from any other source that provides similar information about your genetic characteristics."
Digital Markets Act (DMA) - Contextual Paragraph (39),0.726393044,"Details of the Contextual Paragraph (39) in the Digital Markets Act (DMA): In certain cases, for instance through the imposition of contractual terms and conditions, gatekeepers can restrict the ability of business users of their online intermediation services to offer products or services to end users under more favourable conditions, including price, through other online intermediation services or through direct online sales channels. Where such restrictions relate to third-party online intermediation services, they limit inter-platform contestability, which in turn limits choice of alternative online intermediation services for end users. Where such restrictions relate to direct online sales channels, they unfairly limit the freedom of business users to use such channels. To ensure that business users of online intermediation services of gatekeepers can freely choose alternative online intermediation services or direct online sales channels and differentiate the conditions under which they offer their products or services to end users, it should not be accepted that gatekeepers limit business users from choosing to differentiate commercial conditions, including price. Such a restriction should apply to any measure with equivalent effect, such as increased commission rates or de-listing of the offers of business users.",rectial,"The Digital Markets Act (DMA) addresses the issue of gatekeepers (major online platforms) restricting businesses from offering their products or services at more favorable conditions, including price, on other platforms or through direct online sales. These restrictions limit competition between platforms and reduce the choices available to end users. They also unfairly limit the freedom of businesses to use direct online sales channels. The DMA aims to ensure that businesses can freely choose alternative online platforms or direct sales channels and set their own terms for offering their products or services, including price. The law does not allow gatekeepers to limit this freedom, including through measures such as increasing commission rates or removing businesses' offers."
Digital Services Act (DSA) - Contextual paragraph (49),0.726332724,"Details of the contextual paragraph (49) of the Digital Services Act (DSA): To ensure an adequate level of transparency and accountability, providers of intermediary services should make publicly available an annual report in a machine-readable format, in accordance with the harmonised requirements contained in this Regulation, on the content moderation in which they engage, including the measures taken as a result of the application and enforcement of their terms and conditions. However, in order to avoid disproportionate burdens, those transparency reporting obligations should not apply to providers that are micro or small enterprises as defined in Commission Recommendation 2003/361/EC (25) and which are not very large online platforms within the meaning of this Regulation.",recital,"The Digital Services Act (DSA) requires providers of intermediary services to publish an annual report detailing their content moderation activities, including actions taken based on their terms and conditions. This report must be publicly available and in a format that machines can read. The law aims to improve transparency and accountability. However, to prevent undue burden, this requirement does not apply to small or micro businesses as defined by the Commission Recommendation 2003/361/EC (25), or to those not classified as very large online platforms under this regulation."
General Data Protection Regulation (GDPR) - Contextual Paragraph (57),0.726295948,"Details of the Contextual Paragraph (57) in the General Data Protection Regulation (GDPR): If the personal data processed by a controller do not permit the controller to identify a natural person, the data controller should not be obliged to acquire additional information in order to identify the data subject for the sole purpose of complying with any provision of this Regulation. However, the controller should not refuse to take additional information provided by the data subject in order to support the exercise of his or her rights. Identification should include the digital identification of a data subject, for example through authentication mechanism such as the same credentials, used by the data subject to log-in to the on-line service offered by the data controller.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 57) that says if a company can't identify a person from the data they have, they aren't required to get more information just to comply with this law. However, if the person provides more information to help identify themselves, the company can't refuse to accept it. This can include digital identification, like the login details a person uses for the company's online services."
Digital Markets Act (DMA) - Contextual Paragraph (89),0.726272821,"Details of the Contextual Paragraph (89) in the Digital Markets Act (DMA): When preparing non-confidential summaries for publication in order to effectively enable interested third parties to provide comments, the Commission should give due regard to the legitimate interest of undertakings in the protection of their business secrets and other confidential information.",rectial,"The Digital Markets Act (DMA) has a provision (Paragraph 89) that deals with how non-confidential summaries are prepared for public viewing. This is done to allow interested third parties to comment on them. However, the DMA also emphasizes the need to respect the rights of businesses to protect their trade secrets and confidential information. So, while making these summaries, the Commission must consider the businesses' interest in keeping certain information private."
General Data Protection Regulation (GDPR) - Contextual Paragraph (83),0.726250947,"Details of the Contextual Paragraph (83) in the General Data Protection Regulation (GDPR): In order to maintain security and to prevent processing in infringement of this Regulation, the controller or processor should evaluate the risks inherent in the processing and implement measures to mitigate those risks, such as encryption. Those measures should ensure an appropriate level of security, including confidentiality, taking into account the state of the art and the costs of implementation in relation to the risks and the nature of the personal data to be protected. In assessing data security risk, consideration should be given to the risks that are presented by personal data processing, such as accidental or unlawful destruction, loss, alteration, unauthorised disclosure of, or access to, personal data transmitted, stored or otherwise processed which may in particular lead to physical, material or non-material damage.",recital,"The General Data Protection Regulation (GDPR) requires companies to assess the risks involved in handling personal data and take steps to minimize those risks. These steps could include encryption and should ensure adequate security and confidentiality. The measures taken should reflect the latest technology and be balanced against the cost of implementation, the risks involved, and the type of personal data being protected. Companies should consider risks such as accidental or illegal destruction, loss, alteration, unauthorized disclosure or access to personal data. These risks could potentially cause physical, material, or non-material damage."
Digital Services Act (DSA) - Contextual paragraph (67),0.726244271,"Details of the contextual paragraph (67) of the Digital Services Act (DSA): Dark patterns on online interfaces of online platforms are practices that materially distort or impair, either on purpose or in effect, the ability of recipients of the service to make autonomous and informed choices or decisions. Those practices can be used to persuade the recipients of the service to engage in unwanted behaviours or into undesired decisions which have negative consequences for them. Providers of online platforms should therefore be prohibited from deceiving or nudging recipients of the service and from distorting or impairing the autonomy, decision-making, or choice of the recipients of the service via the structure, design or functionalities of an online interface or a part thereof. This should include, but not be limited to, exploitative design choices to direct the recipient to actions that benefit the provider of online platforms, but which may not be in the recipients' interests, presenting choices in a non-neutral manner, such as giving more prominence to certain choices through visual, auditory, or other components, when asking the recipient of the service for a decision.
It should also include repeatedly requesting a recipient of the service to make a choice where such a choice has already been made, making the procedure of cancelling a service significantly more cumbersome than signing up to it, or making certain choices more difficult or time-consuming than others, making it unreasonably difficult to discontinue purchases or to sign out from a given online platform allowing consumers to conclude distance contracts with traders, and deceiving the recipients of the service by nudging them into decisions on transactions, or by default settings that are very difficult to change, and so unreasonably bias the decision making of the recipient of the service, in a way that distorts and impairs their autonomy, decision-making and choice. However, rules preventing dark patterns should not be understood as preventing providers to interact directly with recipients of the service and to offer new or additional services to them. Legitimate practices, for example in advertising, that are in compliance with Union law should not in themselves be regarded as constituting dark patterns. Those rules on dark patterns should be interpreted as covering prohibited practices falling within the scope of this Regulation to the extent that those practices are not already covered under Directive 2005/29/EC or Regulation (EU) 2016/679.",recital,"The Digital Services Act (DSA) introduces new rules to protect online users from ""dark patterns"". These are manipulative design techniques used by online platforms to trick or pressure users into making decisions they might not want to, such as making purchases or signing up for services. The DSA prohibits platforms from using these tactics, which can include making certain choices more prominent, making it hard to cancel a service, or using default settings that are difficult to change. However, the law doesn't stop platforms from interacting with users or offering new services, as long as they comply with EU law. The DSA covers practices not already regulated under Directive 2005/29/EC or Regulation (EU) 2016/679."
Digital Markets Act (DMA) - Contextual Paragraph (69),0.726231575,"Details of the Contextual Paragraph (69) in the Digital Markets Act (DMA): The obligations of gatekeepers should only be updated after a thorough investigation into the nature and impact of specific practices that may be newly identified, following an in-depth investigation, as unfair or limiting contestability in the same manner as the unfair practices laid down in this Regulation while potentially escaping the scope of the current set of obligations. The Commission should be able to launch an investigation with a view to determining whether the existing obligations need to be updated, either on its own initiative or following a justified request of at least three Member States. When presenting such justified requests, it should be possible for Member States to include information on newly introduced offers of products, services, software or features which raise concerns of contestability or fairness, whether implemented in the context of existing core platform services or otherwise. Where, following a market investigation, the Commission deems it necessary to modify essential elements of this Regulation, such as the inclusion of new obligations that depart from the same contestability or fairness issues addressed by this Regulation, the Commission should advance a proposal to amend this Regulation.",rectial,"The Digital Markets Act (DMA) states that any changes to the responsibilities of digital gatekeepers should only occur after a detailed investigation into new practices that may be unfair or limit competition. The European Commission can initiate this investigation or it can be requested by at least three member countries. These countries can include information about new products or services that may raise concerns about competition or fairness. If the Commission finds it necessary to change key parts of the DMA, such as adding new obligations, it will propose an amendment to the law."
Digital Services Act (DSA) - Contextual paragraph (135),0.726207078,"Details of the contextual paragraph (135) of the Digital Services Act (DSA): The Commission, through the Chair, should participate in the Board without voting rights. Through the Chair, the Commission should ensure that the agenda of the meetings is set in accordance with the requests of the members of the Board as laid down in the rules of procedure and in compliance with the duties of the Board laid down in this Regulation.",recital,"The Digital Services Act (DSA) states that the Commission, represented by the Chair, should be a part of the Board but without the ability to vote. The Chair's role is to make sure the Board's meeting agenda is arranged according to the requests of the Board members, following the established rules and duties outlined in the DSA."
Digital Services Act (DSA) - Article 54 Compensation,0.72617,"Article 54 Compensation in the Digital Services Act (DSA):  Recipients of the service shall have the right to seek, in accordance with Union and national law, compensation from providers of intermediary services, in respect of any damage or loss suffered due to an infringement by those providers of their obligations under this Regulation.",article,The Digital Services Act (DSA) introduces a new rule that allows users of digital services to seek compensation for any damage or loss they experience because the service provider didn't meet their responsibilities under this law. This compensation can be sought following both Union and national law procedures.
Digital Services Act (DSA) - Contextual paragraph (12),0.726131141,"Details of the contextual paragraph (12) of the Digital Services Act (DSA): In order to achieve the objective of ensuring a safe, predictable and trustworthy online environment, for the purpose of this Regulation the concept of 'illegal content' should broadly reflect the existing rules in the offline environment. In particular, the concept of 'illegal content' should be defined broadly to cover information relating to illegal content, products, services and activities. In particular, that concept should be understood to refer to information, irrespective of its form, that under the applicable law is either itself illegal, such as illegal hate speech or terrorist content and unlawful discriminatory content, or that the applicable rules render illegal in view of the fact that it relates to illegal activities. Illustrative examples include the sharing of images depicting child sexual abuse, the unlawful non-consensual sharing of private images, online stalking, the sale of non-compliant or counterfeit products, the sale of products or the provision of services in infringement of consumer protection law, the non-authorised use of copyright protected material, the illegal offer of accommodation services or the illegal sale of live animals. In contrast, an eyewitness video of a potential crime should not be considered to constitute illegal content, merely because it depicts an illegal act, where recording or disseminating such a video to the public is not illegal under national or Union law. In this regard, it is immaterial whether the illegality of the information or activity results from Union law or from national law that is in compliance with Union law and what the precise nature or subject matter is of the law in question.",recital,"The Digital Services Act (DSA) aims to create a safe and predictable online environment by defining 'illegal content' in line with existing offline rules. 'Illegal content' includes information related to illegal activities, products, services, and activities. Examples include hate speech, terrorist content, discriminatory content, child sexual abuse images, non-consensual sharing of private images, online stalking, sale of counterfeit products, copyright infringement, and illegal sales of live animals. However, a video showing a potential crime is not 'illegal content' if recording or sharing it is not illegal. The law applies whether the illegality is based on Union law or national law that complies with Union law."
Digital Services Act (DSA) - Contextual paragraph (144),0.726129889,"Details of the contextual paragraph (144) of the Digital Services Act (DSA): Compliance with the relevant obligations imposed under this Regulation should be enforceable by means of fines and periodic penalty payments. To that end, appropriate levels of fines and periodic penalty payments should also be laid down for non-compliance with the obligations and breach of the procedural rules, subject to appropriate limitation periods in accordance with the principles of proportionality and ne bis in idem. The Commission and the relevant national authorities should coordinate their enforcement efforts in order to ensure that those principles are respected. In particular, the Commission should take into account any fines and penalties imposed on the same legal person for the same facts through a final decision in proceedings relating to an infringement of other Union or national rules, so as to ensure that the overall fines and penalties imposed are proportionate and correspond to the seriousness of the infringements committed. All decisions taken by the Commission under this Regulation are subject to review by the Court of Justice of the European Union in accordance with the TFEU. The Court of Justice of the European Union should have unlimited jurisdiction in respect of fines and penalty payments in accordance with Article 261 TFEU.",recital,"The Digital Services Act (DSA) mandates that companies must comply with its regulations or face fines and periodic penalty payments. The level of these fines and penalties will be proportionate to the seriousness of the violation and will be subject to certain time limitations. The European Commission and national authorities will work together to enforce these rules. If a company is fined for the same violation under different regulations, the Commission will consider these when deciding the total penalty to ensure it is fair. The Court of Justice of the European Union has the power to review any decisions made by the Commission under this law."
Artifical Inellegence Act (AI Act) - Overview paragraph 65,0.726084232,"Aritifical Intelligence Act (AI Act) overview paragraph (65): In order to carry out third-party conformity assessment for AI systems intended to be used for the remote biometric identification of persons, notified bodies should be designated under this Regulation by the national competent authorities, provided they are compliant with a set of requirements, notably on independence, competence and absence of conflicts of interests.",recital,"The Artificial Intelligence Act (AI Act) states that if an AI system is used to remotely identify people, it must be assessed by a third-party body. This body should be appointed by national authorities under this regulation. It's important that this body meets certain criteria, such as being independent, competent, and free from conflicts of interest."
Digital Services Act (DSA) - Contextual paragraph (33),0.726067662,"Details of the contextual paragraph (33) of the Digital Services Act (DSA): The provider of intermediary services should inform the issuing authority about any follow-up given to such orders without undue delay, in compliance with the time limits set out in relevant Union or national law.",recital,"The Digital Services Act (DSA) requires that any company providing intermediary services, such as a social media platform or online marketplace, must promptly inform the relevant authorities about any actions they've taken in response to official orders. This must be done within the timeframe specified by either European Union or national laws."
General Data Protection Regulation (GDPR) - Contextual Paragraph (29),0.726017058,"Details of the Contextual Paragraph (29) in the General Data Protection Regulation (GDPR): In order to create incentives to apply pseudonymisation when processing personal data, measures of pseudonymisation should, whilst allowing general analysis, be possible within the same controller when that controller has taken technical and organisational measures necessary to ensure, for the processing concerned, that this Regulation is implemented, and that additional information for attributing the personal data to a specific data subject is kept separately. The controller processing the personal data should indicate the authorised persons within the same controller.",recital,"The General Data Protection Regulation (GDPR) encourages companies to use pseudonymisation, a method that replaces private data with artificial identifiers, to protect personal data. This process allows for general analysis without revealing individual identities. The company (controller) must take necessary steps to ensure GDPR is followed and any information that could identify a person is stored separately. The company should also specify who within the organization is authorized to process the personal data."
General Data Protection Regulation (GDPR) - Contextual Paragraph (10),0.72599709,"Details of the Contextual Paragraph (10) in the General Data Protection Regulation (GDPR): In order to ensure a consistent and high level of protection of natural persons and to remove the obstacles to flows of personal data within the Union, the level of protection of the rights and freedoms of natural persons with regard to the processing of such data should be equivalent in all Member States. Consistent and homogenous application of the rules for the protection of the fundamental rights and freedoms of natural persons with regard to the processing of personal data should be ensured throughout the Union. Regarding the processing of personal data for compliance with a legal obligation, for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller, Member States should be allowed to maintain or introduce national provisions to further specify the application of the rules of this Regulation. In conjunction with the general and horizontal law on data protection implementing Directive 95/46/EC, Member States have several sector-specific laws in areas that need more specific provisions. This Regulation also provides a margin of manoeuvre for Member States to specify its rules, including for the processing of special categories of personal data (""sensitive data""). To that extent, this Regulation does not exclude Member State law that sets out the circumstances for specific processing situations, including determining more precisely the conditions under which the processing of personal data is lawful.",recital,"The General Data Protection Regulation (GDPR) aims to consistently protect individuals' personal data across all EU member states. It sets a standard for data protection, but allows individual countries to create additional rules for specific situations. This includes processing data for legal obligations, public interest tasks, or official authority. Countries can also make rules for processing special categories of personal data, also known as ""sensitive data"". The GDPR doesn't exclude laws that detail specific situations for lawful data processing. This law works alongside other existing data protection laws."
Digital Services Act (DSA) - Contextual paragraph (127),0.725969851,"Details of the contextual paragraph (127) of the Digital Services Act (DSA): Given the cross-border and cross-sectoral relevance of intermediary services, a high level of cooperation is necessary to ensure the consistent application of this Regulation and the availability of relevant information for the exercise of enforcement tasks through the information sharing system. Cooperation may take different forms depending on the issues at stake, without prejudice to specific joint investigation exercises. It is in any case necessary that the Digital Services Coordinator of establishment of a provider of intermediary services informs other Digital Services Coordinators about issues, investigations and actions which are going to be taken vis  vis such a provider. Moreover, when a competent authority in a Member State holds relevant information for an investigation carried out by the competent authorities in the Member State of establishment, or is able to gather such information located in its territory to which the competent authorities in the Member State of establishment do not have access, the Digital Services Coordinator of destination should assist the Digital Services Coordinator of establishment in a timely manner, including through the exercise of its powers of investigation in accordance with the applicable national procedures and the Charter. The addressee of such investigatory measures should comply with them and be liable in case of failure to comply, and the competent authorities in the Member State of establishment should be able to rely on the information gathered through mutual assistance, in order to ensure compliance with this Regulation.",recital,"The Digital Services Act (DSA) requires strong cooperation across borders and sectors to ensure that digital services are regulated consistently and effectively. This involves sharing relevant information for enforcement tasks. The Digital Services Coordinator (DSC) for each service provider must inform other DSCs about any issues, investigations, or actions that are going to be taken. If a competent authority in one member state has information that could help an investigation in another, the DSC in the first state should assist the DSC in the second. This could involve conducting investigations according to national procedures. Anyone subject to such investigations must comply and could be held liable if they don't. The authorities in the state where the service provider is based should be able to use the information gathered in this way to ensure compliance with the DSA."
Digital Services Act (DSA) - Contextual paragraph (39),0.725961566,"Details of the contextual paragraph (39) of the Digital Services Act (DSA): The requirements to provide information on redress mechanisms available to the provider of the intermediary service and to the recipient of the service who provided the content include a requirement to provide information about administrative complaint-handling mechanisms and judicial redress including appeals against orders issued by judicial authorities. Moreover, Digital Services Coordinators could develop national tools and guidance as regards complaint and redress mechanisms applicable in their respective territory, in order to facilitate access to such mechanisms by recipients of the service. Finally, when applying this Regulation Member States should respect the fundamental right to an effective judicial remedy and to a fair trial as provided for in Article 47 of the Charter. This Regulation should therefore not prevent the relevant national judicial or administrative authorities from issuing, on the basis of the applicable Union or national law, an order to restore content, where such content was in compliance with the terms and conditions of the provider of the intermediary service but has been erroneously considered as illegal by that provider and has been removed.",recital,"The Digital Services Act (DSA) requires online service providers to clearly explain how users can make complaints or seek legal remedies if they feel their content has been unfairly treated. This includes cases where content has been wrongly removed. National Digital Services Coordinators may develop tools to help users access these complaint and remedy procedures. The law also emphasizes that member states must respect the right to a fair trial and effective legal remedy. This means that if content was wrongly considered illegal and removed, national authorities can order it to be restored."
Digital Markets Act (DMA) - Contextual Paragraph (85),0.725953817,"Details of the Contextual Paragraph (85) in the Digital Markets Act (DMA): The Commission should be able to take the necessary actions to monitor the effective implementation of and compliance with the obligations laid down in this Regulation. Such actions should include the ability of the Commission to appoint independent external experts and auditors to assist the Commission in this process, including, where applicable, from competent authorities of the Member States, such as data or consumer protection authorities. When appointing auditors, the Commission should ensure sufficient rotation.",rectial,"The Digital Markets Act (DMA) allows the Commission to take necessary steps to ensure that the rules of the act are being followed. This includes the power to hire independent experts and auditors, who may come from relevant authorities in member countries, such as those involved in data or consumer protection. The Commission must also make sure there is enough rotation when appointing auditors."
General Data Protection Regulation (GDPR) - Contextual Paragraph (31),0.725929916,"Details of the Contextual Paragraph (31) in the General Data Protection Regulation (GDPR): Public authorities to which personal data are disclosed in accordance with a legal obligation for the exercise of their official mission, such as tax and customs authorities, financial investigation units, independent administrative authorities, or financial market authorities responsible for the regulation and supervision of securities markets should not be regarded as recipients if they receive personal data which are necessary to carry out a particular inquiry in the general interest, in accordance with Union or Member State law. The requests for disclosure sent by the public authorities should always be in writing, reasoned and occasional and should not concern the entirety of a filing system or lead to the interconnection of filing systems. The processing of personal data by those public authorities should comply with the applicable data-protection rules according to the purposes of the processing.",recital,"The General Data Protection Regulation (GDPR) Paragraph 31 states that public authorities (like tax departments or financial regulators) can access personal data if legally required for their official duties. However, they're not considered 'recipients' if the data is needed for a specific public interest investigation. Any data requests must be written, justified, and not frequent, and shouldn't involve all data in a system or connect different systems. These authorities must follow data protection rules when handling personal data."
Digital Markets Act (DMA) - Contextual Paragraph (64),0.725912392,"Details of the Contextual Paragraph (64) in the Digital Markets Act (DMA): The lack of interoperability allows gatekeepers that provide number-independent interpersonal communications services to benefit from strong network effects, which contributes to the weakening of contestability. Furthermore, regardless of whether end users ""multi-home"", gatekeepers often provide number-independent interpersonal communications services as part of their platform ecosystem, and this further exacerbates entry barriers for alternative providers of such services and increases costs for end users to switch. Without prejudice to Directive (EU) 2018/1972 of the European Parliament and of the Council ( 14) and, in particular, the conditions and procedures laid down in Article 61 thereof, gatekeepers should therefore ensure, free of charge and upon request, interoperability with certain basic functionalities of their number-independent interpersonal communications services that they provide to their own end users, to third-party providers of such services. Gatekeepers should ensure interoperability for third-party providers of number-independent interpersonal communications services that offer or intend to offer their number-independent interpersonal communications services to end users and business users in the Union. To facilitate the practical implementation of such interoperability, the gatekeeper concerned should be required to publish a reference offer laying down the technical details and general terms and conditions of interoperability with its number-independent interpersonal communications services. It should be possible for the Commission, if applicable, to consult the Body of European Regulators for Electronic Communications, in order to determine whether the technical details and the general terms and conditions published in the reference offer that the gatekeeper intends to implement or has implemented ensures compliance with this obligation. In all cases, the gatekeeper and the requesting provider should ensure that interoperability does not undermine a high level of security and data protection in line with their obligations laid down in this Regulation and applicable Union law, in particular Regulation (EU) 2016/679 and Directive 2002/58/EC. The obligation related to interoperability should be without prejudice to the information and choices to be made available to end users of the number-independent interpersonal communication services of the gatekeeper and the requesting provider under this Regulation and other Union law, in particular Regulation (EU) 2016/679.",rectial,"The Digital Markets Act (DMA) aims to increase competition in the digital market by requiring ""gatekeepers"" (large tech companies) to provide interoperability, or compatibility, with their communication services. This means that third-party providers should be able to integrate their services with those of the gatekeepers, which should be provided free of charge. To ensure this, gatekeepers must publish a reference offer detailing the technical aspects and terms of this interoperability. The European Commission can consult the Body of European Regulators for Electronic Communications to ensure these details comply with the law. However, both gatekeepers and third-party providers must maintain high security and data protection standards. The law also emphasizes that users should be informed and have choices regarding these communication services."
Digital Services Act (DSA) - Contextual paragraph (10),0.725904047,"Details of the contextual paragraph (10) of the Digital Services Act (DSA): This Regulation should be without prejudice to other acts of Union law regulating the provision of information society services in general, regulating other aspects of the provision of intermediary services in the internal market or specifying and complementing the harmonised rules set out in this Regulation, such as Directive 2010/13/EU of the European Parliament and of the Council (7) including the provisions thereof regarding video-sharing platforms, Regulations (EU) 2019/1148 (8), (EU) 2019/1150 (9), (EU) 2021/784 (10) and (EU) 2021/1232 (11) of the European Parliament and of the Council and Directive 2002/58/EC of the European Parliament and of the Council (12), and provisions of Union law set out in a Regulation on European Production and Preservation Orders for electronic evidence in criminal matters and in a Directive laying down harmonised rules on the appointment of legal representatives for the purpose of gathering evidence in criminal proceedings.
Similarly, for reasons of clarity, this Regulation should be without prejudice to Union law on consumer protection, in particular Regulations (EU) 2017/2394 (13) and (EU) 2019/1020 (14) of the European Parliament and of the Council, Directives 2001/95/EC (15), 2005/29/EC (16), 2011/83/EU (17) and 2013/11/EU (18) of the European Parliament and of the Council, and Council Directive 93/13/EEC (19), and on the protection of personal data, in particular Regulation (EU) 2016/679 of the European Parliament and of the Council (20).
This Regulation should also be without prejudice to Union rules on private international law, in particular rules regarding jurisdiction and the recognition and enforcement of judgments in civil and commercial matters, as Regulation (EU) No 1215/2012, and rules on the law applicable to contractual and non-contractual obligations. The protection of individuals with regard to the processing of personal data is governed solely by the rules of Union law on that subject, in particular Regulation (EU) 2016/679 and Directive 2002/58/EC. This Regulation should also be without prejudice to Union law on working conditions and Union law in the field of judicial cooperation in civil and criminal matters. However, to the extent that those Union legal acts pursue the same objectives as those laid down in this Regulation, the rules of this Regulation should apply in respect of issues that are not addressed or not fully addressed by those other legal acts as well as issues on which those other legal acts leave Member States the possibility of adopting certain measures at national level.",recital,"The Digital Services Act (DSA) is a new law that regulates online services. It does not affect other European Union laws that regulate similar services, such as Directive 2010/13/EU and Regulations (EU) 2019/1148, (EU) 2019/1150, (EU) 2021/784, and (EU) 2021/1232. It also does not affect consumer protection laws like Regulations (EU) 2017/2394 and (EU) 2019/1020, or personal data protection laws like Regulation (EU) 2016/679. The DSA does not interfere with laws on international private law or laws on working conditions. However, if these laws do not fully address certain issues or allow member states to adopt measures at a national level, the DSA will apply."
Digital Markets Act (DMA) - Contextual Paragraph (59),0.72589463,"Details of the Contextual Paragraph (59) in the Digital Markets Act (DMA): Gatekeepers benefit from access to vast amounts of data that they collect while providing the core platform services, as well as other digital services. To ensure that gatekeepers do not undermine the contestability of core platform services, or the innovation potential of the dynamic digital sector, by restricting switching or multi-homing, end users, as well as third parties authorised by an end user, should be granted effective and immediate access to the data they provided or that was generated through their activity on the relevant core platform services of the gatekeeper. The data should be received in a format that can be immediately and effectively accessed and used by the end user or the relevant third party authorised by the end user to which the data is ported. Gatekeepers should also ensure, by means of appropriate and high quality technical measures, such as application programming interfaces, that end users or third parties authorised by end users can freely port the data continuously and in real time. This should apply also to any other data at different levels of aggregation necessary to effectively enable such portability. For the avoidance of doubt, the obligation on the gatekeeper to ensure effective portability of data under this Regulation complements the right to data portability under the Regulation (EU) 2016/679. Facilitating switching or multi-homing should lead, in turn, to an increased choice for end users and acts as an incentive for gatekeepers and business users to innovate.",rectial,The Digital Markets Act (DMA) introduces a new rule to ensure fair competition in the digital sector. It focuses on 'gatekeepers' - big tech companies that have access to a lot of user data. The law requires these gatekeepers to allow users and third parties authorized by users to access their own data easily and immediately. This data should be in a format that can be used right away. Gatekeepers must also provide technical ways (like programming interfaces) for users to move their data freely and in real time. This rule is in addition to the existing right to move your data under Regulation (EU) 2016/679. The DMA hopes this will give users more choice and encourage gatekeepers to innovate.
Digital Services Act (DSA) - Contextual paragraph (38),0.725894511,"Details of the contextual paragraph (38) of the Digital Services Act (DSA): Orders to act against illegal content and to provide information are subject to the rules safeguarding the competence of the Member State in which the service provider addressed is established and the rules laying down possible derogations from that competence in certain cases, set out in Article 3 of Directive 2000/31/EC, only if the conditions of that Article are met. Given that the orders in question relate to specific items of illegal content and information, respectively, where they are addressed to providers of intermediary services established in another Member State they do not in principle restrict those providers' freedom to provide their services across borders. Therefore, the rules set out in Article 3 of Directive 2000/31/EC, including those regarding the need to justify measures derogating from the competence of the Member State in which the service provider is established on certain specified grounds and regarding the notification of such measures, do not apply in respect of those orders.",recital,"The Digital Services Act (DSA) allows orders to be made against illegal content and for information to be provided. These orders must follow the rules of the country where the service provider is based, as stated in Article 3 of Directive 2000/31/EC. However, these rules only apply if certain conditions are met. These orders do not generally limit the ability of service providers in other countries to offer their services across borders. Therefore, the rules in Article 3 of Directive 2000/31/EC, including the need to justify certain actions and the requirement to notify of such actions, do not apply to these orders."
"General Data Protection Regulation (GDPR) - Article 22 Automated individual decision-making, including profiling",0.725874722,"Details of Article 22 Automated individual decision-making, including profiling in the General Data Protection Regulation (GDPR): 1. The data subject shall have the right not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects concerning him or her or similarly significantly affects him or her. 2. Paragraph 1 shall not apply if the decision: (a) is necessary for entering into, or performance of, a contract between the data subject and a data controller; (b) is authorised by Union or Member State law to which the controller is subject and which also lays down suitable measures to safeguard the data subject's rights and freedoms and legitimate interests; or (c) is based on the data subject's explicit consent. 3. In the cases referred to in points (a) and (c) of paragraph 2, the data controller shall implement suitable measures to safeguard the data subject's rights and freedoms and legitimate interests, at least the right to obtain human intervention on the part of the controller, to express his or her point of view and to contest the decision. 4. Decisions referred to in paragraph 2 shall not be based on special categories of personal data referred to in Article 9(1), unless point (a) or (g) of Article 9(2) applies and suitable measures to safeguard the data subject's rights and freedoms and legitimate interests are in place.",article,"The General Data Protection Regulation (GDPR) Article 22 states that individuals have the right to not be subject to decisions made solely by automated processes, including profiling, that significantly affect them. However, there are exceptions if the decision is necessary for a contract, is authorized by law, or if the individual has given explicit consent. In these cases, the data controller must implement measures to protect the individual's rights and interests, including the right to human intervention, to express their viewpoint, and to challenge the decision. Decisions cannot be based on special categories of personal data unless specific conditions are met and protective measures are in place."
Digital Markets Act (DMA) - Contextual Paragraph (87),0.725848079,"Details of the Contextual Paragraph (87) in the Digital Markets Act (DMA): In order to ensure effective recovery of fines imposed on associations of undertakings for infringements that they have committed, it is necessary to lay down the conditions on which it should be possible for the Commission to require payment of the fine from the members of that association of undertakings where it is not solvent.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 87) that allows for the recovery of fines from companies that have violated the law. If an association of companies is fined and cannot pay, the law allows the Commission to require the individual members of the association to pay the fine. This is to ensure that penalties for violations are effectively enforced."
General Data Protection Regulation (GDPR) - Contextual Paragraph (78),0.725764155,"Details of the Contextual Paragraph (78) in the General Data Protection Regulation (GDPR): The protection of the rights and freedoms of natural persons with regard to the processing of personal data require that appropriate technical and organisational measures be taken to ensure that the requirements of this Regulation are met. In order to be able to demonstrate compliance with this Regulation, the controller should adopt internal policies and implement measures which meet in particular the principles of data protection by design and data protection by default. Such measures could consist, inter alia, of minimising the processing of personal data, pseudonymising personal data as soon as possible, transparency with regard to the functions and processing of personal data, enabling the data subject to monitor the data processing, enabling the controller to create and improve security features. When developing, designing, selecting and using applications, services and products that are based on the processing of personal data or process personal data to fulfil their task, producers of the products, services and applications should be encouraged to take into account the right to data protection when developing and designing such products, services and applications and, with due regard to the state of the art, to make sure that controllers and processors are able to fulfil their data protection obligations. The principles of data protection by design and by default should also be taken into consideration in the context of public tenders.",recital,"The General Data Protection Regulation (GDPR) Paragraph 78 requires that companies take appropriate measures to protect the rights and personal data of individuals. This includes creating internal policies and implementing procedures that prioritize data protection at the design stage and by default. Measures could include minimizing data processing, using pseudonyms for personal data, being transparent about data use, and allowing individuals to monitor their data processing. Companies that create products or services that handle personal data should consider data protection in their design and ensure they can meet data protection obligations. These principles should also be considered in public tenders."
Digital Services Act (DSA) - Contextual paragraph (93),0.725746334,"Details of the contextual paragraph (93) of the Digital Services Act (DSA): The audit report should be substantiated, in order to give a meaningful account of the activities undertaken and the conclusions reached. It should help inform, and where appropriate suggest improvements to the measures taken by the providers of the very large online platform and of the very large online search engine to comply with their obligations under this Regulation. The audit report should be transmitted to the Digital Services Coordinator of establishment, the Commission and the Board following the receipt of the audit report. Providers should also transmit upon completion without undue delay each of the reports on the risk assessment and the mitigation measures, as well as the audit implementation report of the provider of the very large online platform or of the very large online search engine showing how they have addressed the audit's recommendations. The audit report should include an audit opinion based on the conclusions drawn from the audit evidence obtained. A 'positive opinion' should be given where all evidence shows that the provider of the very large online platform or of the very large online search engine complies with the obligations laid down by this Regulation or, where applicable, any commitments it has undertaken pursuant to a code of conduct or crisis protocol, in particular by identifying, evaluating and mitigating the systemic risks posed by its system and services. A 'positive opinion' should be accompanied by comments where the auditor wishes to include remarks that do not have a substantial effect on the outcome of the audit. A 'negative opinion' should be given where the auditor considers that the provider of the very large online platform or of the very large online search engine does not comply with this Regulation or the commitments undertaken. Where the audit opinion could not reach a conclusion for specific elements that fall within the scope of the audit, an explanation of reasons for the failure to reach such a conclusion should be included in the audit opinion. Where applicable, the report should include a description of specific elements that could not be audited, and an explanation of why these could not be audited.",recital,"The Digital Services Act (DSA) requires large online platforms and search engines to have an audit report that clearly explains their activities and conclusions. This report should suggest improvements to their compliance measures. After the audit, the report should be sent to the Digital Services Coordinator, the Commission, and the Board. The providers should also promptly send reports on risk assessment, mitigation measures, and how they've addressed the audit's recommendations. The audit report will include an opinion, either positive (if the provider complies with the DSA and has managed risks) or negative (if the provider doesn't comply). If the audit can't reach a conclusion on certain elements, the report should explain why. The report should also describe any elements that couldn't be audited and why."
Digital Markets Act (DMA) - Contextual Paragraph (21),0.725745082,Details of the Contextual Paragraph (21) in the Digital Markets Act (DMA): An entrenched and durable position in its operations or the foreseeability of enjoying such a position in the future occurs notably where the contestability of the position of the undertaking providing the core platform service is limited. This is likely to be the case where that undertaking has provided a core platform service in at least three Member States to a very high number of business users and end users over a period of at least 3 years.,rectial,"The Digital Markets Act (DMA) includes a clause (Paragraph 21) that defines a company as having a strong, long-term position in the market if it's hard for other companies to challenge its position. This is particularly true if the company has provided a central service to a large number of business and individual users in at least three member states for a minimum of three years."
Artifical Inellegence Act (AI Act) - Overview paragraph 74,0.72571677,"Aritifical Intelligence Act (AI Act) overview paragraph (74): In order to minimise the risks to implementation resulting from lack of knowledge and expertise in the market as well as to facilitate compliance of providers and notified bodies with their obligations under this Regulation, the AI-on demand platform, the European Digital Innovation Hubs and the Testing and Experimentation Facilities established by the Commission and the Member States at national or EU level should possibly contribute to the implementation of this Regulation. Within their respective mission and fields of competence, they may provide in particular technical and scientific support to providers and notified bodies.",recital,"The Artificial Intelligence Act (AI Act) aims to reduce risks associated with AI implementation due to a lack of knowledge and expertise in the market. It also helps providers and notified bodies meet their obligations under this regulation. Tools like the AI-on demand platform, the European Digital Innovation Hubs, and the Testing and Experimentation Facilities, established by the Commission and Member States, can assist in implementing this regulation. These entities can offer technical and scientific support to providers and notified bodies within their areas of expertise."
General Data Protection Regulation (GDPR) - Contextual Paragraph (3),0.725712597,Details of the Contextual Paragraph (3) in the General Data Protection Regulation (GDPR): Directive 95/46/EC of the European Parliament and of the Council ( 4 ) seeks to harmonise the protection of fundamental rights and freedoms of natural persons in respect of processing activities and to ensure the free flow of personal data between Member States.,recital,The General Data Protection Regulation (GDPR) is a new law that aims to standardize the protection of individual's rights and freedoms regarding the handling of their personal data across all member states of the European Union. The law is specifically designed to safeguard personal information and ensure it can be freely transferred between these countries.
Digital Services Act (DSA) - Article 65 Enforcement of obligations of providers of very large online platforms and of very large online search engines,0.725699723,"Article 65 Enforcement of obligations of providers of very large online platforms and of very large online search engines in the Digital Services Act (DSA):  1.   For the purposes of investigating compliance of providers of very large online platforms and of very large online search engines with the obligations laid down in this Regulation, the Commission may exercise the investigatory powers laid down in this Section even before initiating proceedings pursuant to Article 66(2). It may exercise those powers on its own initiative or following a request pursuant to paragraph 2 of this Article.

2.   Where a Digital Services Coordinator has reason to suspect that a provider of a very large online platform or of a very large online search engine has infringed the provisions of Section 5 of Chapter III or has systemically infringed any of the provisions of this Regulation in a manner that seriously affects recipients of the service in its Member State, it may send, through the information sharing system referred to in Article 85, a request to the Commission to assess the matter.

3.   A request pursuant to paragraph 2 shall be duly reasoned and at least indicate:

(a) the point of contact of the provider of the very large online platform or of the very large online search engine concerned as provided for in Article 11;
(b) a description of the relevant facts, the provisions of this Regulation concerned and the reasons why the Digital Services Coordinator that sent the request suspects that the provider of the very large online platforms or of the very large online search engine concerned infringed this Regulation, including a description of the facts that show that the suspected infringement is of a systemic nature;
(c) any other information that the Digital Services Coordinator that sent the request considers relevant, including, where appropriate, information gathered on its own initiative.",article,"The Digital Services Act (DSA) allows the Commission to investigate large online platforms and search engines to ensure they are following the law. This can be done before any formal proceedings begin, either on the Commission's own initiative or in response to a request. If a Digital Services Coordinator suspects that a large online platform or search engine is breaking the law in a way that seriously affects users, they can ask the Commission to investigate. This request must be well-reasoned and include contact information for the platform or search engine, a description of the suspected wrongdoing, and any other relevant information."
General Data Protection Regulation (GDPR) - Contextual Paragraph (52),0.725667,"Details of the Contextual Paragraph (52) in the General Data Protection Regulation (GDPR): Derogating from the prohibition on processing special categories of personal data should also be allowed when provided for in Union or Member State law and subject to suitable safeguards, so as to protect personal data and other fundamental rights, where it is in the public interest to do so, in particular processing personal data in the field of employment law, social protection law including pensions and for health security, monitoring and alert purposes, the prevention or control of communicable diseases and other serious threats to health. Such a derogation may be made for health purposes, including public health and the management of health-care services, especially in order to ensure the quality and cost-effectiveness of the procedures used for settling claims for benefits and services in the health insurance system, or for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes. A derogation should also allow the processing of such personal data where necessary for the establishment, exercise or defence of legal claims, whether in court proceedings or in an administrative or out-of-court procedure.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 52, that allows some exceptions to the ban on processing certain personal data. This can be done when it's in the public interest and has proper protections in place. This could apply to areas like employment law, social protection, pensions, and health security. It could also be used for managing health-care services, ensuring quality and cost-effectiveness in health insurance claims, or for archiving, research, or statistical purposes. The rule also allows the processing of this personal data for legal claims, whether in court or out-of-court."
Digital Markets Act (DMA) - Contextual Paragraph (30),0.725652695,"Details of the Contextual Paragraph (30) in the Digital Markets Act (DMA): The very rapidly changing and complex technological nature of core platform services requires a regular review of the status of gatekeepers, including those that it is foreseen will enjoy an entrenched and durable position in their operations in the near future. To provide all of the market participants, including the gatekeepers, with the required certainty as to the applicable legal obligations, a time limit for such regular reviews is necessary. It is also important to conduct such reviews on a regular basis and at least every 3 years. Furthermore, it is important to clarify that not every change in the facts on the basis of which an undertaking providing core platform services was designated as a gatekeeper should require amendment of the designation decision. Amendment will only be necessary if the change in the facts also leads to a change in the assessment. Whether or not that is the case should be based on a case-bycase assessment of the facts and circumstances",rectial,"The Digital Markets Act (DMA) requires regular reviews of major tech platforms, known as gatekeepers, due to the fast-paced and complex nature of the tech industry. These reviews, which should occur at least every three years, aim to provide clarity about legal obligations for all market participants. Not every change in a gatekeeper's status will require a change in its legal designation. Any alterations will only be necessary if the changes also affect the legal assessment of the platform. This will be determined on a case-by-case basis."
General Data Protection Regulation (GDPR) - Contextual Paragraph (48),0.725641608,"Details of the Contextual Paragraph (48) in the General Data Protection Regulation (GDPR): Controllers that are part of a group of undertakings or institutions affiliated to a central body may have a legitimate interest in transmitting personal data within the group of undertakings for internal administrative purposes, including the processing of clients' or employees' personal data. The general principles for the transfer of personal data, within a group of undertakings, to an undertaking located in a third country remain unaffected.",recital,"The General Data Protection Regulation (GDPR) allows companies that are part of a larger group or affiliated with a central body to share personal data within the group for internal administrative purposes. This can include processing personal data of clients or employees. However, the basic rules for transferring personal data to a company in a different country still apply."
General Data Protection Regulation (GDPR) - Contextual Paragraph (63),0.72562319,"Details of the Contextual Paragraph (63) in the General Data Protection Regulation (GDPR): A data subject should have the right of access to personal data which have been collected concerning him or her, and to exercise that right easily and at reasonable intervals, in order to be aware of, and verify, the lawfulness of the processing. This includes the right for data subjects to have access to data concerning their health, for example the data in their medical records containing information such as diagnoses, examination results, assessments by treating physicians and any treatment or interventions provided. Every data subject should therefore have the right to know and obtain communication in particular with regard to the purposes for which the personal data are processed, where possible the period for which the personal data are processed, the recipients of the personal data, the logic involved in any automatic personal data processing and, at least when based on profiling, the consequences of such processing. Where possible, the controller should be able to provide remote access to a secure system which would provide the data subject with direct access to his or her personal data. That right should not adversely affect the rights or freedoms of others, including trade secrets or intellectual property and in particular the copyright protecting the software. However, the result of those considerations should not be a refusal to provide all information to the data subject. Where the controller processes a large quantity of information concerning the data subject, the controller should be able to request that, before the information is delivered, the data subject specify the information or processing activities to which the request relates.",recital,"The General Data Protection Regulation (GDPR) gives individuals the right to access their personal data held by companies, including health data. This should be easy and possible at reasonable intervals. Individuals should be informed about why their data is being processed, for how long, who it's shared with, and the logic behind any automatic data processing. If possible, companies should provide direct access to this data through a secure system. This right should not infringe on others' rights, such as trade secrets or intellectual property. Companies can't refuse to provide this information, but if they hold a lot of data about an individual, they can ask them to specify what information they want access to."
General Data Protection Regulation (GDPR) - Contextual Paragraph (124),0.725607276,"Details of the Contextual Paragraph (124) in the General Data Protection Regulation (GDPR): Where the processing of personal data takes place in the context of the activities of an establishment of a controller or a processor in the Union and the controller or processor is established in more than one Member State, or where processing taking place in the context of the activities of a single establishment of a controller or processor in the Union substantially affects or is likely to substantially affect data subjects in more than one Member State, the supervisory authority for the main establishment of the controller or processor or for the single establishment of the controller or processor should act as lead authority. It should cooperate with the other authorities concerned, because the controller or processor has an establishment on the territory of their Member State, because data subjects residing on their territory are substantially affected, or because a complaint has been lodged with them. Also where a data subject not residing in that Member State has lodged a complaint, the supervisory authority with which such complaint has been lodged should also be a supervisory authority concerned. Within its tasks to issue guidelines on any question covering the application of this Regulation, the Board should be able to issue guidelines in particular on the criteria to be taken into account in order to ascertain whether the processing in question substantially affects data subjects in more than one Member State and on what constitutes a relevant and reasoned objection.",recital,"The General Data Protection Regulation (GDPR) Paragraph 124 states that if a company processes personal data and operates in more than one EU country, or if its data processing significantly impacts individuals in multiple EU countries, the supervisory authority in the company's main country should lead any regulatory actions. This authority should collaborate with authorities from other affected countries. This also applies if a complaint is lodged in a country where the data subject doesn't reside. The Board can issue guidelines on determining if data processing significantly impacts individuals in multiple EU countries and what constitutes a valid objection."
Digital Markets Act (DMA) - Contextual Paragraph (93),0.725574195,"Details of the Contextual Paragraph (93) in the Digital Markets Act (DMA): In order to ensure coherence and effective complementarity in the implementation of this Regulation and of other sectoral regulations applicable to gatekeepers, the Commission should benefit from the expertise of a dedicated high-level group. It should be possible for that high-level group to also assist the Commission by means of advice, expertise and recommendations, when relevant, in general matters relating to the implementation or enforcement of this Regulation. The high-level group should be composed of the relevant European bodies and networks, and its composition should ensure a high level of expertise and a geographical balance. The members of the high-level group should regularly report to the bodies and networks they represent regarding the tasks performed in the context of the group, and consult them in that regard.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 93) for the creation of a high-level group to help the Commission implement and enforce the law. This group, made up of experts from various European bodies, will provide advice, expertise, and recommendations. The group's composition will ensure a balance of expertise and representation from different geographical areas. Members of this group are expected to regularly update their respective bodies on the group's activities and seek their input."
General Data Protection Regulation (GDPR) - Contextual Paragraph (158),0.725568,"Details of the Contextual Paragraph (158) in the General Data Protection Regulation (GDPR): Where personal data are processed for archiving purposes, this Regulation should also apply to that processing, bearing in mind that this Regulation should not apply to deceased persons. Public authorities or public or private bodies that hold records of public interest should be services which, pursuant to Union or Member State law, have a legal obligation to acquire, preserve, appraise, arrange, describe, communicate, promote, disseminate and provide access to records of enduring value for general public interest. Member States should also be authorised to provide for the further processing of personal data for archiving purposes, for example with a view to providing specific information related to the political behaviour under former totalitarian state regimes, genocide, crimes against humanity, in particular the Holocaust, or war crimes.",recital,"The General Data Protection Regulation (GDPR) states that any personal data used for archiving must follow the rules of this regulation. However, the GDPR doesn't apply to data of deceased individuals. Public authorities or organizations that hold public interest records are required by law to manage and provide access to these records. The GDPR also allows member states to further process personal data for archiving, such as providing information about political behavior under former totalitarian regimes, genocide, crimes against humanity, including the Holocaust, or war crimes."
General Data Protection Regulation (GDPR) - Contextual Paragraph (128),0.725560308,Details of the Contextual Paragraph (128) in the General Data Protection Regulation (GDPR): The rules on the lead supervisory authority and the one-stop-shop mechanism should not apply where the processing is carried out by public authorities or private bodies in the public interest. In such cases the only supervisory authority competent to exercise the powers conferred to it in accordance with this Regulation should be the supervisory authority of the Member State where the public authority or private body is established.,recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 128, stating that public authorities or private organizations working in public interest are exempt from the 'one-stop-shop' mechanism. This mechanism usually allows one lead supervisory authority to oversee data protection. However, in these cases, the supervisory authority from the same country where the public body or organization is based will be the only one with the power to oversee their data protection activities."
General Data Protection Regulation (GDPR) - Contextual Paragraph (15),0.725493133,"Details of the Contextual Paragraph (15) in the General Data Protection Regulation (GDPR): In order to prevent creating a serious risk of circumvention, the protection of natural persons should be technologically neutral and should not depend on the techniques used. The protection of natural persons should apply to the processing of personal data by automated means, as well as to manual processing, if the personal data are contained or are intended to be contained in a filing system. Files or sets of files, as well as their cover pages, which are not structured according to specific criteria should not fall within the scope of this Regulation.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 15, that aims to protect people's personal data, regardless of the technology used to process it. This protection applies to both automated and manual data processing, as long as the data is or will be part of a filing system. However, files or sets of files that are not organized based on specific criteria are not covered by this law."
Digital Services Act (DSA) - Article 86 Representation,0.725448906,"Article 86 Representation in the Digital Services Act (DSA):  1.   Without prejudice to Directive (EU) 2020/1828 or to any other type of representation under national law, recipients of intermediary services shall at least have the right to mandate a body, organisation or association to exercise the rights conferred by this Regulation on their behalf, provided the body, organisation or association meets all of the following conditions:

(a) it operates on a not-for-profit basis;
(b) it has been properly constituted in accordance with the law of a Member State;
(c) its statutory objectives include a legitimate interest in ensuring that this Regulation is complied with.

2.   Providers of online platforms shall take the necessary technical and organisational measures to ensure that complaints submitted by bodies, organisations or associations referred to in paragraph 1 of this Article on behalf of recipients of the service through the mechanisms referred to in Article 20(1) are processed and decided upon with priority and without undue delay.",article,"The Digital Services Act (DSA) allows users of online services to appoint a non-profit organization to represent their rights under this law, as long as the organization is legally established in a member state and has a legitimate interest in ensuring the law is followed. The DSA also requires online platforms to prioritize and promptly handle complaints submitted by these representative organizations on behalf of users."
General Data Protection Regulation (GDPR) - Contextual Paragraph (73),0.725442529,"Details of the Contextual Paragraph (73) in the General Data Protection Regulation (GDPR): Restrictions concerning specific principles and the rights of information, access to and rectification or erasure of personal data, the right to data portability, the right to object, decisions based on profiling, as well as the communication of a personal data breach to a data subject and certain related obligations of the controllers may be imposed by Union or Member State law, as far as necessary and proportionate in a democratic society to safeguard public security, including the protection of human life especially in response to natural or manmade disasters, the prevention, investigation and prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security, or of breaches of ethics for regulated professions, other important objectives of general public interest of the Union or of a Member State, in particular an important economic or financial interest of the Union or of a Member State, the keeping of public registers kept for reasons of general public interest, further processing of archived personal data to provide specific information related to the political behaviour under former totalitarian state regimes or the protection of the data subject or the rights and freedoms of others, including social protection, public health and humanitarian purposes. Those restrictions should be in accordance with the requirements set out in the Charter and in the European Convention for the Protection of Human Rights and Fundamental Freedoms.",recital,"The General Data Protection Regulation (GDPR) allows certain restrictions on data rights, such as data access, rectification, and erasure, if necessary for public security and other important public interests. These restrictions may be imposed by Union or Member State law. This includes protection during disasters, criminal investigations, maintaining public registers, and protecting data related to political behavior under former totalitarian regimes. These restrictions must align with the Charter and the European Convention for the Protection of Human Rights and Fundamental Freedoms."
Digital Markets Act (DMA) - Contextual Paragraph (65),0.725400209,"Details of the Contextual Paragraph (65) in the Digital Markets Act (DMA): To ensure the effectiveness of the obligations laid down by this Regulation, while also making certain that those obligations are limited to what is necessary to ensure contestability and tackling the harmful effects of the unfair practices by gatekeepers, it is important to clearly define and circumscribe them so as to allow the gatekeeper to fully comply with them, whilst fully complying with applicable law, and in particular Regulation (EU) 2016/679 and Directive 2002/58/EC and legislation on consumer protection, cyber se curity, product safety and accessibility requirements, including Directive (EU) 2019/882 and Directive (EU) 2016/2102 of the European Parliament and of the Council ( 15). The gatekeepers should ensure the compliance with this Regulation by design. Therefore, the necessary measures should be integrated as much as possible into the technological design used by the gatekeepers. It may in certain cases be appropriate for the Commission, following a dialogue with the gatekeeper concerned and after enabling third parties to make comments, to further specify some of the measures that the gatekeeper concerned should adopt in order to effectively comply with obligations that are susceptible of being further specified or, in the event of circumvention, with all obligations. In particular, such further specification should be possible where the implementation of an obligation susceptible to being further specified can be affected by variations of services within a single category of core platform services. For this purpose, it should be possible for the gatekeeper to request the Commission to engage in a process whereby the Commission can further specify some of the measures that the gatekeeper concerned should adopt in order to effectively comply with those obligations. The Commission should have discretion as to whether and when such further specification should be provided, while respecting the principles of equal treatment, proportionality, and good administration. In this respect, the Commission should provide the main reasons underlying its assessment, including any enforcement priorities. This process should not be used to undermine the effectiveness of this Regulation. Furthermore, this process is without prejudice to the powers of the Commission to adopt a decision establishing non-compliance with any of the obligations laid down in this Regulation by a gatekeeper, including the possibility to impose fines or periodic penalty payments. The Commission should be able to reopen proceedings, including where the specified measures turn out not to be effective. A reopening due to an ineffective specification adopted by decision should enable the Commission to amend the specification prospectively. The Commission should also be able to set a reasonable time period within which the proceedings can be reopened if the specified measures turn out not to be effective.",rectial,"The Digital Markets Act (DMA) aims to ensure fair practices by digital ""gatekeepers"" - major tech companies that control access to online markets. These gatekeepers must comply with the DMA and other relevant laws, such as those concerning consumer protection and cybersecurity. The DMA requires these companies to incorporate compliance measures into their technology design. If needed, the European Commission can specify additional measures for gatekeepers to follow. This process will be transparent, with the Commission explaining its decisions and allowing third parties to comment. However, the Commission retains the power to enforce non-compliance penalties, including fines. If specified measures prove ineffective, the Commission can reopen proceedings and amend the measures."
Digital Services Act (DSA) - Contextual paragraph (107),0.725387871,"Details of the contextual paragraph (107) of the Digital Services Act (DSA): The provision of online advertising generally involves several actors, including intermediary services that connect publishers of advertisements with advertisers. Codes of conduct should support and complement the transparency obligations relating to advertising for providers of online platforms, of very large online platforms and of very large online search engines set out in this Regulation in order to provide for flexible and effective mechanisms to facilitate and enhance the compliance with those obligations, notably as concerns the modalities of the transmission of the relevant information. This should include facilitating the transmission of the information on the advertiser who pays for the advertisement when they differ from the natural or legal person on whose behalf the advertisement is presented on the online interface of an online platform. The codes of conduct should also include measures to ensure that meaningful information about the monetisation of data is appropriately shared throughout the value chain. The involvement of a wide range of stakeholders should ensure that those codes of conduct are widely supported, technically sound, effective and offer the highest levels of user-friendliness to ensure that the transparency obligations achieve their objectives. In order to ensure the effectiveness of codes of conduct, the Commission should include evaluation mechanisms in drawing up the codes of conduct. Where appropriate, the Commission may invite the Fundamental Rights Agency or the European Data Protection Supervisor to express their opinions on the respective code of conduct.",recital,"The Digital Services Act (DSA) requires online advertising providers, especially large platforms and search engines, to be transparent about who is paying for ads, even if they're not the ones presenting the ad. This law also requires these providers to share information about how data is monetized. To ensure these rules are followed, the DSA encourages the creation of codes of conduct involving various stakeholders. These codes should be user-friendly, effective, and include evaluation methods. If necessary, the Fundamental Rights Agency or the European Data Protection Supervisor may be asked to review these codes."
Digital Markets Act (DMA) - Contextual Paragraph (14),0.725374579,"Details of the Contextual Paragraph (14) in the Digital Markets Act (DMA): In particular, online intermediation services, online search engines, operating systems, online social networking, video sharing platform services, number-independent interpersonal communication services, cloud computing services, virtual assistants, web browsers and online advertising services, including advertising intermediation services, all have the capacity to affect a large number of end users and businesses, which entails a risk of unfair business practices. Therefore, they should be included in the definition of core platform services and fall into the scope of this Regulation. Online intermediation services can also be active in the field of financial services, and they can intermediate or be used to provide such services as listed non-exhaustively in Annex II to Directive (EU) 2015/1535 of the European Parliament and of the Council ( 13). For the purposes of this Regulation, the definition of core platform services should be technology neutral and should be understood to encompass those provided on or through various means or devices, such as connected TV or embedded digital services in vehicles. In certain circumstances, the notion of end users should encompass users that are traditionally considered business users, but in a given situation do not use the core platform services to provide goods or services to other end users, such as for example businesses relying on cloud computing services for their own purposes.",rectial,"The Digital Markets Act (DMA) is a new law that seeks to regulate online services like search engines, social networking, video sharing, cloud computing, virtual assistants, web browsers, and online advertising. These services can impact many users and businesses, and the law aims to prevent unfair business practices. The DMA also includes online financial services. The law applies regardless of the technology used to provide these services, such as through connected TVs or digital services in vehicles. The DMA also considers businesses that use these services for their own needs, like cloud computing, as end users."
General Data Protection Regulation (GDPR) - Article 63 Consistency mechanism,0.725344181,"Details of Article 63 Consistency mechanism in the General Data Protection Regulation (GDPR): In order to contribute to the consistent application of this Regulation throughout the Union, the supervisory authorities shall cooperate with each other and, where relevant, with the Commission, through the consistency mechanism as set out in this Section.",article,"Article 63 of the General Data Protection Regulation (GDPR) is about the Consistency Mechanism. This article ensures that the rules of GDPR are applied uniformly across all EU countries. To achieve this, the supervisory authorities of each country will work together, and if necessary, with the Commission. This cooperation is done through a system called the consistency mechanism."
General Data Protection Regulation (GDPR) - Article 78 Right to an effective judicial remedy against a supervisory authority,0.725339174,"Details of Article 78 Right to an effective judicial remedy against a supervisory authority in the General Data Protection Regulation (GDPR): 1. Without prejudice to any other administrative or non-judicial remedy, each natural or legal person shall have the right to an effective judicial remedy against a legally binding decision of a supervisory authority concerning them. 2. Without prejudice to any other administrative or non-judicial remedy, each data subject shall have the right to a an effective judicial remedy where the supervisory authority which is competent pursuant to Articles 55 and 56 does not handle a complaint or does not inform the data subject within three months on the progress or outcome of the complaint lodged pursuant to Article 77. 3. Proceedings against a supervisory authority shall be brought before the courts of the Member State where the supervisory authority is established. 4. Where proceedings are brought against a decision of a supervisory authority which was preceded by an opinion or a decision of the Board in the consistency mechanism, the supervisory authority shall forward that opinion or decision to the court.",article,"The General Data Protection Regulation (GDPR) includes Article 78, which allows individuals and businesses to legally challenge decisions made by data protection authorities. If a complaint is not addressed or the complainant is not informed about the progress within three months, they have the right to take the matter to court. Legal proceedings must be initiated in the country where the data protection authority is based. If a court case is related to a decision that was influenced by the Board's opinion, the data protection authority must provide that opinion to the court."
Digital Markets Act (DMA) - Article 42 Representative actions,0.725325227,Details of Article 42 Representative actions in the Digital Markets Act (DMA): Directive (EU) 2020/1828 shall apply to the representative actions brought against infringements by gatekeepers of provisions of this Regulation that harm or may harm the collective interests of consumers.,article,"Article 42 of the Digital Markets Act (DMA) allows for collective legal actions to be taken against 'gatekeepers' (big tech companies) if they break the rules of this Regulation in a way that harms or could potentially harm the interests of consumers. This is governed by Directive (EU) 2020/1828. In simpler terms, if a big tech company does something against the DMA that negatively affects consumers, a group legal action can be brought against them."
Digital Services Act (DSA) - Article 6 Hosting,0.725323856,"Article 6 Hosting in the Digital Services Act (DSA):  1.   Where an information society service is provided that consists of the storage of information provided by a recipient of the service, the service provider shall not be liable for the information stored at the request of a recipient of the service, on condition that the provider:
(a) does not have actual knowledge of illegal activity or illegal content and, as regards claims for damages, is not aware of facts or circumstances from which the illegal activity or illegal content is apparent; or
(b) upon obtaining such knowledge or awareness, acts expeditiously to remove or to disable access to the illegal content.
2.   Paragraph 1 shall not apply where the recipient of the service is acting under the authority or the control of the provider.
3.   Paragraph 1 shall not apply with respect to the liability under consumer protection law of online platforms that allow consumers to conclude distance contracts with traders, where such an online platform presents the specific item of information or otherwise enables the specific transaction at issue in a way that would lead an average consumer to believe that the information, or the product or service that is the object of the transaction, is provided either by the online platform itself or by a recipient of the service who is acting under its authority or control.
4.   This Article shall not affect the possibility for a judicial or administrative authority, in accordance with a Member State's legal system, to require the service provider to terminate or prevent an infringement.",article,"The Digital Services Act (DSA) Article 6 states that online service providers aren't responsible for illegal content stored on their platforms, provided they weren't aware of its illegality. If they become aware, they should quickly remove or block access to it. However, this doesn't apply if the content is posted by someone under the provider's control or authority. Also, online platforms that allow consumers to make purchases from traders are liable under consumer protection law if they present information or products in a way that misleads consumers into thinking the platform itself, or someone under its control, is providing the product or service. Lastly, this law doesn't prevent legal authorities from asking the service provider to stop or prevent an infringement."
Digital Services Act (DSA) - Contextual paragraph (98),0.725323319,"Details of the contextual paragraph (98) of the Digital Services Act (DSA): In addition, where data is publicly accessible, such providers should not prevent researchers meeting an appropriate subset of criteria from using this data for research purposes that contribute to the detection, identification and understanding of systemic risks. They should provide access to such researchers including, where technically possible, in real-time, to the publicly accessible data, for example on aggregated interactions with content from public pages, public groups, or public figures, including impression and engagement data such as the number of reactions, shares, comments from recipients of the service. Providers of very large online platforms or of very large online search engines should be encouraged to cooperate with researchers and provide broader access to data for monitoring societal concerns through voluntary efforts, including through commitments and procedures agreed under codes of conduct or crisis protocols. Those providers and researchers should pay particular attention to the protection of personal data, and ensure that any processing of personal data complies with Regulation (EU) 2016/679. Providers should anonymise or pseudonymise personal data except in those cases that would render impossible the research purpose pursued.",recital,"The Digital Services Act (DSA) allows researchers who meet certain criteria to use publicly accessible data from large online platforms and search engines for research that helps identify and understand systemic risks. This could include real-time data on public interactions with content such as reactions, shares, and comments. The DSA encourages these providers to voluntarily cooperate with researchers and provide wider access to data for monitoring societal issues. However, the law also emphasizes the importance of personal data protection. Any data processing must comply with Regulation (EU) 2016/679, and personal data should be anonymized or pseudonymized, unless doing so would prevent the research from being carried out."
Digital Services Act (DSA) - Article 38 Recommender systems,0.725309312,"Article 38 Recommender systems in the Digital Services Act (DSA):  In addition to the requirements set out in Article 27, providers of very large online platforms and of very large online search engines that use recommender systems shall provide at least one option for each of their recommender systems which is not based on profiling as defined in Article 4, point (4), of Regulation (EU) 2016/679.",article,"The Digital Services Act (DSA) includes a new rule, Article 38, about recommender systems used by large online platforms and search engines. Recommender systems are algorithms that suggest content to users based on their past behavior. This new rule requires these platforms to provide at least one option for their recommender systems that doesn't rely on profiling, meaning it doesn't use your personal data to make recommendations. This is to give users more control over their online experience and protect their privacy."
General Data Protection Regulation (GDPR) - Contextual Paragraph (150),0.725295961,"Details of the Contextual Paragraph (150) in the General Data Protection Regulation (GDPR): In order to strengthen and harmonise administrative penalties for infringements of this Regulation, each supervisory authority should have the power to impose administrative fines. This Regulation should indicate infringements and the upper limit and criteria for setting the related administrative fines, which should be determined by the competent supervisory authority in each individual case, taking into account all relevant circumstances of the specific situation, with due regard in particular to the nature, gravity and duration of the infringement and of its consequences and the measures taken to ensure compliance with the obligations under this Regulation and to prevent or mitigate the consequences of the infringement. Where administrative fines are imposed on an undertaking, an undertaking should be understood to be an undertaking in accordance with Articles 101 and 102 TFEU for those purposes. Where administrative fines are imposed on persons that are not an undertaking, the supervisory authority should take account of the general level of income in the Member State as well as the economic situation of the person in considering the appropriate amount of the fine. The consistency mechanism may also be used to promote a consistent application of administrative fines. It should be for the Member States to determine whether and to which extent public authorities should be subject to administrative fines. Imposing an administrative fine or giving a warning does not affect the application of other powers of the supervisory authorities or of other penalties under this Regulation.",recital,"The General Data Protection Regulation (GDPR) has introduced new rules to strengthen and standardize penalties for violations. Each supervisory authority now has the power to impose fines, the amount of which will be determined case-by-case, considering factors such as the nature, severity, and duration of the violation, its consequences, and any measures taken to comply with the regulation. If fines are imposed on a business, they'll be based on the business's financial situation. If they're imposed on individuals, the person's income and economic situation will be considered. Member states will decide if and how much public authorities should be fined. The imposition of a fine or warning doesn't prevent the application of other penalties under the GDPR."
Digital Markets Act (DMA) - Contextual Paragraph (34),0.725271165,"Details of the Contextual Paragraph (34) in the Digital Markets Act (DMA): Contestability and fairness are intertwined. The lack of, or weak, contestability for a certain service can enable a gatekeeper to engage in unfair practices. Similarly, unfair practices by a gatekeeper can reduce the possibility of business users or others to contest the gatekeeper""s position. A particular obligation in this Regulation may, therefore, address both elements.",rectial,"The Digital Markets Act (DMA) includes a section (Paragraph 34) that discusses the relationship between competition and fairness. It suggests that if a certain service doesn't have enough competition, a dominant company (referred to as a gatekeeper) could use unfair practices. Likewise, if a gatekeeper uses unfair practices, it could limit the ability of other businesses to compete. Therefore, the DMA may impose obligations to address both competition and fairness issues."
General Data Protection Regulation (GDPR) - Contextual Paragraph (40),0.725266278,"Details of the Contextual Paragraph (40) in the General Data Protection Regulation (GDPR): In order for processing to be lawful, personal data should be processed on the basis of the consent of the data subject concerned or some other legitimate basis, laid down by law, either in this Regulation or in other Union or Member State law as referred to in this Regulation, including the necessity for compliance with the legal obligation to which the controller is subject or the necessity for the performance of a contract to which the data subject is party or in order to take steps at the request of the data subject prior to entering into a contract.",recital,"The General Data Protection Regulation (GDPR) requires that personal data can only be processed lawfully if the individual concerned has given consent or if there's another legitimate legal reason. This could be because it's necessary for a contract the individual is part of, or to meet a legal obligation of the data controller. The law applies to all EU member states and any other laws referred to in the GDPR."
General Data Protection Regulation (GDPR) - Contextual Paragraph (132),0.725262403,"Details of the Contextual Paragraph (132) in the General Data Protection Regulation (GDPR): Awareness-raising activities by supervisory authorities addressed to the public should include specific measures directed at controllers and processors, including micro, small and medium-sized enterprises, as well as natural persons in particular in the educational context.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 132) that emphasizes the need for public education about data protection. This law encourages supervisory authorities to take steps to increase awareness about data protection responsibilities among businesses of all sizes, including very small ones, and individuals, especially in educational settings."
Digital Markets Act (DMA) - Contextual Paragraph (108),0.72525686,Details of the Contextual Paragraph (108) in the Digital Markets Act (DMA): The European Data Protection Supervisor was consulted in accordance with Article 42 of Regulation (EU) 2018/1725 and delivered an opinion on 10 February 2021 ( 22).,rectial,"The Digital Markets Act (DMA) is a new law that involves the European Data Protection Supervisor. This official was asked for their opinion on the law, as required by another law (Regulation (EU) 2018/1725), and they gave their thoughts on 10 February 2021. This process is outlined in Paragraph 108 of the DMA."
General Data Protection Regulation (GDPR) - Article 52 Independence,0.725229,"Details of Article 52 Independence in the General Data Protection Regulation (GDPR): 1. Each supervisory authority shall act with complete independence in performing its tasks and exercising its powers in accordance with this Regulation. 2. The member or members of each supervisory authority shall, in the performance of their tasks and exercise of their powers in accordance with this Regulation, remain free from external influence, whether direct or indirect, and shall neither seek nor take instructions from anybody. 3. Member or members of each supervisory authority shall refrain from any action incompatible with their duties and shall not, during their term of office, engage in any incompatible occupation, whether gainful or not. 4. Each Member State shall ensure that each supervisory authority is provided with the human, technical and financial resources, premises and infrastructure necessary for the effective performance of its tasks and exercise of its powers, including those to be carried out in the context of mutual assistance, cooperation and participation in the Board. 5. Each Member State shall ensure that each supervisory authority chooses and has its own staff which shall be subject to the exclusive direction of the member or members of the supervisory authority concerned. 6. Each Member State shall ensure that each supervisory authority is subject to financial control which does not affect its independence and that it has separate, public annual budgets, which may be part of the overall state or national budget.",article,"Article 52 of the General Data Protection Regulation (GDPR) mandates that each supervisory authority must operate independently and free from external influence when performing its duties and exercising its powers. The members of these authorities should not engage in any activity that conflicts with their responsibilities and are not allowed to seek or take instructions from anyone. Each Member State must provide the necessary resources for these authorities to effectively perform their tasks. The authorities should have their own staff, who are under their exclusive direction. They should also have separate, public annual budgets, and their financial control should not compromise their independence."
General Data Protection Regulation (GDPR) - Contextual Paragraph (154),0.725228131,"Details of the Contextual Paragraph (154) in the General Data Protection Regulation (GDPR): This Regulation allows the principle of public access to official documents to be taken into account when applying this Regulation. Public access to official documents may be considered to be in the public interest. Personal data in documents held by a public authority or a public body should be able to be publicly disclosed by that authority or body if the disclosure is provided for by Union or Member State law to which the public authority or public body is subject. Such laws should reconcile public access to official documents and the reuse of public sector information with the right to the protection of personal data and may therefore provide for the necessary reconciliation with the right to the protection of personal data pursuant to this Regulation. The reference to public authorities and bodies should in that context include all authorities or other bodies covered by Member State law on public access to documents. Directive 2003/98/EC of the European Parliament and of the Council ( 1 ) leaves intact and in no way affects the level of protection of natural persons with regard to the processing of personal data under the provisions of Union and Member State law, and in particular does not alter the obligations and rights set out in this Regulation. In particular, that Directive should not apply to documents to which access is excluded or restricted by virtue of the access regimes on the grounds of protection of personal data, and parts of documents accessible by virtue of those regimes which contain personal data the re-use of which has been provided for by law as being incompatible with the law concerning the protection of natural persons with regard to the processing of personal data.",recital,"The General Data Protection Regulation (GDPR) allows public access to official documents, considering it in public interest. However, this must balance with the protection of personal data. Public authorities can disclose personal data if it's allowed by Union or Member State law. These laws should balance public access with personal data protection. Directive 2003/98/EC doesn't affect the protection level of individuals regarding data processing. It doesn't change the obligations and rights in the GDPR. This Directive doesn't apply to documents restricted due to personal data protection, and parts of documents containing personal data whose re-use is legally incompatible with personal data protection law."
Digital Markets Act (DMA) - Contextual Paragraph (109),0.725200236,"Details of the Contextual Paragraph (109) in the Digital Markets Act (DMA): This Regulation respects the fundamental rights and observes the principles recognised by the Charter of Fundamental Rights of the European Union, in particular Articles 16, 47 and 50 thereof. Accordingly, the interpretation and application of this Regulation should respect those rights and principles,",rectial,"The Digital Markets Act (DMA) is a new law that respects and follows the principles outlined in the Charter of Fundamental Rights of the European Union, particularly Articles 16, 47, and 50. These articles cover the protection of personal data, the right to an effective remedy and a fair trial, and the right not to be tried or punished twice in criminal proceedings for the same criminal offence. The DMA must be interpreted and applied in a way that respects these rights and principles."
General Data Protection Regulation (GDPR) - Contextual Paragraph (161),0.725149155,"Details of the Contextual Paragraph (161) in the General Data Protection Regulation (GDPR): For the purpose of consenting to the participation in scientific research activities in clinical trials, the relevant provisions of Regulation (EU) No 536/2014 of the European Parliament and of the Council ( 1 ) should apply.",recital,"The Contextual Paragraph (161) in the General Data Protection Regulation (GDPR) relates to how your personal data is used in scientific research, specifically clinical trials. It states that when you give consent for your data to be used in this way, the rules set out in another law, Regulation (EU) No 536/2014, should be followed. This ensures that your data is handled correctly and your privacy is protected."
General Data Protection Regulation (GDPR) - Contextual Paragraph (131),0.725111365,"Details of the Contextual Paragraph (131) in the General Data Protection Regulation (GDPR): Where another supervisory authority should act as a lead supervisory authority for the processing activities of the controller or processor but the concrete subject matter of a complaint or the possible infringement concerns only processing activities of the controller or processor in the Member State where the complaint has been lodged or the possible infringement detected and the matter does not substantially affect or is not likely to substantially affect data subjects in other Member States, the supervisory authority receiving a complaint or detecting or being informed otherwise of situations that entail possible infringements of this Regulation should seek an amicable settlement with the controller and, if this proves unsuccessful, exercise its full range of powers. This should include: specific processing carried out in the territory of the Member State of the supervisory authority or with regard to data subjects on the territory of that Member State; processing that is carried out in the context of an offer of goods or services specifically aimed at data subjects in the territory of the Member State of the supervisory authority; or processing that has to be assessed taking into account relevant legal obligations under Member State law.",recital,"The General Data Protection Regulation (GDPR) paragraph 131 states that if a data privacy issue only affects one EU member state, the local data protection authority should try to resolve the issue with the company involved. If they can't reach an agreement, the local authority can use its full powers to enforce the law. This applies to data processing done within the member state, data processing targeting residents of that state, or processing that needs to be evaluated based on the state's laws."
Digital Markets Act (DMA) - Article 52 Amendment to Directive (EU) 2020/1828,0.725098,"Details of Article 52 Amendment to Directive (EU) 2020/1828 in the Digital Markets Act (DMA): In Annex I to Directive (EU) 2020/1828, the following point is added: ""(67) Regulation (EU) 2022/1925 of the European Parliament and of the Council of 14 September 2022 on contestable and fair markets in the digital sector and amending Directives (EU) 2019/1937 and (EU) 2020/1828 (Digital Markets Act) (OJ L 265, 21.9.2022, p. 1).""",article,"The Digital Markets Act (DMA) has been updated with a new amendment, Article 52. This amendment, Regulation (EU) 2022/1925, was passed by the European Parliament and Council on 14 September 2022. It aims to ensure fair and competitive digital markets. This change also modifies two previous directives from 2019 and 2020. The details of this new regulation were published in the Official Journal of the European Union on 21 September 2022."
Digital Services Act (DSA) - Definition of 'online interface',0.725095868,"Definition of 'online interface' in the Digital Services Act (DSA): any software, including a website or a part thereof, and applications, including mobile applications.",recital,"The Digital Services Act (DSA) introduces a new term, 'online interface'. This refers to any kind of software, which could be a whole website or just a part of it. It also includes applications, such as those you might use on your mobile phone. So, under the DSA, any software, websites, or apps you use are considered 'online interfaces'."
Digital Services Act (DSA) - Article 22 Trusted flaggers,0.725090802,"Article 22 Trusted flaggers in the Digital Services Act (DSA):  1.   Providers of online platforms shall take the necessary technical and organisational measures to ensure that notices submitted by trusted flaggers, acting within their designated area of expertise, through the mechanisms referred to in Article 16, are given priority and are processed and decided upon without undue delay.

2.   The status of 'trusted flagger' under this Regulation shall be awarded, upon application by any entity, by the Digital Services Coordinator of the Member State in which the applicant is established, to an applicant that has demonstrated that it meets all of the following conditions:

(a) it has particular expertise and competence for the purposes of detecting, identifying and notifying illegal content;
(b) it is independent from any provider of online platforms;
(c) it carries out its activities for the purposes of submitting notices diligently, accurately and objectively.

3.   Trusted flaggers shall publish, at least once a year easily comprehensible and detailed reports on notices submitted in accordance with Article 16 during the relevant period. The report shall list at least the number of notices categorised by:
(a) the identity of the provider of hosting services,
(b) the type of allegedly illegal content notified,
(c) the action taken by the provider.

Those reports shall include an explanation of the procedures in place to ensure that the trusted flagger retains its independence.

Trusted flaggers shall send those reports to the awarding Digital Services Coordinator, and shall make them publicly available. The information in those reports shall not contain personal data.

4.   Digital Services Coordinators shall communicate to the Commission and the Board the names, addresses and email addresses of the entities to which they have awarded the status of the trusted flagger in accordance with paragraph 2 or whose trusted flagger status they have suspended in accordance with paragraph 6 or revoked in accordance with paragraph 7.

5.   The Commission shall publish the information referred to in paragraph 4 in a publicly available database, in an easily accessible and machine-readable format, and shall keep the database up to date.

6.   Where a provider of online platforms has information indicating that a trusted flagger has submitted a significant number of insufficiently precise, inaccurate or inadequately substantiated notices through the mechanisms referred to in Article 16, including information gathered in connection to the processing of complaints through the internal complaint-handling systems referred to in Article 20(4), it shall communicate that information to the Digital Services Coordinator that awarded the status of trusted flagger to the entity concerned, providing the necessary explanations and supporting documents. Upon receiving the information from the provider of online platforms, and if the Digital Services Coordinator considers that there are legitimate reasons to open an investigation, the status of trusted flagger shall be suspended during the period of the investigation. That investigation shall be carried out without undue delay.

7.   The Digital Services Coordinator that awarded the status of trusted flagger to an entity shall revoke that status if it determines, following an investigation either on its own initiative or on the basis information received from third parties, including the information provided by a provider of online platforms pursuant to paragraph 6, that the entity no longer meets the conditions set out in paragraph 2. Before revoking that status, the Digital Services Coordinator shall afford the entity an opportunity to react to the findings of its investigation and its intention to revoke the entity's status as trusted flagger.

8.   The Commission, after consulting the Board, shall, where necessary, issue guidelines to assist providers of online platforms and Digital Services Coordinators in the application of paragraphs 2, 6 and 7.",article,"The Digital Services Act (DSA) introduces the role of 'trusted flaggers' for online platforms. These are entities with expertise in identifying illegal content, who are independent from the platform providers. They must submit notices about illegal content promptly and objectively. These notices will be prioritized by the platform providers. Trusted flaggers must publish annual reports detailing the notices they've submitted, the type of content, and actions taken, ensuring they maintain their independence. This information, excluding personal data, will be sent to the Digital Services Coordinator and made publicly available. If a trusted flagger is found to be submitting inaccurate or unsubstantiated notices, their status can be suspended or revoked after an investigation. The Commission will provide guidelines to assist platform providers and coordinators in implementing these rules."
Digital Services Act (DSA) - Article 35 Mitigation of risks,0.725065947,"Article 35 Mitigation of risks in the Digital Services Act (DSA):  1.   Providers of very large online platforms and of very large online search engines shall put in place reasonable, proportionate and effective mitigation measures, tailored to the specific systemic risks identified pursuant to Article 34, with particular consideration to the impacts of such measures on fundamental rights. Such measures may include, where applicable:

(a) adapting the design, features or functioning of their services, including their online interfaces;
(b) adapting their terms and conditions and their enforcement;
(c) adapting content moderation processes, including the speed and quality of processing notices related to specific types of illegal content and, where appropriate, the expeditious removal of, or the disabling of access to, the content notified, in particular in respect of illegal hate speech or cyber violence, as well as adapting any relevant decision-making processes and dedicated resources for content moderation;
(d) testing and adapting their algorithmic systems, including their recommender systems;
(e) adapting their advertising systems and adopting targeted measures aimed at limiting or adjusting the presentation of advertisements in association with the service they provide;
(f) reinforcing the internal processes, resources, testing, documentation, or supervision of any of their activities in particular as regards detection of systemic risk;
(g) initiating or adjusting cooperation with trusted flaggers in accordance with Article 22 and the implementation of the decisions of out-of-court dispute settlement bodies pursuant to Article 21;
(h) initiating or adjusting cooperation with other providers of online platforms or of online search engines through the codes of conduct and the crisis protocols referred to in Articles 45 and 48 respectively;
(i) taking awareness-raising measures and adapting their online interface in order to give recipients of the service more information;
(j) taking targeted measures to protect the rights of the child, including age verification and parental control tools, tools aimed at helping minors signal abuse or obtain support, as appropriate;
(k) ensuring that an item of information, whether it constitutes a generated or manipulated image, audio or video that appreciably resembles existing persons, objects, places or other entities or events and falsely appears to a person to be authentic or truthful is distinguishable through prominent markings when presented on their online interfaces, and, in addition, providing an easy to use functionality which enables recipients of the service to indicate such information.

2.   The Board, in cooperation with the Commission, shall publish comprehensive reports, once a year. The reports shall include the following:

(a) identification and assessment of the most prominent and recurrent systemic risks reported by providers of very large online platforms and of very large online search engines or identified through other information sources, in particular those provided in compliance with Articles 39, 40 and 42;
(b) best practices for providers of very large online platforms and of very large online search engines to mitigate the systemic risks identified.

Those reports shall present systemic risks broken down by the Member States in which they occurred and in the Union as a whole, as applicable.

3.   The Commission, in cooperation with the Digital Services Coordinators, may issue guidelines on the application of paragraph 1 in relation to specific risks, in particular to present best practices and recommend possible measures, having due regard to the possible consequences of the measures on fundamental rights enshrined in the Charter of all parties involved. When preparing those guidelines the Commission shall organise public consultations.",article,"The Digital Services Act (DSA) requires large online platforms and search engines to implement measures to mitigate systemic risks, with a focus on protecting fundamental rights. These measures may involve adjusting their services, terms and conditions, content moderation processes, algorithms, advertising systems, and internal processes. They may also need to cooperate with trusted flaggers and other providers, provide more information to users, protect children's rights, and ensure manipulated content is clearly marked. The Board and the Commission will publish annual reports assessing systemic risks and best practices for mitigation. The Commission may also issue guidelines on managing specific risks, taking into account the potential impact on fundamental rights."
Artifical Inellegence Act (AI Act) - Overview paragraph 77,0.725044966,"Aritifical Intelligence Act (AI Act) overview paragraph (77): Member States hold a key role in the application and enforcement of this Regulation. In this respect, each Member State should designate one or more national competent authorities for the purpose of supervising the application and implementation of this Regulation. In order to increase organisation efficiency on the side of Member States and to set an official point of contact vis--vis the public and other counterparts at Member State and Union levels, in each Member State one national authority should be designated as national supervisory authority.",recital,"The Artificial Intelligence Act (AI Act) states that each member country has an important role in applying and enforcing this law. Each country should assign one or more national authorities to oversee the application and implementation of this law. To improve efficiency and establish an official point of contact for the public and other parties, each country should designate one national authority as the national supervisory authority."
General Data Protection Regulation (GDPR) - Contextual Paragraph (81),0.725007713,"Details of the Contextual Paragraph (81) in the General Data Protection Regulation (GDPR): To ensure compliance with the requirements of this Regulation in respect of the processing to be carried out by the processor on behalf of the controller, when entrusting a processor with processing activities, the controller should use only processors providing sufficient guarantees, in particular in terms of expert knowledge, reliability and resources, to implement technical and organisational measures which will meet the requirements of this Regulation, including for the security of processing. The adherence of the processor to an approved code of conduct or an approved certification mechanism may be used as an element to demonstrate compliance with the obligations of the controller. The carrying-out of processing by a processor should be governed by a contract or other legal act under Union or Member State law, binding the processor to the controller, setting out the subjectmatter and duration of the processing, the nature and purposes of the processing, the type of personal data and categories of data subjects, taking into account the specific tasks and responsibilities of the processor in the context of the processing to be carried out and the risk to the rights and freedoms of the data subject. The controller and processor may choose to use an individual contract or standard contractual clauses which are adopted either directly by the Commission or by a supervisory authority in accordance with the consistency mechanism and then adopted by the Commission. After the completion of the processing on behalf of the controller, the processor should, at the choice of the controller, return or delete the personal data, unless there is a requirement to store the personal data under Union or Member State law to which the processor is subject.",recital,"The General Data Protection Regulation (GDPR) requires businesses to only use data processors that can guarantee they'll handle data securely and in compliance with GDPR rules. This can be shown through adherence to approved codes of conduct or certification mechanisms. The data processor's tasks, including what data they'll process, for what purpose, and for how long, should be outlined in a legal agreement. After processing, the data should be returned or deleted, unless legally required to be stored. This ensures the protection of personal data and the rights of individuals."
Artifical Inellegence Act (AI Act) - Article 5,0.725000739,"Aritifical Intelligence Act (AI Act) Article 5:
The following artificial intelligence practices shall be prohibited:

(a)the placing on the market, putting into service or use of an AI system that deploys subliminal techniques beyond a persons consciousness in order to materially distort a persons behaviour in a manner that causes or is likely to cause that person or another person physical or psychological harm;

(b)the placing on the market, putting into service or use of an AI system that exploits any of the vulnerabilities of a specific group of persons due to their age, physical or mental disability, in order to materially distort the behaviour of a person pertaining to that group in a manner that causes or is likely to cause that person or another person physical or psychological harm;

(c)the placing on the market, putting into service or use of AI systems by public authorities or on their behalf for the evaluation or classification of the trustworthiness of natural persons over a certain period of time based on their social behaviour or known or predicted personal or personality characteristics, with the social score leading to either or both of the following:

(i)detrimental or unfavourable treatment of certain natural persons or whole groups thereof in social contexts which are unrelated to the contexts in which the data was originally generated or collected;

(ii)detrimental or unfavourable treatment of certain natural persons or whole groups thereof that is unjustified or disproportionate to their social behaviour or its gravity;

(d)the use of real-time remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement, unless and in as far as such use is strictly necessary for one of the following objectives:

(i)the targeted search for specific potential victims of crime, including missing children;

(ii)the prevention of a specific, substantial and imminent threat to the life or physical safety of natural persons or of a terrorist attack;

(iii)the detection, localisation, identification or prosecution of a perpetrator or suspect of a criminal offence referred to in Article 2(2) of Council Framework Decision 2002/584/JHA 62 and punishable in the Member State concerned by a custodial sentence or a detention order for a maximum period of at least three years, as determined by the law of that Member State.

2.The use of real-time remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement for any of the objectives referred to in paragraph 1 point d) shall take into account the following elements:

(a)the nature of the situation giving rise to the possible use, in particular the seriousness, probability and scale of the harm caused in the absence of the use of the system;

(b)the consequences of the use of the system for the rights and freedoms of all persons concerned, in particular the seriousness, probability and scale of those consequences.

In addition, the use of real-time remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement for any of the objectives referred to in paragraph 1 point d) shall comply with necessary and proportionate safeguards and conditions in relation to the use, in particular as regards the temporal, geographic and personal limitations.

3.As regards paragraphs 1, point (d) and 2, each individual use for the purpose of law enforcement of a real-time remote biometric identification system in publicly accessible spaces shall be subject to a prior authorisation granted by a judicial authority or by an independent administrative authority of the Member State in which the use is to take place, issued upon a reasoned request and in accordance with the detailed rules of national law referred to in paragraph 4. However, in a duly justified situation of urgency, the use of the system may be commenced without an authorisation and the authorisation may be requested only during or after the use.

The competent judicial or administrative authority shall only grant the authorisation where it is satisfied, based on objective evidence or clear indications presented to it, that the use of the real-time remote biometric identification system at issue is necessary for and proportionate to achieving one of the objectives specified in paragraph 1, point (d), as identified in the request. In deciding on the request, the competent judicial or administrative authority shall take into account the elements referred to in paragraph 2.

4.A Member State may decide to provide for the possibility to fully or partially authorise the use of real-time remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement within the limits and under the conditions listed in paragraphs 1, point (d), 2 and 3. That Member State shall lay down in its national law the necessary detailed rules for the request, issuance and exercise of, as well as supervision relating to, the authorisations referred to in paragraph 3. Those rules shall also specify in respect of which of the objectives listed in paragraph 1, point (d), including which of the criminal offences referred to in point (iii) thereof, the competent authorities may be authorised to use those systems for the purpose of law enforcement.",article,"The Artificial Intelligence Act (AI Act) prohibits certain uses of AI technology. It bans AI systems that use subliminal techniques to manipulate a person's behavior to the point of causing physical or psychological harm. It also forbids AI systems that exploit vulnerable groups, such as the elderly or disabled, to manipulate their behavior in harmful ways. The law also prohibits public authorities from using AI systems to evaluate or classify individuals based on their social behavior or personality traits, leading to unfair or harmful treatment. The use of real-time biometric identification systems in public spaces for law enforcement is also restricted, unless it's necessary for specific objectives like searching for crime victims or preventing imminent threats. This use must be authorized by a judicial or independent administrative authority, and must take into account the potential harm and consequences of using the system. Member states can decide to allow the use of these systems within certain limits and conditions."
Digital Services Act (DSA) - Article 76 Periodic penalty payments,0.724980175,"Article 76 Periodic penalty payments in the Digital Services Act (DSA):  1.   The Commission may adopt a decision, imposing on the provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1), as applicable, periodic penalty payments not exceeding 5 % of the average daily income or worldwide annual turnover in the preceding financial year per day, calculated from the date appointed by the decision, in order to compel them to:

(a) supply correct and complete information in response to a decision requiring information pursuant to Article 67;
(b) submit to an inspection which it has ordered by decision pursuant to Article 69;
(c) comply with a decision ordering interim measures pursuant to Article 70(1);
(d) comply with commitments made legally binding by a decision pursuant to Article 71(1);
(e) comply with a decision pursuant to Article 73(1), including where applicable the requirements it contains relating to the action plan referred to in Article 75.

2.   Where the provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1) has satisfied the obligation which the periodic penalty payment was intended to enforce, the Commission may fix the definitive amount of the periodic penalty payment at a figure lower than that under the original decision.",article,"The Digital Services Act (DSA) allows the Commission to impose daily penalties on large online platforms or search engines if they fail to comply with certain obligations. These penalties can be up to 5% of the company's average daily income or annual turnover from the previous financial year. The obligations include providing accurate information when required, submitting to inspections, complying with interim measures and legally binding commitments, and adhering to certain decisions and action plans. If the company fulfills its obligations, the Commission can reduce the penalty amount from the original decision."
Artifical Inellegence Act (AI Act) - Overview paragraph 34,0.724950433,"Aritifical Intelligence Act (AI Act) overview paragraph (34): As regards the management and operation of critical infrastructure, it is appropriate to classify as high-risk the AI systems intended to be used as safety components in the management and operation of road traffic and the supply of water, gas, heating and electricity, since their failure or malfunctioning may put at risk the life and health of persons at large scale and lead to appreciable disruptions in the ordinary conduct of social and economic activities.",recital,"The Artificial Intelligence Act (AI Act) categorizes AI systems used in managing and operating critical infrastructure like road traffic, water, gas, heating, and electricity supplies as high-risk. This is because any failure or malfunction in these systems could pose significant risks to people's lives and health on a large scale. It could also cause considerable disruptions to everyday social and economic activities."
General Data Protection Regulation (GDPR) - Article 55 Competence,0.724941432,"Details of Article 55 Competence in the General Data Protection Regulation (GDPR): 1. Each supervisory authority shall be competent for the performance of the tasks assigned to and the exercise of the powers conferred on it in accordance with this Regulation on the territory of its own Member State. 2. Where processing is carried out by public authorities or private bodies acting on the basis of point (c) or (e) of Article 6(1), the supervisory authority of the Member State concerned shall be competent. In such cases Article 56 does not apply. 3. Supervisory authorities shall not be competent to supervise processing operations of courts acting in their judicial capacity.",article,"Article 55 of the General Data Protection Regulation (GDPR) outlines the responsibilities of supervisory authorities. Each authority is responsible for tasks and powers within its own country. If data processing is done by public authorities or private bodies based on specific conditions, the supervisory authority of that country will oversee it. However, these authorities do not have the power to supervise court operations."
General Data Protection Regulation (GDPR) - Contextual Paragraph (88),0.724843681,"Details of the Contextual Paragraph (88) in the General Data Protection Regulation (GDPR): In setting detailed rules concerning the format and procedures applicable to the notification of personal data breaches, due consideration should be given to the circumstances of that breach, including whether or not personal data had been protected by appropriate technical protection measures, effectively limiting the likelihood of identity fraud or other forms of misuse. Moreover, such rules and procedures should take into account the legitimate interests of law-enforcement authorities where early disclosure could unnecessarily hamper the investigation of the circumstances of a personal data breach.",recital,"The General Data Protection Regulation (GDPR) has a new provision (Paragraph 88) that sets rules for reporting personal data breaches. These rules consider the context of the breach, including whether the data was adequately protected, and the potential for identity theft or misuse. They also consider the needs of law enforcement, to avoid hindering investigations through premature disclosure."
Digital Services Act (DSA) - Article 66 Initiation of proceedings by the Commission and cooperation in investigation,0.724828422,"Article 66 Initiation of proceedings by the Commission and cooperation in investigation in the Digital Services Act (DSA):  1.   The Commission may initiate proceedings in view of the possible adoption of decisions pursuant to Articles 73 and 74 in respect of the relevant conduct by the provider of the very large online platform or of the very large online search engine that the Commission suspect of having infringed any of the provisions of this Regulation.

2.   Where the Commission decides to initiate proceedings pursuant to paragraph 1 of this Article, it shall notify all Digital Services Coordinators and the Board through the information sharing system referred to in Article 85, as well as the provider of the very large online platform or of the very large online search engine concerned.

The Digital Services Coordinators shall, without undue delay after being informed of initiation of the proceedings, transmit to the Commission any information they hold about the infringement at stake.

The initiation of proceedings pursuant to paragraph 1 of this Article by the Commission shall relieve the Digital Services Coordinator, or any competent authority where applicable, of its powers to supervise and enforce provided for in this Regulation pursuant to Article 56(4).

3.   In the exercise of its powers of investigation under this Regulation the Commission may request the individual or joint support of any Digital Services Coordinators concerned by the suspected infringement, including the Digital Services Coordinator of establishment. The Digital Services Coordinators that have received such a request, and, where involved by the Digital Services Coordinator, any other competent authority, shall cooperate sincerely and in a timely manner with the Commission and shall be entitled to exercise their investigative powers referred to in Article 51(1) in respect of the provider of the very large online platform or of the very large online search engine at stake, with regard to information, persons and premises located within the territory of their Member State and in accordance with the request.

4.   The Commission shall provide the Digital Services Coordinator of establishment and the Board with all relevant information about the exercise of the powers referred to in Articles 67 to 72 and its preliminary findings referred to in Article 79(1). The Board shall submit its views on those preliminary findings to the Commission within the period set pursuant to Article 79(2). The Commission shall take utmost account of any views of the Board in its decision.",article,"The Digital Services Act (DSA) allows the Commission to start proceedings against large online platforms or search engines if they suspect a violation of the regulation. The Commission must notify all Digital Services Coordinators and the Board when proceedings begin. These coordinators then have to provide the Commission with any information they have about the suspected violation. Once the Commission starts proceedings, the coordinators are no longer responsible for overseeing and enforcing the regulation. The Commission can also ask for help from any coordinators involved in the suspected violation. The Commission must keep the coordinators and the Board updated on their investigation and preliminary findings. The Board can give their opinion on these findings, which the Commission must consider in their final decision."
General Data Protection Regulation (GDPR) - Contextual Paragraph (24),0.724807799,"Details of the Contextual Paragraph (24) in the General Data Protection Regulation (GDPR): The processing of personal data of data subjects who are in the Union by a controller or processor not established in the Union should also be subject to this Regulation when it is related to the monitoring of the behaviour of such data subjects in so far as their behaviour takes place within the Union. In order to determine whether a processing activity can be considered to monitor the behaviour of data subjects, it should be ascertained whether natural persons are tracked on the internet including potential subsequent use of personal data processing techniques which consist of profiling a natural person, particularly in order to take decisions concerning her or him or for analysing or predicting her or his personal preferences, behaviours and attitudes.",recital,"The General Data Protection Regulation (GDPR) Paragraph 24 states that any company, regardless of where it is based, must follow this law if it collects or uses personal data of people located in the European Union. This includes tracking their online activities or using their data to profile them, such as predicting their preferences or behaviors."
General Data Protection Regulation (GDPR) - Contextual Paragraph (37),0.72478205,"Details of the Contextual Paragraph (37) in the General Data Protection Regulation (GDPR): A group of undertakings should cover a controlling undertaking and its controlled undertakings, whereby the controlling undertaking should be the undertaking which can exert a dominant influence over the other undertakings by virtue, for example, of ownership, financial participation or the rules which govern it or the power to have personal data protection rules implemented. An undertaking which controls the processing of personal data in undertakings affiliated to it should be regarded, together with those undertakings, as a group of undertakings.",recital,"The General Data Protection Regulation (GDPR) has a new provision, Contextual Paragraph (37). It states that a group of businesses includes a controlling business and those it controls. The controlling business has significant influence over the others, possibly through ownership, financial involvement, or rules. If a business controls the handling of personal data in its affiliated businesses, it's considered part of a group of businesses."
Artifical Inellegence Act (AI Act) - Overview paragraph 28,0.724719286,"Aritifical Intelligence Act (AI Act) overview paragraph (28): AI systems could produce adverse outcomes to health and safety of persons, in particular when such systems operate as components of products. Consistently with the objectives of Union harmonisation legislation to facilitate the free movement of products in the internal market and to ensure that only safe and otherwise compliant products find their way into the market, it is important that the safety risks that may be generated by a product as a whole due to its digital components, including AI systems, are duly prevented and mitigated. For instance, increasingly autonomous robots, whether in the context of manufacturing or personal assistance and care should be able to safely operate and performs their functions in complex environments. Similarly, in the health sector where the stakes for life and health are particularly high, increasingly sophisticated diagnostics systems and systems supporting human decisions should be reliable and accurate. The extent of the adverse impact caused by the AI system on the fundamental rights protected by the Charter is of particular relevance when classifying an AI system as high-risk. Those rights include the right to human dignity, respect for private and family life, protection of personal data, freedom of expression and information, freedom of assembly and of association, and non-discrimination, consumer protection, workers rights,rights of persons with disabilities, right to an effective remedy and to a fair trial, right of defence and the presumption of innocence, right to good administration.In addition to those rights, it is important to highlight that children have specific rights as enshrined in Article 24 of the EU Charter and in the United Nations Convention on the Rights of the Child (further elaborated in the UNCRC General Comment No. 25 as regards the digital environment), both of which require consideration of the childrens vulnerabilities and provision of such protection and care as necessary for their well-being.The fundamental right to a high level of environmental protection enshrined in the Charter and implemented in Union policies should also be considered when assessing the severity of the harm that an AI system can cause, including in relation to the health and safety of persons.",recital,"The Artificial Intelligence Act (AI Act) emphasizes the need for safety in AI systems, particularly those that could impact health and safety. This includes AI components in products, autonomous robots, and healthcare systems. The law aims to ensure that these AI systems are reliable, accurate, and safe. The law also considers the potential negative impact of AI systems on fundamental human rights, such as privacy, freedom of expression, non-discrimination, consumer protection, and more. Special attention is given to the rights of children and environmental protection. The goal is to prevent and mitigate any risks posed by AI systems and ensure only safe and compliant products are in the market."
Artifical Inellegence Act (AI Act) - Article 45,0.72470361,"Aritifical Intelligence Act (AI Act) Article 45 Appeal against decisions of notified bodies:

Member States shall ensure that an appeal procedure against decisions of the notified bodies is available to parties having a legitimate interest in that decision.",article,"The Artificial Intelligence Act (AI Act) Article 45 states that all member states must provide a way for people to appeal decisions made by notified bodies, if they have a valid interest in the decision. This means if you're affected by a decision made by these bodies, you have the right to challenge it."
Digital Markets Act (DMA) - Contextual Paragraph (19),0.724625409,"Details of the Contextual Paragraph (19) in the Digital Markets Act (DMA): By contrast, there could be a number of factors concerning market capitalisation that would require an in-depth assessment in determining whether an undertaking providing core platform services should be deemed to have a significant impact on the internal market. This could be the case where the market capitalisation of the undertaking providing core platform services in preceding financial years was significantly lower than the threshold and the volatility of its market capitalisation over the observed period was disproportionate to overall equity market volatility or its market capitalisation trajectory relative to market trends was inconsistent with a rapid and unidirectional growth.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 19) that discusses how a company's market value could affect its classification under the law. The law suggests that companies offering core platform services may be considered as having a significant impact on the internal market based on certain factors related to their market value. This could happen if the company's market value in previous years was much lower than the set threshold, or if its market value has fluctuated greatly compared to overall market trends, or if its market value growth doesn't align with rapid and consistent market growth trends."
Digital Services Act (DSA) - Definition of 'online search engine',0.724592566,"Definition of 'online search engine' in the Digital Services Act (DSA): an intermediary service that allows users to input queries in order to perform searches of, in principle, all websites, or all websites in a particular language, on the basis of a query on any subject in the form of a keyword, voice request, phrase or other input, and returns results in any format in which information related to the requested content can be found.",recital,"The Digital Services Act (DSA) defines an 'online search engine' as a service that lets users search virtually all websites or all websites in a specific language. Users can search by typing keywords, asking questions vocally, or other methods. The search engine then provides results in any format where the requested information can be found."
Digital Markets Act (DMA) - Definition of virtual assistant,0.724582195,"Details of the Definition of virtual assistant in the Digital Markets Act (DMA): ""virtual assistant"" means a software that can process demands, tasks or questions, including those based on audio, visual, written input, gestures or motions, and that, based on those demands, tasks or questions, provides access to other services or controls connected physical devices;",rectial,"The Digital Markets Act (DMA) has introduced a new definition for the term ""virtual assistant"". According to the DMA, a virtual assistant is a type of software that can process various types of requests, tasks, or questions. These can come in the form of audio, visual, written input, gestures, or motions. After processing these inputs, the virtual assistant can either provide access to other services or control connected physical devices."
Digital Markets Act (DMA) - Contextual Paragraph (86),0.724513292,"Details of the Contextual Paragraph (86) in the Digital Markets Act (DMA): Compliance with the obligations imposed by this Regulation should be enforceable by means of fines and periodic penalty payments. To that end, appropriate levels of fines and periodic penalty payments should also be laid down for non-compliance with the obligations and breach of the procedural rules subject to appropriate limitation periods, in accordance with the principles of proportionality and ne bis in idem. The Commission and the relevant national authorities should coordinate their enforcement efforts in order to ensure that those principles are respected. In particular, the Commission should take into account any fines and penalties imposed on the same legal person for the same facts through a final decision in proceedings relating to an infringement of other Union or national rules, so as to ensure that the overall fines and penalties imposed correspond to the seriousness of the infringements committed.",rectial,"The Digital Markets Act (DMA) allows for fines and regular penalty payments to be enforced if a company does not comply with the rules set out in the regulation. The size of these fines and penalties will be determined based on the severity of the violation and will be subject to certain time limits. The European Commission and national authorities will work together to ensure these rules are enforced fairly. If a company has already been fined for the same violation under different EU or national laws, this will be taken into consideration to ensure that the overall penalties match the seriousness of the violation."
General Data Protection Regulation (GDPR) - Contextual Paragraph (113),0.724507332,"Details of the Contextual Paragraph (113) in the General Data Protection Regulation (GDPR): Transfers which can be qualified as not repetitive and that only concern a limited number of data subjects, could also be possible for the purposes of the compelling legitimate interests pursued by the controller, when those interests are not overridden by the interests or rights and freedoms of the data subject and when the controller has assessed all the circumstances surrounding the data transfer. The controller should give particular consideration to the nature of the personal data, the purpose and duration of the proposed processing operation or operations, as well as the situation in the country of origin, the third country and the country of final destination, and should provide suitable safeguards to protect fundamental rights and freedoms of natural persons with regard to the processing of their personal data. Such transfers should be possible only in residual cases where none of the other grounds for transfer are applicable. For scientific or historical research purposes or statistical purposes, the legitimate expectations of society for an increase of knowledge should be taken into consideration. The controller should inform the supervisory authority and the data subject about the transfer.",recital,"The General Data Protection Regulation (GDPR) allows for occasional, limited transfers of personal data if it serves a significant, legitimate interest of the data handler (controller). This is only allowed if it doesn't infringe on the rights and freedoms of the individual whose data is being transferred. The controller must consider the nature of the data, the purpose and duration of its use, and the conditions in the countries involved in the transfer. They must also ensure the data is properly protected. This type of transfer should only be used when no other transfer options are available. For research or statistical purposes, the societal benefit of increased knowledge must be considered. The controller must notify the relevant authority and the individual about the transfer."
Digital Services Act (DSA) - Contextual paragraph (148),0.724488914,"Details of the contextual paragraph (148) of the Digital Services Act (DSA): The effective enforcement and monitoring of this Regulation requires a seamless and real-time exchange of information among the Digital Services Coordinators, the Board and the Commission, based on the information flows and procedures set out in this Regulation. This may also warrant access to this system by other competent authorities, where appropriate. At the same time, given that the information exchanged may be confidential or involving personal data, it should remain protected from unauthorised access, in accordance with the purposes for which the information has been gathered. For this reason, all communications between those authorities should take place on the basis of a reliable and secure information sharing system, whose details should be laid down in an implementing act. The information sharing system may be based on existing internal market tools, to the extent that they can meet the objectives of this Regulation in a cost-effective manner.",recital,"The Digital Services Act (DSA) requires a constant, real-time exchange of information between the Digital Services Coordinators, the Board, and the Commission. This system may also be accessed by other relevant authorities. However, to protect any confidential or personal data, the information must be safeguarded from unauthorized access. All communications should use a reliable, secure information sharing system, the specifics of which will be defined in a future act. This system could potentially use existing market tools if they are cost-effective and meet the regulation's objectives."
General Data Protection Regulation (GDPR) - Article 1 Subject-matter and objectives,0.724475086,Details of the Article 1 Subject-matter and objectives in the General Data Protection Regulation (GDPR): 1. This Regulation lays down rules relating to the protection of natural persons with regard to the processing of personal data and rules relating to the free movement of personal data. 2. This Regulation protects fundamental rights and freedoms of natural persons and in particular their right to the protection of personal data. 3. The free movement of personal data within the Union shall be neither restricted nor prohibited for reasons connected with the protection of natural persons with regard to the processing of personal data.,article,"The General Data Protection Regulation (GDPR) is a new law that sets rules for how personal data of individuals is handled. The law aims to protect people's fundamental rights, particularly their right to privacy of their personal data. It also ensures that personal data can move freely within the Union, and such movement cannot be restricted or prohibited for reasons related to data protection."
General Data Protection Regulation (GDPR) - Definition of enterprise,0.724445105,"Details of the Definition of enterprise in the General Data Protection Regulation (GDPR): ""enterprise"" means a natural or legal person engaged in an economic activity, irrespective of its legal form, including partnerships or associations regularly engaged in an economic activity;",recital,"The General Data Protection Regulation (GDPR) has a new definition for ""enterprise"". An enterprise is any individual or organization involved in economic activity, regardless of its legal structure. This includes partnerships and associations that regularly participate in economic activity. So, if you or your organization are involved in any form of economic activity, you would be considered an enterprise under GDPR."
Artifical Inellegence Act (AI Act) - Overview paragraph 69,0.72440809,"Aritifical Intelligence Act (AI Act) overview paragraph (69): In order to facilitate the work of the Commission and the Member States in the artificial intelligence field as well as to increase the transparency towards the public, providers of high-risk AI systems other than those related to products falling within the scope of relevant existing Union harmonisation legislation, should be required to register their high-risk AI system in a EU database, to be established and managed by the Commission. The Commission should be the controller of that database, in accordance with Regulation (EU) 2018/1725 of the European Parliament and of theCouncil55. In order to ensure the full functionality of the database, when deployed, the procedure for setting the database should include the elaboration of functional specifications by the Commission and an independent audit report.",recital,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems, not covered by existing Union legislation, to register their systems in a new EU database. This database, controlled by the Commission, will increase transparency and help the Commission and Member States in their work with AI. To ensure the database works properly, the Commission will detail its functions and an independent audit report will be included in its setup. This is all in line with Regulation (EU) 2018/1725 of the European Parliament and of the Council 55."
General Data Protection Regulation (GDPR) - Contextual Paragraph (19),0.724406183,"Details of the Contextual Paragraph (19) in the General Data Protection Regulation (GDPR): The protection of natural persons with regard to the processing of personal data by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security and the free movement of such data, is the subject of a specific Union legal act. This Regulation should not, therefore, apply to processing activities for those purposes. However, personal data processed by public authorities under this Regulation should, when used for those purposes, be governed by a more specific Union legal act, namely Directive (EU) 2016/680 of the European Parliament and of the Council ( 1 ). Member States may entrust competent authorities within the meaning of Directive (EU) 2016/680 with tasks which are not necessarily carried out for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and prevention of threats to public security, so that the processing of personal data for those other purposes, in so far as it is within the scope of Union law, falls within the scope of this Regulation.

With regard to the processing of personal data by those competent authorities for purposes falling within scope of this Regulation, Member States should be able to maintain or introduce more specific provisions to adapt the application of the rules of this Regulation. Such provisions may determine more precisely specific requirements for the processing of personal data by those competent authorities for those other purposes, taking into account the constitutional, organisational and administrative structure of the respective Member State. When the processing of personal data by private bodies falls within the scope of this Regulation, this Regulation should provide for the possibility for Member States under specific conditions to restrict by law certain obligations and rights when such a restriction constitutes a necessary and proportionate measure in a democratic society to safeguard specific important interests including public security and the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security. This is relevant for instance in the framework of anti-money laundering or the activities of forensic laboratories.",recital,"The General Data Protection Regulation (GDPR) Paragraph 19 explains that personal data used by authorities for crime prevention, investigation, detection, prosecution, or penalties is covered by a specific EU law, not the GDPR. However, if public authorities use personal data for these purposes under the GDPR, it should be governed by the specific EU law, Directive (EU) 2016/680. Member states can assign tasks to authorities that aren't related to crime prevention or public security, and the data processing for these tasks falls under the GDPR. Member states can also maintain or introduce rules to adapt how the GDPR applies to data processing for these other purposes. If private bodies process personal data under the GDPR, member states can restrict certain obligations and rights to safeguard public security and crime prevention. This could be relevant for anti-money laundering or forensic lab activities."
Digital Markets Act (DMA) - Contextual Paragraph (44),0.724402905,"Details of the Contextual Paragraph (44) in the Digital Markets Act (DMA): The conduct of requiring business users or end users to subscribe to, or register with, any other core platform services of gatekeepers listed in the designation decision or which meet the thresholds of active end users and business users set out in this Regulation, as a condition for using, accessing, signing up for or registering with a core platform service gives the gatekeepers a means of capturing and locking-in new business users and end users for their core platform services by ensuring that business users cannot access one core platform service without also at least registering or creating an account for the purposes of receiving a second core platform service. That conduct also gives gatekeepers a potential advantage in terms of accumulation of data. As such, this conduct is liable to raise barriers to entry and should be prohibited.",rectial,"The Digital Markets Act (DMA) includes a section (Paragraph 44) that prevents large online platforms (gatekeepers) from forcing users to sign up for additional services as a condition for using their main service. This practice can trap new users and give these platforms an unfair advantage by collecting more data. The law aims to stop this, making the digital market more accessible and fair."
Artifical Inellegence Act (AI Act) - Overview paragraph 12,0.724399924,"Aritifical Intelligence Act (AI Act) overview paragraph (12): This Regulation should also apply to Union institutions, offices, bodies and agencies when acting as a provider or user of an AI system. AI systems exclusively developed or used for military purposes should be excluded from the scope of this Regulation where that use falls under the exclusive remit of the Common Foreign and Security Policy regulated under Title V of the Treaty on the European Union (TEU).This Regulation should be without prejudice to the provisions regarding the liability of intermediary service providers set out in Directive 2000/31/EC of the European Parliament and of the Council [as amended by the Digital Services Act].",recital,"The Artificial Intelligence Act (AI Act) applies to all EU institutions, offices, and agencies when they are using or providing an AI system. However, AI systems developed or used solely for military purposes are not covered by this law if they fall under the European Union's Common Foreign and Security Policy. This law does not affect the existing rules about the liability of intermediary service providers, which are outlined in the Directive 2000/31/EC, as amended by the Digital Services Act."
Artifical Inellegence Act (AI Act) - Overview paragraph 48,0.724359274,"Aritifical Intelligence Act (AI Act) overview paragraph (48): High-risk AI systems should be designed and developed in such a way that natural persons can oversee their functioning. For this purpose, appropriate human oversight measures should be identified by the provider of the system before its placing on the marketor putting into service. In particular, where appropriate, such measures should guarantee that the system is subject to in-built operational constraints that cannot be overridden by the system itself and is responsive to the human operator, and that the natural persons to whom human oversight has been assigned have the necessary competence, training and authority to carry out that role.",recital,"The Artificial Intelligence Act (AI Act) states that high-risk AI systems must be created in a way that allows human oversight. The company providing the AI system should identify suitable methods for this before the system is launched or used. These methods should ensure that the AI system has built-in operational limits that it cannot bypass, and that it can respond to human operators. Furthermore, the people assigned to oversee the AI system should have the required skills, training, and authority to do so."
Artifical Inellegence Act (AI Act) - Article 68,0.724359214,"Aritifical Intelligence Act (AI Act) Article 68 Formal non-compliance:

1.Where the market surveillance authority of a Member State makes one of the following findings, it shall require the relevant provider to put an end to the non-compliance concerned:

(a)the conformity marking has been affixed in violation of Article 49;

(b)the conformity marking has not been affixed;

(c)the EU declaration of conformity has not been drawn up;

(d)the EU declaration of conformity has not been drawn up correctly;

(e)the identification number of the notified body, which is involved in the conformity assessment procedure, where applicable, has not been affixed;

2.Where the non-compliance referred to in paragraph 1 persists, the Member State concerned shall take all appropriate measures to restrict or prohibit the high-risk AI system being made available on the market or ensure that it is recalled or withdrawn from the market.",article,"The Artificial Intelligence Act (AI Act) Article 68 states that if a provider is found not complying with certain rules, the relevant authority will require them to correct this. The rules include correctly marking their product, creating an EU declaration of conformity, and including the identification number of the body involved in the conformity assessment. If the provider continues to not comply, the Member State can take measures such as restricting or prohibiting the product from being sold or ensuring it is recalled or removed from the market."
General Data Protection Regulation (GDPR) - Contextual Paragraph (27),0.724356353,Details of the Contextual Paragraph (27) in the General Data Protection Regulation (GDPR): This Regulation does not apply to the personal data of deceased persons. Member States may provide for rules regarding the processing of personal data of deceased persons.,recital,"The General Data Protection Regulation (GDPR), specifically Paragraph 27, states that the law does not apply to the personal data of people who have passed away. However, individual member countries can create their own rules about how to handle the personal data of deceased individuals."
Digital Services Act (DSA) - Article 45 Codes of conduct,0.724328399,"Article 45 Codes of conduct in the Digital Services Act (DSA):  1.   The Commission and the Board shall encourage and facilitate the drawing up of voluntary codes of conduct at Union level to contribute to the proper application of this Regulation, taking into account in particular the specific challenges of tackling different types of illegal content and systemic risks, in accordance with Union law in particular on competition and the protection of personal data.

2.   Where significant systemic risk within the meaning of Article 34(1) emerge and concern several very large online platforms or very large online search engines, the Commission may invite the providers of very large online platforms concerned or the providers of very large online search engines concerned, and other providers of very large online platforms, of very large online search engines, of online platforms and of other intermediary services, as appropriate, as well as relevant competent authorities, civil society organisations and other relevant stakeholders, to participate in the drawing up of codes of conduct, including by setting out commitments to take specific risk mitigation measures, as well as a regular reporting framework on any measures taken and their outcomes.

3.   When giving effect to paragraphs 1 and 2, the Commission and the Board, and where relevant other bodies, shall aim to ensure that the codes of conduct clearly set out their specific objectives, contain key performance indicators to measure the achievement of those objectives and take due account of the needs and interests of all interested parties, and in particular citizens, at Union level. The Commission and the Board shall also aim to ensure that participants report regularly to the Commission and their respective Digital Services Coordinators of establishment on any measures taken and their outcomes, as measured against the key performance indicators that they contain. Key performance indicators and reporting commitments shall take into account differences in size and capacity between different participants.

4.   The Commission and the Board shall assess whether the codes of conduct meet the aims specified in paragraphs 1 and 3, and shall regularly monitor and evaluate the achievement of their objectives, having regard to the key performance indicators that they might contain. They shall publish their conclusions.

The Commission and the Board shall also encourage and facilitate regular review and adaptation of the codes of conduct.

In the case of systematic failure to comply with the codes of conduct, the Commission and the Board may invite the signatories to the codes of conduct to take the necessary action.",article,"The Digital Services Act (DSA) encourages the creation of voluntary codes of conduct to help manage illegal content and systemic risks online. This is particularly relevant for large online platforms and search engines. If significant risks arise, the Commission may invite these platforms, relevant authorities, and other stakeholders to help create these codes. These codes should have clear objectives and key performance indicators. They should also consider the needs and interests of all parties, particularly citizens. Participants must regularly report on their progress, taking into account their size and capacity. The Commission and the Board will assess whether these codes are effective and will publish their findings. If the codes are not being followed, the Commission and the Board can request necessary action."
General Data Protection Regulation (GDPR) - Contextual Paragraph (67),0.724292338,"Details of the Contextual Paragraph (67) in the General Data Protection Regulation (GDPR): Methods by which to restrict the processing of personal data could include, inter alia, temporarily moving the selected data to another processing system, making the selected personal data unavailable to users, or temporarily removing published data from a website. In automated filing systems, the restriction of processing should in principle be ensured by technical means in such a manner that the personal data are not subject to further processing operations and cannot be changed. The fact that the processing of personal data is restricted should be clearly indicated in the system.",recital,"The General Data Protection Regulation (GDPR) has a new section (Paragraph 67) that talks about how to limit the use of personal data. This could be done by temporarily moving the data to a different system, making the data inaccessible to users, or temporarily removing the data from a website. For automated filing systems, these limitations should be implemented using technical methods to ensure that the data can't be further processed or altered. It should be clear in the system when the processing of personal data has been restricted."
General Data Protection Regulation (GDPR) - Contextual Paragraph (51),0.724246264,"Details of the Contextual Paragraph (51) in the General Data Protection Regulation (GDPR): Personal data which are, by their nature, particularly sensitive in relation to fundamental rights and freedoms merit specific protection as the context of their processing could create significant risks to the fundamental rights and freedoms. Those personal data should include personal data revealing racial or ethnic origin, whereby the use of the term ""racial origin"" in this Regulation does not imply an acceptance by the Union of theories which attempt to determine the existence of separate human races. The processing of photographs should not systematically be considered to be processing of special categories of personal data as they are covered by the definition of biometric data only when processed through a specific technical means allowing the unique identification or authentication of a natural person. Such personal data should not be processed, unless processing is allowed in specific cases set out in this Regulation, taking into account that Member States law may lay down specific provisions on data protection in order to adapt the application of the rules of this Regulation for compliance with a legal obligation or for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller. In addition to the specific requirements for such processing, the general principles and other rules of this Regulation should apply, in particular as regards the conditions for lawful processing. Derogations from the general prohibition for processing such special categories of personal data should be explicitly provided, inter alia, where the data subject gives his or her explicit consent or in respect of specific needs in particular where the processing is carried out in the course of legitimate activities by certain associations or foundations the purpose of which is to permit the exercise of fundamental freedoms.",recital,"The General Data Protection Regulation (GDPR) provides special protection for sensitive personal data, such as racial or ethnic origin. It also covers biometric data like photographs, but only when they're used for unique identification or authentication. This sensitive data should not be processed unless allowed by the GDPR or specific national laws. Even then, the processing must comply with the general principles and rules of the GDPR. Exceptions to this rule can be made if the person the data belongs to gives explicit consent, or if the processing is needed for certain legitimate activities by specific organizations, aimed at protecting fundamental freedoms."
Artifical Inellegence Act (AI Act) - Overview paragraph 2,0.724217057,"Aritifical Intelligence Act (AI Act) overview paragraph (2): Artificial intelligence systems (AI systems) can be easily deployed in multiple sectors of the economy and society, including cross border, and circulate throughout the Union. Certain Member States have already explored the adoption of national rules to ensure that artificial intelligence is safe and is developed and used in compliance with fundamental rights obligations. Differing national rules may lead to fragmentation of the internal market and decrease legal certainty for operators that develop or use AI systems. A consistent and high level of protection throughout the Union should therefore be ensured, while divergences hampering the free circulation of AI systems and related products and services within the internal market should be prevented, by laying down uniform obligations for operators and guaranteeing the uniform protection of overriding reasons of public interest and of rights of persons throughout the internal market based on Article 114 of the Treaty on the Functioning of the European Union (TFEU). To the extent that this Regulation contains specific ruleson the protection of individuals with regard to the processing of personal dataconcerningrestrictions of the use of AI systems for real-time remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this Regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU.In light ofthose specific rules and the recourse to Article 16 TFEU, it is appropriateto consult the European Data Protection Board.",recital,"The Artificial Intelligence Act (AI Act) is a new law that aims to regulate the use of artificial intelligence (AI) systems across different sectors in the European Union. Some member states have already implemented national rules to ensure AI usage is safe and respects fundamental rights. However, these varying rules can cause confusion and legal uncertainty for those developing or using AI systems. The AI Act aims to provide a consistent level of protection across the EU, ensuring AI systems and related products and services can circulate freely within the internal market. It also includes specific rules on the use of AI for real-time remote biometric identification in public spaces for law enforcement purposes. The European Data Protection Board will be consulted in relation to these specific rules."
Digital Services Act (DSA) - Contextual paragraph (117),0.724187493,"Details of the contextual paragraph (117) of the Digital Services Act (DSA): Member States should ensure that violations of the obligations laid down in this Regulation can be sanctioned in a manner that is effective, proportionate and dissuasive, taking into account the nature, gravity, recurrence and duration of the violation, in view of the public interest pursued, the scope and kind of activities carried out, as well as the economic capacity of the infringer. In particular, penalties should take into account whether the provider of intermediary services concerned systematically or recurrently fails to comply with its obligations stemming from this Regulation, as well as, where relevant, the number of recipients of the service affected, the intentional or negligent character of the infringement and whether the provider is active in several Member States. Where this Regulation provides for a maximum amount of fines or of a periodic penalty payment, this maximum amount should apply per infringement of this Regulation and without prejudice to the modulation of the fines or periodic penalty payments for specific infringements. Member States should ensure that the imposition of fines or periodic penalty payments in respect of infringements should in each individual case be effective, proportionate and dissuasive by setting up national rules and procedures in accordance with this Regulation, taking into account all the criteria concerning the general conditions for imposing the fines or periodic penalty payments.",recital,"The Digital Services Act (DSA) requires member countries to enforce penalties for violations of the law in a way that is effective, balanced, and discouraging. The severity of the penalty will depend on factors such as the nature and duration of the violation, the public interest, the type of activities involved, and the financial capacity of the offender. Penalties will be heavier if the service provider repeatedly fails to meet its obligations, affects a large number of people, acts intentionally or negligently, or operates in multiple member states. The maximum fine or penalty applies to each violation and can be adjusted based on the specifics of each case. Each member state must establish national rules to ensure the penalties are applied effectively and fairly."
Digital Services Act (DSA) - Contextual paragraph (35),0.724156678,"Details of the contextual paragraph (35) of the Digital Services Act (DSA): The conditions and requirements laid down in this Regulation should be fulfilled at the latest when the order is transmitted to the provider concerned. Therefore, the order may be issued in one of the official languages of the issuing authority of the Member State concerned. However, where that language is different from the language declared by the provider of intermediary services, or from another official language of the Member States agreed between the authority issuing the order and the provider of intermediary services, the transmission of the order should be accompanied by a translation of at least the elements of the order which are set out in this Regulation. Where a provider of intermediary services has agreed with the authorities of a Member State to use a certain language, it should be encouraged to accept orders in the same language issued by authorities in other Member States. The orders should include elements that enable the addressee to identify the issuing authority, including the contact details of a contact point within that authority where appropriate, and to verify the authenticity of the order.",recital,"The Digital Services Act (DSA) states that when an order is sent to a provider, it must meet all the conditions and requirements outlined in the regulation. The order can be issued in the official language of the issuing authority's country. However, if the provider's declared language or another agreed language is different, a translation of the order's key elements must be included. If a provider has agreed to use a specific language with a country's authorities, they should also accept orders in that language from other countries. The order must contain details to identify the issuing authority and verify its authenticity."
Digital Markets Act (DMA) - Contextual Paragraph (101),0.724109769,"Details of the Contextual Paragraph (101) in the Digital Markets Act (DMA): In accordance with Regulation (EU) No 182/2011, each Member State should be represented in the advisory committee and decide on the composition of its delegation. Such delegation can include, inter alia, experts from the competent authorities within the Member States, which hold the relevant expertise for a specific issue presented to the advisory committee.",rectial,"The Digital Markets Act (DMA) includes a section (Paragraph 101) that requires each member country to have representation in an advisory committee. Each country can decide who will be part of its delegation, which can include experts from its own authorities who have relevant knowledge on the issues being discussed by the committee. This is in line with an existing regulation, EU No 182/2011."
Artifical Inellegence Act (AI Act) - Overview paragraph 60,0.724102795,"Aritifical Intelligence Act (AI Act) overview paragraph (60): In the light of the complexity of the artificial intelligence value chain, relevant third parties, notably the ones involved in the sale and the supply of software, software tools and components, pre-trained models and data, or providers of network services, should cooperate, as appropriate, with providers and users to enable their compliance with the obligations under this Regulation and with competent authorities established under this Regulation.",recital,"The Artificial Intelligence Act (AI Act) requires all parties involved in the creation, sale, and use of artificial intelligence (AI) - including software, tools, pre-trained models, data, and network services - to work together to meet the regulations set by this law. This cooperation is necessary to ensure everyone complies with the rules and works with the relevant authorities set up under this law."
General Data Protection Regulation (GDPR) - Contextual Paragraph (65),0.724083066,"Details of the Contextual Paragraph (65) in the General Data Protection Regulation (GDPR): A data subject should have the right to have personal data concerning him or her rectified and a ""right to be forgotten"" where the retention of such data infringes this Regulation or Union or Member State law to which the controller is subject. In particular, a data subject should have the right to have his or her personal data erased and no longer processed where the personal data are no longer necessary in relation to the purposes for which they are collected or otherwise processed, where a data subject has withdrawn his or her consent or objects to the processing of personal data concerning him or her, or where the processing of his or her personal data does not otherwise comply with this Regulation. That right is relevant in particular where the data subject has given his or her consent as a child and is not fully aware of the risks involved by the processing, and later wants to remove such personal data, especially on the internet. The data subject should be able to exercise that right notwithstanding the fact that he or she is no longer a child. However, the further retention of the personal data should be lawful where it is necessary, for exercising the right of freedom of expression and information, for compliance with a legal obligation, for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller, on the grounds of public interest in the area of public health, for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes, or for the establishment, exercise or defence of legal claims.",recital,"The General Data Protection Regulation (GDPR) gives individuals the right to correct or erase their personal data if it's not needed, if they withdraw consent, or if it's not being handled correctly. This is especially important for data given as a child, as they may not have fully understood the risks. They can still exercise this right even when they're no longer a child. However, data can still be kept if it's needed for freedom of speech, legal obligations, public interest tasks, public health, archiving, research, statistics, or legal claims."
Digital Services Act (DSA) - Article 75 Enhanced supervision of remedies to address infringements of obligations laid down,0.724068582,"Article 75 Enhanced supervision of remedies to address infringements of obligations laid down in the Digital Services Act (DSA):  1.   When adopting a decision pursuant to Article 73 in relation to an infringement by a provider of a very large online platform or of a very large online search engine of any of the provisions of Section 5 of Chapter III, the Commission shall make use of the enhanced supervision system laid down in this Article. When doing so, it shall take utmost account of any opinion of the Board pursuant to this Article.

2.   In the decision referred to in Article 73, the Commission shall require the provider of a very large online platform or of a very large online search engine concerned to draw up and communicate, within a reasonable period specified in the decision, to the Digital Services Coordinators, the Commission and the Board an action plan setting out the necessary measures which are sufficient to terminate or remedy the infringement. Those measures shall include a commitment to perform an independent audit in accordance with Article 37(3) and (4) on the implementation of the other measures, and shall specify the identity of the auditors, as well as the methodology, timing and follow-up of the audit. The measures may also include, where appropriate, a commitment to participate in a relevant code of conduct, as provided for in Article 45.

3.   Within one month following receipt of the action plan, the Board shall communicate its opinion on the action plan to the Commission. Within one month following receipt of that opinion, the Commission shall decide whether the measures set out in the action plan are sufficient to terminate or remedy the infringement, and shall set a reasonable period for its implementation. The possible commitment to adhere to relevant codes of conduct shall be taken into account in that decision. The Commission shall subsequently monitor the implementation of the action plan. To that end, the provider of a very large online platform or of a very large online search engine concerned shall communicate the audit report to the Commission without undue delay after it becomes available, and shall keep the Commission up to date on steps taken to implement the action plan. The Commission may, where necessary for such monitoring, require the provider of a very large online platform or of a very large online search engine concerned to provide additional information within a reasonable period set by the Commission.

The Commission shall keep the Board and the Digital Services Coordinators informed about the implementation of the action plan, and about its monitoring thereof.

4.   The Commission may take necessary measures in accordance with this Regulation, in particular Article 76(1), point (e), and Article 82(1), where:
(a) the provider of the very large online platform or of the very large online search engine concerned fails to provide any action plan, the audit report, the necessary updates or any additional information required, within the applicable period;
(b) the Commission rejects the proposed action plan because it considers that the measures set out therein are insufficient to terminate or remedy the infringement; or
(c) the Commission considers, on the basis of the audit report, any updates or additional information provided or any other relevant information available to it, that the implementation of the action plan is insufficient to terminate or remedy the infringement.",article,"The Digital Services Act (DSA) introduces stricter supervision for large online platforms and search engines. If these providers infringe on the DSA's rules, the Commission will require them to create an action plan to rectify the issue. This plan must include an independent audit and may also involve adherence to a specific code of conduct. The Commission will then review the action plan and decide if it's sufficient to fix the infringement. The provider must keep the Commission updated on their progress and provide an audit report. If the provider fails to comply, or if the Commission deems the action plan or its implementation insufficient, the Commission can take further measures. The Commission will keep the Board and Digital Services Coordinators informed about the action plan's implementation and its monitoring."
Digital Markets Act (DMA) - Contextual Paragraph (37),0.724047482,"Details of the Contextual Paragraph (37) in the Digital Markets Act (DMA): The less personalised alternative should not be different or of degraded quality compared to the service provided to the end users who provide consent, unless a degradation of quality is a direct consequence of the gatekeeper not being able to process such personal data or signing in end users to a service. Not giving consent should not be more difficult than giving consent. When the gatekeeper requests consent, it should proactively present a user-friendly solution to the end user to provide, modify or withdraw consent in an explicit, clear and straightforward manner. In particular, consent should be given by a clear affirmative action or statement establishing a freely given, specific, informed and unambiguous indication of agreement by the end user, as defined in Regulation (EU) 2016/679. At the time of giving consent, and only where applicable, the end user should be informed that not giving consent can lead to a less personalised offer, but that otherwise the core platform service will remain unchanged and that no functionalities will be suppressed. Exceptionally, if consent cannot be given directly to the gatekeeper's core platform service, end users should be able to give consent through each third-party service that makes use of that core platform service, to allow the gatekeeper to process personal data for the purposes of providing online advertising services. Lastly, it should be as easy to withdraw consent as to give it. Gatekeepers should not design, organise or operate their online interfaces in a way that deceives, manipulates or otherwise materially distorts or impairs the ability of end users to freely give consent. In particular, gatekeepers should not be allowed to prompt end users more than once a year to give consent for the same processing purpose in respect of which they initially did not give consent or withdrew their consent. This Regulation is without prejudice to Regulation (EU) 2016/679, including its enforcement framework, which remains fully applicable with respect to any claims by data subjects relating to an infringement of their rights under that Regulation.",rectial,"The Digital Markets Act (DMA) requires online service providers, known as gatekeepers, to offer a user-friendly way to give, change, or withdraw consent for personal data use. The quality of service should not be lower for users who don't consent unless it's directly due to the lack of data. It should be just as easy to refuse consent as to give it, and users should be informed that refusing consent may result in a less personalized service, but won't affect the core service or its features. Gatekeepers can't trick or pressure users into giving consent and can't ask for consent more than once a year for the same purpose if it was initially refused or withdrawn. This law doesn't affect existing regulations under Regulation (EU) 2016/679, which still applies to any claims about rights infringement."
General Data Protection Regulation (GDPR) - Article 99 Entry into force and application,0.724038363,Details of Article 99 Entry into force and application in the General Data Protection Regulation (GDPR): 1. This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union. 2. It shall apply from 25 May 2018.,article,"The General Data Protection Regulation (GDPR) is a new law that was officially published in the European Union's Official Journal. It became effective 20 days after its publication. However, it only started to be applied from May 25, 2018."
General Data Protection Regulation (GDPR) - Contextual Paragraph (43),0.723980844,"Details of the Contextual Paragraph (43) in the General Data Protection Regulation (GDPR): In order to ensure that consent is freely given, consent should not provide a valid legal ground for the processing of personal data in a specific case where there is a clear imbalance between the data subject and the controller, in particular where the controller is a public authority and it is therefore unlikely that consent was freely given in all the circumstances of that specific situation. Consent is presumed not to be freely given if it does not allow separate consent to be given to different personal data processing operations despite it being appropriate in the individual case, or if the performance of a contract, including the provision of a service, is dependent on the consent despite such consent not being necessary for such performance.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Contextual Paragraph (43), which ensures that your consent to use your personal data must be freely given. This means that if there's a power imbalance between you and the organization asking for your consent, especially if it's a public authority, your consent may not be considered valid. Also, if you're not allowed to give separate consent for different data uses, or if your consent is required to perform a contract or service even when it's not necessary, then your consent is not considered freely given."
General Data Protection Regulation (GDPR) - Contextual Paragraph (127),0.723968506,"Details of the Contextual Paragraph (127) in the General Data Protection Regulation (GDPR): Each supervisory authority not acting as the lead supervisory authority should be competent to handle local cases where the controller or processor is established in more than one Member State, but the subject matter of the specific processing concerns only processing carried out in a single Member State and involves only data subjects in that single Member State, for example, where the subject matter concerns the processing of employees' personal data in the specific employment context of a Member State. In such cases, the supervisory authority should inform the lead supervisory authority without delay about the matter. After being informed, the lead supervisory authority should decide, whether it will handle the case pursuant to the provision on cooperation between the lead supervisory authority and other supervisory authorities concerned (""one-stop-shop mechanism""), or whether the supervisory authority which informed it should handle the case at local level. When deciding whether it will handle the case, the lead supervisory authority should take into account whether there is an establishment of the controller or processor in the Member State of the supervisory authority which informed it in order to ensure effective enforcement of a decision vis--vis the controller or processor. Where the lead supervisory authority decides to handle the case, the supervisory authority which informed it should have the possibility to submit a draft for a decision, of which the lead supervisory authority should take utmost account when preparing its draft decision in that one-stop-shop mechanism.",recital,"The General Data Protection Regulation (GDPR) Paragraph 127 allows local data protection authorities to handle cases where a company operates in multiple EU states, but the data processing issue only involves one state. For example, if a company is handling employee data in a way that only affects one country, the local authority can deal with it. However, they must inform the lead authority, who then decides whether to take over the case or let the local authority handle it. This decision is based on where the company is located to ensure effective enforcement. If the lead authority takes over, the local authority can still contribute to the decision-making process."
Digital Services Act (DSA) - Contextual paragraph (45),0.723960102,"Details of the contextual paragraph (45) of the Digital Services Act (DSA): Whilst the freedom of contract of providers of intermediary services should in principle be respected, it is appropriate to set certain rules on the content, application and enforcement of the terms and conditions of those providers in the interests of transparency, the protection of recipients of the service and the avoidance of unfair or arbitrary outcomes. Providers of the intermediary services should clearly indicate and maintain up-to-date in their terms and conditions the information as to the grounds on the basis of which they may restrict the provision of their services. In particular, they should include information on any policies, procedures, measures and tools used for the purpose of content moderation, including algorithmic decision-making and human review, as well as the rules of procedure of their internal complaint-handling system. They should also provide easily accessible information on the right to terminate the use of the service. Providers of intermediary services may use graphical elements in their terms of service, such as icons or images, to illustrate the main elements of the information requirements set out in this Regulation. Providers should inform recipients of their service through appropriate means of significant changes made to terms and conditions, for instance when they modify the rules on information that is permitted on their service, or other such changes which could directly impact the ability of the recipients to make use of the service.",recital,"The Digital Services Act (DSA) sets new rules for online service providers to ensure transparency and fairness. It requires these providers to clearly state in their terms and conditions the reasons they may limit their services. They must also detail their content moderation methods, including the use of algorithms and human review, and their complaint-handling procedures. They should make it easy for users to understand how to end their use of the service. The DSA allows providers to use graphics like icons or images to help explain these terms. If significant changes are made to the terms, such as changes to what content is allowed, providers must inform users in a suitable way, especially if these changes could affect the users' ability to use the service."
General Data Protection Regulation (GDPR) - Contextual Paragraph (95),0.723937392,"Details of the Contextual Paragraph (95) in the General Data Protection Regulation (GDPR): The processor should assist the controller, where necessary and upon request, in ensuring compliance with the obligations deriving from the carrying out of data protection impact assessments and from prior consultation of the supervisory authority.",recital,The General Data Protection Regulation (GDPR) introduces a new rule in Paragraph 95. This rule states that the 'processor' (the organization or person handling your personal data) must help the 'controller' (the organization or person deciding why and how your personal data is processed) to meet their obligations. This includes conducting data protection impact assessments and consulting with the supervisory authority if needed. This is to ensure that your data is properly protected.
General Data Protection Regulation (GDPR) - Contextual Paragraph (55),0.72393,"Details of the Contextual Paragraph (55) in the General Data Protection Regulation (GDPR): Moreover, the processing of personal data by official authorities for the purpose of achieving the aims, laid down by constitutional law or by international public law, of officially recognised religious associations, is carried out on grounds of public interest.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 55) that allows government authorities to handle personal data, but only to fulfill goals set by constitutional or international public law. This is specifically for officially recognized religious groups, and it's done in the interest of the public."
Digital Services Act (DSA) - Contextual paragraph (15),0.723886907,"Details of the contextual paragraph (15) of the Digital Services Act (DSA): Where some of the services provided by a provider are covered by this Regulation whilst others are not, or where the services provided by a provider are covered by different sections of this Regulation, the relevant provisions of this Regulation should apply only in respect of those services that fall within their scope.",recital,"The Digital Services Act (DSA) has a specific rule (paragraph 15) that addresses service providers who offer multiple services, some of which may be covered by this law and others not. This rule states that the provisions of the DSA only apply to those services that are within the scope of the law. If a service provider offers services that are covered by different sections of the DSA, then the relevant rules of those sections apply to those specific services."
Digital Services Act (DSA) - Definition of 'consumer',0.723857343,"Definition of 'consumer' in the Digital Services Act (DSA): any natural person who is acting for purposes which are outside his or her trade, business, craft, or profession.",recital,"The Digital Services Act (DSA) has a specific definition for the term 'consumer'. According to this new law, a 'consumer' is any individual who is using services for personal reasons, not related to their job, business, or professional activities. This means if you're using a service for anything that isn't part of your work or business, you're considered a 'consumer' under the DSA."
Digital Markets Act (DMA) - Definition of national court,0.723835886,"Details of the Definition of national court in the Digital Markets Act (DMA): ""national court"" means a court or tribunal of a Member State within the meaning of Article 267 TFEU.",rectial,"The Digital Markets Act (DMA) has defined what a ""national court"" is. According to the DMA, a ""national court"" refers to any court or tribunal that is part of a Member State, as described in Article 267 TFEU. This means it's a legal institution within a country that's a member of the European Union, as defined by the Treaty on the Functioning of the European Union (TFEU)."
Digital Markets Act (DMA) - Article 37 Cooperation with national authorities,0.723802745,"Details of Article 37 Cooperation with national authorities in the Digital Markets Act (DMA): 1. The Commission and Member States shall work in close cooperation and coordinate their enforcement actions to ensure coherent, effective and complementary enforcement of available legal instruments applied to gatekeepers within the meaning of this Regulation. 2. The Commission may consult national authorities where appropriate, on any matter relating to the application of this Regulation.",article,"The Digital Markets Act (DMA) requires the European Commission and Member States to work closely together to enforce the law effectively on digital ""gatekeepers"" - large online platforms that control access to important digital services. This cooperation is meant to ensure that actions taken are consistent, effective, and complement each other. The Commission also has the right to consult with national authorities on any matters related to the application of this law, if needed."
Digital Markets Act (DMA) - Article 9 Suspension,0.723793268,"Details of Article 9 Suspension in the Digital Markets Act (DMA): 1. Where the gatekeeper demonstrates in a reasoned request that compliance with a specific obligation laid down in Article 5, 6 or 7 for a core platform service listed in the designation decision pursuant to Article 3(9) would endanger, due to exceptional circumstances beyond the gatekeeper""s control, the economic viability of its operation in the Union, the Commission may adopt an implementing act setting out its decision to exceptionally suspend, in whole or in part, the specific obligation referred to in that reasoned request (""the suspension decision""). In that implementing act, the Commission shall substantiate its suspension decision by identifying the exceptional circumstances justifying the suspension. That implementing act shall be limited to the extent and the duration necessary to address such threat to the gatekeeper""s viability. The Commission shall aim to adopt that implementing act without delay and at the latest 3 months following receipt of a complete reasoned request. That implementing act shall be adopted in accordance with the advisory procedure referred to in Article 50(2). 2. Where suspension is granted pursuant to paragraph 1, the Commission shall review its suspension decision every year, unless a shorter interval is specified in that decision. Following such a review the Commission shall either wholly or partly lift the suspension, or decide that the conditions in paragraph 1 continue to be met. 3. In cases of urgency, the Commission may, acting on a reasoned request by a gatekeeper, provisionally suspend the application of a specific obligation referred to in paragraph 1 to one or more individual core platform services already prior to the decision pursuant to that paragraph. Such a request may be made and granted at any time pending the assessment of the Commission pursuant to paragraph 1. 4. In assessing the request referred to in paragraphs 1 and 3, the Commission shall take into account, in particular, the impact of the compliance with the specific obligation on the economic viability of the operation of the gatekeeper in the Union as well as on third parties, in particular SMEs and consumers. The suspension may be made subject to conditions and obligations to be defined by the Commission in order to ensure a fair balance between those interests and the objectives of this Regulation.",article,"The Digital Markets Act (DMA) Article 9 Suspension allows a ""gatekeeper"" (a major digital platform) to request suspension of certain obligations if they can prove that these obligations would threaten their economic viability due to exceptional circumstances beyond their control. The European Commission can then decide to suspend these obligations, either partially or fully. The Commission must explain why it has made this decision and it should only last as long as necessary to protect the gatekeeper's viability. The Commission aims to make this decision within 3 months of receiving the request. Once a suspension is granted, it is reviewed annually. In urgent cases, the Commission can provisionally suspend obligations before making a final decision. The impact of the obligations on the gatekeeper, small-medium enterprises (SMEs) and consumers is considered in the decision-making process. The suspension may come with conditions to ensure a balance between these interests and the DMA's objectives."
General Data Protection Regulation (GDPR) - Contextual Paragraph (49),0.723777831,"Details of the Contextual Paragraph (49) in the General Data Protection Regulation (GDPR): The processing of personal data to the extent strictly necessary and proportionate for the purposes of ensuring network and information security, i.e. the ability of a network or an information system to resist, at a given level of confidence, accidental events or unlawful or malicious actions that compromise the availability, authenticity, integrity and confidentiality of stored or transmitted personal data, and the security of the related services offered by, or accessible via, those networks and systems, by public authorities, by computer emergency response teams (CERTs), computer security incident response teams (CSIRTs), by providers of electronic communications networks and services and by providers of security technologies and services, constitutes a legitimate interest of the data controller concerned. This could, for example, include preventing unauthorised access to electronic communications networks and malicious code distribution and stopping ""denial of service"" attacks and damage to computer and electronic communication systems.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 49) that allows for the processing of personal data if it's absolutely necessary to maintain network and information security. This means that certain entities like public authorities, emergency response teams, and providers of electronic communication networks can handle your personal data to prevent things like unauthorized access, malicious code distribution, and attacks that can damage computer systems. This is considered a legitimate interest of the entity controlling the data."
Artifical Inellegence Act (AI Act) - Overview paragraph 37,0.723745465,"Aritifical Intelligence Act (AI Act) overview paragraph (37): Another area in which the use of AI systems deserves special consideration is the access to and enjoyment of certain essential private and public services and benefitsnecessary forpeopleto fully participate in society or to improve ones standard of living. In particular, AI systems used to evaluate the credit score or creditworthiness of natural persons should be classified as high-risk AI systems, since they determine those persons access to financial resources or essential services such as housing, electricity, and telecommunication services. AI systems used for this purpose may lead to discrimination of persons or groups and perpetuate historical patterns of discrimination, for example based on racial or ethnic origins, disabilities, age, sexual orientation, or create new forms of discriminatory impacts. Considering the very limited scale of the impact and the available alternatives on the market, it is appropriate to exempt AI systems for the purpose of creditworthiness assessment and credit scoring when put into service by small-scale providers for their own use. Natural persons applying for or receiving public assistance benefits and services from public authorities are typically dependent on those benefits and services and in a vulnerable position in relation to the responsible authorities. If AI systems are used for determining whether such benefits and services should be denied, reduced, revoked or reclaimed by authorities, they may have a significant impact on persons livelihood and may infringe their fundamental rights, such as the right to social protection, non-discrimination, human dignity or an effective remedy. Those systems should therefore be classified as high-risk. Nonetheless, this Regulation should not hamper the development and use of innovative approaches in the public administration, which would stand to benefit from a wider use of compliant and safe AI systems, provided that those systems do not entail a high risk to legal and natural persons. Finally, AI systems used to dispatch or establish priority in the dispatching of emergency first response services should also be classified as high-risk since they make decisions in very critical situations for the life and health of persons and their property.",recital,"The Artificial Intelligence Act (AI Act) states that AI systems used to evaluate a person's credit score or determine their access to essential services like housing, electricity, and telecommunication should be considered high-risk. These systems could potentially lead to discrimination based on factors like race, age, or sexual orientation. However, small-scale providers using AI for credit assessments are exempt from this rule. The Act also considers AI systems used by public authorities to determine eligibility for public assistance as high-risk due to their potential impact on people's livelihoods and fundamental rights. Despite this, the Act encourages the use of safe and compliant AI systems in public administration. Lastly, AI systems used for dispatching emergency first response services are also classified as high-risk due to their critical role in life and health situations."
Artifical Inellegence Act (AI Act) - Overview paragraph 22,0.723704875,"Aritifical Intelligence Act (AI Act) overview paragraph (22): Furthermore, it is appropriate to provide, within the exhaustive framework set by this Regulation that such use in the territory of a Member State in accordance with this Regulation should only be possible where and in as far as the Member State in question has decided to expressly provide for the possibility to authorise such use in itsdetailed rules of national law. Consequently, Member States remain free under this Regulation not to provide for such a possibility at all or to only provide for such a possibility in respect of some of the objectives capable of justifying authorised use identified in this Regulation.",recital,"The Artificial Intelligence Act (AI Act) allows individual member states to decide if and how they want to use artificial intelligence (AI) within their borders. This means that each state can either choose not to use AI at all, or they can set their own detailed rules about how AI can be used. However, the use of AI must still fall within the guidelines set by the AI Act. This law does not force states to use AI, but it does provide a framework for those that choose to do so."
Digital Markets Act (DMA) - Contextual Paragraph (17),0.723650336,"Details of the Contextual Paragraph (17) in the Digital Markets Act (DMA): The fact that an undertaking has a very significant turnover in the Union and provides a core platform service in at least three Member States constitutes compelling indication that that undertaking has a significant impact on the internal market. This is equally true where an undertaking providing a core platform service in at least three Member States has a very significant market capitalisation or equivalent fair market value. Therefore, an undertaking providing a core platform service should be presumed to have a significant impact on the internal market where it provides a core platform service in at least three Member States and where either its group turnover realised in the Union is equal to or exceeds a specific, high threshold, or the market capitalisation of the group is equal to or exceeds a certain high absolute value. For undertakings providing core platform services that belong to undertakings that are not publicly listed, the equivalent fair market value should be used as the reference. It should be possible for the Commission to use its power to adopt delegated acts to develop an objective methodology to calculate that value.  A high group turnover realised in the Union in conjunction with the threshold number of users in the Union of core platform services reflects a relatively strong ability to monetise those users. A high market capitalisation relative to the same threshold number of users in the Union reflects a relatively significant potential to monetise those users in the near future. This monetisation potential in turn reflects, in principle, the gateway position of the undertakings concerned. Both indicators, in addition, reflect the financial capacity of the undertakings concerned, including their ability to leverage their access to financial markets to reinforce their position. This can, for example, happen where this superior access is used to acquire other undertakings, an ability which has in turn been shown to have potential negative effects on innovation. Market capitalisation can also reflect the expected future position and effect on the internal market of the undertakings concerned, despite a potentially relatively low current turnover. The market capitalisation value should be based on a level that reflects the average market capitalisation of the largest publicly listed undertakings in the Union over an appropriate period.",rectial,"The Digital Markets Act (DMA) suggests that a company is presumed to have a significant impact on the European market if it provides a core platform service in at least three EU countries and either has a high turnover or a high market capitalization. This also applies to companies that aren't publicly listed, using their fair market value instead. The DMA allows the Commission to develop a method to calculate these values. The law indicates that a company's high turnover or market capitalization, along with a large user base, shows its ability to monetize those users and reinforces its market position. This could potentially stifle innovation, especially if the company uses its financial strength to acquire other businesses. The market capitalization value should reflect the average of the largest publicly listed companies in the EU over a certain period."
Digital Services Act (DSA) - Contextual paragraph (66),0.723640859,"Details of the contextual paragraph (66) of the Digital Services Act (DSA): In order to ensure transparency and to enable scrutiny over the content moderation decisions of the providers of online platforms and monitoring the spread of illegal content online, the Commission should maintain and publish a database which contains the decisions and statements of reasons of the providers of online platforms when they remove or otherwise restrict availability of and access to information. In order to keep the database continuously updated, the providers of online platforms should submit, in a standard format, the decisions and statement of reasons without undue delay after taking a decision, to allow for real-time updates where technically possible and proportionate to the means of the online platform in question. The structured database should allow access to, and queries for, the relevant information, in particular as regards the type of alleged illegal content at stake.",recital,"The Digital Services Act (DSA) requires online platform providers to be transparent about their content moderation decisions, especially when they remove or limit access to information. The European Commission will maintain a publicly available database containing these decisions and the reasons behind them. To keep this database current, online platform providers must promptly submit their decisions and explanations in a standard format, allowing real-time updates when technically feasible. This database will enable users to access and search for specific information, particularly about the type of alleged illegal content involved."
General Data Protection Regulation (GDPR) - Contextual Paragraph (76),0.723630607,"Details of the Contextual Paragraph (76) in the General Data Protection Regulation (GDPR): The likelihood and severity of the risk to the rights and freedoms of the data subject should be determined by reference to the nature, scope, context and purposes of the processing. Risk should be evaluated on the basis of an objective assessment, by which it is established whether data processing operations involve a risk or a high risk.",recital,"The General Data Protection Regulation (GDPR) includes a rule (Paragraph 76) that requires the risk to a person's privacy to be evaluated objectively. This means that when a company is processing personal data, they need to consider how likely it is that the person's rights could be violated and how serious that violation would be. This assessment should consider the type of data, the extent of processing, the context in which it's happening, and the purpose of processing. The company should then decide if the data processing poses a risk or a high risk."
Artifical Inellegence Act (AI Act) - Overview paragraph 17,0.723625243,"Aritifical Intelligence Act (AI Act) overview paragraph (17): AIsystemsproviding social scoring of natural persons for general purpose by public authorities or on their behalf may lead to discriminatory outcomes and the exclusion of certain groups. They may violate the right to dignity and non-discrimination and the values of equality and justice. Such AI systems evaluate or classify the trustworthiness of natural persons based on their social behaviour in multiple contexts or known or predicted personal or personality characteristics. The social score obtained from such AI systems may lead to the detrimental or unfavourable treatment of natural persons or whole groups thereof in social contexts, which are unrelated to the context in which the data was originally generated or collected or to a detrimental treatment that is disproportionate or unjustified to the gravity of their social behaviour.Such AI systems should be therefore prohibited.",recital,"The Artificial Intelligence Act (AI Act) states that AI systems used by public authorities to assign social scores to individuals could lead to discrimination and exclusion of certain groups. These systems, which rate people's trustworthiness based on their social behavior or personal characteristics, could violate rights to dignity, equality, and justice. The social score generated by these AI systems could result in unfair or harmful treatment of individuals or groups in situations unrelated to the original context of the data collection. Therefore, the use of such AI systems should be banned."
Artifical Inellegence Act (AI Act) - Overview paragraph 58,0.723569632,"Aritifical Intelligence Act (AI Act) overview paragraph (58): Given the nature of AI systems and the risks to safety and fundamental rights possibly associated with their use, including as regard the need to ensure proper monitoring of the performance of an AI system in a real-life setting, it is appropriate to set specific responsibilities for users. Users should in particular use high-risk AI systems in accordance with the instructions of use and certain other obligations should be provided for with regard to monitoring of the functioning of the AI systems and with regard to record-keeping, as appropriate.",recital,"The Artificial Intelligence Act (AI Act) establishes that due to the potential risks and safety concerns associated with AI systems, users have specific responsibilities. These include using high-risk AI systems as per the provided instructions, monitoring the performance of these systems in real-world settings, and maintaining appropriate records. This is to ensure the safe and responsible use of AI technology."
Digital Markets Act (DMA) - Contextual Paragraph (68),0.723545253,"Details of the Contextual Paragraph (68) in the Digital Markets Act (DMA): Within the timeframe for complying with their obligations under this Regulation, gatekeepers should inform the Commission, through mandatory reporting, about the measures they intend to implement or have implemented in order to ensure effective compliance with those obligations, including those measures concerning compliance with Regulation (EU) 2016/679, to the extent they are relevant for compliance with the obligations provided under this Regulation, which should allow the Commission to fulfil its duties under this Regulation. In addition, a clear and comprehensible non-confidential summary of such information should be made publicly available while taking into account the legitimate interest of gatekeepers in the protection of their business secrets and other confidential information. This non-confidential publication should enable third parties to assess whether the gatekeepers comply with the obligations laid down in this Regulation. Such reporting should be without prejudice to any enforcement action by the Commission at any time following the reporting. The Commission should publish online a link to the non-confidential summary of the report, as well as all other public information based on information obligations under this Regulation, in order to ensure accessibility of such information in a usable and comprehensive manner, in particular for small and medium enterprises (SMEs).",rectial,"The Digital Markets Act (DMA) requires gatekeepers (large tech companies) to report to the Commission about how they plan to or have already complied with the law. They also need to share how they are complying with Regulation (EU) 2016/679, if it's relevant. The Commission will use this information to do its job under the DMA. Gatekeepers must also provide a public, non-confidential summary of this information, while still protecting their business secrets. This allows others to check if gatekeepers are following the law. The Commission can take action at any time, even after the report is submitted. They will also publish a link to the summary and other public information online to make it accessible, especially for small and medium businesses."
General Data Protection Regulation (GDPR) - Contextual Paragraph (97),0.723531187,"Details of the Contextual Paragraph (97) in the General Data Protection Regulation (GDPR): Where the processing is carried out by a public authority, except for courts or independent judicial authorities when acting in their judicial capacity, where, in the private sector, processing is carried out by a controller whose core activities consist of processing operations that require regular and systematic monitoring of the data subjects on a large scale, or where the core activities of the controller or the processor consist of processing on a large scale of special categories of personal data and data relating to criminal convictions and offences, a person with expert knowledge of data protection law and practices should assist the controller or processor to monitor internal compliance with this Regulation. In the private sector, the core activities of a controller relate to its primary activities and do not relate to the processing of personal data as ancillary activities. The necessary level of expert knowledge should be determined in particular according to the data processing operations carried out and the protection required for the personal data processed by the controller or the processor. Such data protection officers, whether or not they are an employee of the controller, should be in a position to perform their duties and tasks in an independent manner.",recital,"The General Data Protection Regulation (GDPR) requires public authorities and certain businesses to have a data protection officer. This applies to businesses whose main activities involve large scale data processing, especially of sensitive personal data and criminal records. The officer, who should be an expert in data protection law and practices, will help ensure the organization follows the GDPR. The level of expertise required depends on the nature of the data processing and the protection needed for the data. The officer can be an employee but must be able to perform their duties independently."
Digital Markets Act (DMA) - Contextual Paragraph (18),0.723530054,"Details of the Contextual Paragraph (18) in the Digital Markets Act (DMA): Whereas a market capitalisation at or above the threshold in the last financial year should give rise to a presumption that an undertaking providing core platform services has a significant impact on the internal market, a sustained market capitalisation of the undertaking providing core platform services at or above the threshold over three or more years should be considered as further strengthening that presumption.",rectial,"The Digital Markets Act (DMA) includes a rule (Paragraph 18) stating that if a company providing core platform services has a market value at or above a certain level in the last financial year, it's assumed that the company has a significant influence on the internal market. If this high market value is maintained for three or more years, this assumption is even stronger."
Artifical Inellegence Act (AI Act) - Overview paragraph 73,0.723529577,"Aritifical Intelligence Act (AI Act) overview paragraph (73): In order to promote and protect innovation, it is important that the interests of small-scale providers and users of AI systems are taken into particular account. To this objective, Member States should develop initiatives, which are targeted at those operators, including on awareness raising and information communication. Moreover,the specific interests and needs of small-scale providers shall be taken into account when Notified Bodies set conformity assessment fees.Translation costs related to mandatory documentation and communication with authorities may constitute a significant cost for providers and other operators, notably those of a smaller scale. Member States should possibly ensure that one of the languages determined and accepted by them for relevant providers documentation and for communication with operators is one which is broadly understood by the largest possible number of cross-border users.",recital,"The Artificial Intelligence Act (AI Act) emphasizes the importance of supporting and protecting small-scale AI providers and users. Member States are encouraged to create initiatives that raise awareness and improve communication for these operators. When setting assessment fees, the specific needs and interests of these small-scale providers should be considered. The law also recognizes that translation costs for mandatory documents can be a significant burden, particularly for smaller operators. As a result, Member States are urged to ensure that one of the accepted languages for documentation and communication is widely understood to accommodate the largest number of cross-border users."
Digital Services Act (DSA) - Contextual paragraph (6),0.723515749,"Details of the contextual paragraph (6) of the Digital Services Act (DSA): In practice, certain providers of intermediary services intermediate in relation to services that may or may not be provided by electronic means, such as remote information technology services, transport, accommodation or delivery services. This Regulation should apply only to intermediary services and not affect requirements set out in Union or national law relating to products or services intermediated through intermediary services, including in situations where the intermediary service constitutes an integral part of another service which is not an intermediary service as recognised in the case-law of the Court of Justice of the European Union.",recital,"The Digital Services Act (DSA) applies specifically to intermediary services, which are services that facilitate other services, like IT, transport, accommodation, or delivery services. The law does not impact regulations related to the products or services provided through these intermediaries. This means that even if an intermediary service is part of another service that isn't an intermediary service, the DSA only applies to the intermediary portion. This is based on the established case-law of the Court of Justice of the European Union."
Artifical Inellegence Act (AI Act) - Context Section 5.2.4,0.723513842,"Aritifical Intelligence Act (AI Act) context section 5.2.4.TRANSPARENCY OBLIGATIONS FOR CERTAIN AI SYSTEMS (TITLE IV): 

Title IV concerns certain AI systems to take account of the specific risks of manipulation they pose. Transparency obligations will apply for systems that (i) interact with humans, (ii) are used to detect emotions or determine association with (social) categories based on biometric data, or (iii) generate or manipulate content (deep fakes). When persons interact with an AI system or their emotions or characteristics are recognised through automated means, people must be informed of that circumstance. If an AI system is used to generate or manipulate image, audio or video content that appreciably resembles authentic content, there should be an obligation to disclose that the content is generated through automated means, subject to exceptions for legitimate purposes (law enforcement, freedom of expression). This allows persons to make informed choices or step back from a given situation.5.2.4.TRANSPARENCY OBLIGATIONS FOR CERTAIN AI SYSTEMS (TITLE IV):

Title IV concerns certain AI systems to take account of the specific risks of manipulation they pose. Transparency obligations will apply for systems that (i) interact with humans, (ii) are used to detect emotions or determine association with (social) categories based on biometric data, or (iii) generate or manipulate content (deep fakes). When persons interact with an AI system or their emotions or characteristics are recognised through automated means, people must be informed of that circumstance. If an AI system is used to generate or manipulate image, audio or video content that appreciably resembles authentic content, there should be an obligation to disclose that the content is generated through automated means, subject to exceptions for legitimate purposes (law enforcement, freedom of expression). This allows persons to make informed choices or step back from a given situation.",recital,"The Artificial Intelligence Act (AI Act) has a section called Title IV which is about transparency rules for certain AI systems. These rules apply to AI systems that interact with humans, detect emotions or social categories using biometric data, or create or change content to make it look real ('deep fakes'). The law says that people must be told when they are interacting with these types of AI systems or when their emotions or characteristics are being recognized by them. If an AI system is making or changing content to look real, it must be disclosed that the content was created by AI, unless it's for acceptable reasons like law enforcement or freedom of expression. This way, people can make informed decisions or avoid certain situations."
General Data Protection Regulation (GDPR) - Article 44 General principle for transfers,0.723495245,"Details of Article 44 General principle for transfers in the General Data Protection Regulation (GDPR): Any transfer of personal data which are undergoing processing or are intended for processing after transfer to a third country or to an international organisation shall take place only if, subject to the other provisions of this Regulation, the conditions laid down in this Chapter are complied with by the controller and processor, including for onward transfers of personal data from the third country or an international organisation to another third country or to another international organisation. All provisions in this Chapter shall be applied in order to ensure that the level of protection of natural persons guaranteed by this Regulation is not undermined.",article,"The General Data Protection Regulation (GDPR) Article 44 states that any transfer of personal data to a foreign country or international organization can only occur if certain conditions are met. These conditions are designed to ensure that the individual's data privacy is not compromised. The law applies to both the initial transfer and any subsequent transfers of data. The aim is to maintain the same level of data protection that is guaranteed by the GDPR, regardless of where the data is transferred."
Digital Services Act (DSA) - Contextual paragraph (110),0.723483,"Details of the contextual paragraph (110) of the Digital Services Act (DSA): Given the cross-border nature of the services at stake and the horizontal range of obligations introduced by this Regulation, one authority appointed with the task of supervising the application and, where necessary, enforcing this Regulation should be identified as a Digital Services Coordinator in each Member State. Where more than one competent authority is appointed to supervise the application of, and enforce, this Regulation, only one authority in that Member State should be designated as a Digital Services Coordinator. The Digital Services Coordinator should act as the single contact point with regard to all matters related to the application of this Regulation for the Commission, the Board, the Digital Services Coordinators of other Member States, as well as for other competent authorities of the Member State in question. In particular, where several competent authorities are entrusted with tasks under this Regulation in a given Member State, the Digital Services Coordinator should coordinate and cooperate with those authorities in accordance with the national law setting their respective tasks and without prejudice to the independent assessment of the other competent authorities. While not entailing any hierarchical supraordination over other competent authorities in the exercise of their tasks, the Digital Services Coordinator should ensure effective involvement of all relevant competent authorities and should timely report their assessment in the context of cooperation on supervision and enforcement at Union level. Moreover, in addition to the specific mechanisms provided for in this Regulation as regards cooperation at Union level, Member State should also ensure cooperation among the Digital Services Coordinator and other competent authorities designated at national level, where applicable, through appropriate tools, such as by pooling of resources, joint task forces, joint investigations and mutual assistance mechanisms.",recital,"The Digital Services Act (DSA) requires each member state to appoint a Digital Services Coordinator. This authority will oversee the application and enforcement of the DSA regulations. If multiple authorities are appointed, only one can be designated as the Digital Services Coordinator. This coordinator will act as the main contact point for all matters related to the DSA, coordinating with other authorities and reporting their assessments. The coordinator doesn't have hierarchical power over other authorities but ensures their effective involvement. The DSA also encourages cooperation between the Digital Services Coordinator and other national authorities, suggesting tools like resource pooling, joint task forces, and mutual assistance mechanisms."
Digital Markets Act (DMA) - Contextual Paragraph (36),0.723448396,"Details of the Contextual Paragraph (36) in the Digital Markets Act (DMA): Gatekeepers often directly collect personal data of end users for the purpose of providing online advertising services when end users use third-party websites and software applications. Third parties also provide gatekeepers with personal data of their end users in order to make use of certain services provided by the gatekeepers in the context of their core platform services, such as custom audiences. The processing, for the purpose of providing online advertising services, of personal data from third parties using core platform services gives gatekeepers potential advantages in terms of accumulation of data, thereby raising barriers to entry. This is because gatekeepers process personal data from a significantly larger number of third parties than other undertakings. Similar advantages result from the conduct of (i) combining end user personal data collected from a core platform service with data collected from other services; (ii) cross-using personal data from a core platform service in other services provided separately by the gatekeeper, notably services which are not provided together with, or in support of, the relevant core platform service, and vice versa; or (iii) signing-in end users to different services of gatekeepers in order to combine personal data. To ensure that gatekeepers do not unfairly undermine the contestability of core platform services, gatekeepers should enable end users to freely choose to opt-in to such data processing and sign-in practices by offering a less personalised but equivalent alternative, and without making the use of the core platform service or certain functionalities thereof conditional upon the end user""s consent. This should be without prejudice to the gatekeeper processing personal data or signing in end users to a service, relying on the legal basis under Article 6(1), points (c), (d) and (e), of Regulation (EU) 2016/679, but not on Article 6(1), points (b) and (f) of that Regulation.",rectial,"The Digital Markets Act (DMA) addresses how large online platforms, known as gatekeepers, collect and use personal data for online advertising. Gatekeepers often obtain this data directly from users or from third-party sites and apps. This data collection gives gatekeepers an advantage, as they have access to more data than other businesses. Gatekeepers can also combine data from different services, use data from one service in another, or sign-in users to various services to combine data. To prevent unfair practices, the DMA requires gatekeepers to allow users to opt-in to such data processing. Users should be offered a less personalized, but equivalent alternative if they don't consent to data processing. Gatekeepers can still process data or sign users into a service under certain legal conditions, but not based on user consent alone."
Digital Markets Act (DMA) - Definition of online search engine,0.723445773,"Details of the Definition of online search engine in the Digital Markets Act (DMA): ""online search engine"" means an online search engine as defined in Article 2, point (5), of Regulation (EU) 2019/1150;",rectial,"The Digital Markets Act (DMA) provides a definition for what constitutes an ""online search engine."" This definition is outlined in Article 2, point (5), of Regulation (EU) 2019/1150. In simpler terms, the DMA gives a clear explanation of what an online search engine, like Google or Bing, is according to European Union law."
General Data Protection Regulation (GDPR) - Article 69 Independence,0.72341609,"Details of Article 69 Independence in the General Data Protection Regulation (GDPR): 1. The Board shall act independently when performing its tasks or exercising its powers pursuant to Articles 70 and 71. 2. Without prejudice to requests by the Commission referred to in point (b) of Article 70(1) and in Article 70(2), the Board shall, in the performance of its tasks or the exercise of its powers, neither seek nor take instructions from anybody.",article,"Article 69 of the General Data Protection Regulation (GDPR) mandates that the Board must act independently when carrying out its duties or using its powers as laid out in Articles 70 and 71. This means that the Board should not seek or follow instructions from anyone when performing these tasks, except in certain situations where requests are made by the Commission, as detailed in Article 70."
"General Data Protection Regulation (GDPR) - Article 12 Transparent information, communication and modalities for the exercise of the rights of the data subject",0.723403811,"Details of Article 12 Transparent information, communication and modalities for the exercise of the rights of the data subject in the General Data Protection Regulation (GDPR): 1. The controller shall take appropriate measures to provide any information referred to in Articles 13 and 14 and any communication under Articles 15 to 22 and 34 relating to processing to the data subject in a concise, transparent, intelligible and easily accessible form, using clear and plain language, in particular for any information addressed specifically to a child. The information shall be provided in writing, or by other means, including, where appropriate, by electronic means. When requested by the data subject, the information may be provided orally, provided that the identity of the data subject is proven by other means. 2. The controller shall facilitate the exercise of data subject rights under Articles 15 to 22. In the cases referred to in Article 11(2), the controller shall not refuse to act on the request of the data subject for exercising his or her rights under Articles 15 to 22, unless the controller demonstrates that it is not in a position to identify the data subject. 3. The controller shall provide information on action taken on a request under Articles 15 to 22 to the data subject without undue delay and in any event within one month of receipt of the request. That period may be extended by two further months where necessary, taking into account the complexity and number of the requests. The controller shall inform the data subject of any such extension within one month of receipt of the request, together with the reasons for the delay. Where the data subject makes the request by electronic form means, the information shall be provided by electronic means where possible, unless otherwise requested by the data subject. 4. If the controller does not take action on the request of the data subject, the controller shall inform the data subject without delay and at the latest within one month of receipt of the request of the reasons for not taking action and on the possibility of lodging a complaint with a supervisory authority and seeking a judicial remedy. 5. Information provided under Articles 13 and 14 and any communication and any actions taken under Articles 15 to 22 and 34 shall be provided free of charge. Where requests from a data subject are manifestly unfounded or excessive, in particular because of their repetitive character, the controller may either: (a) charge a reasonable fee taking into account the administrative costs of providing the information or communication or taking the action requested; or (b) refuse to act on the request. The controller shall bear the burden of demonstrating the manifestly unfounded or excessive character of the request. 6. Without prejudice to Article 11, where the controller has reasonable doubts concerning the identity of the natural person making the request referred to in Articles 15 to 21, the controller may request the provision of additional information necessary to confirm the identity of the data subject. 7. The information to be provided to data subjects pursuant to Articles 13 and 14 may be provided in combination with standardised icons in order to give in an easily visible, intelligible and clearly legible manner a meaningful overview of the intended processing. Where the icons are presented electronically they shall be machine-readable. 8. The Commission shall be empowered to adopt delegated acts in accordance with Article 92 for the purpose of determining the information to be presented by the icons and the procedures for providing standardised icons.",article,"The General Data Protection Regulation (GDPR) Article 12 ensures transparency and easy access to personal data for individuals. It mandates that organizations (controllers) provide clear, understandable information about how they use personal data. This information should be free, written (or electronic if suitable), and provided within a month of request. If the request is complex, the time can be extended by two months. If the organization doesn't act on the request, they must explain why and inform the individual about their right to complain. However, if requests are unreasonable or repetitive, the organization can charge a fee or refuse the request. If the organization doubts the identity of the requester, they can ask for more information. The use of standard icons for electronic communication is encouraged for clarity. The Commission can decide the information presented by these icons."
General Data Protection Regulation (GDPR) - Contextual Paragraph (42),0.723372638,"Details of the Contextual Paragraph (42) in the General Data Protection Regulation (GDPR): Where processing is based on the data subject's consent, the controller should be able to demonstrate that the data subject has given consent to the processing operation. In particular in the context of a written declaration on another matter, safeguards should ensure that the data subject is aware of the fact that and the extent to which consent is given. In accordance with Council Directive 93/13/EEC ( 1 ) a declaration of consent preformulated by the controller should be provided in an intelligible and easily accessible form, using clear and plain language and it should not contain unfair terms. For consent to be informed, the data subject should be aware at least of the identity of the controller and the purposes of the processing for which the personal data are intended. Consent should not be regarded as freely given if the data subject has no genuine or free choice or is unable to refuse or withdraw consent without detriment.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 42, which states that if a company wants to use your personal data, they must prove that you gave them clear permission to do so. This includes making sure you understand what you're agreeing to when you give consent. The company must provide this information in a simple, easy-to-understand way and can't include unfair terms. You should also know who the company is and why they want to use your data. If you feel forced to give consent or can't easily withdraw it without negative consequences, then your consent is not considered valid."
Digital Services Act (DSA) - Article 4,0.723311543,"Article 4 details in the Digital Services Act (DSA): 1.   Where an information society service is provided that consists of the transmission in a communication network of information provided by a recipient of the service, or the provision of access to a communication network, the service provider shall not be liable for the information transmitted or accessed, on condition that the provider:
(a) does not initiate the transmission;
(b) does not select the receiver of the transmission; and
(c) does not select or modify the information contained in the transmission.
2.   The acts of transmission and of provision of access referred to in paragraph 1 shall include the automatic, intermediate and transient storage of the information transmitted in so far as this takes place for the sole purpose of carrying out the transmission in the communication network, and provided that the information is not stored for any period longer than is reasonably necessary for the transmission.
3.   This Article shall not affect the possibility for a judicial or administrative authority, in accordance with a Member State's legal system, to require the service provider to terminate or prevent an infringement.",article,"The Digital Services Act (DSA) Article 4 states that online service providers aren't responsible for the information users share or access through their platform, as long as they don't initiate, select the recipient, or modify the shared content. This includes temporary storage of information only for transmission purposes, but it shouldn't be stored longer than necessary. However, this doesn't prevent legal authorities from requiring the service provider to stop or prevent a violation."
Artifical Inellegence Act (AI Act) - Article 37,0.723289251,"Aritifical Intelligence Act (AI Act) Article 37 Challenge to the competence of notified bodies:

1.The Commission shall, where necessary, investigate all cases where there are reasons to doubt whether a notified body complies with the requirements laid down in Article 33.

2.The Notifying authority shall provide the Commission, on request, with all relevant information relating to the notification of the notified body concerned.

3.The Commission shall ensure that all confidential information obtained in the course of its investigations pursuant to this Article is treated confidentially.

4.Where the Commission ascertains that a notified body does not meet or no longer meets the requirements laid down in Article 33, it shall adopt a reasoned decision requesting the notifying Member State to take the necessary corrective measures, including withdrawal of notification if necessary. That implementing act shall be adopted in accordance with the examination procedure referred to in Article 74(2).",article,"The Artificial Intelligence Act (AI Act) Article 37 allows the Commission to investigate if there are doubts about a notified body's compliance with set requirements. The Notifying authority must provide all relevant information about the notified body to the Commission when asked. Any confidential information obtained during the investigation must be kept confidential. If the Commission finds that a notified body is not meeting the requirements, it can request the Member State to take corrective actions, including withdrawing the notification if necessary. All these actions follow a specific examination procedure."
Digital Services Act (DSA) - Article 92 Anticipated application to providers of very large online platforms and of very large online search engines,0.723272204,Article 92 Anticipated application to providers of very large online platforms and of very large online search engines in the Digital Services Act (DSA):  This Regulation shall apply to providers of very large online platforms and of very large online search engines designated pursuant to Article 33(4) from four months after the notification to the provider concerned referred to in Article 33(6) where that date is earlier than 17 February 2024.,article,"The Digital Services Act (DSA) is a new law that will apply to providers of very large online platforms and search engines. These providers will be identified according to the criteria set out in Article 33(4) of the Act. The law will take effect four months after the providers have been notified, as long as this date is earlier than 17 February 2024."
Digital Services Act (DSA) - Article 60 Referral to the Commission in,0.723263621,"Article 60 Referral to the Commission in the Digital Services Act (DSA):  1.   The Digital Services Coordinator of establishment may launch and lead joint investigations with the participation of one or more other Digital Services Coordinators concerned:

(a) at its own initiative, to investigate an alleged infringement of this Regulation by a given provider of intermediary services in several Member States; or
(b) upon recommendation of the Board, acting on the request of at least three Digital Services Coordinators alleging, based on a reasonable suspicion, an infringement by a given provider of intermediary services affecting recipients of the service in their Member States.

2.   Any Digital Services Coordinator that proves that it has a legitimate interest in participating in a joint investigation pursuant to paragraph 1 may request to do so. The joint investigation shall be concluded within three months from its launch, unless otherwise agreed amongst the participants.

The Digital Services Coordinator of establishment shall communicate its preliminary position on the alleged infringement no later than one month after the end of the deadline referred to in the first subparagraph to all Digital Services Coordinators, the Commission and the Board. The preliminary position shall take into account the views of all other Digital Services Coordinators participating in the joint investigation. Where applicable, this preliminary position shall also set out the enforcement measures envisaged.

3.   The Board may refer the matter to the Commission pursuant to Article 59, where:
(a) the Digital Services Coordinator of establishment failed to communicate its preliminary position within the deadline set out in paragraph 2;
(b) the Board substantially disagrees with the preliminary position communicated by the Digital Services Coordinator of establishment; or
(c) the Digital Services Coordinator of establishment failed to initiate the joint investigation promptly following the recommendation by the Board pursuant to paragraph 1, point (b).

4.   In carrying out the joint investigation, the participating Digital Services Coordinators shall cooperate in good faith, taking into account, where applicable, the indications of the Digital Services Coordinator of establishment and the Board's recommendation. The Digital Services Coordinators of destination participating in the joint investigation shall be entitled, at the request of or after having consulted the Digital Services Coordinator of establishment, to exercise their investigative powers referred to in Article 51(1) in respect of the providers of intermediary services concerned by the alleged infringement, with regard to information and premises located within their territory.",article,"The Digital Services Act (DSA) allows for the Digital Services Coordinator to initiate and lead investigations into potential violations of the law by digital service providers. These investigations can be initiated either on their own or based on recommendations from the Board, which requires at least three Digital Services Coordinators to suspect a violation. Any Coordinator with a legitimate interest can request to participate in the investigation. The investigation should be completed within three months, and a preliminary position on the alleged violation should be communicated within one month of the investigation's conclusion. If the Coordinator fails to communicate the preliminary position or initiate the investigation promptly, or if the Board disagrees with the preliminary position, the matter can be referred to the Commission. The Coordinators involved in the investigation must cooperate and may exercise their investigative powers as needed."
General Data Protection Regulation (GDPR) - Contextual Paragraph (22),0.723262131,"Details of the Contextual Paragraph (22) in the General Data Protection Regulation (GDPR): Any processing of personal data in the context of the activities of an establishment of a controller or a processor in the Union should be carried out in accordance with this Regulation, regardless of whether the processing itself takes place within the Union. Establishment implies the effective and real exercise of activity through stable arrangements. The legal form of such arrangements, whether through a branch or a subsidiary with a legal personality, is not the determining factor in that respect.",recital,"The General Data Protection Regulation (GDPR) states that any handling of personal data by a business or data processor in the European Union must comply with GDPR rules, even if the actual data processing happens outside the EU. The law applies to businesses that are actively and regularly operating in the EU, regardless of whether they're branches or subsidiaries with their own legal status. The key factor is that they have a stable presence in the EU, not their specific legal structure."
Digital Markets Act (DMA) - Contextual Paragraph (96),0.723224223,"Details of the Contextual Paragraph (96) in the Digital Markets Act (DMA): The implementation of some of the gatekeepers"" obligations, such as those related to data access, data portability or interoperability could be facilitated by the use of technical standards. In this respect, it should be possible for the Commission, where appropriate and necessary, to request European standardisation bodies to develop them.",rectial,"The Digital Markets Act (DMA) includes a clause (Paragraph 96) that allows for the use of technical standards to help enforce certain obligations of digital ""gatekeepers"" (large, influential tech companies). These obligations could involve access to data, transferring data, or making systems work together. If needed, the European Commission can ask European standardisation bodies to develop these technical standards."
California Consumer Privacy Act Regulations (CCPA) - Article 5. Special Rules Regarding Consumers Under 16 Years of Age -  999.332 Notice to Consumers Under 16 Years of Age,0.723223388,"Details of Article 5. Special Rules Regarding Consumers Under 16 Years of Age -  999.332 Notice to Consumers Under 16 Years of Age in the California Consumer Privacy Act Regulations (CCPA): (a) A business subject to sections 999.330 and 999.331 shall include a description of the processes set forth in those sections in its privacy policy. (b) A business that exclusively targets offers of goods or services directly to consumers under 16 years of age and does not sell the personal information without the affirmative authorization of consumers at least 13 years of age and less than 16 years of age, or the affirmative authorization of their parent or guardian for consumers under 13 years of age, is not required to provide the notice of right to opt-out.",article,"The California Consumer Privacy Act (CCPA) has a new rule, Article 5, specifically for consumers under 16 years of age. Businesses must describe in their privacy policy how they handle the personal data of these young consumers. However, if a business only targets offers to consumers under 16 and doesn't sell their personal data without clear permission from the consumer (if they're between 13 and 16) or their parent/guardian (if they're under 13), then the business doesn't need to provide the option to opt-out of data selling."
Artifical Inellegence Act (AI Act) - Article 35,0.723190486,"Aritifical Intelligence Act (AI Act) Article 36 Changes to notifications:

1.Where a notifying authority has suspicions or has been informed that a notified body no longer meets the requirements laid down in Article 33, or that it is failing to fulfil its obligations, that authority shall without delay investigate the matter with the utmost diligence. In that context, it shall inform the notified body concerned about the objections raised and give it the possibility to make its views known. If the notifying authority comes to the conclusion that the notified body investigation no longer meets the requirements laid down in Article 33 or that it is failing to fulfil its obligations, it shall restrict, suspend or withdraw the notification as appropriate, depending on the seriousness of the failure. It shall also immediately inform the Commission and the other Member States accordingly.

2.In the event of restriction, suspension or withdrawal of notification, or where the notified body has ceased its activity, the notifying authority shall take appropriate steps to ensure that the files of that notified body are either taken over by another notified body or kept available for the responsible notifying authorities at their request.",article,"The Artificial Intelligence Act (AI Act) Article 36 changes how authorities handle notifications about AI bodies not meeting requirements or failing their duties. If an authority suspects or is informed of such issues, it must promptly investigate. The AI body under investigation will be informed and allowed to respond. If the authority concludes that the AI body is indeed not meeting standards or failing its duties, it can limit, suspend, or withdraw the body's notification, based on the severity of the issue. This decision will also be communicated to the Commission and other Member States. If a body's notification is limited, suspended, or withdrawn, or if it stops operating, the authority will ensure that the body's files are transferred to another body or kept accessible for responsible authorities as needed."
General Data Protection Regulation (GDPR) - Contextual Paragraph (140),0.723165572,"Details of the Contextual Paragraph (140) in the General Data Protection Regulation (GDPR): The Board should be assisted by a secretariat provided by the European Data Protection Supervisor. The staff of the European Data Protection Supervisor involved in carrying out the tasks conferred on the Board by this Regulation should perform its tasks exclusively under the instructions of, and report to, the Chair of the Board.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 140, stating that the European Data Protection Board should have a secretariat, provided by the European Data Protection Supervisor. The staff from the Supervisor's office, who are helping the Board with tasks related to this regulation, should only work under the instructions of, and report to, the Chair of the Board."
Artifical Inellegence Act (AI Act) - Overview paragraph 56,0.723088384,"Aritifical Intelligence Act (AI Act) overview paragraph (56): To enable enforcement of this Regulation and create a level-playing field for operators, and taking into account the different forms of making available of digital products, it is important to ensure that, under all circumstances, a person established in the Union can provide authorities with all the necessary information on the compliance of an AI system. Therefore, prior to making their AI systems available in the Union, where an importer cannot be identified, providers established outside the Union shall, by written mandate, appoint an authorised representative established in the Union.",recital,"The Artificial Intelligence Act (AI Act) requires that before AI systems can be used in the Union, there must be a person based in the Union who can provide authorities with all necessary information about the AI system's compliance with regulations. If the importer cannot be identified, providers outside the Union must appoint an authorized representative within the Union. This ensures fair competition and effective regulation enforcement."
Digital Services Act (DSA) - Article 81 Fines,0.723042309,"Article 81 Fines in the Digital Services Act (DSA):  In accordance with Article 261 TFEU, the Court of Justice of the European Union has unlimited jurisdiction to review decisions by which the Commission has imposed fines or periodic penalty payments. It may cancel, reduce or increase the fine or periodic penalty payment imposed.",article,"The Digital Services Act (DSA) includes Article 81, which gives the Court of Justice of the European Union the power to review any decisions made by the Commission regarding fines or recurring penalties. This means the Court can either cancel, decrease, or increase the fines or penalties that have been imposed by the Commission."
Artifical Inellegence Act (AI Act) - Definition of 'placing on the market',0.723017037,"Within the Aritifical Intelligence Act (AI Act), the Definition of placing on the market means the first making available of an AI system on the Union market;",recital,The Artificial Intelligence Act (AI Act) introduces a term called 'placing on the market.' This refers to the first time an AI system becomes available for use or purchase within the Union market.
General Data Protection Regulation (GDPR) - Article 27 Representatives of controllers or processors not established in the Union,0.722890615,"Details of Article 27 Representatives of controllers or processors not established in the Union in the General Data Protection Regulation (GDPR): 1. Where Article 3(2) applies, the controller or the processor shall designate in writing a representative in the Union. 2. The obligation laid down in paragraph 1 of this Article shall not apply to: (a) processing which is occasional, does not include, on a large scale, processing of special categories of data as referred to in Article 9(1) or processing of personal data relating to criminal convictions and offences referred to in Article 10, and is unlikely to result in a risk to the rights and freedoms of natural persons, taking into account the nature, context, scope and purposes of the processing; or (b) a public authority or body. 3. The representative shall be established in one of the Member States where the data subjects, whose personal data are processed in relation to the offering of goods or services to them, or whose behaviour is monitored, are. 4. The representative shall be mandated by the controller or processor to be addressed in addition to or instead of the controller or the processor by, in particular, supervisory authorities and data subjects, on all issues related to processing, for the purposes of ensuring compliance with this Regulation. 5. The designation of a representative by the controller or processor shall be without prejudice to legal actions which could be initiated against the controller or the processor themselves.",article,"The General Data Protection Regulation (GDPR) Article 27 requires companies not based in the EU to appoint a representative within the EU. This representative will handle all matters related to data processing, ensuring the company complies with GDPR. However, this requirement doesn't apply to occasional data processing that doesn't involve large-scale processing of special categories of data, or to public authorities. The representative should be located in the EU country where the data subjects are based. This representative can be contacted by supervisory authorities and data subjects in addition to or instead of the company. Appointing a representative doesn't protect the company from legal actions related to data processing."
Artifical Inellegence Act (AI Act) - Overview paragraph 51,0.722880661,"Aritifical Intelligence Act (AI Act) overview paragraph (51): Cybersecurity plays a crucial role in ensuring that AI systems are resilient against attempts to alter their use, behaviour, performance or compromise their security properties by malicious third parties exploiting the systems vulnerabilities. Cyberattacks against AI systems can leverage AI specific assets, such as training data sets (e.g. data poisoning) or trained models (e.g. adversarial attacks), or exploit vulnerabilities in the AI systems digital assets or the underlying ICT infrastructure. To ensure a level of cybersecurity appropriate to the risks, suitable measures should therefore be taken by the providers of high-risk AI systems, also taking into account as appropriate the underlying ICT infrastructure.",recital,"The Artificial Intelligence Act (AI Act) emphasizes the importance of cybersecurity in protecting AI systems from potential threats or misuse by malicious parties. These threats could exploit weaknesses in the AI system, its data sets, or its digital infrastructure. To counter these threats, the law requires providers of high-risk AI systems to implement appropriate cybersecurity measures. These measures should also consider the system's underlying digital infrastructure."
Artifical Inellegence Act (AI Act) - Article 39,0.722842276,"Aritifical Intelligence Act (AI Act) Article 39 Conformity assessment bodies of third countries:

Conformity assessment bodies established under the law of a third country with which the Union has concluded an agreement may be authorised to carry out the activities of notified Bodies under this Regulation.",article,"The Artificial Intelligence Act (AI Act) allows for certain organizations, known as conformity assessment bodies, from countries outside of the Union to be authorized to perform activities of notified bodies under this regulation. This is only possible if the Union has an existing agreement with the third country. These activities might include ensuring that artificial intelligence systems meet specific standards or regulations."
Digital Markets Act (DMA) - Contextual Paragraph (75),0.722792387,"Details of the Contextual Paragraph (75) in the Digital Markets Act (DMA): The Commission should investigate and assess whether additional behavioural, or, where appropriate, structural remedies are justified, in order to ensure that the gatekeeper cannot frustrate the objectives of this Regulation by systematic non-compliance with one or several of the obligations laid down in this Regulation. This is the case where the Commission has issued against a gatekeeper at least three non-compliance decisions within the period of 8 years, which can concern different core platform services and different obligations laid down in this Regulation, and if the gatekeeper has maintained, extended or further strengthened its impact in the internal market, the economic dependency of its business users and end users on the gatekeeper""s core platform services or the entrenchment of its position. A gatekeeper should be deemed to have maintained, extended or strengthened its gatekeeper position where, despite the enforcement actions taken by the Commission, that gatekeeper still holds or has further consolidated or entrenched its importance as a gateway for business users to reach end users. The Commission should in such cases have the power to impose any remedy, whether behavioural or structural, having due regard to the principle of proportionality. In this context, the Commission should have the power to prohibit, to the extent that such remedy is proportionate and necessary in order to maintain or restore fairness and contestability as affected by the systematic non-compliance, during a limited time-period, the gatekeeper from entering into a concentration regarding those core platform services or the other services provided in the digital sector or services enabling the collection of data that are affected by the systematic non-compliance. In order to enable effective involvement of third parties and the possibility to test remedies before its application, the Commission should publish a detailed non-confidential summary of the case and the measures to be taken. The Commission should be able to reopen proceedings, including where the specified remedies turn out not to be effective. A reopening due to ineffective remedies adopted by decision should enable the Commission to amend the remedies prospectively. The Commission should also be able to set a reasonable time period within which it should be possible to reopen the proceedings if the remedies prove not to be effective.",rectial,"The Digital Markets Act (DMA) allows the European Commission to investigate and take action against companies that control access to online markets (gatekeepers) if they repeatedly violate the rules of the Act. If a gatekeeper has been found non-compliant three times in eight years, the Commission can impose restrictions to prevent the company from abusing its market position. These restrictions could include prohibiting the gatekeeper from acquiring other businesses in the digital sector. The Commission will also publish a summary of the case and the measures taken, allowing third parties to get involved and test the effectiveness of the remedies. If the remedies are not effective, the Commission can reopen the case and adjust the remedies. The Commission will set a reasonable timeframe for reopening the case if the remedies prove ineffective."
General Data Protection Regulation (GDPR) - Article 67 Exchange of information,0.722743213,"Details of Article 67 Exchange of information in the General Data Protection Regulation (GDPR): The Commission may adopt implementing acts of general scope in order to specify the arrangements for the exchange of information by electronic means between supervisory authorities, and between supervisory authorities and the Board, in particular the standardised format referred to in Article 64. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 93(2).",article,"Article 67 of the General Data Protection Regulation (GDPR) allows the Commission to create rules about how information is shared electronically between supervisory authorities and the Board. This includes deciding on a standard format for such exchanges, as mentioned in Article 64. The rules will be established following the examination procedure outlined in Article 93(2)."
General Data Protection Regulation (GDPR) - Contextual Paragraph (98),0.722725332,"Details of the Contextual Paragraph (98) in the General Data Protection Regulation (GDPR): Associations or other bodies representing categories of controllers or processors should be encouraged to draw up codes of conduct, within the limits of this Regulation, so as to facilitate the effective application of this Regulation, taking account of the specific characteristics of the processing carried out in certain sectors and the specific needs of micro, small and medium enterprises. In particular, such codes of conduct could calibrate the obligations of controllers and processors, taking into account the risk likely to result from the processing for the rights and freedoms of natural persons.",recital,"The General Data Protection Regulation (GDPR) encourages organizations that represent groups of data controllers or processors to create codes of conduct. These codes should help apply the GDPR effectively, considering the unique needs of different sectors and small to medium businesses. The codes could adjust the responsibilities of controllers and processors, considering the potential risks to people's rights and freedoms from data processing."
Digital Markets Act (DMA) - Contextual Paragraph (28),0.722671688,"Details of the Contextual Paragraph (28) in the Digital Markets Act (DMA): Applying only those obligations that are necessary and proportionate to achieve the objectives of this Regulation should allow the Commission to intervene in time and effectively, while fully respecting the proportionality of the measures considered. It should also reassure actual or potential market participants about the contestability and fairness of the services concerned.",rectial,"The Contextual Paragraph (28) in the Digital Markets Act (DMA) is about ensuring that only necessary and proportionate obligations are applied to achieve the goals of this regulation. This allows the Commission to take timely and effective action, while maintaining a balance in the measures taken. The law also aims to assure current or potential market participants about the fairness and competitiveness of the services involved."
Artifical Inellegence Act (AI Act) - Article 36,0.722632468,"Aritifical Intelligence Act (AI Act) Article 35 Identification numbers and lists of notified bodies designated under this Regulation:

1.The Commission shall assign an identification number to notified bodies. It shall assign a single number, even where a body is notified under several Union acts.

2.The Commission shall make publicly available the list of the bodies notified under this Regulation, including the identification numbers that have been assigned to them and the activities for which they have been notified. The Commission shall ensure that the list is kept up to date.",article,"The Artificial Intelligence Act (AI Act) states that the Commission will assign a unique identification number to notified bodies, even if they fall under multiple Union acts. The Commission will also maintain and publicly share a list of these bodies, including their assigned numbers and the activities they are notified for. This ensures transparency and easy identification of these entities."
California Consumer Privacy Act Regulations (CCPA) - Article 3. Business Practices for Handling Consumer Requests -  999.316 Requests to Opt-In After Opting-Out of the Sale of Personal Information,0.722630441,"Details of Article 3. Business Practices for Handling Consumer Requests -  999.316 Requests to Opt-In After Opting-Out of the Sale of Personal Information in the California Consumer Privacy Act Regulations (CCPA): (a) Requests to opt-in to the sale of personal information shall use a two-step opt-in process whereby the consumer shall first, clearly request to opt-in and then second, separately confirm their choice to opt-in. (b) If a consumer who has opted-out of the sale of their personal information initiates a transaction or attempts to use a product or service that requires the sale of their personal information, a business may inform the consumer that the transaction, product, or service requires the sale of their personal information and provide instructions on how the consumer can opt-in.",article,"The new California Consumer Privacy Act Regulations (CCPA) introduces Article 3, which outlines how businesses should handle customer requests to share their personal information. If a customer who previously chose not to share their personal data (opted-out) decides they want to share it (opt-in), the business must follow a two-step process: the customer must first clearly request to opt-in, then separately confirm this decision. If a customer who has opted-out wants to use a service or product that requires sharing their personal data, the business can tell them that their personal information needs to be sold and explain how to opt-in."
Digital Services Act (DSA) - Article 20 Internal complaint-handling system,0.722539723,"Article 20 Internal complaint-handling system in the Digital Services Act (DSA):  1.   Providers of online platforms shall provide recipients of the service, including individuals or entities that have submitted a notice, for a period of at least six months following the decision referred to in this paragraph, with access to an effective internal complaint-handling system that enables them to lodge complaints, electronically and free of charge, against the decision taken by the provider of the online platform upon the receipt of a notice or against the following decisions taken by the provider of the online platform on the grounds that the information provided by the recipients constitutes illegal content or is incompatible with its terms and conditions:
(a) decisions whether or not to remove or disable access to or restrict visibility of the information;
(b) decisions whether or not to suspend or terminate the provision of the service, in whole or in part, to the recipients;
(c) decisions whether or not to suspend or terminate the recipients' account;
(d) decisions whether or not to suspend, terminate or otherwise restrict the ability to monetise information provided by the recipients.
2.   The period of at least six months referred to in paragraph 1 of this Article shall start on the day on which the recipient of the service is informed about the decision in accordance with Article 16(5) or Article 17.
3.   Providers of online platforms shall ensure that their internal complaint-handling systems are easy to access, user-friendly and enable and facilitate the submission of sufficiently precise and adequately substantiated complaints.
4.   Providers of online platforms shall handle complaints submitted through their internal complaint-handling system in a timely, non-discriminatory, diligent and non-arbitrary manner. Where a complaint contains sufficient grounds for the provider of the online platform to consider that its decision not to act upon the notice is unfounded or that the information to which the complaint relates is not illegal and is not incompatible with its terms and conditions, or contains information indicating that the complainant's conduct does not warrant the measure taken, it shall reverse its decision referred to in paragraph 1 without undue delay.
5.   Providers of online platforms shall inform complainants without undue delay of their reasoned decision in respect of the information to which the complaint relates and of the possibility of out-of-court dispute settlement provided for in Article 21 and other available possibilities for redress.
6.   Providers of online platforms shall ensure that the decisions, referred to in paragraph 5, are taken under the supervision of appropriately qualified staff, and not solely on the basis of automated means.",article,"The Digital Services Act (DSA) requires online platform providers to have an effective, user-friendly, and free complaint-handling system. This system should allow users to challenge decisions made by the platform regarding content removal, service suspension, account termination, and monetization restrictions. Users should be able to file complaints for at least six months after the decision is made. The platform must handle complaints promptly and fairly, and if a complaint is valid, the platform must reverse its decision without unnecessary delay. The platform must also quickly inform the user of their decision regarding the complaint and provide information about other ways to resolve the dispute. Decisions should not be made solely by automated systems but supervised by qualified staff."
Digital Services Act (DSA) - Article 67 Requests for information,0.722525239,"Article 67 Requests for information in the Digital Services Act (DSA):  1.   In order to carry out the tasks assigned to it under this Section, the Commission may, by simple request or by decision, require the provider of the very large online platform or of the very large online search engine concerned, as well as any other natural or legal person acting for purposes related to their trade, business, craft or profession that may be reasonably aware of information relating to the suspected infringement, including organisations performing the audits referred to in Article 37 and Article 75(2), to provide such information within a reasonable period.

2.   When sending a simple request for information to the provider of the very large online platform or of the very large online search engine concerned or other person referred to in paragraph 1 of this Article, the Commission shall state the legal basis and the purpose of the request, specify what information is required and set the period within which the information is to be provided, and the fines provided for in Article 74 for supplying incorrect, incomplete or misleading information.

3.   Where the Commission requires the provider of the very large online platform or of the very large online search engine concerned or other person referred to in paragraph 1 of this Article to supply information by decision, it shall state the legal basis and the purpose of the request, specify what information is required and set the period within which it is to be provided. It shall also indicate the fines provided for in Article 74 and indicate or impose the periodic penalty payments provided for in Article 76. It shall further indicate the right to have the decision reviewed by the Court of Justice of the European Union.

4.   The providers of the very large online platform or of the very large online search engine concerned or other person referred to in paragraph 1 or their representatives and, in the case of legal persons, companies or firms, or where they have no legal personality, the persons authorised to represent them by law or by their constitution shall supply the information requested on behalf of the provider of the very large online platform or of the very large online search engine concerned or other person referred to in paragraph 1. Lawyers duly authorised to act may supply the information on behalf of their clients. The latter shall remain fully responsible if the information supplied is incomplete, incorrect or misleading.

5.   At the request of the Commission, the Digital Services Coordinators and other competent authorities shall provide the Commission with all necessary information to carry out the tasks assigned to it under this Section.

6.   The Commission shall, without undue delay after sending the simple request or the decision referred to in paragraph 1 of this Article, send a copy thereof to the Digital Services Coordinators, through the information sharing system referred to in Article 85.",article,"The Digital Services Act (DSA) allows the Commission to request information from large online platforms and search engines, or any other related businesses, if they suspect a violation of the law. The Commission must specify the legal basis and purpose of the request, what information is needed, and the timeframe for providing it. If the information provided is incorrect or misleading, fines may be imposed. The businesses or their legal representatives must provide the requested information, and they are fully responsible for its accuracy. The Commission can also request necessary information from Digital Services Coordinators and other authorities. After making a request, the Commission must send a copy to the Digital Services Coordinators."
Digital Services Act (DSA) - Definition of 'online platform',0.722507238,"Definition of 'online platform' in the Digital Services Act (DSA): a hosting service that, at the request of a recipient of the service, stores and disseminates information to the public, unless that activity is a minor and purely ancillary feature of another service or a minor functionality of the principal service and, for objective and technical reasons, cannot be used without that other service, and the integration of the feature or functionality into the other service is not a means to circumvent the applicability of this Regulation.",recital,"The Digital Services Act (DSA) defines an 'online platform' as a service that stores and shares information to the public at the request of a user. However, if this activity is just a small, secondary part of another service, and it can't be used without that main service, it's not considered an 'online platform' under this law. This rule can't be bypassed by integrating the feature into the main service."
Digital Services Act (DSA) - Contextual paragraph (53),0.722497225,"Details of the contextual paragraph (53) of the Digital Services Act (DSA): The notice and action mechanisms should allow for the submission of notices which are sufficiently precise and adequately substantiated to enable the provider of hosting services concerned to take an informed and diligent decision, compatible with the freedom of expression and of information, in respect of the content to which the notice relates, in particular whether or not that content is to be considered illegal content and is to be removed or access thereto is to be disabled. Those mechanisms should be such as to facilitate the provision of notices that contain an explanation of the reasons why the individual or the entity submitting a notice considers that content to be illegal content, and a clear indication of the location of that content. Where a notice contains sufficient information to enable a diligent provider of hosting services to identify, without a detailed legal examination, that it is clear that the content is illegal, the notice should be considered to give rise to actual knowledge or awareness of illegality. Except for the submission of notices relating to offences referred to in Articles 3 to 7 of Directive 2011/93/EU of the European Parliament and of the Council (26), those mechanisms should ask the individual or the entity submitting a notice to disclose its identity in order to avoid misuse.",recital,"The Digital Services Act (DSA) requires online hosting services to have mechanisms for users to report content they believe is illegal. These reports must be detailed and substantiated enough for the provider to make an informed decision about the content's legality without infringing on freedom of expression. The reporting mechanisms should make it easy for users to explain why they believe the content is illegal and where it is located. If a report provides enough information for the provider to identify the content as clearly illegal without needing a detailed legal examination, the provider is considered to be aware of the illegality. Except for certain offences, the person or entity reporting the content must reveal their identity to prevent misuse of the reporting system."
Digital Services Act (DSA) - Contextual paragraph (101),0.722484648,"Details of the contextual paragraph (101) of the Digital Services Act (DSA): The Commission should be in possession of all the necessary resources, in terms of staffing, expertise, and financial means, for the performance of its tasks under this Regulation. In order to ensure the availability of the resources necessary for the adequate supervision at Union level under this Regulation, and considering that Member States should be entitled to charge providers established in their territory a supervisory fee to in respect of the supervisory and enforcement tasks exercised by their authorities, the Commission should charge a supervisory fee, the level of which should be established on an annual basis, on very large online platforms and very large online search engines. The overall amount of the annual supervisory fee charged should be established on the basis of the overall amount of the costs incurred by the Commission to exercise its supervisory tasks under this Regulation, as reasonably estimated beforehand. Such amount should include costs relating to the exercise of the specific powers and tasks of supervision, investigation, enforcement and monitoring in respect of providers of very large online platforms and of very large online search engines, including costs related to the designation of very large online platforms and of very large online search engines or to the set up, maintenance and operation of the databases envisaged under this Regulation.
It should also include costs relating to the set-up, maintenance and operation of the basic information and institutional infrastructure for the cooperation among Digital Services Coordinators, the Board and the Commission, taking into account the fact that in view of their size and reach very large online platforms and very large online search engines have a significant impact on the resources needed to support such infrastructure. The estimation of the overall costs should take into account the supervisory costs incurred in the previous year including, where applicable, those costs exceeding the individual annual supervisory fee charged in the previous year. The external assigned revenues resulting from the annual supervisory fee could be used to finance additional human resources, such as contractual agents and seconded national experts, and other expenditure related to the fulfilment of the tasks entrusted to the Commission by this Regulation. The annual supervisory fee to be charged on providers of very large online platforms and of very large online search engines should be proportionate to the size of the service as reflected by the number of its active recipients of the service in the Union. Moreover, the individual annual supervisory fee should not exceed an overall ceiling for each provider of very large online platforms or of very large online search engines taking into account the economic capacity of the provider of the designated service or services.",recital,"The Digital Services Act (DSA) requires the Commission to have sufficient resources, including staff, expertise, and funds, to carry out its duties. To ensure this, the Commission will charge an annual supervisory fee to large online platforms and search engines. This fee will be based on the Commission's estimated costs for supervision, investigation, enforcement, and monitoring of these platforms and search engines. The fee will also cover costs for maintaining cooperation among Digital Services Coordinators, the Board, and the Commission. The fee will be proportionate to the size of the service, based on the number of its active users in the Union, and will not exceed a maximum limit considering the provider's economic capacity. The revenue from this fee may be used to finance additional resources and expenses related to the Commission's tasks under the DSA."
General Data Protection Regulation (GDPR) - Contextual Paragraph (18),0.72247684,"Details of the Contextual Paragraph (18) in the General Data Protection Regulation (GDPR): This Regulation does not apply to the processing of personal data by a natural person in the course of a purely personal or household activity and thus with no connection to a professional or commercial activity. Personal or household activities could include correspondence and the holding of addresses, or social networking and online  activity undertaken within the context of such activities. However, this Regulation applies to controllers or processors which provide the means for processing personal data for such personal or household activities.",recital,"The General Data Protection Regulation (GDPR) doesn't apply to individuals using personal data for strictly personal or household activities, like correspondence or social networking. However, if a company provides the tools for processing this personal data, they must comply with the GDPR."
Digital Services Act (DSA) - Article 56 Competences,0.722439885,"Article 56 Competences in the Digital Services Act (DSA):  1.   The Member State in which the main establishment of the provider of intermediary services is located shall have exclusive powers to supervise and enforce this Regulation, except for the powers provided for in paragraphs 2, 3 and 4.

2.   The Commission shall have exclusive powers to supervise and enforce Section 5 of Chapter III.

3.   The Commission shall have powers to supervise and enforce this Regulation, other than those laid down in Section 5 of Chapter III thereof, against providers of very large online platforms and of very large online search engines.

4.   Where the Commission has not initiated proceedings for the same infringement, the Member State in which the main establishment of the provider of very large online platform or of very large online search engine is located shall have powers to supervise and enforce the obligations under this Regulation, other than those laid down in Section 5 of Chapter III, with respect to those providers.

5.   Member States and the Commission shall supervise and enforce the provisions of this Regulation in close cooperation.

6.   Where a provider of intermediary services does not have an establishment in the Union, the Member State where its legal representative resides or is established or the Commission shall have powers, as applicable, in accordance with paragraphs 1 and 4 of this Article, to supervise and enforce the relevant obligations under this Regulation.

7.   Where a provider of intermediary services fails to appoint a legal representative in accordance with Article 13, all Member States and, in case of a provider of a very large online platform or very large online search engine, the Commission shall have powers to supervise and enforce in accordance with this Article.

Where a Digital Services Coordinator intends to exercise its powers under this paragraph, it shall notify all other Digital Services Coordinators and the Commission, and ensure that the applicable safeguards afforded by the Charter are respected, in particular to avoid that the same conduct is sanctioned more than once for the infringement of the obligations laid down in this Regulation. Where the Commission intends to exercise its powers under this paragraph, it shall notify all other Digital Services Coordinators of that intention. Following the notification pursuant to this paragraph, other Member States shall not initiate proceedings for the same infringement as that referred to in the notification.

",article,"The new law, the Digital Services Act (DSA), outlines the roles of Member States and the Commission in regulating online services. The country where the main office of an online service provider is located will primarily enforce the law, except for Section 5 of Chapter III, which is handled by the Commission. The Commission also oversees very large online platforms and search engines. If the Commission hasn't started proceedings for a violation, the Member State can step in. They must work closely together to enforce the law. If a service provider doesn't have an office in the Union, the country where its legal representative is located or the Commission will enforce the law. If a provider doesn't appoint a legal representative, all Member States and the Commission can enforce the law. They must avoid punishing the same violation more than once."
General Data Protection Regulation (GDPR) - Article 54 Rules on the establishment of the supervisory authority,0.722425342,"Details of Article 54 Rules on the establishment of the supervisory authority in the General Data Protection Regulation (GDPR): 1. Each Member State shall provide by law for all of the following: (a) the establishment of each supervisory authority; (b) the qualifications and eligibility conditions required to be appointed as member of each supervisory authority; (c) the rules and procedures for the appointment of the member or members of each supervisory authority; (d) the duration of the term of the member or members of each supervisory authority of no less than four years, except for the first appointment after 24 May 2016, part of which may take place for a shorter period where that is necessary to protect the independence of the supervisory authority by means of a staggered appointment procedure; (e) whether and, if so, for how many terms the member or members of each supervisory authority is eligible for reappointment; (f) the conditions governing the obligations of the member or members and staff of each supervisory authority, prohibitions on actions, occupations and benefits incompatible therewith during and after the term of office and rules governing the cessation of employment. 2. The member or members and the staff of each supervisory authority shall, in accordance with Union or Member State law, be subject to a duty of professional secrecy both during and after their term of office, with regard to any confidential information which has come to their knowledge in the course of the performance of their tasks or exercise of their powers. During their term of office, that duty of professional secrecy shall in particular apply to reporting by natural persons of infringements of this Regulation.",article,"Article 54 of the General Data Protection Regulation (GDPR) requires each member state to establish a supervisory authority to oversee data protection. The law outlines the qualifications needed to be a member, the appointment process, and the minimum term of four years. The law also specifies the conditions for reappointment and the obligations of members and staff, including restrictions on certain activities during and after their term. It also mandates a duty of professional secrecy for all members and staff, both during and after their term, especially when it comes to reporting data protection violations."
General Data Protection Regulation (GDPR) - Article 97 Commission reports,0.72241354,"Details of Article 97 Commission reports in the General Data Protection Regulation (GDPR): 1. By 25 May 2020 and every four years thereafter, the Commission shall submit a report on the evaluation and review of this Regulation to the European Parliament and to the Council. The reports shall be made public. 2. In the context of the evaluations and reviews referred to in paragraph 1, the Commission shall examine, in particular, the application and functioning of: (a) Chapter V on the transfer of personal data to third countries or international organisations with particular regard to decisions adopted pursuant to Article 45(3) of this Regulation and decisions adopted on the basis of Article 25(6) of Directive 95/46/EC; (b) Chapter VII on cooperation and consistency. 3. For the purpose of paragraph 1, the Commission may request information from Member States and supervisory authorities. 4. In carrying out the evaluations and reviews referred to in paragraphs 1 and 2, the Commission shall take into account the positions and findings of the European Parliament, of the Council, and of other relevant bodies or sources. 5. The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account of developments in information technology and in the light of the state of progress in the information society.",article,"Article 97 of the General Data Protection Regulation (GDPR) requires the Commission to submit a public report every four years, starting from 25 May 2020, to the European Parliament and Council. This report will review and evaluate the application of the GDPR, specifically focusing on the transfer of personal data to third countries or international organizations and cooperation and consistency. The Commission can request information from Member States and supervisory authorities for this report. The Commission will consider the positions and findings of the European Parliament, Council, and other relevant bodies. If necessary, the Commission may propose amendments to the GDPR, particularly considering developments in information technology and the progress of the information society."
Digital Markets Act (DMA) - Contextual Paragraph (76),0.722396791,"Details of the Contextual Paragraph (76) in the Digital Markets Act (DMA): Where, in the course of an investigation into systematic non-compliance, a gatekeeper offers commitments to the Commission, the latter should be able to adopt a decision making these commitments binding on the gatekeeper concerned, where it finds that the commitments ensure effective compliance with the obligations set out in this Regulation. That decision should also find that there are no longer grounds for action by the Commission as regards the systematic non-compliance under investigation. In assessing whether the commitments offered by the gatekeeper are sufficient to ensure effective compliance with the obligations under this Regulation, the Commission should be allowed to take into account tests undertaken by the gatekeeper to demonstrate the effectiveness of the offered commitments in practice. The Commission should verify that the commitments decision is fully respected and reaches its objectives, and should be entitled to reopen the decision if it finds that the commitments are not effective.",rectial,"The Digital Markets Act (DMA) includes a provision (Paragraph 76) that allows a digital company (gatekeeper) under investigation for not following the law to offer ways they plan to fix the problem (commitments). If the European Commission believes these commitments will effectively solve the issue, they can make them legally binding and stop the investigation. The Commission can also consider any tests the company has done to show that their commitments will work. However, the Commission will check if the company is sticking to these commitments and meeting its objectives. If the commitments aren't effective, the Commission can reopen the decision."
Digital Services Act (DSA) - Contextual paragraph (102),0.722358108,"Details of the contextual paragraph (102) of the Digital Services Act (DSA): To facilitate the effective and consistent application of the obligations in this Regulation that may require implementation through technological means, it is important to promote voluntary standards covering certain technical procedures, where the industry can help develop standardised means to support providers of intermediary services in complying with this Regulation, such as allowing the submission of notices, including through application programming interfaces, or standards related to terms and conditions or standards relating to audits, or standards related to the interoperability of advertisement repositories. In addition, such standards could include standards related to online advertising, recommender systems, accessibility and the protection of minors online. Providers of intermediary services are free to adopt the standards, but their adoption does not presume compliance with this Regulation. At the same time, by providing best practices, such standards could in particular be useful for relatively small providers of intermediary services. The standards could distinguish between different types of illegal content or different types of intermediary services, as appropriate.",recital,"The Digital Services Act (DSA) encourages the creation of voluntary industry standards to help online service providers comply with the law. These standards could cover technical procedures like submitting notices, terms and conditions, audits, and advertising. They could also address issues like user recommendations, online safety for minors, and accessibility. While these standards can provide useful guidelines, especially for smaller providers, adopting them doesn't automatically mean a provider is fully compliant with the DSA. The standards can vary based on the type of illegal content or service provided."
General Data Protection Regulation (GDPR) - Contextual Paragraph (60),0.722352207,"Details of the Contextual Paragraph (60) in the General Data Protection Regulation (GDPR): The principles of fair and transparent processing require that the data subject be informed of the existence of the processing operation and its purposes. The controller should provide the data subject with any further information necessary to ensure fair and transparent processing taking into account the specific circumstances and context in which the personal data are processed. Furthermore, the data subject should be informed of the existence of profiling and the consequences of such profiling. Where the personal data are collected from the data subject, the data subject should also be informed whether he or she is obliged to provide the personal data and of the consequences, where he or she does not provide such data. That information may be provided in combination with standardised icons in order to give in an easily visible, intelligible and clearly legible manner, a meaningful overview of the intended processing. Where the icons are presented electronically, they should be machine-readable.",recital,"The General Data Protection Regulation (GDPR) requires that individuals be clearly informed about how their personal data is being used. This includes explaining why the data is being collected, any potential consequences of data profiling, and whether providing this data is mandatory. If the individual chooses not to provide the data, they must be informed of any potential repercussions. This information should be presented in a clear and understandable way, possibly with the use of standard icons. If these icons are used online, they should be machine-readable."
Artifical Inellegence Act (AI Act) - Definition of 'publicly accessible space',0.722348511,"Within the Aritifical Intelligence Act (AI Act), the Definition of publicly accessible space means any physical place accessible to the public, regardless of whether certain conditions for access may apply;",recital,"The Artificial Intelligence Act (AI Act) includes a term called 'publicly accessible space'. This refers to any place that the public can access. Even if there are certain conditions or rules for entering, it's still considered a 'publicly accessible space' under this law."
General Data Protection Regulation (GDPR) - Article 42 Certification,0.722336769,"Details of Article 42 Certification in the General Data Protection Regulation (GDPR): 1. The Member States, the supervisory authorities, the Board and the Commission shall encourage, in particular at Union level, the establishment of data protection certification mechanisms and of data protection seals and marks, for the purpose of demonstrating compliance with this Regulation of processing operations by controllers and processors. The specific needs of micro, small and medium-sized enterprises shall be taken into account. 2. In addition to adherence by controllers or processors subject to this Regulation, data protection certification mechanisms, seals or marks approved pursuant to paragraph 5 of this Article may be established for the purpose of demonstrating the existence of appropriate safeguards provided by controllers or processors that are not subject to this Regulation pursuant to Article 3 within the framework of personal data transfers to third countries or international organisations under the terms referred to in point (f) of Article 46(2). Such controllers or processors shall make binding and enforceable commitments, via contractual or other legally binding instruments, to apply those appropriate safeguards, including with regard to the rights of data subjects. 3. The certification shall be voluntary and available via a process that is transparent. 4. A certification pursuant to this Article does not reduce the responsibility of the controller or the processor for compliance with this Regulation and is without prejudice to the tasks and powers of the supervisory authorities which are competent pursuant to Article 55 or 56. 5. A certification pursuant to this Article shall be issued by the certification bodies referred to in Article 43 or by the competent supervisory authority, on the basis of criteria approved by that competent supervisory authority pursuant to Article 58(3) or by the Board pursuant to Article 63. Where the criteria are approved by the Board, this may result in a common certification, the European Data Protection Seal. 6. The controller or processor which submits its processing to the certification mechanism shall provide the certification body referred to in Article 43, or where applicable, the competent supervisory authority, with all information and access to its processing activities which are necessary to conduct the certification procedure. 7. Certification shall be issued to a controller or processor for a maximum period of three years and may be renewed, under the same conditions, provided that the relevant requirements continue to be met. Certification shall be withdrawn, as applicable, by the certification bodies referred to in Article 43 or by the competent supervisory authority where the requirements for the certification are not or are no longer met. 8. The Board shall collate all certification mechanisms and data protection seals and marks in a register and shall make them publicly available by any appropriate means.",article,"The General Data Protection Regulation (GDPR) has introduced Article 42 Certification. It encourages the creation of data protection certification systems, seals, and marks to demonstrate that data controllers and processors are complying with GDPR rules. This is particularly important for small and medium-sized businesses. These certifications can also show that appropriate safeguards are in place for data transfers to third countries or international organizations. The certification process is voluntary, transparent, and does not reduce the responsibility of the data controller or processor to comply with GDPR rules. Certifications are issued by approved bodies or authorities and are valid for up to three years, but can be renewed if requirements are still met. If requirements are not met, the certification can be withdrawn. All certification mechanisms and data protection seals and marks will be publicly available in a register."
Digital Services Act (DSA) - Article 72 Monitoring actions,0.722321868,"Article 72 Monitoring actions in the Digital Services Act (DSA):  1.   For the purposes of carrying out the tasks assigned to it under this Section, the Commission may take the necessary actions to monitor the effective implementation and compliance with this Regulation by providers of the very large online platform and of the very large online search engines. The Commission may order them to provide access to, and explanations relating to, its databases and algorithms. Such actions may include, imposing an obligation on the provider of the very large online platform or of the very large online search engine to retain all documents deemed to be necessary to assess the implementation of and compliance with the obligations under this Regulation.

2.   The actions pursuant to paragraph 1 may include the appointment of independent external experts and auditors, as well as experts and auditors from competent national authorities with the agreement of the authority concerned, to assist the Commission in monitoring the effective implementation and compliance with the relevant provisions of this Regulation and to provide specific expertise or knowledge to the Commission.",article,"The Digital Services Act (DSA) allows the Commission to monitor large online platforms and search engines to ensure they are following the law. The Commission can request access to their databases and algorithms, and may require them to keep certain documents. This is to check how well they are implementing and complying with the law. If necessary, the Commission can appoint independent experts and auditors, including those from national authorities, to help with this monitoring process and provide specialist knowledge."
Digital Services Act (DSA) - Article 74 Fines,0.722315609,"Article 74 Fines in the Digital Services Act (DSA):  1.   In the decision referred to in Article 73, the Commission may impose on the provider of the very large online platform or of the very large online search engine concerned fines not exceeding 6 % of its total worldwide annual turnover in the preceding financial year where it finds that the provider, intentionally or negligently:

(a) infringes the relevant provisions of this Regulation;
(b) fails to comply with a decision ordering interim measures under Article 70; or
(c) fails to comply with a commitment made binding by a decision pursuant to Article 71.

2.   The Commission may adopt a decision imposing on the provider of the very large online platform or of the very large online search engine concerned or on another natural or legal person referred to in Article 67(1) fines not exceeding 1 % of the total annual income or worldwide turnover in the preceding financial year, where they intentionally or negligently:

(a) supply incorrect, incomplete or misleading information in response to a simple request or request by a decision pursuant to Article 67;
(b) fail to reply to the request for information by decision within the set period;
(c) fail to rectify within the period set by the Commission, incorrect, incomplete or misleading information given by a member of staff, or fail or refuse to provide complete information;
(d) refuse to submit to an inspection pursuant to Article 69;
(e) fail to comply with the measures adopted by the Commission pursuant to Article 72; or
(f) fail to comply with the conditions for access to the Commission's file pursuant to Article 79(4).

3.   Before adopting the decision pursuant to paragraph 2 of this Article, the Commission shall communicate its preliminary findings to the provider of the very large online platform or of the very large online search engine concerned or to another person referred to in Article 67(1).

4.   In fixing the amount of the fine, the Commission shall have regard to the nature, gravity, duration and recurrence of the infringement and, for fines imposed pursuant to paragraph 2, the delay caused to the proceedings.",article,"The Digital Services Act (DSA) allows the Commission to impose fines on large online platforms or search engines. If these providers intentionally or negligently violate the DSA, fail to comply with interim measures, or break a binding commitment, they could be fined up to 6% of their previous year's global turnover. They could also be fined up to 1% of their annual income or global turnover if they provide incorrect or misleading information, fail to respond to an information request, refuse an inspection, or fail to comply with Commission measures or conditions for file access. Before a fine is imposed, the Commission will communicate its preliminary findings to the provider. The fine amount will consider the nature, severity, duration, and recurrence of the violation, and any delay caused to proceedings."
General Data Protection Regulation (GDPR) - Contextual Paragraph (89),0.722190499,"Details of the Contextual Paragraph (89) in the General Data Protection Regulation (GDPR): Directive 95/46/EC provided for a general obligation to notify the processing of personal data to the supervisory authorities. While that obligation produces administrative and financial burdens, it did not in all cases contribute to improving the protection of personal data. Such indiscriminate general notification obligations should therefore be abolished, and replaced by effective procedures and mechanisms which focus instead on those types of processing operations which are likely to result in a high risk to the rights and freedoms of natural persons by virtue of their nature, scope, context and purposes. Such types of processing operations may be those which in, particular, involve using new technologies, or are of a new kind and where no data protection impact assessment has been carried out before by the controller, or where they become necessary in the light of the time that has elapsed since the initial processing.",recital,"The General Data Protection Regulation (GDPR) has updated a previous law (Directive 95/46/EC) which required all personal data processing to be reported to supervisory authorities. This old rule was seen as burdensome and not always effective in protecting personal data. The new law removes this general requirement and instead focuses on activities that have a high risk of violating individuals' rights and freedoms. These high-risk activities often involve new technologies or new types of data processing, especially when no previous data protection assessment has been done, or when a significant amount of time has passed since the initial data processing."
Digital Markets Act (DMA) - Contextual Paragraph (12),0.722187698,"Details of the Contextual Paragraph (12) in the Digital Markets Act (DMA): This Regulation should also apply without prejudice to the rules resulting from other acts of Union law regulating certain aspects of the provision of services covered by this Regulation, in particular Regulations (EU) 2016/679 ( 4 ) and (EU) 2019/1150 ( 5 ) of the European Parliament and of the Council and a Regulation on a single market for digital services, and Directives 2002/58/EC ( 6 ), 2005/29/EC ( 7 ), 2010/13/EU ( 8 ), (EU) 2015/2366 ( 9 ), (EU) 2019/790 ( 10) and (EU) 2019/882 ( 11) of the European Parliament and of the Council, and Council Directive 93/13/EEC ( 12), as well as national rules aimed at enforcing or implementing those Union legal acts.",rectial,"The Digital Markets Act (DMA) is a new law that applies to the provision of certain digital services. However, it doesn't override existing regulations from the European Union (EU) that also govern these services. These include Regulations (EU) 2016/679 and (EU) 2019/1150, a Regulation on a single market for digital services, and several Directives from the European Parliament and the Council. The DMA also doesn't affect national laws that enforce or implement these EU legal acts."
Digital Markets Act (DMA) - Contextual Paragraph (82),0.722156,"Details of the Contextual Paragraph (82) in the Digital Markets Act (DMA): The Commission should be able to directly request that undertakings or associations of undertakings provide any relevant evidence, data and information. In addition, the Commission should be able to request any relevant information from competent authorities within the Member State, or from any natural person or legal person for the purpose of this Regulation. When complying with a decision of the Commission, undertakings are obliged to answer factual questions and to provide documents.",rectial,"The Digital Markets Act (DMA) allows the Commission to directly ask businesses or business groups for any necessary evidence, data, or information. The Commission can also request relevant information from authorities within the Member State, or from any individual or legal entity for the purposes of this law. Businesses must answer factual questions and provide documents when complying with a Commission decision."
Digital Services Act (DSA) - Definition of 'trader',0.722154,"Definition of 'trader' in the Digital Services Act (DSA): any natural person, or any legal person irrespective of whether it is privately or publicly owned, who is acting, including through any person acting in his or her name or on his or her behalf, for purposes relating to his or her trade, business, craft or profession.",recital,"The Digital Services Act (DSA) defines a 'trader' as any individual or organization, regardless of whether it's privately or publicly owned, who is involved in activities related to their trade, business, craft, or profession. This includes anyone acting on their behalf or in their name."
Artifical Inellegence Act (AI Act) - Article 52,0.722129464,"Aritifical Intelligence Act (AI Act) Article 52 Transparency obligations for certain AI systems:

1.Providers shall ensure that AI systems intended to interact with natural persons are designed and developed in such a way that natural persons are informed that they are interacting with an AI system, unless this is obvious from the circumstances and the context of use. This obligation shall not apply to AI systems authorised by law to detect, prevent, investigate and prosecute criminal offences, unless those systems are available for the public to report a criminal offence.

2.Users of an emotion recognition system or a biometric categorisation system shall inform of the operation of the system the natural persons exposed thereto. This obligation shall not apply to AI systems used for biometric categorisation, which are permitted by law to detect, prevent and investigate criminal offences.

3.Users of an AI system that generates or manipulates image, audio or video content that appreciably resembles existing persons, objects, places or other entities or events and would falsely appear to a person to be authentic or truthful (deep fake), shall disclose that the content has been artificially generated or manipulated.

However, the first subparagraph shall not apply where the use is authorised by law to detect, prevent, investigate and prosecute criminal offences or it is necessary for the exercise of the right to freedom of expression and the right to freedom of the arts and sciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to appropriate safeguards for the rights and freedoms of third parties.

4.Paragraphs 1, 2 and 3 shall not affect the requirements and obligations set out in Title III of this Regulation.",article,"The Artificial Intelligence Act (AI Act) requires providers of AI systems to inform users when they are interacting with an AI, unless it's clear from the context or the AI is being used for legal criminal investigations. This also applies to users of emotion recognition or biometric systems, and to AI systems that create or alter images, audio, or video to resemble real things or events (known as 'deep fakes'). However, these rules don't apply when the AI is used for legal reasons, freedom of expression, or artistic and scientific purposes, provided it doesn't infringe on others' rights. These requirements don't affect any obligations in Title III of the AI Act."
General Data Protection Regulation (GDPR) - Definition of representative,0.722060263,"Details of the Definition of representative in the General Data Protection Regulation (GDPR): ""representative"" means a natural or legal person established in the Union who, designated by the controller or processor in writing pursuant to Article 27, represents the controller or processor with regard to their respective obligations under this Regulation;",recital,"The General Data Protection Regulation (GDPR) has a new definition for ""representative"". This refers to an individual or a company based in the European Union (EU) who is officially appointed in writing by a data controller or processor. The representative's role is to act on behalf of the data controller or processor, helping them fulfill their responsibilities under the GDPR."
Digital Services Act (DSA) - Contextual paragraph (71),0.722032666,"Details of the contextual paragraph (71) of the Digital Services Act (DSA): The protection of minors is an important policy objective of the Union. An online platform can be considered to be accessible to minors when its terms and conditions permit minors to use the service, when its service is directed at or predominantly used by minors, or where the provider is otherwise aware that some of the recipients of its service are minors, for example because it already processes personal data of the recipients of its service revealing their age for other purposes. Providers of online platforms used by minors should take appropriate and proportionate measures to protect minors, for example by designing their online interfaces or parts thereof with the highest level of privacy, safety and security for minors by default where appropriate or adopting standards for protection of minors, or participating in codes of conduct for protecting minors. They should consider best practices and available guidance, such as that provided by the communication of the Commission on A Digital Decade for children and youth: the new European strategy for a better internet for kids (BIK+). Providers of online platforms should not present advertisements based on profiling using personal data of the recipient of the service when they are aware with reasonable certainty that the recipient of the service is a minor. In accordance with Regulation (EU) 2016/679, notably the principle of data minimisation as provided for in Article 5(1), point (c), thereof, this prohibition should not lead the provider of the online platform to maintain, acquire or process more personal data than it already has in order to assess if the recipient of the service is a minor. Thus, this obligation should not incentivize providers of online platforms to collect the age of the recipient of the service prior to their use. It should be without prejudice to Union law on protection of personal data.",recital,"The Digital Services Act (DSA) aims to protect minors using online platforms. If a platform's terms and conditions allow minors to use the service, or if it's predominantly used by or directed at minors, the platform must take measures to protect them. This could include designing interfaces with high levels of privacy, safety, and security for minors, or adopting standards for their protection. The law also discourages platforms from displaying ads based on personal data profiling if the user is likely a minor. However, this should not encourage platforms to collect more personal data than necessary, including the user's age. This law supports the principle of data minimisation and respects existing Union laws on personal data protection."
Digital Services Act (DSA) - Contextual paragraph (37),0.722028315,"Details of the contextual paragraph (37) of the Digital Services Act (DSA): The orders to provide information regulated by this Regulation concern the production of specific information about individual recipients of the intermediary service concerned who are identified in those orders for the purposes of determining compliance by the recipients of the service with applicable Union or national rules. Such orders should request information with the aim of enabling the identification of the recipients of the service concerned. Therefore, orders regarding information on a group of recipients of the service who are not specifically identified, including orders to provide aggregate information required for statistical purposes or evidence-based policy-making, are not covered by the requirements of this Regulation on the provision of information.",recital,"The Digital Services Act (DSA) states that companies providing intermediary services must provide specific information about individual users if ordered to do so. This is to ensure these users are following the relevant EU or national rules. The orders can ask for information that helps identify these users. However, the DSA does not require companies to provide information about groups of users who are not specifically identified, such as for statistical or policy-making purposes."
General Data Protection Regulation (GDPR) - Article 9 Processing of special categories of personal data,0.722026587,"Details of Article 9 Processing of special categories of personal data in the General Data Protection Regulation (GDPR): 1. Processing of personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union membership, and the processing of genetic data, biometric data for the purpose of uniquely identifying a natural person, data concerning health or data concerning a natural person's sex life or sexual orientation shall be prohibited. 2. Paragraph 1 shall not apply if one of the following applies: (a) the data subject has given explicit consent to the processing of those personal data for one or more specified purposes, except where Union or Member State law provide that the prohibition referred to in paragraph 1 may not be lifted by the data subject; (b) processing is necessary for the purposes of carrying out the obligations and exercising specific rights of the controller or of the data subject in the field of employment and social security and social protection law in so far as it is authorised by Union or Member State law or a collective agreement pursuant to Member State law providing for appropriate safeguards for the fundamental rights and the interests of the data subject; (c) processing is necessary to protect the vital interests of the data subject or of another natural person where the data subject is physically or legally incapable of giving consent; (d) processing is carried out in the course of its legitimate activities with appropriate safeguards by a foundation, association or any other not-for-profit body with a political, philosophical, religious or trade union aim and on condition that the processing relates solely to the members or to former members of the body or to persons who have regular contact with it in connection with its purposes and that the personal data are not disclosed outside that body without the consent of the data subjects; (e) processing relates to personal data which are manifestly made public by the data subject; (f) processing is necessary for the establishment, exercise or defence of legal claims or whenever courts are acting in their judicial capacity; (g) processing is necessary for reasons of substantial public interest, on the basis of Union or Member State law which shall be proportionate to the aim pursued, respect the essence of the right to data protection and provide for suitable and specific measures to safeguard the fundamental rights and the interests of the data subject; (h) processing is necessary for the purposes of preventive or occupational medicine, for the assessment of the working capacity of the employee, medical diagnosis, the provision of health or social care or treatment or the management of health or social care systems and services on the basis of Union or Member State law or pursuant to contract with a health professional and subject to the conditions and safeguards referred to in paragraph 3; (i) processing is necessary for reasons of public interest in the area of public health, such as protecting against serious cross-border threats to health or ensuring high standards of quality and safety of health care and of medicinal products or medical devices, on the basis of Union or Member State law which provides for suitable and specific measures to safeguard the rights and freedoms of the data subject, in particular professional secrecy; (j) processing is necessary for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes in accordance with Article 89(1) based on Union or Member State law which shall be proportionate to the aim pursued, respect the essence of the right to data protection and provide for suitable and specific measures to safeguard the fundamental rights and the interests of the data subject. 3. Personal data referred to in paragraph 1 may be processed for the purposes referred to in point (h) of paragraph 2 when those data are processed by or under the responsibility of a professional subject to the obligation of professional secrecy under Union or Member State law or rules established by national competent bodies or by another person also subject to an obligation of secrecy under Union or Member State law or rules established by national competent bodies. 4. Member States may maintain or introduce further conditions, including limitations, with regard to the processing of genetic data, biometric data or data concerning health.",article,"The General Data Protection Regulation (GDPR) Article 9 restricts the processing of sensitive personal data such as racial or ethnic origin, political opinions, religious beliefs, trade union membership, genetic and biometric data, health data, and data about a person's sex life or sexual orientation. However, there are exceptions to this rule. For instance, if the person has given clear consent, or if the processing is necessary for legal, employment, social security, or health reasons, among others. The law also allows for the processing of this data for public interest, scientific research, or statistical purposes under certain conditions. Member states can also introduce further conditions or limitations for processing genetic, biometric, or health data."
Digital Services Act (DSA) - Article 14 Terms and conditions in the Digital Services Act (DSA),0.721987903,"Article 14 Terms and conditions in the Digital Services Act (DSA):  1.   Providers of intermediary services shall include information on any restrictions that they impose in relation to the use of their service in respect of information provided by the recipients of the service, in their terms and conditions. That information shall include information on any policies, procedures, measures and tools used for the purpose of content moderation, including algorithmic decision-making and human review, as well as the rules of procedure of their internal complaint handling system. It shall be set out in clear, plain, intelligible, user-friendly and unambiguous language, and shall be publicly available in an easily accessible and machine-readable format.
2.   Providers of intermediary services shall inform the recipients of the service of any significant change to the terms and conditions.
3.   Where an intermediary service is primarily directed at minors or is predominantly used by them, the provider of that intermediary service shall explain the conditions for, and any restrictions on, the use of the service in a way that minors can understand.
4.   Providers of intermediary services shall act in a diligent, objective and proportionate manner in applying and enforcing the restrictions referred to in paragraph 1, with due regard to the rights and legitimate interests of all parties involved, including the fundamental rights of the recipients of the service, such as the freedom of expression, freedom and pluralism of the media, and other fundamental rights and freedoms as enshrined in the Charter.
5.   Providers of very large online platforms and of very large online search engines shall provide recipients of services with a concise, easily-accessible and machine-readable summary of the terms and conditions, including the available remedies and redress mechanisms, in clear and unambiguous language.
6.   Very large online platforms and very large online search engines within the meaning of Article 33 shall publish their terms and conditions in the official languages of all the Member States in which they offer their services.",article,"The Digital Services Act (DSA) requires providers of digital services to clearly explain any restrictions on the use of their service, including content moderation policies and complaint handling systems, in their terms and conditions. These must be easy to understand and publicly available. If the service is mostly used by minors, the terms must be explained in a way they can understand. Providers must also inform users of any significant changes to these terms. The DSA also mandates that providers apply these rules fairly and respect users' rights, including freedom of expression. Large online platforms and search engines must provide a concise summary of their terms and conditions, including how to seek remedies or redress. They must also publish their terms in the official languages of all the countries where they offer their services."
Digital Markets Act (DMA) - Definition of video-sharing platform service,0.721957743,"Details of the Definition of video-sharing platform service in the Digital Markets Act (DMA): ""video-sharing platform service"" means a video-sharing platform service as defined in Article 1(1), point (aa), of Directive 2010/13/EU;",rectial,"The Digital Markets Act (DMA) has a new definition for ""video-sharing platform service."" This term refers to any service that allows users to share videos, as outlined in Article 1(1), point (aa), of Directive 2010/13/EU. This new law simply clarifies what is meant by a video-sharing platform within the context of the DMA."
General Data Protection Regulation (GDPR) - Contextual Paragraph (44),0.721951067,Details of the Contextual Paragraph (44) in the General Data Protection Regulation (GDPR): Processing should be lawful where it is necessary in the context of a contract or the intention to enter into a contract.,recital,"The General Data Protection Regulation (GDPR) has a rule (Paragraph 44) that says it is legal to process personal data if it is needed for a contract or if there is an intention to create a contract. This means that a company can use your personal information if it's necessary to fulfill a contract you have with them, or if you're planning to enter into a contract with them."
Digital Services Act (DSA) - Article 93 Entry into force and application,0.721922755,"Article 93 Entry into force and application in the Digital Services Act (DSA):  1.   This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union.

2.   This Regulation shall apply from 17 February 2024.

However, Article 24(2), (3) and (6), Article 33(3) to (6), Article 37(7), Article 40(13), Article 43 and Sections 4, 5 and 6 of Chapter IV shall apply from 16 November 2022.

This Regulation shall be binding in its entirety and directly applicable in all Member States.

Done at Strasbourg, 19 October 2022.",article,"The Digital Services Act (DSA) is a new law that will officially start on the 20th day after it's published in the Official Journal of the European Union. The law will be in full effect from February 17, 2024. However, certain parts of the law, specifically Article 24(2), (3) and (6), Article 33(3) to (6), Article 37(7), Article 40(13), Article 43 and Sections 4, 5 and 6 of Chapter IV, will start earlier, on November 16, 2022. This law applies to all member states of the European Union."
Artifical Inellegence Act (AI Act) - Article 25,0.721912,"Aritifical Intelligence Act (AI Act) Article 25 Authorised representatives:
1.Prior to making their systems available on the Union market, where an importer cannot be identified, providers established outside the Union shall, by written mandate, appoint an authorised representative which is established in the Union.

2.The authorised representative shall perform the tasks specified in the mandate received from the provider. The mandate shall empower the authorised representative to carry out the following tasks:

(a)keep a copy of the EU declaration of conformity and the technical documentation at the disposal of the national competent authorities and national authorities referred to in Article 63(7);

(b)provide a national competent authority, upon a reasoned request, with all the information and documentation necessary to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law;

(c)cooperate with competent national authorities, upon a reasoned request, on any action the latter takes in relation to the high-risk AI system.",article,"The Artificial Intelligence Act (AI Act) requires that any AI system providers based outside the EU must appoint a representative within the EU before they can offer their systems in the Union market. This representative, appointed through a written mandate, is responsible for keeping a copy of the EU declaration of conformity and the technical documentation for national authorities. They must also provide any information and documentation needed to prove that a high-risk AI system meets the requirements of the AI Act. This includes access to automatically generated logs if they are under the provider's control. The representative must also cooperate with national authorities regarding any actions related to the high-risk AI system."
General Data Protection Regulation (GDPR) - Article 41 Monitoring of approved codes of conduct,0.721870959,"Details of Article 41 Monitoring of approved codes of conduct in the General Data Protection Regulation (GDPR): 1. Without prejudice to the tasks and powers of the competent supervisory authority under Articles 57 and 58, the monitoring of compliance with a code of conduct pursuant to Article 40 may be carried out by a body which has an appropriate level of expertise in relation to the subject-matter of the code and is accredited for that purpose by the competent supervisory authority. 2. A body as referred to in paragraph 1 may be accredited to monitor compliance with a code of conduct where that body has: (a) demonstrated its independence and expertise in relation to the subject-matter of the code to the satisfaction of the competent supervisory authority; (b) established procedures which allow it to assess the eligibility of controllers and processors concerned to apply the code, to monitor their compliance with its provisions and to periodically review its operation; (c) established procedures and structures to handle complaints about infringements of the code or the manner in which the code has been, or is being, implemented by a controller or processor, and to make those procedures and structures transparent to data subjects and the public; and (d) demonstrated to the satisfaction of the competent supervisory authority that its tasks and duties do not result in a conflict of interests. 3. The competent supervisory authority shall submit the draft criteria for accreditation of a body as referred to in paragraph 1 of this Article to the Board pursuant to the consistency mechanism referred to in Article 63. 4. Without prejudice to the tasks and powers of the competent supervisory authority and the provisions of Chapter VIII, a body as referred to in paragraph 1 of this Article shall, subject to appropriate safeguards, take appropriate action in cases of infringement of the code by a controller or processor, including suspension or exclusion of the controller or processor concerned from the code. It shall inform the competent supervisory authority of such actions and the reasons for taking them. 5. The competent supervisory authority shall revoke the accreditation of a body as referred to in paragraph 1 if the conditions for accreditation are not, or are no longer, met or where actions taken by the body infringe this Regulation. 6. This Article shall not apply to processing carried out by public authorities and bodies.",article,"Article 41 of the General Data Protection Regulation (GDPR) allows for an independent body with relevant expertise to monitor adherence to approved codes of conduct. This body must prove its independence and expertise, have procedures to evaluate and monitor compliance, handle complaints transparently, and ensure no conflict of interest. It can take action against those who violate the code, including suspension or exclusion, and must report such actions to the supervisory authority. If the body fails to meet accreditation conditions or violates the regulation, its accreditation can be revoked. This article doesn't apply to public authorities and bodies."
Digital Services Act (DSA) - Contextual paragraph (103),0.721849501,"Details of the contextual paragraph (103) of the Digital Services Act (DSA): The Commission and the Board should encourage the drawing-up of voluntary codes of conduct, as well as the implementation of the provisions of those codes in order to contribute to the application of this Regulation. The Commission and the Board should aim that the codes of conduct clearly define the nature of the public interest objectives being addressed, that they contain mechanisms for independent evaluation of the achievement of those objectives and that the role of relevant authorities is clearly defined. Particular attention should be given to avoiding negative effects on security, the protection of privacy and personal data, as well as to the prohibition on imposing general monitoring obligations. While the implementation of codes of conduct should be measurable and subject to public oversight, this should not impair the voluntary nature of such codes and the freedom of interested parties to decide whether to participate. In certain circumstances, it is important that very large online platforms cooperate in the drawing-up and adhere to specific codes of conduct. Nothing in this Regulation prevents other service providers from adhering to the same standards of due diligence, adopting best practices and benefitting from the guidelines provided by the Commission and the Board, by participating in the same codes of conduct.",recital,"The Digital Services Act (DSA) encourages the creation of voluntary codes of conduct to help implement its regulations. These codes should clearly state their public interest goals, have independent evaluation mechanisms, and clearly define the role of relevant authorities. They should also ensure security, privacy, and personal data protection, and avoid imposing general monitoring obligations. The effectiveness of these codes should be measurable and open to public scrutiny, while maintaining their voluntary nature. Large online platforms are particularly encouraged to create and follow these codes. Other service providers are also free to follow these standards and benefit from the guidelines provided by the Commission and the Board."
Digital Markets Act (DMA) - Contextual Paragraph (7),0.721839249,"Details of the Contextual Paragraph (7) in the Digital Markets Act (DMA): Therefore, the purpose of this Regulation is to contribute to the proper functioning of the internal market by laying down rules to ensure contestability and fairness for the markets in the digital sector in general, and for business users and end users of core platform services provided by gatekeepers in particular. Business users and end users of core platform services provided by gatekeepers should be afforded appropriate regulatory safeguards throughout the Union against the unfair practices of gatekeepers, in order to facilitate cross-border business within the Union and thereby improve the proper functioning of the internal market, and to eliminate existing or likely emerging fragmentation in the specific areas covered by this Regulation. Moreover, while gatekeepers tend to adopt global or at least pan-European business models and algorithmic structures, they can adopt, and in some cases have adopted, different business conditions and practices in different Member States, which is liable to create disparities between the competitive conditions for the users of core platform services provided by gatekeepers, to the detriment of integration of the internal market.",rectial,"The Digital Markets Act (DMA) aims to ensure fair competition in the digital sector, especially for businesses and users of major online platforms (referred to as 'gatekeepers'). The law provides protections against unfair practices by these gatekeepers, facilitating cross-border business within the European Union and improving the functioning of the internal market. The DMA also addresses the issue of gatekeepers using different business conditions in different countries, which can create competitive disparities and hinder market integration."
Digital Services Act (DSA) - Article 40 Data access and scrutiny,0.72183311,"Article 40 Data access and scrutiny in paragraphs 1 - 7 in the Digital Services Act (DSA):  1.   Providers of very large online platforms or of very large online search engines shall provide the Digital Services Coordinator of establishment or the Commission, at their reasoned request and within a reasonable period specified in that request, access to data that are necessary to monitor and assess compliance with this Regulation.

2.   Digital Services Coordinators and the Commission shall use the data accessed pursuant to paragraph 1 only for the purpose of monitoring and assessing compliance with this Regulation and shall take due account of the rights and interests of the providers of very large online platforms or of very large online search engines and the recipients of the service concerned, including the protection of personal data, the protection of confidential information, in particular trade secrets, and maintaining the security of their service.

3.   For the purposes of paragraph 1, providers of very large online platforms or of very large online search engines shall, at the request of either the Digital Service Coordinator of establishment or of the Commission, explain the design, the logic, the functioning and the testing of their algorithmic systems, including their recommender systems.

4.   Upon a reasoned request from the Digital Services Coordinator of establishment, providers of very large online platforms or of very large online search engines shall, within a reasonable period, as specified in the request, provide access to data to vetted researchers who meet the requirements in paragraph 8 of this Article, for the sole purpose of conducting research that contributes to the detection, identification and understanding of systemic risks in the Union, as set out pursuant to Article 34(1), and to the assessment of the adequacy, efficiency and impacts of the risk mitigation measures pursuant to Article 35.

5.   Within 15 days following receipt of a request as referred to in paragraph 4, providers of very large online platforms or of very large online search engines may request the Digital Services Coordinator of establishment, to amend the request, where they consider that they are unable to give access to the data requested because one of following two reasons:

(a) they do not have access to the data;
(b) giving access to the data will lead to significant vulnerabilities in the security of their service or the protection of confidential information, in particular trade secrets.

6.   Requests for amendment pursuant to paragraph 5 shall contain proposals for one or more alternative means through which access may be provided to the requested data or other data which are appropriate and sufficient for the purpose of the request.

The Digital Services Coordinator of establishment shall decide on the request for amendment within 15 days and communicate to the provider of the very large online platform or of the very large online search engine its decision and, where relevant, the amended request and the new period to comply with the request.

7.   Providers of very large online platforms or of very large online search engines shall facilitate and provide access to data pursuant to paragraphs 1 and 4 through appropriate interfaces specified in the request, including online databases or application programming interfaces.

8.   Upon a duly substantiated application from researchers, the Digital Services Coordinator of establishment shall grant such researchers the status of 'vetted researchers' for the specific research referred to in the application and issue a reasoned request for data access to a provider of very large online platform or of very large online search engine a pursuant to paragraph 4, where the researchers demonstrate that they meet all of the following conditions:

(a) they are affiliated to a research organisation as defined in Article 2, point (1), of Directive (EU) 2019/790;
(b) they are independent from commercial interests;
(c) their application discloses the funding of the research;
(d) they are capable of fulfilling the specific data security and confidentiality requirements corresponding to each request and to protect personal data, and they describe in their request the appropriate technical and organisational measures that they have put in place to this end;
(e) their application demonstrates that their access to the data and the time frames requested are necessary for, and proportionate to, the purposes of their research, and that the expected results of that research will contribute to the purposes laid down in paragraph 4;
(f) the planned research activities will be carried out for the purposes laid down in paragraph 4;
(g) they have committed themselves to making their research results publicly available free of charge, within a reasonable period after the completion of the research, subject to the rights and interests of the recipients of the service concerned, in accordance with Regulation (EU) 2016/679.

Upon receipt of the application pursuant to this paragraph, the Digital Services Coordinator of establishment shall inform the Commission and the Board.

9.   Researchers may also submit their application to the Digital Services Coordinator of the Member State of the research organisation to which they are affiliated. Upon receipt of the application pursuant to this paragraph the Digital Services Coordinator shall conduct an initial assessment as to whether the respective researchers meet all of the conditions set out in paragraph 8. The respective Digital Services Coordinator shall subsequently send the application, together with the supporting documents submitted by the respective researchers and the initial assessment, to the Digital Services Coordinator of establishment. The Digital Services Coordinator of establishment shall take a decision whether to award a researcher the status of 'vetted researcher' without undue delay.

While taking due account of the initial assessment provided, the final decision to award a researcher the status of 'vetted researcher' lies within the competence of Digital Services Coordinator of establishment, pursuant to paragraph 8.

10.   The Digital Services Coordinator that awarded the status of vetted researcher and issued the reasoned request for data access to the providers of very large online platforms or of very large online search engines in favour of a vetted researcher shall issue a decision terminating the access if it determines, following an investigation either on its own initiative or on the basis of information received from third parties, that the vetted researcher no longer meets the conditions set out in paragraph 8, and shall inform the provider of the very large online platform or of the very large online search engine concerned of the decision. Before terminating the access, the Digital Services Coordinator shall allow the vetted researcher to react to the findings of its investigation and to its intention to terminate the access.

11.   Digital Services Coordinators of establishment shall communicate to the Board the names and contact information of the natural persons or entities to which they have awarded the status of 'vetted researcher' in accordance with paragraph 8, as well as the purpose of the research in respect of which the application was made or, where they have terminated the access to the data in accordance with paragraph 10, communicate that information to the Board.

12.   Providers of very large online platforms or of very large online search engines shall give access without undue delay to data, including, where technically possible, to real-time data, provided that the data is publicly accessible in their online interface by researchers, including those affiliated to not for profit bodies, organisations and associations, who comply with the conditions set out in paragraph 8, points (b), (c), (d) and (e), and who use the data solely for performing research that contributes to the detection, identification and understanding of systemic risks in the Union pursuant to Article 34(1).

13.   The Commission shall, after consulting the Board, adopt delegated acts supplementing this Regulation by laying down the technical conditions under which providers of very large online platforms or of very large online search engines are to share data pursuant to paragraphs 1 and 4 and the purposes for which the data may be used. Those delegated acts shall lay down the specific conditions under which such sharing of data with researchers can take place in compliance with Regulation (EU) 2016/679, as well as relevant objective indicators, procedures and, where necessary, independent advisory mechanisms in support of sharing of data, taking into account the rights and interests of the providers of very large online platforms or of very large online search engines and the recipients of the service concerned, including the protection of confidential information, in particular trade secrets, and maintaining the security of their service.",article,"The Digital Services Act (DSA) requires large online platforms and search engines to provide data access to the Digital Services Coordinator or the Commission for monitoring and assessing compliance with the regulation. This data will also be used to understand their algorithmic systems. These platforms may also need to provide data to approved researchers for research purposes. If the platforms cannot provide the requested data due to lack of access or security concerns, they can propose alternative means of providing necessary data. Researchers seeking data access must meet certain conditions, including affiliation to a research organization, independence from commercial interests, and ability to protect data security and confidentiality. The DSA also allows for the termination of data access if a researcher no longer meets these conditions. The Commission will set the technical conditions for data sharing and its purposes."
Artifical Inellegence Act (AI Act) - Overview paragraph 36,0.721827865,"Aritifical Intelligence Act (AI Act) overview paragraph (36): AI systems used in employment, workers management and access to self-employment, notably for the recruitment and selection of persons, for making decisions on promotion and termination and for task allocation, monitoring or evaluation of persons in work-related contractual relationships, should also be classified as high-risk, since those systems may appreciably impact future career prospects and livelihoods of these persons. Relevant work-related contractual relationships should involve employees and persons providing services through platforms as referred to in the Commission Work Programme 2021. Such persons should in principle not be considered users within the meaning of this Regulation. Throughout the recruitment process and in theevaluation, promotion, or retention of persons in work-related contractual relationships, such systems may perpetuate historical patterns of discrimination, for example against women, certain age groups, persons with disabilities, or persons of certain racial or ethnic origins or sexual orientation. AI systems used to monitor the performance and behaviour of these persons may also impact their rights to data protection and privacy.",recital,"The Artificial Intelligence Act (AI Act) states that AI systems used in employment processes, such as recruitment, promotion, termination, and task allocation, should be considered high-risk. This is because these systems can significantly affect a person's career and livelihood, and may unintentionally perpetuate historical patterns of discrimination. This applies to both employees and people who provide services through platforms. These individuals are not considered users under this regulation. The Act also suggests that AI systems used to monitor an employee's performance and behavior could potentially infringe on their data protection and privacy rights."
General Data Protection Regulation (GDPR) - Article 66 Urgency procedure,0.721821547,"Details of Article 66 Urgency procedure in the General Data Protection Regulation (GDPR): 1. In exceptional circumstances, where a supervisory authority concerned considers that there is an urgent need to act in order to protect the rights and freedoms of data subjects, it may, by way of derogation from the consistency mechanism referred to in Articles 63, 64 and 65 or the procedure referred to in Article 60, immediately adopt provisional measures intended to produce legal effects on its own territory with a specified period of validity which shall not exceed three months. The supervisory authority shall, without delay, communicate those measures and the reasons for adopting them to the other supervisory authorities concerned, to the Board and to the Commission. 2. Where a supervisory authority has taken a measure pursuant to paragraph 1 and considers that final measures need urgently be adopted, it may request an urgent opinion or an urgent binding decision from the Board, giving reasons for requesting such opinion or decision. 3. Any supervisory authority may request an urgent opinion or an urgent binding decision, as the case may be, from the Board where a competent supervisory authority has not taken an appropriate measure in a situation where there is an urgent need to act, in order to protect the rights and freedoms of data subjects, giving reasons for requesting such opinion or decision, including for the urgent need to act. 4. By derogation from Article 64(3) and Article 65(2), an urgent opinion or an urgent binding decision referred to in paragraphs 2 and 3 of this Article shall be adopted within two weeks by simple majority of the members of the Board.",article,"Article 66 of the General Data Protection Regulation (GDPR) allows a supervisory authority to take immediate, temporary measures to protect data subjects' rights and freedoms in urgent situations. These measures, which can last up to three months, bypass the usual procedures laid out in Articles 60, 63, 64, and 65. The supervisory authority must promptly inform other relevant authorities, the Board, and the Commission about these measures and the reasons for them. If the authority believes that permanent measures are urgently needed, it can request an urgent opinion or decision from the Board. If a supervisory authority fails to act in an urgent situation, any other authority can request an urgent opinion or decision from the Board. These urgent opinions or decisions must be made within two weeks by a simple majority of the Board's members."
Artifical Inellegence Act (AI Act) - Definition of 'importer',0.721821427,"Within the Aritifical Intelligence Act (AI Act), the Definition of importer means any natural or legal person established in the Union that places on the market or puts into service an AI system that bears the name or trademark of a natural or legal person established outside the Union;",recital,The Artificial Intelligence Act (AI Act) defines an 'importer' as any individual or company based within the Union (EU) who introduces an AI system to the market or uses it in their services. This AI system must be branded with the name or trademark of an individual or company that is based outside of the Union.
Artifical Inellegence Act (AI Act) - Context Section 2.2,0.721818626,"Aritifical Intelligence Act (AI Act) context section 2.2.Subsidiarity (for non-exclusive competence): 

The nature of AI, which often relies on large and varied datasets and which may be embedded in any product or service circulating freely within the internal market, entails that the objectives of this proposal cannot be effectively achieved by Member States alone. Furthermore, an emerging patchwork of potentially divergent national rules will hamper the seamless circulation of products and services related to AI systems across the EU and will be ineffective in ensuring the safety and protection of fundamental rights and Union values across the different Member States. National approaches in addressing the problems will only create additional legal uncertainty and barriers, and will slow market uptake of AI.

The objectives of this proposal can be better achieved at Union level to avoid a further fragmentation of the Single Market into potentially contradictory national frameworks preventing the free circulation of goods and services embedding AI. A solid European regulatory framework for trustworthy AI will also ensure a level playing field and protect all people, while strengthening Europes competitiveness and industrial basis in AI. Only common action at Union level can also protect the Unions digital sovereignty and leverage its tools and regulatory powers to shape global rules and standards.2.2.Subsidiarity (for non-exclusive competence):

The nature of AI, which often relies on large and varied datasets and which may be embedded in any product or service circulating freely within the internal market, entails that the objectives of this proposal cannot be effectively achieved by Member States alone. Furthermore, an emerging patchwork of potentially divergent national rules will hamper the seamless circulation of products and services related to AI systems across the EU and will be ineffective in ensuring the safety and protection of fundamental rights and Union values across the different Member States. National approaches in addressing the problems will only create additional legal uncertainty and barriers, and will slow market uptake of AI.

The objectives of this proposal can be better achieved at Union level to avoid a further fragmentation of the Single Market into potentially contradictory national frameworks preventing the free circulation of goods and services embedding AI. A solid European regulatory framework for trustworthy AI will also ensure a level playing field and protect all people, while strengthening Europes competitiveness and industrial basis in AI. Only common action at Union level can also protect the Unions digital sovereignty and leverage its tools and regulatory powers to shape global rules and standards.",recital,"The Artificial Intelligence Act (AI Act) suggests that individual member states cannot effectively regulate AI due to its complexity and widespread use. It warns that different national rules could disrupt the smooth operation of AI-related products and services across the EU. This could also jeopardize safety, fundamental rights, and EU values. The Act proposes a unified approach at the Union level to prevent fragmentation and inconsistencies in the Single Market. A robust European regulatory framework for AI is necessary to ensure fairness, protect all individuals, and boost Europe's competitiveness in AI. The Act emphasizes that only joint action at the Union level can safeguard the EU's digital sovereignty and influence global AI rules and standards."
General Data Protection Regulation (GDPR) - Contextual Paragraph (38),0.721792221,"Details of the Contextual Paragraph (38) in the General Data Protection Regulation (GDPR): Children merit specific protection with regard to their personal data, as they may be less aware of the risks, consequences and safeguards concerned and their rights in relation to the processing of personal data. Such specific protection should, in particular, apply to the use of personal data of children for the purposes of marketing or creating personality or user profiles and the collection of personal data with regard to children when using services offered directly to a child. The consent of the holder of parental responsibility should not be necessary in the context of preventive or counselling services offered directly to a child.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph 38, specifically for protecting children's personal data. This is because children might not fully understand the risks and rights associated with their data. The law particularly focuses on preventing the misuse of children's data for marketing, creating personality or user profiles, and when services are directly offered to a child. However, if the services offered to a child are for prevention or counseling purposes, parental consent is not required."
Digital Services Act (DSA) - Definition of 'recipient of the service',0.721776247,"Definition of 'recipient of the service' in the Digital Services Act (DSA): any natural or legal person who uses an intermediary service, in particular for the purposes of seeking information or making it accessible.",recital,"The Digital Services Act (DSA) introduces a term called 'recipient of the service'. This refers to any individual or organization that uses a middleman service. This could be for the purpose of finding information or making it available. In simpler terms, if you're using a service to either get or share information, you are considered a 'recipient of the service' under this law."
Artifical Inellegence Act (AI Act) - Definition of 'withdrawal of an AI system',0.721773326,"Within the Aritifical Intelligence Act (AI Act), the Definition of withdrawal of an AI system means any measure aimed at preventing the distribution, display and offer of an AI system;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'withdrawal of an AI system'. This means taking steps to stop the sharing, showing, or selling of an AI system. This could be done for various reasons, such as if the AI system is found to be unsafe or not complying with certain rules."
Digital Services Act (DSA) - Contextual paragraph (72),0.721767068,"Details of the contextual paragraph (72) of the Digital Services Act (DSA): In order to contribute to a safe, trustworthy and transparent online environment for consumers, as well as for other interested parties such as competing traders and holders of intellectual property rights, and to deter traders from selling products or services in violation of the applicable rules, online platforms allowing consumers to conclude distance contracts with traders should ensure that such traders are traceable. The trader should therefore be required to provide certain essential information to the providers of online platforms allowing consumers to conclude distance contracts with traders, including for purposes of promoting messages on or offering products. That requirement should also be applicable to traders that promote messages on products or services on behalf of brands, based on underlying agreements. Those providers of online platforms should store all information in a secure manner for the duration of their contractual relationship with the trader and 6 months thereafter, to allow any claims to be filed against the trader or orders related to the trader to be complied with.
This obligation is necessary and proportionate, so that the information can be accessed, in accordance with the applicable law, including on the protection of personal data, by public authorities and private parties with a legitimate interest, including through the orders to provide information referred to in this Regulation. This obligation leaves unaffected potential obligations to preserve certain content for longer periods of time, on the basis of other Union law or national laws, in compliance with Union law. Without prejudice to the definition provided for in this Regulation, any trader, irrespective of whether it is a natural or legal person, identified on the basis of Article 6a(1), point (b), of Directive 2011/83/EU and Article 7(4), point (f), of Directive 2005/29/EC should be traceable when offering a product or service through an online platform. Directive 2000/31/EC obliges all information society services providers to render easily, directly and permanently accessible to the recipients of the service and competent authorities certain information allowing the identification of all providers. The traceability requirements for providers of online platforms allowing consumers to conclude distance contracts with traders set out in this Regulation do not affect the application of Council Directive (EU) 2021/514 (30), which pursues other legitimate public interest objectives.",recital,"The Digital Services Act (DSA) aims to create a safer and more transparent online environment for consumers, competitors, and intellectual property rights holders. It requires online platforms that facilitate distance contracts between consumers and traders to ensure those traders are traceable. Traders must provide essential information to these platforms, which must securely store this information for the duration of their contract with the trader and for six months after. This allows claims to be filed against the trader or orders related to the trader to be complied with. This information can be accessed by public authorities and private parties with a legitimate interest, in accordance with the law. The DSA also obliges all online service providers to make certain identifying information easily accessible. These requirements do not affect the application of Council Directive (EU) 2021/514, which pursues other public interest objectives."
Artifical Inellegence Act (AI Act) - Overview paragraph 64,0.72173363,"Aritifical Intelligence Act (AI Act) overview paragraph (64): Given the more extensive experience of professional pre-market certifiers in the field of product safety and the different nature of risks involved, it is appropriate to limit, at least in an initial phase of application of this Regulation, the scope of application of third-party conformity assessment for high-risk AI systems other than those related to products. Therefore, the conformity assessment of such systems should be carried out as a general rule by the provider under its own responsibility, with the only exception of AI systems intended to be used for the remote biometric identification of persons, for which the involvement of a notified body in the conformity assessment should be foreseen, to the extent they are not prohibited.",recital,"The Artificial Intelligence Act (AI Act) states that in its initial phase, the assessment of high-risk AI systems not related to products should be done by the provider themselves, due to their extensive experience in product safety and unique risk factors. The only exception is for AI systems used for remote biometric identification of people. In this case, a notified body should be involved in the assessment, unless such systems are prohibited."
Digital Markets Act (DMA) - Contextual Paragraph (35),0.72173059,"Details of the Contextual Paragraph (35) in the Digital Markets Act (DMA): The obligations laid down in this Regulation are therefore necessary to address identified public policy concerns, there being no alternative and less restrictive measures that would effectively achieve the same result, having regard to the need to safeguard public order, protect privacy and fight fraudulent and deceptive commercial practices.",rectial,"The Digital Markets Act (DMA) introduces new rules to protect public order, privacy, and prevent fraudulent and deceptive business practices. These rules are necessary because there are no other less restrictive measures that can effectively achieve the same outcome. The DMA is designed to address public policy issues that have been identified, ensuring that the digital market operates fairly and transparently for everyone."
Digital Services Act (DSA) - Contextual paragraph (34),0.721702397,"Details of the contextual paragraph (34) of the Digital Services Act (DSA): Relevant national authorities should be able to issue such orders against content considered illegal or orders to provide information on the basis of Union law or national law in compliance with Union law, in particular the Charter, and to address them to providers of intermediary services, including those established in another Member State. However, this Regulation should be without prejudice to Union law in the field of judicial cooperation in civil or criminal matters, including Regulation (EU) No 1215/2012 and a Regulation on European production and preservation orders for electronic evidence in criminal matters, and to national criminal or civil procedural law. Therefore, where those laws in the context of criminal or civil proceedings provide for conditions that are additional to or incompatible with the conditions provided for in this Regulation in relation to orders to act against illegal content or to provide information, the conditions provided for in this Regulation might not apply or might be adapted. In particular, the obligation on the Digital Services Coordinator from the Member State of the issuing authority to transmit a copy of the orders to all other Digital Services Coordinators might not apply in the context of criminal proceedings or might be adapted, where the applicable national criminal procedural law so provides.
Furthermore, the obligation for the orders to contain a statement of reasons explaining why the information is illegal content should be adapted, where necessary, under the applicable national criminal procedural law for the prevention, investigation, detection and prosecution of criminal offences. Finally, the obligation on the providers of intermediary services to inform the recipient of the service might be delayed in accordance with applicable Union or national law, in particular in the context of criminal, civil or administrative proceedings. In addition, the orders should be issued in compliance with Regulation (EU) 2016/679 and the prohibition of general obligations to monitor information or to actively seek facts or circumstances indicating illegal activity laid down in this Regulation. The conditions and requirements laid down in this Regulation which apply to orders to act against illegal content are without prejudice to other Union acts providing for similar systems for acting against specific types of illegal content, such as Regulation (EU) 2021/784, Regulation (EU) 2019/1020, or Regulation (EU) 2017/2394 that confers specific powers to order the provision of information to Member State consumer law enforcement authorities, whilst the conditions and requirements that apply to orders to provide information are without prejudice to other Union acts providing for similar relevant rules for specific sectors. Those conditions and requirements should be without prejudice to retention and preservation rules under applicable national law, in compliance with Union law and confidentiality requests by law enforcement authorities related to the non-disclosure of information. Those conditions and requirements should not affect the possibility for Member States to require a provider of intermediary services to prevent an infringement, in compliance with Union law including this Regulation, and in particular with the prohibition of general monitoring obligations.",recital,"The Digital Services Act (DSA) allows national authorities to issue orders against content deemed illegal or to demand information from intermediary service providers, even those in other member states. However, these orders must align with Union law and the Charter. This law does not interfere with existing laws on civil or criminal matters. If these laws provide additional or conflicting conditions, the DSA's conditions may be adjusted or not apply. For instance, the obligation to share orders with all Digital Services Coordinators may not apply in criminal proceedings. The requirement for orders to explain why content is illegal may also be adjusted based on national criminal procedural law. The obligation to inform the recipient of the service may be delayed in certain proceedings. The DSA also respects privacy laws and prohibits general monitoring obligations. It does not affect the ability of member states to require providers to prevent infringements."
Digital Markets Act (DMA) - Contextual Paragraph (81),0.721698225,"Details of the Contextual Paragraph (81) in the Digital Markets Act (DMA): The Commission should be empowered to request information necessary for the purpose of this Regulation. In particular, the Commission should have access to any relevant documents, data, database, algorithm and information necessary to open and conduct investigations and to monitor the compliance with the obligations laid down in this Regulation, irrespective of who possesses such information, and regardless of their form or format, their storage medium, or the place where they are stored.",rectial,"The Digital Markets Act (DMA) has a clause, Contextual Paragraph (81), which allows the European Commission to request any information it needs to enforce this law. This includes documents, data, databases, algorithms, and other relevant information. The Commission can ask for this information from anyone, regardless of where or how it's stored. This is to help the Commission investigate potential violations and ensure everyone is following the rules set out in the DMA."
Digital Services Act (DSA) - Article 21 Out-of-court dispute settlement,0.721695542,"Article 21 Out-of-court dispute settlement in the Digital Services Act (DSA):  1.   Recipients of the service, including individuals or entities that have submitted notices, addressed by the decisions referred to in Article 20(1) shall be entitled to select any out-of-court dispute settlement body that has been certified in accordance with paragraph 3 of this Article in order to resolve disputes relating to those decisions, including complaints that have not been resolved by means of the internal complaint-handling system referred to in that Article.

Providers of online platforms shall ensure that information about the possibility for recipients of the service to have access to an out-of-court dispute settlement, as referred to in the first subparagraph, is easily accessible on their online interface, clear and user-friendly.

The first subparagraph is without prejudice to the right of the recipient of the service concerned to initiate, at any stage, proceedings to contest those decisions by the providers of online platforms before a court in accordance with the applicable law.

2.   Both parties shall engage, in good faith, with the selected certified out-of-court dispute settlement body with a view to resolving the dispute.
Providers of online platforms may refuse to engage with such out-of-court dispute settlement body if a dispute has already been resolved concerning the same information and the same grounds of alleged illegality or incompatibility of content.
The certified out-of-court dispute settlement body shall not have the power to impose a binding settlement of the dispute on the parties.

3.   The Digital Services Coordinator of the Member State where the out-of-court dispute settlement body is established shall, for a maximum period of five years, which may be renewed, certify the body, at its request, where the body has demonstrated that it meets all of the following conditions:
(a) it is impartial and independent, including financially independent, of providers of online platforms and of recipients of the service provided by providers of online platforms, including of individuals or entities that have submitted notices;
(b) it has the necessary expertise in relation to the issues arising in one or more particular areas of illegal content, or in relation to the application and enforcement of terms and conditions of one or more types of online platform, allowing the body to contribute effectively to the settlement of a dispute;
(c) its members are remunerated in a way that is not linked to the outcome of the procedure;
(d) the out-of-court dispute settlement that it offers is easily accessible, through electronic communications technology and provides for the possibility to initiate the dispute settlement and to submit the requisite supporting documents online;
(e) it is capable of settling disputes in a swift, efficient and cost-effective manner and in at least one of the official languages of the institutions of the Union;
(f) the out-of-court dispute settlement that it offers takes place in accordance with clear and fair rules of procedure that are easily and publicly accessible, and that comply with applicable law, including this Article.

The Digital Services Coordinator shall, where applicable, specify in the certificate:

(a) the particular issues to which the body's expertise relates, as referred to in point (b) of the first subparagraph; and
(b) the official language or languages of the institutions of the Union in which the body is capable of settling disputes, as referred to in point (e) of the first subparagraph.

4.   Certified out-of-court dispute settlement bodies shall report to the Digital Services Coordinator that certified them, on an annual basis, on their functioning, specifying at least the number of disputes they received, the information about the outcomes of those disputes, the average time taken to resolve them and any shortcomings or difficulties encountered. They shall provide additional information at the request of that Digital Services Coordinator.

Digital Services Coordinators shall, every two years, draw up a report on the functioning of the out-of-court dispute settlement bodies that they certified. That report shall in particular:

(a) list the number of disputes that each certified out-of-court dispute settlement body has received annually;
(b) indicate the outcomes of the procedures brought before those bodies and the average time taken to resolve the disputes;
(c) identify and explain any systematic or sectoral shortcomings or difficulties encountered in relation to the functioning of those bodies;
(d) identify best practices concerning that functioning;
(e) make recommendations as to how to improve that functioning, where appropriate.

Certified out-of-court dispute settlement bodies shall make their decisions available to the parties within a reasonable period of time and no later than 90 calendar days after the receipt of the complaint. In the case of highly complex disputes, the certified out-of-court dispute settlement body may, at its own discretion, extend the 90 calendar day period for an additional period that shall not exceed 90 days, resulting in a maximum total duration of 180 days.

5.   If the out-of-court dispute settlement body decides the dispute in favour of the recipient of the service, including the individual or entity that has submitted a notice, the provider of the online platform shall bear all the fees charged by the out-of-court dispute settlement body, and shall reimburse that recipient, including the individual or entity, for any other reasonable expenses that it has paid in relation to the dispute settlement. If the out-of-court dispute settlement body decides the dispute in favour of the provider of the online platform, the recipient of the service, including the individual or entity, shall not be required to reimburse any fees or other expenses that the provider of the online platform paid or is to pay in relation to the dispute settlement, unless the out-of-court dispute settlement body finds that that recipient manifestly acted in bad faith.

The fees charged by the out-of-court dispute settlement body to the providers of online platforms for the dispute settlement shall be reasonable and shall in any event not exceed the costs incurred by the body. For recipients of the service, the dispute settlement shall be available free of charge or at a nominal fee.

Certified out-of-court dispute settlement bodies shall make the fees, or the mechanisms used to determine the fees, known to the recipient of the service, including to the individuals or entities that have submitted a notice, and to the provider of the online platform concerned, before engaging in the dispute settlement.

6.   Member States may establish out-of-court dispute settlement bodies for the purposes of paragraph 1 or support the activities of some or all out-of-court dispute settlement bodies that they have certified in accordance with paragraph 3.

Member States shall ensure that any of their activities undertaken under the first subparagraph do not affect the ability of their Digital Services Coordinators to certify the bodies concerned in accordance with paragraph 3.

7.   A Digital Services Coordinator that has certified an out-of-court dispute settlement body shall revoke that certification if it determines, following an investigation either on its own initiative or on the basis of the information received by third parties, that the out-of-court dispute settlement body no longer meets the conditions set out in paragraph 3. Before revoking that certification, the Digital Services Coordinator shall afford that body an opportunity to react to the findings of its investigation and its intention to revoke the out-of-court dispute settlement body's certification.

8.   Digital Services Coordinators shall notify to the Commission the out-of-court dispute settlement bodies that they have certified in accordance with paragraph 3, including where applicable the specifications referred to in the second subparagraph of that paragraph, as well as the out-of-court dispute settlement bodies the certification of which they have revoked. The Commission shall publish a list of those bodies, including those specifications, on a dedicated website that is easily accessible, and keep it up to date.

9.   This Article is without prejudice to Directive 2013/11/EU and alternative dispute resolution procedures and entities for consumers established under that Directive.\n",article,"The Digital Services Act (DSA) introduces a new provision for out-of-court dispute settlement. Users of online platforms can choose a certified body to resolve disputes that couldn't be settled internally. Online platforms must make this information clear, accessible, and user-friendly. Users can also take their dispute to court at any time. Both parties must engage in good faith with the chosen dispute resolution body. The body cannot impose a binding settlement and can refuse to engage if the dispute has already been resolved. The body must be certified by the Digital Services Coordinator of the member state, ensuring its impartiality, expertise, independence, accessibility, efficiency, and adherence to fair procedures. The body must report annually on its functioning and decisions must be made within 90 days, extendable to 180 days for complex cases. If the user wins the dispute, the platform must bear all fees. If the platform wins, the user doesn't have to reimburse any fees unless they acted in bad faith. The dispute resolution must be free or nominally priced for users. The certification can be revoked if the body no longer meets the conditions."
Digital Services Act (DSA) - Article 23 Measures and protection against misuse,0.721678138,"Article 23 Measures and protection against misuse in the Digital Services Act (DSA):  1.   Providers of online platforms shall suspend, for a reasonable period of time and after having issued a prior warning, the provision of their services to recipients of the service that frequently provide manifestly illegal content.

2.   Providers of online platforms shall suspend, for a reasonable period of time and after having issued a prior warning, the processing of notices and complaints submitted through the notice and action mechanisms and internal complaints-handling systems referred to in Articles 16 and 20, respectively, by individuals or entities or by complainants that frequently submit notices or complaints that are manifestly unfounded.

3.   When deciding on suspension, providers of online platforms shall assess, on a case-by-case basis and in a timely, diligent and objective manner, whether the recipient of the service, the individual, the entity or the complainant engages in the misuse referred to in paragraphs 1 and 2, taking into account all relevant facts and circumstances apparent from the information available to the provider of online platforms. Those circumstances shall include at least the following:

(a) the absolute numbers of items of manifestly illegal content or manifestly unfounded notices or complaints, submitted within a given time frame;
(b) the relative proportion thereof in relation to the total number of items of information provided or notices submitted within a given time frame;
(c) the gravity of the misuses, including the nature of illegal content, and of its consequences;
(d) where it is possible to identify it, the intention of the recipient of the service, the individual, the entity or the complainant.

4.   Providers of online platforms shall set out, in a clear and detailed manner, in their terms and conditions their policy in respect of the misuse referred to in paragraphs 1 and 2, and shall give examples of the facts and circumstances that they take into account when assessing whether certain behaviour constitutes misuse and the duration of the suspension.",article,"The Digital Services Act (DSA) requires online platform providers to suspend their services to users who frequently post illegal content or make unfounded complaints, after giving a prior warning. The suspension period should be reasonable and each case should be evaluated individually, considering factors such as the number and proportion of illegal content or unfounded complaints, the severity of the misuse, and the user's intentions. The providers must clearly state their policy on misuse in their terms and conditions, including examples of what they consider misuse and how long the suspension will last."
General Data Protection Regulation (GDPR) - Article 88 Processing in the context of employment,0.721665263,"Details of Article 88 Processing in the context of employment in the General Data Protection Regulation (GDPR): 1. Member States may, by law or by collective agreements, provide for more specific rules to ensure the protection of the rights and freedoms in respect of the processing of employees' personal data in the employment context, in particular for the purposes of the recruitment, the performance of the contract of employment, including discharge of obligations laid down by law or by collective agreements, management, planning and organisation of work, equality and diversity in the workplace, health and safety at work, protection of employer's or customer's property and for the purposes of the exercise and enjoyment, on an individual or collective basis, of rights and benefits related to employment, and for the purpose of the termination of the employment relationship. 2. Those rules shall include suitable and specific measures to safeguard the data subject's human dignity, legitimate interests and fundamental rights, with particular regard to the transparency of processing, the transfer of personal data within a group of undertakings, or a group of enterprises engaged in a joint economic activity and monitoring systems at the work place. 3. Each Member State shall notify to the Commission those provisions of its law which it adopts pursuant to paragraph 1, by 25 May 2018 and, without delay, any subsequent amendment affecting them.",article,"The General Data Protection Regulation (GDPR) has a new rule, Article 88, about handling employees' personal data. This rule allows countries to create laws or agreements that provide specific rules for protecting employees' personal data in the workplace. This can include data used for hiring, contract fulfillment, work management, equality, safety, protecting property, and ending employment. The rules must also include measures to protect the employee's dignity, interests, and rights, especially regarding data transparency, data transfers within business groups, and workplace monitoring systems. Each country must inform the Commission about any laws they create under this rule by 25 May 2018 and any changes to them."
Artifical Inellegence Act (AI Act) - Definition of 'national competent authority',0.721622705,"Within the Aritifical Intelligence Act (AI Act), the Definition of national competent authority means the national supervisory authority, the notifying authority and the market surveillance authority;",recital,"The Artificial Intelligence Act (AI Act) introduces a new term, 'national competent authority.' This term refers to three types of national authorities: the supervisory authority, which oversees the law's implementation; the notifying authority, which communicates important information; and the market surveillance authority, which monitors the market to ensure compliance with the law."
Artifical Inellegence Act (AI Act) - Overview paragraph 84,0.721581161,"Aritifical Intelligence Act (AI Act) overview paragraph (84): Member States should take all necessary measures to ensure that the provisions of this Regulation are implemented, including by laying down effective, proportionate and dissuasive penalties for their infringement. For certain specific infringements, Member States should take into account the margins and criteria set out in this Regulation. The European Data Protection Supervisor should have the power to impose fines onUnion institutions, agencies and bodies falling within the scope of this Regulation.",recital,"The Artificial Intelligence Act (AI Act) requires all Member States to enforce its provisions, including setting up effective penalties for any violations. The penalties should be strong enough to discourage violations and should be proportionate to the infringement. For certain specific violations, the penalties should follow the guidelines set out in the AI Act. The European Data Protection Supervisor has the authority to fine Union institutions, agencies, and bodies that fall under this regulation."
Artifical Inellegence Act (AI Act) - Overview paragraph 40,0.721525073,"Aritifical Intelligence Act (AI Act) overview paragraph (40): Certain AI systemsintended for the administration of justice and democratic processesshould be classified as high-risk, considering their potentially significant impact on democracy, rule of law, individual freedoms as well as the right to an effective remedy and to a fair trial. In particular, to address the risks of potential biases, errors and opacity, it is appropriate to qualify as high-risk AI systems intended to assist judicial authorities in researching and interpreting facts and the law and in applying the law to a concrete set of facts. Such qualification should not extend, however, to AI systems intended for purely ancillary administrative activities that do not affect the actual administration of justice in individual cases, such asanonymisation or pseudonymisation of judicial decisions, documents or data, communication between personnel,administrative tasks or allocation of resources.",recital,"The Artificial Intelligence Act (AI Act) states that AI systems used in legal and democratic processes should be considered high-risk due to their potential impact on democracy, individual freedoms, and the right to a fair trial. This includes AI used to assist judges in researching and interpreting laws. However, AI used for minor administrative tasks that don't directly impact the administration of justice, such as anonymizing documents or managing resources, are not considered high-risk. This classification aims to address potential biases, errors, and lack of transparency in AI systems."
Digital Markets Act (DMA) - Article 47 Guidelines,0.721495152,Details of Article 47 Guidelines in the Digital Markets Act (DMA): The Commission may adopt guidelines on any of the aspects of this Regulation in order to facilitate its effective implementation and enforcement.,article,"The Digital Markets Act (DMA) includes a provision known as Article 47 Guidelines. This clause allows the Commission (the body responsible for enforcing the law) to create additional guidelines to help implement and enforce the law effectively. Essentially, it means the Commission can provide further instructions or clarifications on any part of the DMA to ensure it's properly understood and followed."
Digital Markets Act (DMA) - Definition of control,0.721460521,"Details of the Definition of control in the Digital Markets Act (DMA): ""control"" means the possibility of exercising decisive influence on an undertaking, within the meaning of Article 3(2) of Regulation (EC) No 139/2004;",rectial,"The Digital Markets Act (DMA) introduces a new definition for ""control"". In this context, ""control"" refers to the ability to have a significant impact on a business or enterprise. This is based on the guidelines set out in Article 3(2) of Regulation (EC) No 139/2004. In simpler terms, if you can make crucial decisions that shape the direction of a company, the DMA considers you to be in ""control""."
Artifical Inellegence Act (AI Act) - Overview paragraph 53,0.721434712,"Aritifical Intelligence Act (AI Act) overview paragraph (53): It is appropriate that a specific natural or legal person, defined as the provider, takes the responsibility for the placing on the market or putting into service of a high-risk AI system, regardless of whether that natural or legal person is the person who designed or developed the system.",recital,"The Artificial Intelligence Act (AI Act) states that a particular individual or organization, referred to as the 'provider', should be responsible for introducing a high-risk AI system to the market or for its use. This is true even if the 'provider' is not the one who designed or developed the AI system. This law ensures that there's always a clear party accountable for any high-risk AI systems."
Digital Markets Act (DMA) - Article 4 Review of the status of gatekeeper,0.721419096,"Details of Article 4 Review of the status of gatekeeper in the Digital Markets Act (DMA): 1. The Commission may, upon request or on its own initiative, reconsider, amend or repeal at any moment a designation decision adopted pursuant to Article 3 for one of the following reasons: (a) there has been a substantial change in any of the facts on which the designation decision was based; (b) the designation decision was based on incomplete, incorrect or misleading information. 2. The Commission shall regularly, and at least every 3 years, review whether the gatekeepers continue to satisfy the requirements laid down in Article 3(1). That review shall also examine whether the list of core platform services of the gatekeeper which are individually an important gateway for business users to reach end users, as referred to in Article 3(1), point (b), needs to be amended. Those reviews shall have no suspending effect on the gatekeeper""s obligations. The Commission shall also examine at least every year whether new undertakings providing core platform services satisfy those requirements. Where the Commission, on the basis of the reviews pursuant to the first subparagraph, finds that the facts on which the designation of the undertakings providing core platform services as gatekeepers was based, have changed, it shall adopt a decision confirming, amending or repealing the designation decision. 3. The Commission shall publish and update a list of gatekeepers and the list of the core platform services for which they need to comply with the obligations laid down in Chapter III on an on-going basis.",article,"The Digital Markets Act (DMA) allows the Commission to review, amend, or repeal the status of a 'gatekeeper' (a dominant online platform). This can happen if there's a significant change in the circumstances that led to the initial designation, or if the original decision was based on incorrect or misleading information. The Commission will review the status of gatekeepers every three years, and also check annually for any new businesses that might qualify as gatekeepers. If the facts change, the Commission can confirm, change, or repeal the gatekeeper designation. The Commission will also maintain and update a list of gatekeepers and the services they provide, and the obligations they must meet under the DMA."
Digital Markets Act (DMA) - Definition of end user,0.721417,"Details of the Definition of end user in the Digital Markets Act (DMA): ""end user"" means any natural or legal person using core platform services other than as a business user;",rectial,"The Digital Markets Act (DMA) has defined the term ""end user"". According to the DMA, an ""end user"" is anyone, whether an individual or a company, who uses core platform services for purposes other than business. This means if you're using these services for personal, non-commercial reasons, you're considered an ""end user"" under this law."
General Data Protection Regulation (GDPR) - Contextual Paragraph (139),0.721405387,"Details of the Contextual Paragraph (139) in the General Data Protection Regulation (GDPR): In order to promote the consistent application of this Regulation, the Board should be set up as an independent body of the Union. To fulfil its objectives, the Board should have legal personality. The Board should be represented by its Chair. It should replace the Working Party on the Protection of Individuals with Regard to the Processing of Personal Data established by Directive 95/46/EC. It should consist of the head of a supervisory authority of each Member State and the European Data Protection Supervisor or their respective representatives. The Commission should participate in the Board's activities without voting rights and the European Data Protection Supervisor should have specific voting rights. The Board should contribute to the consistent application of this Regulation throughout the Union, including by advising the Commission, in particular on the level of protection in third countries or international organisations, and promoting cooperation of the supervisory authorities throughout the Union. The Board should act independently when performing its tasks.",recital,"The General Data Protection Regulation (GDPR) has introduced a new independent body called the Board. This Board replaces the previous Working Party on the Protection of Individuals with regard to the Processing of Personal Data. It's made up of heads of supervisory authorities from each Member State and the European Data Protection Supervisor. The Board's role is to ensure the GDPR is consistently applied across the Union. It will advise the Commission, especially on data protection matters in third countries or international organizations, and promote cooperation among supervisory authorities across the Union. The Board will act independently in performing its tasks."
General Data Protection Regulation (GDPR) - Article 23 Restrictions,0.72134006,"Details of Article 23 Restrictions in the General Data Protection Regulation (GDPR): 1. Union or Member State law to which the data controller or processor is subject may restrict by way of a legislative measure the scope of the obligations and rights provided for in Articles 12 to 22 and Article 34, as well as Article 5 in so far as its provisions correspond to the rights and obligations provided for in Articles 12 to 22, when such a restriction respects the essence of the fundamental rights and freedoms and is a necessary and proportionate measure in a democratic society to safeguard: (a) national security; (b) defence; (c) public security; (d) the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security; (e) other important objectives of general public interest of the Union or of a Member State, in particular an important economic or financial interest of the Union or of a Member State, including monetary, budgetary and taxation a matters, public health and social security; (f) the protection of judicial independence and judicial proceedings; (g) the prevention, investigation, detection and prosecution of breaches of ethics for regulated professions; (h) a monitoring, inspection or regulatory function connected, even occasionally, to the exercise of official authority in the cases referred to in points (a) to (e) and (g); (i) the protection of the data subject or the rights and freedoms of others; (j) the enforcement of civil law claims. 2. In particular, any legislative measure referred to in paragraph 1 shall contain specific provisions at least, where relevant, as to: (a) the purposes of the processing or categories of processing; (b) the categories of personal data; (c) the scope of the restrictions introduced; (d) the safeguards to prevent abuse or unlawful access or transfer; (e) the specification of the controller or categories of controllers; (f) the storage periods and the applicable safeguards taking into account the nature, scope and purposes of the processing or categories of processing; (g) the risks to the rights and freedoms of data subjects; and (h) the right of data subjects to be informed about the restriction, unless that may be prejudicial to the purpose of the restriction.",article,"Article 23 of the General Data Protection Regulation (GDPR) allows for restrictions on data rights and obligations under certain conditions. These restrictions can be imposed by Union or Member State law, and must respect fundamental rights and freedoms. They must also be necessary for the protection of national security, defence, public security, and other public interests. These restrictions can also be applied for the prevention and prosecution of criminal offences, protection of judicial proceedings, and enforcement of civil law claims. Any law imposing such restrictions must clearly specify the purpose, the types of personal data involved, the extent of the restrictions, safeguards against abuse, the data controller, storage periods, risks to data subjects, and their right to be informed about the restriction."
General Data Protection Regulation (GDPR) - Definition of group of undertakings,0.721333086,"Details of the Definition of group of undertakings in the General Data Protection Regulation (GDPR): ""group of undertakings"" means a controlling undertaking and its controlled undertakings;",recital,"The General Data Protection Regulation (GDPR) introduces a term called ""group of undertakings"". This refers to a main company (controlling undertaking) and its subsidiaries (controlled undertakings). Essentially, it's a way to describe a larger corporation and all the smaller companies it owns or controls. This is important for data privacy as it helps clarify who is responsible for protecting personal data within a corporate group."
California Consumer Privacy Act Regulations (CCPA) - Article 6. Non-Discrimination -  999.336 Discriminatory Practices,0.721280932,"Details of Article 6. Non-Discrimination -  999.336 Discriminatory Practices in the California Consumer Privacy Act Regulations (CCPA): (a) A financial incentive or a price or service difference is discriminatory, and therefore prohibited by Civil Code section 1798.125, if the business treats a consumer differently because the consumer exercised a right conferred by the CCPA or these regulations. (b) A business may offer a financial incentive or price or service difference if it is reasonably related to the value of the consumers data. If a business is unable to calculate a good-faith estimate of the value of the consumers data or cannot show that the financial incentive or price or service difference is reasonably related to the value of the consumers data, that business shall not offer the financial incentive or price or service difference. (c) A businesss denial of a consumers request to know, request to delete, or request to opt-out for reasons permitted by the CCPA or these regulations shall not be considered discriminatory. (d) Illustrative examples follow: (1) Example 1: A music streaming business offers a free service as well as a premium service that costs $5 per month. If only the consumers who pay for the music streaming service are allowed to opt-out of the sale of their personal information, then the practice is discriminatory, unless the $5-per-month payment is reasonably related to the value of the consumers data to the business. (2) Example 2: A clothing business offers a loyalty program whereby customers receive a $5-off coupon by email after spending $100 with the business. A consumer submits a request to delete all personal information the business has collected about them but also informs the business that they want to continue to participate in the loyalty program. The business may deny their request to delete with regard to their email address and the amount the consumer has spent with the business because that information is necessary for the business to provide the loyalty program requested by the consumer and is reasonably anticipated within the context of the businesss ongoing relationship with them pursuant to Civil Code section 1798.105, subdivision (d)(1). (3) Example 3: A grocery store offers a loyalty program whereby consumers receive coupons and special discounts when they provide their phone numbers. A consumer submits a request to opt-out of the sale of their personal information. The retailer complies with their request but no longer allows the consumer to participate in the loyalty program. This practice is discriminatory unless the grocery store can demonstrate that the value of the coupons and special discounts are reasonably related to the value of the consumers data to the business. (4) Example 4: An online bookseller collects information about consumers, including their email addresses. It offers coupons to consumers through browser pop-up windows while the consumer uses the booksellers website. A consumer submits a request to delete all personal information that the bookseller has collected about them, including their email address and their browsing and purchasing history. The bookseller complies with the request but stops providing the periodic coupons to the consumer. The booksellers failure to provide coupons is discriminatory unless the value of the coupons is reasonably related to the value provided to the business by the consumers data. The bookseller may not deny the consumers request to delete with regard to the email address because the email address is not necessary to provide the coupons or reasonably aligned with the expectations of the consumer based on the consumers relationship with the business. (e) A business shall notify consumers of any financial incentive or price or service difference subject to Civil Code section 1798.125 that it offers in accordance with section 999.307. (f) A businesss charging of a reasonable fee pursuant to Civil Code section 1798.145, subdivision (i)(3), shall not be considered a financial incentive subject to these regulations. (g) A price or service difference that is the direct result of compliance with a state or federal law shall not be considered discriminatory.",article,"The California Consumer Privacy Act (CCPA) prohibits businesses from treating consumers differently if they exercise their rights under the CCPA. This includes offering financial incentives or service differences based on the value of a consumer's data. If a business can't estimate the value of a consumer's data or show that the incentive or service difference is related to that value, they can't offer it. Denying a consumer's request to know, delete, or opt-out for reasons allowed by the CCPA isn't considered discriminatory. Businesses must also notify consumers of any financial incentives or service differences they offer. Charging a reasonable fee isn't considered a financial incentive. Any price or service difference resulting from compliance with state or federal law isn't considered discriminatory."
Digital Services Act (DSA) - Article 28 Online protection of minors,0.721271515,"Article 28 Online protection of minors in the Digital Services Act (DSA):  1.   Providers of online platforms accessible to minors shall put in place appropriate and proportionate measures to ensure a high level of privacy, safety, and security of minors, on their service.
2.   Providers of online platform shall not present advertisements on their interface based on profiling as defined in Article 4, point (4), of Regulation (EU) 2016/679 using personal data of the recipient of the service when they are aware with reasonable certainty that the recipient of the service is a minor.
3.   Compliance with the obligations set out in this Article shall not oblige providers of online platforms to process additional personal data in order to assess whether the recipient of the service is a minor.
4.   The Commission, after consulting the Board, may issue guidelines to assist providers of online platforms in the application of paragraph 1.",article,"The Digital Services Act (DSA) has introduced a new law, Article 28, for the online protection of minors. It requires online platforms to take appropriate measures to ensure minors' privacy, safety, and security. The law also prohibits these platforms from showing ads based on profiling using personal data when they reasonably know the user is a minor. However, the law doesn't require platforms to collect additional personal data to determine if a user is a minor. The Commission may issue guidelines to help online platforms implement these measures."
Digital Markets Act (DMA) - Contextual Paragraph (15),0.721268833,"Details of the Contextual Paragraph (15) in the Digital Markets Act (DMA): The fact that a digital service qualifies as a core platform service does not in itself give rise to sufficiently serious concerns of contestability or unfair practices. It is only when a core platform service constitutes an important gateway and is operated by an undertaking with a significant impact in the internal market and an entrenched and durable position, or by an undertaking that will foreseeably enjoy such a position in the near future, that such concerns arise. Accordingly, the targeted set of harmonised rules in this Regulation should apply only to undertakings designated on the basis of those three objective criteria, and they should only apply to those of their core platform services that individually constitute an important gateway for business users to reach end users. The fact that it is possible that an undertaking providing core platform services not only intermediates between business users and end users, but also between end users and end users, for example in the case of number-independent interpersonal communications services, should not preclude the conclusion that such an undertaking is or could be an important gateway for business users to reach end users.",rectial,"The Digital Markets Act (DMA) states that not all digital services are automatically considered problematic or unfair. Concerns only arise when a service acts as a key access point, is run by a company with a significant market impact and a strong, lasting position, or a company expected to have such a position soon. The DMA's rules apply only to companies that meet these criteria, and only to their services that serve as a crucial access point for businesses to reach consumers. Even if a company's service also connects consumers to other consumers, it can still be considered a key access point for businesses."
Digital Services Act (DSA) - Article 12 Points of contact for recipients of the service,0.72123903,"Article 12 Points of contact for recipients of the service in the Digital Services Act (DSA):  1.   Providers of intermediary services shall designate a single point of contact to enable recipients of the service to communicate directly and rapidly with them, by electronic means and in a user-friendly manner, including by allowing recipients of the service to choose the means of communication, which shall not solely rely on automated tools.
2.   In addition to the obligations provided under Directive 2000/31/EC, providers of intermediary services shall make public the information necessary for the recipients of the service in order to easily identify and communicate with their single points of contact. That information shall be easily accessible, and shall be kept up to date.",article,"The Digital Services Act (DSA) requires online service providers to establish a single, user-friendly point of contact for their customers. This contact point should be accessible through various electronic means, not just automated tools. The DSA also mandates these providers to publicly share information needed for customers to easily identify and communicate with these contact points. This information must be easily accessible and regularly updated."
California Consumer Privacy Act Regulations (CCPA) - Article 4. Verification of Requests -  999.324 Verification for Password-Protected Accounts,0.7212286,"Details of Article 4. Verification of Requests -  999.324 Verification for Password-Protected Accounts in the California Consumer Privacy Act Regulations (CCPA): (a) If a business maintains a password-protected account with the consumer, the business may verify the consumers identity through the businesss existing authentication practices for the consumers account, provided that the business follows the requirements in section 999.323. The business shall also require a consumer to re-authenticate themself before disclosing or deleting the consumers data. (b) If a business suspects fraudulent or malicious activity on or from the password-protected account, the business shall not comply with a consumers request to know or request to delete until further verification procedures determine that the consumer request is authentic and the consumer making the request is the person about whom the business has collected information. The business may use the procedures set forth in section 999.325 to further verify the identity of the consumer.",article,"The California Consumer Privacy Act Regulations (CCPA) has a new section, Article 4. Verification of Requests. This section states that if a business has a password-protected account with a customer, they can confirm the customer's identity using their existing account verification processes. However, the business must also ask the customer to verify their identity again before sharing or deleting their data. If the business suspects any fraudulent or harmful activity on the account, they should not fulfill any requests to access or delete data until they have further confirmed the customer's identity. The business can use the methods outlined in section 999.325 to do this additional verification."
General Data Protection Regulation (GDPR) - Article 51 Supervisory authority,0.721222401,"Details of Article 51 Supervisory authority in the General Data Protection Regulation (GDPR): 1. Each Member State shall provide for one or more independent public authorities to be responsible for monitoring the application of this Regulation, in order to protect the fundamental rights and freedoms of natural persons in relation to processing and to facilitate the free flow of personal data within the Union (supervisory authority). 2. Each supervisory authority shall contribute to the consistent application of this Regulation throughout the Union. For that purpose, the supervisory authorities shall cooperate with each other and the Commission in accordance with Chapter VII. 3. Where more than one supervisory authority is established in a Member State, that Member State shall designate the supervisory authority which is to represent those authorities in the Board and shall set out the mechanism to ensure compliance by the other authorities with the rules relating to the consistency mechanism referred to in Article 63. 4. Each Member State shall notify to the Commission the provisions of its law which it adopts pursuant to this Chapter, by 25 May 2018 and, without delay, any subsequent amendment affecting them.",article,"Article 51 of the General Data Protection Regulation (GDPR) requires each member state to have one or more independent authorities to monitor the application of the GDPR. These authorities are tasked with protecting individuals' rights and freedoms regarding data processing, and ensuring the free flow of personal data within the EU. They are also required to cooperate with each other and the Commission to ensure the GDPR is applied consistently across the EU. If a member state has more than one supervisory authority, it must designate one to represent the others on the Board and ensure compliance with consistency rules. Each member state must notify the Commission of any laws they adopt related to this by 25 May 2018, and any subsequent changes."
General Data Protection Regulation (GDPR) - Article 29 Processing under the authority of the controller or processor,0.721162856,"Details of Article 29 Processing under the authority of the controller or processor in the General Data Protection Regulation (GDPR): The processor and any person acting under the authority of the controller or of the processor, who has access to personal data, shall not process those data except on instructions from the controller, unless required to do so by Union or Member State law.",article,"Article 29 of the General Data Protection Regulation (GDPR) states that anyone who has access to personal data, whether they are the processor or someone acting under the authority of the controller or processor, can only process that data based on instructions from the controller. The only exception to this rule is if they are legally required to process the data by Union or Member State law."
General Data Protection Regulation (GDPR) - Contextual Paragraph (171),0.721151,"Details of the Contextual Paragraph (171) in the General Data Protection Regulation (GDPR): Directive 95/46/EC should be repealed by this Regulation. Processing already under way on the date of application of this Regulation should be brought into conformity with this Regulation within the period of two years after which this Regulation enters into force. Where processing is based on consent pursuant to Directive 95/46/EC, it is not necessary for the data subject to give his or her consent again if the manner in which the consent has been given is in line with the conditions of this Regulation, so as to allow the controller to continue such processing after the date of application of this Regulation. Commission decisions adopted and authorisations by supervisory authorities based on Directive 95/46/EC remain in force until amended, replaced or repealed.",recital,"The General Data Protection Regulation (GDPR) will replace Directive 95/46/EC. All ongoing data processing must comply with the new GDPR within two years of its enforcement. If the data subject has already given consent under the old directive and it aligns with the new GDPR, they don't need to give consent again. All decisions and authorizations based on the old directive will remain valid until they are changed or repealed."
Digital Services Act (DSA) - Article 33 Very large online platforms and very large online search engines,0.721147954,"Article 33 Very large online platforms and very large online search engines in the Digital Services Act (DSA):  1.   This Section shall apply to online platforms and online search engines which have a number of average monthly active recipients of the service in the Union equal to or higher than 45 million, and which are designated as very large online platforms or very large online search engines pursuant to paragraph 4.

2.   The Commission shall adopt delegated acts in accordance with Article 87 to adjust the number of average monthly active recipients of the service in the Union referred to in paragraph 1, where the Union's population increases or decreases at least by 5 % in relation to its population in 2020 or its population after adjustment by means of a delegated act in the year in which the latest delegated act was adopted. In such a case, it shall adjust the number so that it corresponds to 10 % of the Union's population in the year in which it adopts the delegated act, rounded up or down to allow the number to be expressed in millions.

3.   The Commission may adopt delegated acts in accordance with Article 87, after consulting the Board, to supplement the provisions of this Regulation by laying down the methodology for calculating the number of average monthly active recipients of the service in the Union, for the purposes of paragraph 1 of this Article and Article 24(2), ensuring that the methodology takes account of market and technological developments.

4.   The Commission shall, after having consulted the Member State of establishment or after taking into account the information provided by the Digital Services Coordinator of establishment pursuant to Article 24(4), adopt a decision designating as a very large online platform or a very large online search engine for the purposes of this Regulation the online platform or the online search engine which has a number of average monthly active recipients of the service equal to or higher than the number referred to in paragraph 1 of this Article. The Commission shall take its decision on the basis of data reported by the provider of the online platform or of the online search engine pursuant to Article 24(2), or information requested pursuant to Article 24(3) or any other information available to the Commission.

The failure by the provider of the online platform or of the online search engine to comply with Article 24(2) or to comply with the request by the Digital Services Coordinator of establishment or by the Commission pursuant to Article 24(3) shall not prevent the Commission from designating that provider as a provider of a very large online platform or of a very large online search engine pursuant to this paragraph.

Where the Commission bases its decision on other information available to the Commission pursuant to the first subparagraph of this paragraph or on the basis of additional information requested pursuant to Article 24(3), the Commission shall give the provider of the online platform or of the online search engine concerned 10 working days in which to submit its views on the Commission's preliminary findings and on its intention to designate the online platform or the online search engine as a very large online platform or as a very large online search engine, respectively. The Commission shall take due account of the views submitted by the provider concerned.

The failure of the provider of the online platform or of the online search engine concerned to submit its views pursuant to the third subparagraph shall not prevent the Commission from designating that online platform or that online search engine as a very large online platform or as a very large online search engine, respectively, based on other information available to it.

5.   The Commission shall terminate the designation if, during an uninterrupted period of one year, the online platform or the online search engine does not have a number of average monthly active recipients of the service equal to or higher than the number referred to in paragraph 1.

6.   The Commission shall notify its decisions pursuant to paragraphs 4 and 5, without undue delay, to the provider of the online platform or of the online search engine concerned, to the Board and to the Digital Services Coordinator of establishment.

The Commission shall ensure that the list of designated very large online platforms and very large online search engines is published in the Official Journal of the European Union, and shall keep that list up to date. The obligations set out in this Section shall apply, or cease to apply, to the very large online platforms and very large online search engines concerned from four months after the notification to the provider concerned referred to in the first subparagraph.",article,"The Digital Services Act (DSA) applies to online platforms and search engines with more than 45 million average monthly users in the European Union. The Commission can adjust this number if the EU's population changes by at least 5%. The Commission can also determine how to calculate the number of users, taking into account market and technological changes. If a platform or search engine meets the user threshold, the Commission can designate it as a ""very large online platform"" or ""very large online search engine."" This designation can be made even if the platform or search engine does not provide requested data. If the platform or search engine falls below the user threshold for a year, the Commission can remove the designation. The Commission will notify the platform or search engine, publish the list of designations, and update it regularly. The obligations under the DSA apply four months after notification."
Artifical Inellegence Act (AI Act) - Overview paragraph 49,0.721141696,"Aritifical Intelligence Act (AI Act) overview paragraph (49): High-risk AI systems should perform consistently throughout their lifecycle and meet an appropriate level of accuracy, robustness and cybersecurity in accordance with the generally acknowledged state of the art. The level of accuracy and accuracy metrics should be communicated to the users.",recital,"The Artificial Intelligence Act (AI Act) states that high-risk AI systems must perform reliably and consistently throughout their use. They should also meet high standards of accuracy, strength, and cybersecurity based on current best practices. The accuracy of these systems should be clearly communicated to users."
Artifical Inellegence Act (AI Act) - Overview paragraph 89,0.721101,Aritifical Intelligence Act (AI Act) overview paragraph (89): The European Data Protection Supervisor and the European Data Protection Board were consulted in accordance with Article 42(2) of Regulation (EU) 2018/1725 and delivered an opinion on [].,recital,The Artificial Intelligence Act (AI Act) is a new law that has been reviewed and given an opinion on by the European Data Protection Supervisor and the European Data Protection Board. These two entities were consulted as per the requirements of Article 42(2) of Regulation (EU) 2018/1725. This process ensures that the AI Act respects data protection standards and regulations in the European Union.
General Data Protection Regulation (GDPR) - Contextual Paragraph (93),0.721074939,"Details of the Contextual Paragraph (93) in the General Data Protection Regulation (GDPR): In the context of the adoption of the Member State law on which the performance of the tasks of the public authority or public body is based and which regulates the specific processing operation or set of operations in question, Member States may deem it necessary to carry out such assessment prior to the processing activities.",recital,The General Data Protection Regulation (GDPR) includes a section (Paragraph 93) that allows countries in the European Union to assess and regulate how public authorities or bodies handle personal data before they start processing it. This is to ensure that these bodies follow the specific laws of their country when handling personal data.
Artifical Inellegence Act (AI Act) - Article 70,0.721035898,"Aritifical Intelligence Act (AI Act) Article 70 Confidentiality:

1.National competent authorities and notified bodies involved in the application of this Regulation shall respect the confidentiality of information and data obtained in carrying out their tasks and activities in such a manner as to protect, in particular:

(a)intellectual property rights, and confidential business information or trade secrets of a natural or legal person, including source code, except the cases referred to in Article 5 of Directive 2016/943 on the protection of undisclosed know-how and business information (trade secrets) against their unlawful acquisition, use and disclosure apply.

(b)the effective implementation of this Regulation, in particular for the purpose of inspections, investigations or audits;(c) public and national security interests;

(c)integrity of criminal or administrative proceedings.

2.Without prejudice to paragraph 1, information exchanged on a confidential basis between the national competent authorities and between national competent authorities and the Commission shall not be disclosed without the prior consultation of the originating national competent authority and the user when high-risk AI systems referred to in points 1, 6 and 7 of Annex III are used by law enforcement, immigration or asylum authorities, when such disclosure would jeopardise public and national security interests.

When the law enforcement, immigration or asylum authorities are providers of high-risk AI systems referred to in points 1, 6 and 7 of Annex III, the technical documentation referred to in Annex IV shall remain within the premises of those authorities. Those authorities shall ensure that the market surveillance authorities referred to in Article 63(5) and (6), as applicable, can, upon request, immediately access the documentation or obtain a copy thereof. Only staff of the market surveillance authority holding the appropriate level of security clearance shall be allowed to access that documentation or any copy thereof.

3.Paragraphs 1 and 2 shall not affect the rights and obligations of the Commission, Member States and notified bodies with regard to the exchange of information and the dissemination of warnings, nor the obligations of the parties concerned to provide information under criminal law of the Member States.

4.The Commission and Member States may exchange, where necessary, confidential information with regulatory authorities of third countries with which they have concluded bilateral or multilateral confidentiality arrangements guaranteeing an adequate level of confidentiality.",article,"The Artificial Intelligence Act (AI Act) Article 70 focuses on confidentiality. It requires national authorities and notified bodies to protect confidential information, including intellectual property and trade secrets, during their duties. This confidentiality is also important for inspections, investigations, audits, and maintaining public and national security. Confidential information exchanged between national authorities should not be disclosed without prior consultation, especially when high-risk AI systems are used by law enforcement or immigration authorities. If these authorities provide high-risk AI systems, their technical documentation should remain within their premises but be accessible to market surveillance authorities upon request. The article does not affect the rights and obligations of the Commission, Member States, and notified bodies in exchanging information and warnings. The Commission and Member States may also exchange confidential information with regulatory authorities of other countries, given adequate confidentiality arrangements are in place."
Digital Services Act (DSA) - Contextual paragraph (8),0.721030176,"Details of the contextual paragraph (8) of the Digital Services Act (DSA): Such a substantial connection to the Union should be considered to exist where the service provider has an establishment in the Union or, in the absence of such an establishment, where the number of recipients of the service in one or more Member States is significant in relation to the population thereof, or on the basis of the targeting of activities towards one or more Member States. The targeting of activities towards one or more Member States can be determined on the basis of all relevant circumstances, including factors such as the use of a language or a currency generally used in that Member State, or the possibility of ordering products or services, or the use of a relevant top-level domain. The targeting of activities towards a Member State could also be derived from the availability of an application in the relevant national application store, from the provision of local advertising or advertising in a language used in that Member State, or from the handling of customer relations such as by providing customer service in a language generally used in that Member State. A substantial connection should also be assumed where a service provider directs its activities to one or more Member States within the meaning of Article 17(1), point (c), of Regulation (EU) No 1215/2012 of the European Parliament and of the Council (6). In contrast, mere technical accessibility of a website from the Union cannot, on that ground alone, be considered as establishing a substantial connection to the Union.",recital,"The Digital Services Act (DSA) establishes that a service provider has a significant connection to the European Union (EU) if it has an establishment in the EU, or if it has a large number of users in one or more EU countries. This connection can also be determined by whether the provider targets its services to one or more EU countries. This can be shown by factors such as using a language or currency common in that country, offering products or services, or using a relevant domain. The availability of an app in a national app store, local advertising, or customer service in the local language can also indicate targeting. However, just because a website can be accessed from the EU doesn't mean it has a significant connection to the EU."
Artifical Inellegence Act (AI Act) - Overview paragraph 10,0.72102648,"Aritifical Intelligence Act (AI Act) overview paragraph (10): In order to ensure a level playing field and an effective protection of rights and freedoms of individuals across the Union, the rules established by this Regulation should apply to providers of AI systems in a non-discriminatory manner, irrespective of whether they are established within the Union or in a third country, and to users of AI systems established within the Union.",recital,"The Artificial Intelligence Act (AI Act) is a new law that aims to protect people's rights and freedoms when it comes to the use of artificial intelligence (AI). It applies to all providers of AI systems, regardless of where they are located, and to any users of AI systems based in the Union. This means that everyone must follow the same rules, ensuring fairness and non-discrimination."
Digital Markets Act (DMA) - Contextual Paragraph (71),0.72099191,"Details of the Contextual Paragraph (71) in the Digital Markets Act (DMA): To ensure the effectiveness of the review of gatekeeper status, as well as the possibility to adjust the list of core platform services provided by a gatekeeper, the gatekeepers should inform the Commission of all of their intended acquisitions, prior to their implementation, of other undertakings providing core platform services or any other services provided within the digital sector or other services that enable the collection of data. Such information should not only serve the review process regarding the status of individual gatekeepers, but will also provide information that is crucial to monitoring broader contestability trends in the digital sector and can therefore be a useful factor for consideration in the context of the market investigations provided for by this Regulation. Furthermore, the Commission should inform Member States of such information, given the possibility of using the information for national merger control purposes and as, under certain circumstances, it is possible for the national competent authority to refer those acquisitions to the Commission for the purposes of merger control. The Commission should also publish annually a list of acquisitions of which it has been informed by the gatekeeper. To ensure the necessary transparency and usefulness of such information for different purposes provided for by this Regulation, gatekeepers should provide at least information about the undertakings concerned by the concentration, their Union and worldwide annual turnover, their field of activity, including activities directly related to the concentration, the transaction value or an estimation thereof, a summary of the concentration, including its nature and rationale, as well as a list of the Member States concerned by the operation.",rectial,"The Digital Markets Act (DMA) requires large online platforms, known as gatekeepers, to inform the European Commission about any planned acquisitions before they take place. This includes companies that provide core platform services or any services that collect data. This information helps the Commission monitor competition in the digital sector and can be used in market investigations. The Commission will also share this information with EU Member States for their national merger control purposes. Furthermore, the Commission will publish a yearly list of acquisitions reported by the gatekeepers. The gatekeepers must provide details about the companies involved in the acquisition, their annual turnover, their activities, the value of the transaction, a summary of the acquisition, and a list of the affected Member States."
Digital Markets Act (DMA) - Article 10 Exemption for grounds of public health and public security,0.720953286,"Details of Article 10 Exemption for grounds of public health and public security in the Digital Markets Act (DMA): 1. The Commission may, acting on a reasoned request by a gatekeeper or on its own initiative, adopt an implementing act setting out its decision, to exempt that gatekeeper, in whole or in part, from a specific obligation laid down in Article 5, 6 or 7 in relation to a core platform service listed in the designation decision pursuant to Article 3(9), where such exemption is justified on the grounds set out in paragraph 3 of this Article (""the exemption decision""). The Commission shall adopt the exemption decision within 3 months after receiving a complete reasoned request and shall provide a reasoned statement explaining the grounds for the exemption. That implementing act shall be adopted in accordance with the advisory procedure referred to in Article 50(2). 2. Where an exemption is granted pursuant to paragraph 1, the Commission shall review its exemption decision if the ground for the exemption no longer exists or at least every year. Following such a review, the Commission shall either wholly or partially lift the exemption, or decide that the conditions of paragraph 1 continue to be met. 3. An exemption pursuant to paragraph 1 may only be granted on grounds of public health or public security. 4. In cases of urgency, the Commission may, acting on a reasoned request by a gatekeeper or on its own initiative, provisionally suspend the application of a specific obligation referred to in paragraph 1 to one or more individual core platform services already prior to the decision pursuant to that paragraph. Such a request may be made and granted at any time pending the assessment of the Commission pursuant to paragraph 1. 5. In assessing the request referred to in paragraphs 1 and 4, the Commission shall take into account, in particular, the impact of the compliance with the specific obligation on the grounds in paragraph 3, as well as the effects on the gatekeeper concerned and on third parties. The Commission may subject the suspension to conditions and obligations in order to ensure a fair balance between the goals pursued by the grounds in paragraph 3 and the objectives of this Regulation.",article,"The Digital Markets Act (DMA) Article 10 allows the Commission to exempt a digital platform (gatekeeper) from certain obligations under Articles 5, 6 or 7 if it's necessary for public health or security. The Commission can initiate this exemption or it can be requested by the gatekeeper. A detailed explanation must be provided for the exemption, which should be decided within three months of the request. The exemption can be reviewed and possibly lifted annually or if the reason for it no longer exists. In urgent situations, the Commission can temporarily suspend a gatekeeper's obligations before making a formal decision. The Commission must consider the impact of the obligation on public health or security, the gatekeeper, and third parties when making its decision."
Artifical Inellegence Act (AI Act) - Overview paragraph 66,0.720943153,"Aritifical Intelligence Act (AI Act) overview paragraph (66): In line with the commonly established notion of substantial modification for products regulated by Union harmonisation legislation, it is appropriate that an AI system undergoes a new conformity assessment whenever a change occurs which may affect the compliance of the system with this Regulation or when the intended purpose of the system changes. In addition, as regards AI systems which continue to learn after being placed on the market or put into service (i.e. they automatically adapt how functions are carried out), it is necessary to provide rules establishing that changes to the algorithm and its performance that have been pre-determined by the provider and assessed at the moment of the conformity assessment should not constitute a substantial modification.",recital,"The Artificial Intelligence Act (AI Act) states that any significant changes made to an AI system, which could affect its compliance with the law or its intended use, must undergo a new assessment to ensure it still meets regulations. However, for AI systems that continue to learn and adapt their functions after being launched, any changes to the algorithm or performance that were planned and evaluated by the provider at the time of the initial assessment, are not considered significant modifications."
Artifical Inellegence Act (AI Act) - Overview paragraph 13,0.720941365,"Aritifical Intelligence Act (AI Act) overview paragraph (13): In order to ensure a consistent and high level of protection of public interests as regards health, safety and fundamental rights, common normative standards for all high-risk AI systems should be established. Those standards should be consistent with the Charter of fundamental rights of the European Union (the Charter) and should be non-discriminatory and in line with the Unions international trade commitments.",recital,"The Artificial Intelligence Act (AI Act) aims to protect public interests like health, safety, and basic rights by setting common standards for all high-risk AI systems. These standards should align with the Charter of Fundamental Rights of the European Union, ensuring they are fair and do not discriminate. They should also comply with the Union's international trade agreements."
Digital Markets Act (DMA) - Definition of online social networking service,0.720937,"Details of the Definition of online social networking service in the Digital Markets Act (DMA): ""online social networking service"" means a platform that enables end users to connect and communicate with each other, share content and discover other users and content across multiple devices and, in particular, via chats, posts, videos and recommendations;",rectial,"The Digital Markets Act (DMA) defines an ""online social networking service"" as any platform that allows users to connect, communicate, share content, and discover other users and content. This can be done through various means such as chats, posts, videos, and recommendations, and across different devices."
Digital Services Act (DSA) - Article 9 Orders to act against illegal content,0.720896602,"Article 9 Orders to act against illegal content in the Digital Services Act (DSA):  1.   Upon the receipt of an order to act against one or more specific items of illegal content, issued by the relevant national judicial or administrative authorities, on the basis of the applicable Union law or national law in compliance with Union law, providers of intermediary services shall inform the authority issuing the order, or any other authority specified in the order, of any effect given to the order without undue delay, specifying if and when effect was given to the order.
2.   Member States shall ensure that when an order referred to in paragraph 1 is transmitted to the provider, it meets at least the following conditions:
(a) that order contains the following elements:
(i) a reference to the legal basis under Union or national law for the order;
(ii) a statement of reasons explaining why the information is illegal content, by reference to one or more specific provisions of Union law or national law in compliance with Union law;
(iii) information identifying the issuing authority;
(iv) clear information enabling the provider of intermediary services to identify and locate the illegal content concerned, such as one or more exact URL and, where necessary, additional information;
(v) information about redress mechanisms available to the provider of intermediary services and to the recipient of the service who provided the content;
(vi) where applicable, information about which authority is to receive the information about the effect given to the orders;
(b) the territorial scope of that order, on the basis of the applicable rules of Union and national law, including the Charter, and, where relevant, general principles of international law, is limited to what is strictly necessary to achieve its objective;
(c) that order is transmitted in one of the languages declared by the provider of intermediary services pursuant to Article 11(3) or in another official language of the Member States, agreed between the authority issuing the order and that provider, and is sent to the electronic point of contact designated by that provider, in accordance with Article 11; where the order is not drafted in the language declared by the provider of intermediary services or in another bilaterally agreed language, the order may be transmitted in the language of the authority issuing the order, provided that it is accompanied by a translation into such declared or bilaterally agreed language of at least the elements set out in points (a) and (b) of this paragraph.
3.   The authority issuing the order or, where applicable, the authority specified therein, shall transmit it, along with any information received from the provider of intermediary services concerning the effect given to that order to the Digital Services Coordinator from the Member State of the issuing authority.
4.   After receiving the order from the judicial or administrative authority, the Digital Services Coordinator of the Member State concerned shall, without undue delay, transmit a copy of the order referred to in paragraph 1 of this Article to all other Digital Services Coordinators through the system established in accordance with Article 85.
5.   At the latest when effect is given to the order or, where applicable, at the time provided by the issuing authority in its order, providers of intermediary services shall inform the recipient of the service concerned of the order received and to the effect given to it. Such information provided to the recipient of the service shall include a statement of reasons, the possibilities for redress that exist, and a description of the territorial scope of the order, in accordance with paragraph 2.
6.   The conditions and requirements laid down in this Article shall be without prejudice to national civil and criminal procedural law.",article,"The Digital Services Act (DSA) requires online service providers to act quickly against illegal content when ordered by national authorities. The order must specify its legal basis, why the content is illegal, who issued the order, and how to identify the illegal content. It should also provide information about how to challenge the order and who should be informed about the action taken. This order must be in a language that the service provider understands. After receiving the order, the provider should inform the content creator about it, including reasons and how to challenge it. The DSA also requires the national authority to share the order with the Digital Services Coordinator, who then shares it with other Coordinators. This law doesn't affect national civil and criminal procedures."
General Data Protection Regulation (GDPR) - Article 32 Security of processing,0.720852256,"Details of Article 32 Security of processing in the General Data Protection Regulation (GDPR): 1. Taking into account the state of the art, the costs of implementation and the nature, scope, context and purposes of processing as well as the risk of varying likelihood and severity for the rights and freedoms of natural persons, the controller and the processor shall implement appropriate technical and organisational measures to ensure a level of security appropriate to the risk, including inter alia as appropriate: (a) the pseudonymisation and encryption of personal data; (b) the ability to ensure the ongoing confidentiality, integrity, availability and resilience of processing systems and services; (c) the ability to restore the availability and access to personal data in a timely manner in the event of a physical or technical incident; (d) a process for regularly testing, assessing and evaluating the effectiveness of technical and organisational measures for ensuring the security of the processing. 2. In assessing the appropriate level of security account shall be taken in particular of the risks that are presented by processing, in particular from accidental or unlawful destruction, loss, alteration, unauthorised disclosure of, or access to personal data transmitted, stored or otherwise processed. 3. Adherence to an approved code of conduct as referred to in Article 40 or an approved certification mechanism as referred to in Article 42 may be used as an element by which to demonstrate compliance with the requirements set out in paragraph 1 of this Article. 4. The controller and processor shall take steps to ensure that any natural person acting under the authority of the controller or the processor who has access to personal data does not process them except on instructions from the controller, unless he or she is required to do so by Union or Member State law.",article,"The General Data Protection Regulation (GDPR) Article 32 mandates companies to implement suitable technical and organizational measures to ensure the security of personal data. This includes encryption, maintaining confidentiality, and the ability to restore data quickly after a technical issue. Regular testing of these measures is also required. The level of security should be proportionate to the potential risks, such as accidental loss or unauthorized access to the data. Compliance can be demonstrated through adherence to approved codes of conduct or certification mechanisms. Additionally, anyone with access to personal data must only process it under the instructions of the company, unless required by law."
Artifical Inellegence Act (AI Act) - Overview paragraph 45,0.720848501,"Aritifical Intelligence Act (AI Act) overview paragraph (45): For the development of high-risk AI systems, certain actors, such as providers, notified bodies and other relevant entities, such as digital innovation hubs, testing experimentation facilities and researchers, should be able to access and use high quality datasets within their respective fields of activities which are related to this Regulation. European common data spaces established by the Commission and the facilitation of data sharing between businesses and with government in the public interest will be instrumental to provide trustful, accountable and non-discriminatory access to high quality data for the training, validation and testing of AI systems. For example, in health, the European health data space will facilitate non-discriminatory access to health data and the training of artificial intelligence algorithms on those datasets, in a privacy-preserving, secure, timely, transparent and trustworthy manner, and with an appropriate institutional governance. Relevant competent authorities,including sectoral ones, providing or supporting the access to data may also support the provision of high-quality data for the training, validation and testing of AI systems.",recital,"The Artificial Intelligence Act (AI Act) allows certain groups like providers, researchers, and innovation hubs to access and use high-quality datasets related to their work. This is to help develop high-risk AI systems. The European Commission will establish common data spaces to facilitate data sharing between businesses and the government. This will ensure reliable, fair, and non-discriminatory access to high-quality data for training, testing, and validating AI systems. For instance, in the health sector, the European health data space will provide fair access to health data and allow for the training of AI algorithms in a secure, timely, transparent, and trustworthy way. Relevant authorities that provide or support data access can also help provide high-quality data for AI system development."
General Data Protection Regulation (GDPR) - Contextual Paragraph (91),0.720840454,"Details of the Contextual Paragraph (91) in the General Data Protection Regulation (GDPR): This should in particular apply to large-scale processing operations which aim to process a considerable amount of personal data at regional, national or supranational level and which could affect a large number of data subjects and which are likely to result in a high risk, for example, on account of their sensitivity, where in accordance with the achieved state of technological knowledge a new technology is used on a large scale as well as to other processing operations which result in a high risk to the rights and freedoms of data subjects, in particular where those operations render it more difficult for data subjects to exercise their rights. A data protection impact assessment should also be made where personal data are processed for taking decisions regarding specific natural persons following any systematic and extensive evaluation of personal aspects relating to natural persons based on profiling those data or following the processing of special categories of personal data, biometric data, or data on criminal convictions and offences or related security measures. A data protection impact assessment is equally required for monitoring publicly accessible areas on a large scale, especially when using optic-electronic devices or for any other operations where the competent supervisory authority considers that the processing is likely to result in a high risk to the rights and freedoms of data subjects, in particular because they prevent data subjects from exercising a right or using a service or a contract, or because they are carried out systematically on a large scale. The processing of personal data should not be considered to be on a large scale if the processing concerns personal data from patients or clients by an individual physician, other health care professional or lawyer. In such cases, a data protection impact assessment should not be mandatory.",recital,"The General Data Protection Regulation (GDPR) requires a data protection impact assessment for large-scale operations that process a lot of personal data and could pose a high risk due to their sensitivity. This includes using new technology, making it harder for individuals to exercise their rights, processing special categories of personal data, or monitoring public areas. An assessment is also needed when the supervisory authority believes the processing could pose a high risk to individual's rights and freedoms. However, individual health care professionals or lawyers processing their patients or clients' data are not considered large-scale and don't require an assessment."
General Data Protection Regulation (GDPR) - Article 7 Conditions for consent,0.720835507,"Details of Article 7 Conditions for consent in the General Data Protection Regulation (GDPR): 1. Where processing is based on consent, the controller shall be able to demonstrate that the data subject has consented to processing of his or her personal data. 2. If the data subject's consent is given in the context of a written declaration which also concerns other matters, the request for consent shall be presented in a manner which is clearly distinguishable from the other matters, in an intelligible and easily accessible form, using clear and plain language. Any part of such a declaration which constitutes an infringement of this Regulation shall not be binding. 3. The data subject shall have the right to withdraw his or her consent at any time. The withdrawal of consent shall not affect the lawfulness of processing based on consent before its withdrawal. Prior to giving consent, the data subject shall be informed thereof. It shall be as easy to withdraw as to give consent. 4. When assessing whether consent is freely given, utmost account shall be taken of whether, inter alia, the performance of a contract, including the provision of a service, is conditional on consent to the processing of personal data that is not necessary for the performance of that contract.",article,"The General Data Protection Regulation (GDPR) Article 7 outlines rules for obtaining consent to use personal data. The company must prove that the person agreed to their data being used. If the agreement is part of a larger document, the consent part must be clear and easy to understand. Any part of the agreement that breaks these rules is not valid. People can withdraw their consent at any time, and it should be as easy to withdraw consent as it is to give it. This won't affect any data use that happened before the consent was withdrawn. When checking if consent was freely given, it's important to consider whether agreeing to data use was a condition of a contract or service, especially if the data isn't necessary for that contract or service."
Artifical Inellegence Act (AI Act) - Definition of 'emotion recognition system',0.720824301,"Within the Aritifical Intelligence Act (AI Act), the Definition of emotion recognition system means an AI system for the purpose of identifying or inferring emotions or intentions of natural persons on the basis of their biometric data;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'emotion recognition system'. This refers to a type of artificial intelligence (AI) system that is designed to identify or guess the emotions or intentions of real people by analyzing their biometric data (like facial expressions, heart rate, etc.)."
Digital Services Act (DSA) - Article 27 Recommender system transparency,0.720820427,"Article 27 Recommender system transparency in the Digital Services Act (DSA):  1.   Providers of online platforms that use recommender systems shall set out in their terms and conditions, in plain and intelligible language, the main parameters used in their recommender systems, as well as any options for the recipients of the service to modify or influence those main parameters.

2.   The main parameters referred to in paragraph 1 shall explain why certain information is suggested to the recipient of the service. They shall include, at least:

(a) the criteria which are most significant in determining the information suggested to the recipient of the service;
(b) the reasons for the relative importance of those parameters.

3.   Where several options are available pursuant to paragraph 1 for recommender systems that determine the relative order of information presented to recipients of the service, providers of online platforms shall also make available a functionality that allows the recipient of the service to select and to modify at any time their preferred option. That functionality shall be directly and easily accessible from the specific section of the online platform's online interface where the information is being prioritised.",article,"The Digital Services Act (DSA) has a new rule, Article 27, about transparency in online recommendation systems. Online platform providers must clearly explain in their terms and conditions how their recommendation systems work and how users can change the settings. This includes explaining why certain information is suggested to users and the criteria used to determine these suggestions. If there are different options for how information is presented, users should be able to easily choose and change their preference at any time. This option should be easily accessible where the information is being prioritized on the platform."
Artifical Inellegence Act (AI Act) - Article 12,0.720780075,"Aritifical Intelligence Act (AI Act) Article 12 Record-keeping: 

1.High-risk AI systems shall be designed and developed with capabilities enabling the automatic recording of events (logs) while the high-risk AI systems is operating. Those logging capabilities shall conform to recognised standards or common specifications.

2.The logging capabilities shall ensure a level of traceability of the AI systems functioning throughout its lifecycle that is appropriate to the intended purpose of the system.

3.In particular, logging capabilities shall enable the monitoring of the operation of the high-risk AI system with respect to the occurrence of situations that may result in the AI system presenting a risk within the meaning of Article 65(1) or lead to a substantial modification, and facilitate the post-market monitoring referred to in Article 61.

4.For high-risk AI systems referred to in paragraph 1, point (a) of Annex III, the logging capabilities shall provide, at a minimum:

(a)recording of the period of each use of the system (start date and time and end date and time of each use);

(b)the reference database against which input data has been checked by the system;

(c)the input data for which the search has led to a match;

(d)the identification of the natural persons involved in the verification of the results, as referred to in Article 14 (5).",article,"The Artificial Intelligence Act (AI Act) requires high-risk AI systems to automatically record events (logs) during operation, following recognized standards. These logs should track the AIs functioning throughout its lifespan, relevant to its intended use. The logs should monitor the AI system's operation, especially in situations that might present a risk or lead to significant changes. They should also help with post-market monitoring. For certain high-risk AI systems, the logs must at least record the duration of each use, the reference database checked by the system, the data that matched the search, and the identification of the individuals verifying the results."
Digital Markets Act (DMA) - Contextual Paragraph (31),0.720719934,"Details of the Contextual Paragraph (31) in the Digital Markets Act (DMA): To safeguard the contestability and fairness of core platform services provided by gatekeepers, it is necessary to provide in a clear and unambiguous manner for a set of harmonised rules with regard to those services. Such rules are needed to address the risk of harmful effects of practices by gatekeepers, to the benefit of the business environment in the services concerned, of users and ultimately of society as a whole. The obligations correspond to those practices that are considered as undermining contestability or as being unfair, or both, when taking into account the features of the digital sector and which have a particularly negative direct impact on business users and end users. It should be possible for the obligations laid down by this Regulation to specifically take into account the nature of the core platform services provided. The obligations in this Regulation should not only ensure contestability and fairness with respect to core platform services listed in the designation decision, but also with respect to other digital products and services into which gatekeepers leverage their gateway position, which are often provided together with, or in support of, the core platform services.",rectial,"The Digital Markets Act (DMA) is a new law that aims to ensure fairness and competition in digital platform services provided by major tech companies, also known as gatekeepers. It introduces a set of rules to prevent harmful practices by these gatekeepers that could negatively impact businesses, users, and society. The rules are designed to prevent these companies from exploiting their dominant position, especially in relation to other digital products and services. The DMA is not just about maintaining competition, but also about ensuring fairness in the digital sector."
Digital Markets Act (DMA) - Contextual Paragraph (77),0.72066772,"Details of the Contextual Paragraph (77) in the Digital Markets Act (DMA): The services in the digital sector and the types of practices relating to these services can change quickly and to a significant extent. To ensure that this Regulation remains up to date and constitutes an effective and holistic regulatory response to the problems posed by gatekeepers, it is important to provide for a regular review of the lists of core platform services, as well as of the obligations provided for in this Regulation. This is particularly important to ensure that a practice that is likely to limit the contestability of core platform services or is unfair is identified. While it is important to conduct a review on a regular basis, given the dynamically changing nature of the digital sector, in order to ensure legal certainty as to the regulatory conditions, any reviews should be conducted within a reasonable and appropriate timeframe. Market investigations should also ensure that the Commission has a solid evidentiary basis on which it can assess whether it should propose to amend this Regulation in order to review, expand, or further detail, the lists of core platform services. They should equally ensure that the Commission has a solid evidentiary basis on which it can assess whether it should propose to amend the obligations laid down in this Regulation or whether it should adopt a delegated act updating such obligations.",rectial,"The Digital Markets Act (DMA) acknowledges that the digital sector changes rapidly. To keep up, the DMA will regularly review its list of core platform services and its regulations. This is to ensure that any practices that could limit competition or are unfair are identified. Reviews will be conducted within a reasonable timeframe to provide legal certainty. The DMA will also conduct market investigations to ensure it has enough evidence to decide whether it needs to amend its regulations or update its obligations."
General Data Protection Regulation (GDPR) - Contextual Paragraph (53),0.720618248,"Details of the Contextual Paragraph (53) in the General Data Protection Regulation (GDPR): Special categories of personal data which merit higher protection should be processed for health-related purposes only where necessary to achieve those purposes for the benefit of natural persons and society as a whole, in particular in the context of the management of health or social care services and systems, including processing by the management and central national health authorities of such data for the purpose of quality control, management information and the general national and local supervision of the health or social care system, and ensuring continuity of health or social care and cross-border healthcare or health security, monitoring and alert purposes, or for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes, based on Union or Member State law which has to meet an objective of public interest, as well as for studies conducted in the public interest in the area of public health. Therefore, this Regulation should provide for harmonised conditions for the processing of special categories of personal data concerning health, in respect of specific needs, in particular where the processing of such data is carried out for certain health-related purposes by persons subject to a legal obligation of professional secrecy. Union or Member State law should provide for specific and suitable measures so as to protect the fundamental rights and the personal data of natural persons. Member States should be allowed to maintain or introduce further conditions, including limitations, with regard to the processing of genetic data, biometric data or data concerning health. However, this should not hamper the free flow of personal data within the Union when those conditions apply to cross-border processing of such data.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 53) that focuses on protecting special categories of personal data, particularly health-related data. This data can only be used when necessary for the benefit of individuals and society, such as for managing health or social care services, quality control, research, or public health studies. The law aims to create uniform conditions for handling this sensitive data, while also respecting professional secrecy obligations. It allows individual countries in the Union to add further conditions or limitations on processing certain types of data (like genetic or biometric data), as long as these don't restrict the free movement of personal data within the Union for cross-border processing."
Artifical Inellegence Act (AI Act) - Overview paragraph 31,0.720618248,"Aritifical Intelligence Act (AI Act) overview paragraph (31): The classification of an AI system as high-risk pursuant to this Regulation should not necessarily mean that the product whose safety component is the AI system, or the AI system itself as a product, is considered high-risk under the criteria established in the relevant Union harmonisation legislation that applies to the product. This is notably the case for Regulation (EU) 2017/745 of the European Parliament and of theCouncil47and Regulation (EU) 2017/746 of the European Parliament and of the Council48, where a third-party conformity assessment is provided for medium-risk and high-risk products.",recital,"The Artificial Intelligence Act (AI Act) states that if an AI system is classified as high-risk, it doesn't automatically mean that the product using this AI system, or the AI system itself, is considered 'high-risk' under existing European Union laws. This is particularly true for Regulation (EU) 2017/745 and Regulation (EU) 2017/746, where a third-party checks the safety of medium-risk and high-risk products."
General Data Protection Regulation (GDPR) - Article 17 Right to erasure ('right to be forgotten'),0.720613897,"Details of Article 17 Right to erasure (right to be forgotten) in the General Data Protection Regulation (GDPR): 1. The data subject shall have the right to obtain from the controller the erasure of personal data concerning him or her without undue delay and the controller shall have the obligation to erase personal data without undue delay where one of the following grounds applies: (a) the personal data are no longer necessary in relation to the purposes for which they were collected or otherwise processed; (b) the data subject withdraws consent on which the processing is based according to point (a) of Article 6(1), or point (a) of Article 9(2), and where there is no other legal ground for the processing; (c) the data subject objects to the processing pursuant to Article 21(1) and there are no overriding legitimate grounds for the processing, or the data subject objects to the processing pursuant to Article 21(2); (d) the personal data have been unlawfully processed; (e) the personal data have to be erased for compliance with a legal obligation in Union or Member State law to which the controller is subject; (f) the personal data have been collected in relation to the offer of information society services referred to in Article 8(1). 2. Where the controller has made the personal data public and is obliged pursuant to paragraph 1 to erase the personal data, the controller, taking account of available technology and the cost of implementation, shall take reasonable steps, including technical measures, to inform controllers which are processing the personal data that the data subject has requested the erasure by such controllers of any links to, or copy or replication of, those personal data. 3. Paragraphs 1 and 2 shall not apply to the extent that processing is necessary: (a) for exercising the right of freedom of expression and information; (b) for compliance with a legal obligation which requires processing by Union or Member State law to which the controller is subject or for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller; (c) for reasons of public interest in the area of public health in accordance with points (h) and (i) of Article 9(2) as well as Article 9(3); (d) for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes in accordance with Article 89(1) in so far as the right referred to in paragraph 1 is likely to render impossible or seriously impair the achievement of the objectives of that processing; or (e) for the establishment, exercise or defence of legal claims.",article,"Article 17 of the General Data Protection Regulation (GDPR) provides the 'right to be forgotten', meaning individuals can ask for their personal data to be deleted without unnecessary delay. This can happen if the data is no longer needed, if the individual withdraws their consent, objects to the data processing, if the data was processed unlawfully, or if erasing the data is a legal requirement. If the data has been made public, the organization must make reasonable efforts to inform others processing the data about the erasure request. However, there are exceptions where data processing is necessary, such as for freedom of expression, legal obligations, public health reasons, archiving for public interest, research, statistical purposes, or for legal claims."
California Consumer Privacy Act Regulations (CCPA) - Definition of Third-party identity verification service,0.720575452,Details of Definition of Third-party identity verification service in the California Consumer Privacy Act Regulations (CCPA): Third-party identity verification service means a security process offered by an independent third party that verifies the identity of the consumer making a request to the business. Third-party identity verification services are subject to the requirements set forth in Article 4 regarding requests to know and requests to delete.,recital,"The California Consumer Privacy Act (CCPA) defines a ""third-party identity verification service"" as a security procedure provided by an independent company to confirm the identity of a customer making a request to a business. These services must follow the rules outlined in Article 4 of the CCPA, which pertain to requests to access or delete personal information."
General Data Protection Regulation (GDPR) - Article 95 Relationship with Directive 2002/58/EC,0.720469,Details of Article 95 Relationship with Directive 2002/58/EC in the General Data Protection Regulation (GDPR): This Regulation shall not impose additional obligations on natural or legal persons in relation to processing in connection with the provision of publicly available electronic communications services in public communication networks in the Union in relation to matters for which they are subject to specific obligations with the same objective set out in Directive 2002/58/EC.,article,"Article 95 of the General Data Protection Regulation (GDPR) states that individuals or businesses providing public electronic communication services in the European Union won't have extra obligations imposed on them by this regulation. If they're already following specific obligations under Directive 2002/58/EC, which has the same goal as the GDPR, they won't have to do anything extra."
Digital Services Act (DSA) - Contextual paragraph (141),0.720461249,"Details of the contextual paragraph (141) of the Digital Services Act (DSA): The Commission should be able to request information necessary for the purpose of ensuring the effective implementation of and compliance with the obligations laid down in this Regulation, throughout the Union. In particular, the Commission should have access to any relevant documents, data and information necessary to open and conduct investigations and to monitor the compliance with the relevant obligations laid down in this Regulation, irrespective of who possesses the documents, data or information in question, and regardless of their form or format, their storage medium, or the precise place where they are stored. The Commission should be able to directly require by means of a duly substantiated request for information that the provider of the very large online platform or of the very large online search engine concerned as well as any other natural or legal persons acting for purposes related to their trade, business, craft or profession that may be reasonably aware of information relating to the suspected infringement or the infringement, as applicable, provide any relevant evidence, data and information. In addition, the Commission should be able to request any relevant information from any public authority, body or agency within the Member State for the purpose of this Regulation. The Commission should be able to require access to, and explanations by means of exercise of investigatory powers, such as requests for information or interviews, relating to documents, data, information, data-bases and algorithms of relevant persons, and to interview, with their consent, any natural or legal persons who may be in possession of useful information and to record the statements made by any technical means. The Commission should also be empowered to undertake such inspections as are necessary to enforce the relevant provisions of this Regulation. Those investigatory powers aim to complement the Commission's possibility to ask Digital Services Coordinators and other Member States' authorities for assistance, for instance by providing information or in the exercise of those powers.",recital,"The Digital Services Act (DSA) allows the European Commission to request any necessary information to ensure that online platforms and search engines are complying with the law. This includes access to documents, data, and information needed for investigations, regardless of who has them or where they're stored. The Commission can request this information from the platform providers, anyone associated with their business who might have relevant information, and any public authority within the EU. The Commission can also conduct interviews and inspections as needed. This power complements the Commission's ability to ask for help from Digital Services Coordinators and authorities in EU member states."
Digital Services Act (DSA) - Article 5 Caching,0.720451355,"Article 5 Caching in the Digital Services Act (DSA):  1.   Where an information society service is provided that consists of the transmission in a communication network of information provided by a recipient of the service, the service provider shall not be liable for the automatic, intermediate and temporary storage of that information, performed for the sole purpose of making more efficient or more secure the information's onward transmission to other recipients of the service upon their request, on condition that the provider:
(a) does not modify the information;
(b) complies with conditions on access to the information;
(c) complies with rules regarding the updating of the information, specified in a manner widely recognised and used by industry;
(d) does not interfere with the lawful use of technology, widely recognised and used by industry, to obtain data on the use of the information; and
(e) acts expeditiously to remove or to disable access to the information it has stored upon obtaining actual knowledge of the fact that the information at the initial source of the transmission has been removed from the network, or access to it has been disabled, or that a judicial or an administrative authority has ordered such removal or disablement.
2.   This Article shall not affect the possibility for a judicial or administrative authority, in accordance with a Member State's legal system, to require the service provider to terminate or prevent an infringement.",article,"The Digital Services Act (DSA) has a new rule, Article 5, about data caching. It says that if a company stores data temporarily to make its service better or safer, it won't be held responsible for that data. However, it mustn't change the data, must follow access and update rules, and mustn't interfere with legal data use. If the company learns that the original data has been removed or blocked, or if a court orders it, the company must quickly remove or block access to the stored data. This rule doesn't stop courts from ordering the company to stop or prevent illegal activities."
Artifical Inellegence Act (AI Act) - Context Section 3.4,0.720393777,"Aritifical Intelligence Act (AI Act) context section 3.4.Regulatory fitness and simplification: 

This proposal lays down obligation that will apply to providers and users of high-risk AI systems. For providers who develop and place such systems on the Union market, it will create legal certainty and ensure that no obstacle to the cross-border provision of AI-related services and products emerge. For companies using AI, it will promote trust among their customers. For national public administrations, it will promote public trust in the use of AI and strengthen enforcement mechanisms (by introducing a European coordination mechanism, providing for appropriate capacities, and facilitating audits of the AI systems with new requirements for documentation, traceability and transparency). Moreover, the framework will envisage specific measures supporting innovation, including regulatory sandboxes and specific measures supporting small-scale users and providers of high-risk AI systems to comply with the new rules.

The proposal also specifically aims at strengthening Europes competitiveness and industrial basis in AI. Full consistency is ensured with existing sectoral Union legislation applicable to AI systems (e.g. on products and services) that will bring further clarity and simplify the enforcement of the new rules.3.4.Regulatory fitness and simplification:

This proposal lays down obligation that will apply to providers and users of high-risk AI systems. For providers who develop and place such systems on the Union market, it will create legal certainty and ensure that no obstacle to the cross-border provision of AI-related services and products emerge. For companies using AI, it will promote trust among their customers. For national public administrations, it will promote public trust in the use of AI and strengthen enforcement mechanisms (by introducing a European coordination mechanism, providing for appropriate capacities, and facilitating audits of the AI systems with new requirements for documentation, traceability and transparency). Moreover, the framework will envisage specific measures supporting innovation, including regulatory sandboxes and specific measures supporting small-scale users and providers of high-risk AI systems to comply with the new rules.

The proposal also specifically aims at strengthening Europes competitiveness and industrial basis in AI. Full consistency is ensured with existing sectoral Union legislation applicable to AI systems (e.g. on products and services) that will bring further clarity and simplify the enforcement of the new rules.",recital,"The Artificial Intelligence Act (AI Act) is a new law that sets rules for companies that create or use high-risk AI systems. The law aims to make the use of AI safer and more trustworthy, by setting standards for documentation, traceability, and transparency. It also includes measures to encourage innovation, like regulatory sandboxes, and support for smaller users and providers of AI. The law is designed to make sure AI-related services and products can be provided across borders without any issues. It also aims to strengthen Europe's position in the AI industry. The AI Act is in line with existing laws related to AI systems, which will make it easier to enforce."
Artifical Inellegence Act (AI Act) - Overview paragraph 72,0.72038275,"Aritifical Intelligence Act (AI Act) overview paragraph (72): The objectives of the regulatory sandboxes should be to foster AI innovation by establishing a controlled experimentation and testing environment in the development and pre-marketing phase with a view to ensuring compliance of the innovative AI systems with this Regulation and other relevant Union and Member States legislation; to enhance legal certainty for innovators and the competent authorities oversight and understanding of the opportunities, emerging risks and the impacts of AI use, and to accelerate access to markets, including by removing barriers for small and medium enterprises (SMEs) and start-ups. To ensure uniform implementation across the Union and economies of scale, it is appropriate to establish common rules for the regulatory sandboxes implementation and a framework for cooperation between the relevant authorities involved in the supervision of the sandboxes. This Regulation should provide the legal basis for the use of personal data collected for other purposes for developing certain AI systems in the public interest within the AI regulatory sandbox, in line with Article 6(4) of Regulation (EU) 2016/679, and Article 6 of Regulation (EU) 2018/1725, and without prejudice to Article 4(2) of Directive (EU) 2016/680. Participants in the sandbox should ensure appropriate safeguards and cooperate with the competent authorities, including by following their guidance and actingexpeditiously and in good faith to mitigate any high-risks to safety and fundamental rights that may arise during the development and experimentation in the sandbox. The conduct of the participants in the sandbox should be taken into account when competent authorities decide whether to impose an administrative fine under Article 83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.",recital,"The Artificial Intelligence Act (AI Act) aims to encourage AI innovation by creating a controlled environment for testing and developing AI systems before they are marketed. This is to ensure these systems comply with this law and other relevant laws in the Union and Member States. The Act also aims to provide legal clarity for innovators and improve oversight by authorities, while speeding up market access, especially for small and medium enterprises and start-ups. The Act sets common rules for these testing environments, or 'regulatory sandboxes', and outlines how authorities should cooperate. It also allows for personal data collected for other purposes to be used in the development of certain AI systems in the public interest within these sandboxes. Participants must ensure they have appropriate safeguards and work closely with authorities to quickly address any high-risk issues that may arise. Their conduct in the sandbox may influence whether authorities decide to impose fines."
Digital Services Act (DSA) - Definition of 'dissemination to the public',0.720380604,"Definition of 'dissemination to the public' in the Digital Services Act (DSA): making information available, at the request of the recipient of the service who provided the information, to a potentially unlimited number of third parties.",recital,"The Digital Services Act (DSA) has a new definition for 'dissemination to the public'. This means that if you, as a user of a digital service, provide certain information, that info could be made available to an unlimited number of third parties if you request it. In simpler terms, it's like you're giving permission for your information to be shared widely if you ask for it to be."
Digital Services Act (DSA) - Contextual paragraph (122),0.720332682,"Details of the contextual paragraph (122) of the Digital Services Act (DSA): The Digital Services Coordinator should regularly publish, for example on its website, a report on the activities carried out under this Regulation. In particular, the report should be published in a machine-readable format and include an overview of complaints received and of their follow-up, such as the overall number of complaints received and the number of complaints that led to the opening of a formal investigation or to the transmission to other Digital Services Coordinators, without referring to any personal data. Given that the Digital Services Coordinator is also made aware of orders to take action against illegal content or to provide information regulated by this Regulation through the information sharing system, the Digital Services Coordinator should include in its annual report the number and categories of such orders addressed to providers of intermediary services issued by judicial and administrative authorities in its Member State.",recital,"The Digital Services Act (DSA) requires the Digital Services Coordinator to regularly publish a report on their website about their activities. This report should include information about the number of complaints received, how they were handled, and whether they led to a formal investigation or were passed on to other coordinators. The report should not include any personal data. Additionally, the report should include the number and types of orders given to intermediary service providers to take action against illegal content or to provide information. These orders are issued by legal and administrative authorities in the coordinator's member state."
Artifical Inellegence Act (AI Act) - Overview paragraph 16,0.72033143,"Aritifical Intelligence Act (AI Act) overview paragraph (16): The placing on the market, putting into service or use of certain AI systems intended to distorthumanbehaviour, whereby physical or psychological harms are likely to occur, should be forbidden. Such AI systems deploy subliminal components individuals cannot perceive or exploit vulnerabilities ofchildren andpeople due to their age, physical or mental incapacities. They do so with the intention to materially distort the behaviour of a person and in a manner that causes or is likely to cause harm to that or another person. The intention may not be presumed if the distortion of human behaviour results from factors external to the AI system which are outside of the control of the provider or the user. Research for legitimate purposes in relation to such AI systems should not be stifled by the prohibition, if such research does not amount to use of the AI system in human-machine relations that exposes natural persons to harm and such research is carried out in accordance with recognised ethical standards for scientific research.",recital,"The Artificial Intelligence Act (AI Act) prohibits the use of certain AI systems that are designed to manipulate human behavior in a way that could cause physical or psychological harm. This includes AI systems that use subliminal messages or take advantage of vulnerabilities in children or individuals with physical or mental disabilities. The law does not apply if the harmful behavior is caused by factors outside of the AI system's control. However, the law does not prevent legitimate research related to these AI systems, provided that the research follows ethical standards and does not expose people to harm."
General Data Protection Regulation (GDPR) - Article 3 Territorial scope ,0.720257103,"Details of Article 3 Territorial scope  in the General Data Protection Regulation (GDPR): 1. This Regulation applies to the processing of personal data in the context of the activities of an establishment of a controller or a processor in the Union, regardless of whether the processing takes place in the Union or not. 2. This Regulation applies to the processing of personal data of data subjects who are in the Union by a controller or processor not established in the Union, where the processing activities are related to: (a) the offering of goods or services, irrespective of whether a payment of the data subject is required, to such data subjects in the Union; or (b) the monitoring of their behaviour as far as their behaviour takes place within the Union. 3. This Regulation applies to the processing of personal data by a controller not established in the Union, but in a place where Member State law applies by virtue of public international law.",recital,"The General Data Protection Regulation (GDPR) Article 3 is about where the law applies. It applies to any company in the EU that processes personal data, even if the data processing happens outside the EU. It also applies to companies outside the EU if they process data of people inside the EU, whether they're selling goods or services to them, or monitoring their behavior. Lastly, it applies to companies outside the EU that process personal data in places where EU law is enforced due to international agreements."
Digital Markets Act (DMA) - Contextual Paragraph (22),0.720220208,"Details of the Contextual Paragraph (22) in the Digital Markets Act (DMA): Such thresholds can be affected by market and technical developments. The Commission should therefore be empowered to adopt delegated acts to specify the methodology for determining whether the quantitative thresholds are met, and to regularly adjust it to market and technological developments where necessary. Such delegated acts should not amend the quantitative thresholds set out in this Regulation.",rectial,"The Digital Markets Act (DMA) includes a clause (Paragraph 22) that allows the Commission to adjust the methods used to determine if certain market limits have been met. These adjustments can be made in response to changes in the market or technology. However, the Commission does not have the power to change the actual market limits established in the law. This ensures that the law remains flexible and applicable in a rapidly changing digital landscape."
General Data Protection Regulation (GDPR) - Article 84 Penalties,0.720214903,"Details of Article 84 Penalties in the General Data Protection Regulation (GDPR): 1. Member States shall lay down the rules on other penalties applicable to infringements of this Regulation in particular for infringements which are not subject to administrative fines pursuant to Article 83, and shall take all measures necessary to ensure that they are implemented. Such penalties shall be effective, proportionate and dissuasive. 2. Each Member State shall notify to the Commission the provisions of its law which it adopts pursuant to paragraph 1, by 25 May 2018 and, without delay, any subsequent amendment affecting them.",article,"Article 84 of the General Data Protection Regulation (GDPR) states that each member country must establish its own rules for penalties related to violations of this regulation. These penalties should be effective, reasonable, and discouraging. Each country must inform the Commission about these rules by May 25, 2018, and must promptly report any changes to these rules. This is especially important for violations that are not covered by administrative fines under Article 83."
Artifical Inellegence Act (AI Act) - Definition of 'biometric categorisation system',0.720214605,"Within the Aritifical Intelligence Act (AI Act), the Definition of biometric categorisation system means an AI system for the purpose of assigning natural persons to specific categories, such as sex, age, hair colour, eye colour, tattoos, ethnic origin or sexual or political orientation, on the basis of their biometric data;",recital,"The Artificial Intelligence Act (AI Act) introduces the term 'biometric categorisation system'. This refers to an AI system that categorizes people into different groups based on their biometric data. The categories can include things like sex, age, hair color, eye color, tattoos, ethnic background, or even political or sexual orientation."
Artifical Inellegence Act (AI Act) - Overview paragraph 57,0.720193744,"Aritifical Intelligence Act (AI Act) overview paragraph (57): In line with New Legislative Framework principles, specific obligations for relevant economic operators, such as importers and distributors, should be set to ensure legal certainty and facilitate regulatory compliance by those relevant operators.",recital,"The Artificial Intelligence Act (AI Act) sets out new rules for businesses involved in importing and distributing products. These businesses, known as economic operators, will have specific legal responsibilities to follow. This is to make sure everyone understands the law and can easily follow it. The law is designed to provide clarity and ensure everyone involved in these operations is compliant with the regulations."
Artifical Inellegence Act (AI Act) - Overview paragraph 4,0.720136166,"Aritifical Intelligence Act (AI Act) overview paragraph (4): At the same time, depending on the circumstances regarding its specific application and use, artificial intelligence may generate risks and cause harm to public interests and rights that are protected by Union law. Such harm might be material or immaterial.",recital,"The Artificial Intelligence Act (AI Act) acknowledges that while artificial intelligence (AI) can be beneficial, it can also pose risks and potentially harm public interests and rights protected by Union law. This harm could be either physical or non-physical, depending on how AI is applied and used. The law aims to regulate these potential risks and ensure that AI is used responsibly and safely."
Artifical Inellegence Act (AI Act) - Overview paragraph 75,0.720128179,"Aritifical Intelligence Act (AI Act) overview paragraph (75): It is appropriate that the Commission facilitates, to the extent possible, access to Testing and Experimentation Facilities to bodies, groups or laboratories established or accredited pursuant to any relevant Union harmonisation legislation and which fulfil tasks in the context of conformity assessment of products or devices covered by that Union harmonisation legislation. This is notably the case for expert panels, expert laboratories and reference laboratories in the field of medical devices pursuant to Regulation (EU) 2017/745 and Regulation (EU) 2017/746.",recital,"The Artificial Intelligence Act (AI Act) aims to make it easier for certain groups, bodies, or labs to access Testing and Experimentation Facilities. These groups must be established or accredited under relevant Union legislation and must be involved in assessing the conformity of products or devices under that legislation. This particularly applies to expert panels and labs in the medical devices field, as regulated by Regulation (EU) 2017/745 and Regulation (EU) 2017/746."
General Data Protection Regulation (GDPR) - Contextual Paragraph (90),0.720116496,"Details of the Contextual Paragraph (90) in the General Data Protection Regulation (GDPR): In such cases, a data protection impact assessment should be carried out by the controller prior to the processing in order to assess the particular likelihood and severity of the high risk, taking into account the nature, scope, context and purposes of the processing and the sources of the risk. That impact assessment should include, in particular, the measures, safeguards and mechanisms envisaged for mitigating that risk, ensuring the protection of personal data and demonstrating compliance with this Regulation.",recital,"The General Data Protection Regulation (GDPR) requires companies to conduct a data protection impact assessment before processing personal data. This assessment is necessary when there's a high risk to the privacy of individuals. The assessment should evaluate the potential risk and its severity, considering factors like why the data is being processed, the extent of data processing, and the source of risk. The assessment should also outline the steps taken to reduce the risk, protect personal data, and show that the company is following the GDPR."
Artifical Inellegence Act (AI Act) - Definition of 'operator',0.720116258,"Within the Aritifical Intelligence Act (AI Act), the Definition of operator means the provider, the user, the authorised representative, the importer and the distributor;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'operator'. This term refers to anyone who is a provider, user, authorized representative, importer, or distributor. In simpler terms, if you're involved in any way with the supply, use, representation, import, or distribution of artificial intelligence, you're considered an 'operator' under this law."
Digital Markets Act (DMA) - Article 23 Powers to conduct inspections,0.720031321,"Details of Article 23 Powers to conduct inspections in the Digital Markets Act (DMA): 1. In order to carry out its duties under this Regulation, the Commission may conduct all necessary inspections of an undertaking or association of undertakings. 2. The officials and other accompanying persons authorised by the Commission to conduct an inspection are empowered to: (a) enter any premises, land and means of transport of undertakings and associations of undertakings; (b) examine the books and other records related to the business, irrespective of the medium on which they are stored; (c) take or obtain in any form copies of or extracts from such books or records; (d) require the undertaking or association of undertakings to provide access to and explanations on its organisation, functioning, IT system, algorithms, data-handling and business practices and to record or document the explanations given by any technical means; (e) seal any business premises and books or records for the duration of, and to the extent necessary for, the inspection; (f) ask any representative or member of staff of the undertaking or association of undertakings for explanations of facts or documents relating to the subject-matter and purpose of the inspection, and to record the answers by any technical means. 3. To carry out inspections, the Commission may request the assistance of auditors or experts appointed by the Commission pursuant to Article 26(2), as well as the assistance of the national competent authority of the Member State, enforcing the rules referred to in Article 1(6) in whose territory the inspection is to be conducted. 4. During inspections the Commission, auditors or experts appointed by it and the national competent authority of the Member State, enforcing the rules referred to in Article 1(6) in whose territory the inspection is to be conducted may require the undertaking or association of undertakings to provide access to and explanations on its organisation, functioning, IT system, algorithms, data-handling and business conducts. The Commission and auditors or experts appointed by it and the national competent authority of the Member State, enforcing the rules referred to in Article 1(6) in whose territory the inspection is to be conducted may address questions to any representative or member of staff. 5. The officials and other accompanying persons authorised by the Commission to conduct an inspection shall exercise their powers upon production of a written authorisation specifying the subject matter and purpose of the inspection and the fines provided for in Article 30 applicable in the event that the production of the required books or other records related to the business is incomplete or where the answers to questions asked under paragraphs 2 and 4 of this Article are incorrect or misleading. In good time before the inspection, the Commission shall give notice of the inspection to the national competent authority of the Member State enforcing the rules referred to in Article 1(6) in whose territory it is to be conducted. 6. Undertakings or associations of undertakings are required to submit to an inspection ordered by a Commission decision. That decision shall specify the subject matter and purpose of the inspection, set the date on which it is to begin and indicate the fines and periodic penalty payments provided for in Articles 30 and 31 respectively, and the right to have that decision reviewed by the Court of Justice. 7. Officials of, and the persons authorised or appointed by, the national competent authority of the Member State enforcing the rules referred to in Article 1(6) in whose territory the inspection is to be conducted shall, at the request of that authority or of the Commission, actively assist the officials and other accompanying persons authorised by the Commission. To this end, they shall enjoy the powers set out in paragraphs 2 and 4 of this Article. 8. Where the officials and other accompanying persons authorised by the Commission find that an undertaking or association of undertakings opposes an inspection ordered pursuant to this Article, the Member State concerned shall afford them the necessary assistance, requesting, where appropriate, the assistance of the police or of an equivalent enforcement authority, so as to enable them to conduct their inspection. 9. If, according to national rules, the assistance provided for in paragraph 8 of this Article requires authorisation from a judicial authority, the Commission or the national competent authority of the Member State enforcing the rules referred to in Article 1(6) or officials authorised by those authorities shall apply for it. Such authorisation may also be applied for as a precautionary measure. 10. Where authorisation referred to in paragraph 9 of this Article is applied for, the national judicial authority shall verify that the Commission decision is authentic and that the coercive measures envisaged are neither arbitrary nor excessive having regard to the subject matter of the inspection. In its control of the proportionality of the coercive measures, the national judicial authority may ask the Commission, directly or through the national competent authority of the Member State, enforcing the rules referred to in Article 1(6), for detailed explanations in particular on the grounds the Commission has for suspecting infringement of this Regulation, as well as on the seriousness of the suspected infringement and on the nature of the involvement of the undertaking concerned. However, the national judicial authority may not call into question the necessity of the inspection nor demand that it be provided with the information in the file of the Commission. The lawfulness of the Commission decision shall be subject to review only by the Court of Justice.",article,"The Digital Markets Act (DMA) gives the European Commission the power to inspect businesses for compliance. Officials can enter any business premises, examine books and records, take copies, and ask for explanations about the business's operations, IT systems, data handling, and business practices. They can also seal premises and records during an inspection. The Commission may enlist auditors or experts, and request assistance from the national authority of the member state where the inspection is taking place. Inspections require written authorization detailing the purpose, subject matter, and potential fines. Businesses must comply with inspections, which can be ordered by a Commission decision. If a business resists, the member state must provide necessary assistance, potentially involving police or equivalent enforcement authority. If national rules require judicial authorization for such assistance, the Commission or national authority must apply for it. The national judicial authority verifies the authenticity of the Commission decision and ensures the measures are not arbitrary or excessive. The lawfulness of the Commission decision can only be reviewed by the Court of Justice."
Digital Services Act (DSA) - Article 44 Standards,0.720023453,"Article 44 Standards in the Digital Services Act (DSA):  1.   The Commission shall consult the Board, and shall support and promote the development and implementation of voluntary standards set by relevant European and international standardisation bodies, at least in respect of the following:

(a) electronic submission of notices under Article 16;
(b) templates, design and process standards for communicating with the recipients of the service in a user-friendly manner on restrictions resulting from terms and conditions and changes thereto;
(c) electronic submission of notices by trusted flaggers under Article 22, including through application programming interfaces;
(d) specific interfaces, including application programming interfaces, to facilitate compliance with the obligations set out in Articles 39 and 40;
(e) auditing of very large online platforms and of very large online search engines pursuant to Article 37;
(f) interoperability of the advertisement repositories referred to in Article 39(2);
(g) transmission of data between advertising intermediaries in support of transparency obligations pursuant to Article 26(1), points (b), (c) and (d);
(h) technical measures to enable compliance with obligations relating to advertising contained in this Regulation, including the obligations regarding prominent markings for advertisements and commercial communications referred to in Article 26;
(i) choice interfaces and presentation of information on the main parameters of different types of recommender systems, in accordance with Articles 27 and 38;
(j) standards for targeted measures to protect minors online.

2.   The Commission shall support the update of the standards in the light of technological developments and the behaviour of the recipients of the services in question. The relevant information regarding the update of the standards shall be publicly available and easily accessible.",article,"The Digital Services Act (DSA) requires the Commission to consult with the Board and promote the development of voluntary standards for digital services. These standards include creating user-friendly communication methods for service restrictions, electronic submission of notices, auditing of large online platforms and search engines, and data transmission between advertising intermediaries for transparency. The DSA also mandates technical measures to ensure compliance with advertising regulations and standards for protecting minors online. The Commission will also update these standards as technology advances and user behavior changes. Information about these updates will be publicly available and easy to access."
General Data Protection Regulation (GDPR) - Contextual Paragraph (69),0.720021546,"Details of the Contextual Paragraph (69) in the General Data Protection Regulation (GDPR): Where personal data might lawfully be processed because processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller, or on grounds of the legitimate interests of a controller or a third party, a data subject should, nevertheless, be entitled to object to the processing of any personal data relating to his or her particular situation. It should be for the controller to demonstrate that its compelling legitimate interest overrides the interests or the fundamental rights and freedoms of the data subject.",recital,"The General Data Protection Regulation (GDPR) has a clause (Paragraph 69) that allows people to object to their personal data being processed, even if it's done for public interest, official authority, or legitimate interests of the data handler or a third party. However, if the data handler can prove that their reason for processing the data is more important than the person's rights and freedoms, they can continue with the data processing."
Digital Services Act (DSA) - Article 31 Compliance by design,0.720019519,"Article 31 Compliance by design in the Digital Services Act (DSA):  1.   Providers of online platforms allowing consumers to conclude distance contracts with traders shall ensure that its online interface is designed and organised in a way that enables traders to comply with their obligations regarding pre-contractual information, compliance and product safety information under applicable Union law.

In particular, the provider concerned shall ensure that its online interface enables traders to provide information on the name, address, telephone number and email address of the economic operator, as defined in Article 3, point (13), of Regulation (EU) 2019/1020 and other Union law.

2.   Providers of online platforms allowing consumers to conclude distance contracts with traders shall ensure that its online interface is designed and organised in a way that it allows traders to provide at least the following:

(a) the information necessary for the clear and unambiguous identification of the products or the services promoted or offered to consumers located in the Union through the services of the providers;
(b) any sign identifying the trader such as the trademark, symbol or logo; and,
(c) where applicable, the information concerning the labelling and marking in compliance with rules of applicable Union law on product safety and product compliance.

3.   Providers of online platforms allowing consumers to conclude distance contracts with traders shall make best efforts to assess whether such traders have provided the information referred to in paragraphs 1 and 2 prior to allowing them to offer their products or services on those platforms. After allowing the trader to offer products or services on its online platform that allows consumers to conclude distance contracts with traders, the provider shall make reasonable efforts to randomly check in any official, freely accessible and machine-readable online database or online interface whether the products or services offered have been identified as illegal.",article,"The Digital Services Act (DSA) requires online platforms that enable consumers to make distance contracts with traders to design their interface in a way that allows traders to comply with their legal obligations. This includes providing pre-contractual information, compliance, and product safety information. The platform must also allow traders to provide clear identification of their products or services, their trademark, and any relevant labelling information. Before allowing traders to offer their products or services on the platform, the provider must check if they have provided all the necessary information. Afterward, the provider must occasionally check if the offered products or services have been identified as illegal."
Digital Services Act (DSA) - Article 71 Commitments,0.720007658,"Article 71 Commitments in the Digital Services Act (DSA):  1.   If, during proceedings under this Section, the provider of the very large online platform or of the very large online search engine concerned offers commitments to ensure compliance with the relevant provisions of this Regulation, the Commission may by decision make those commitments binding on the provider of the very large online platform or of the very large online search engine concerned and declare that there are no further grounds for action.

2.   The Commission may, upon request or on its own initiative, reopen the proceedings:

(a) where there has been a material change in any of the facts on which the decision was based;
(b) where the provider of the very large online platform or of the very large online search engine concerned acts contrary to its commitments; or
(c) where the decision was based on incomplete, incorrect or misleading information provided by the provider of the very large online platform or of the very large online search engine concerned or other person referred to in Article 67(1).

3.   Where the Commission considers that the commitments offered by the provider of the very large online platform or of the very large online search engine concerned are unable to ensure effective compliance with the relevant provisions of this Regulation, it shall reject those commitments in a reasoned decision when concluding the proceedings.",article,"The Digital Services Act (DSA) allows large online platforms and search engines to offer commitments to follow its rules during legal proceedings. If the European Commission agrees, these commitments become mandatory and no further action is taken. However, the Commission can reopen the case if there's a significant change in the situation, if the provider breaks its commitments, or if the decision was based on wrong or misleading information. If the Commission thinks the provider's commitments aren't enough to ensure they'll follow the rules, it can reject them and explain why when the proceedings conclude."
Digital Services Act (DSA) - Article 1,0.720006227,"Subject matter (Article 1) details in the Digital Services Act (DSA): 1.   The aim of this Regulation is to contribute to the proper functioning of the internal market for intermediary services by setting out harmonised rules for a safe, predictable and trusted online environment that facilitates innovation and in which fundamental rights enshrined in the Charter, including the principle of consumer protection, are effectively protected.

2.   This Regulation lays down harmonised rules on the provision of intermediary services in the internal market. In particular, it establishes:

(a) a framework for the conditional exemption from liability of providers of intermediary services;

(b) rules on specific due diligence obligations tailored to certain specific categories of providers of intermediary services;

(c) rules on the implementation and enforcement of this Regulation, including as regards the cooperation of and coordination between the competent authorities.",article,"The Digital Services Act (DSA) is a new law designed to regulate online intermediary services. Its goal is to create a safe and reliable online environment that encourages innovation while protecting consumer rights. The DSA sets out unified rules for these services, including a system for potentially exempting providers from certain liabilities, specific rules for different types of providers, and guidelines for implementing and enforcing the law. This includes cooperation between the authorities responsible for enforcing the law."
Digital Services Act (DSA) - Definition of 'persons with disabilities',0.719961822,"Definition of 'persons with disabilities' in the Digital Services Act (DSA): 'persons with disabilities' as referred to in Article 3, point (1), of Directive (EU) 2019/882 of the European Parliament and of the Council (38).",recital,"The Digital Services Act (DSA) is a new law that includes a specific definition for 'persons with disabilities'. This definition is based on Article 3, point (1), of Directive (EU) 2019/882 from the European Parliament and Council. The law is designed to ensure that digital services are accessible and fair for all users, including those with disabilities."
Digital Markets Act (DMA) - Contextual Paragraph (32),0.719890177,"Details of the Contextual Paragraph (32) in the Digital Markets Act (DMA): For the purpose of this Regulation, contestability should relate to the ability of undertakings to effectively overcome barriers to entry and expansion and challenge the gatekeeper on the merits of their products and services. The features of core platform services in the digital sector, such as network effects, strong economies of scale, and benefits from data have limited the contestability of those services and the related ecosystems. Such a weak contestability reduces the incentives to innovate and improve products and services for the gatekeeper, its business users, its challengers and customers and thus negatively affects the innovation potential of the wider online platform economy. Contestability of the services in the digital sector can also be limited if there is more than one gatekeeper for a core platform service. This Regulation should therefore ban certain practices by gatekeepers that are liable to increase barriers to entry or expansion, and impose certain obligations on gatekeepers that tend to lower those barriers. The obligations should also address situations where the position of the gatekeeper may be entrenched to such an extent that inter-platform competition is not effective in the short term, meaning that intraplatform competition needs to be created or increased.",rectial,"The Digital Markets Act (DMA) aims to increase competition in the digital sector. It focuses on the concept of 'contestability', which refers to the ability of companies to challenge dominant 'gatekeepers' in the digital market. The DMA recognizes that factors like network effects, economies of scale, and data benefits have made it difficult for new entrants to compete. This lack of competition can stifle innovation and negatively impact the overall online platform economy. The DMA aims to prohibit practices by gatekeepers that increase these barriers to entry and impose obligations that would lower them. It also addresses situations where a gatekeeper's dominance is so entrenched that competition between platforms is ineffective, suggesting that competition within platforms needs to be created or increased."
Artifical Inellegence Act (AI Act) - Overview paragraph 30,0.719851434,"Aritifical Intelligence Act (AI Act) overview paragraph (30): As regards AI systems that are safety components of products, or which are themselves products, falling within the scope of certain Union harmonisation legislation, it is appropriate to classify them as high-risk under this Regulation if the product in question undergoes the conformity assessment procedure with a third-party conformity assessment body pursuant to that relevant Union harmonisation legislation. In particular, such products are machinery, toys, lifts, equipment and protective systems intended for use in potentially explosive atmospheres, radio equipment, pressure equipment, recreational craft equipment, cableway installations,appliances burning gaseous fuels, medical devices, and in vitro diagnostic medical devices.",recital,"The Artificial Intelligence Act (AI Act) states that AI systems that are either part of a product or are a product themselves, and fall under certain EU regulations, should be considered high-risk. This is especially true if the product goes through a conformity assessment process with a third-party body according to those EU regulations. These products include machinery, toys, lifts, equipment for use in potentially explosive atmospheres, radio equipment, pressure equipment, recreational craft equipment, cableway installations, appliances using gas, medical devices, and in vitro diagnostic medical devices."
Digital Markets Act (DMA) - Contextual Paragraph (48),0.719848096,"Details of the Contextual Paragraph (48) in the Digital Markets Act (DMA): In relation to cloud computing services, the obligation not to use the data of business users should extend to data provided or generated by business users of the gatekeeper in the context of their use of the cloud computing service of the gatekeeper, or through its software application store that allows end users of cloud computing services access to software applications. That obligation should not affect the right of the gatekeeper to use aggregated data for providing other services provided together with, or in support of, its core platform service, such as data analytics services, subject to compliance with Regulation (EU) 2016/679 and Directive 2002/58/EC, as well as with the relevant obligations in this Regulation concerning such services.",rectial,"The Digital Markets Act (DMA) includes a rule (Paragraph 48) about cloud computing services. This rule says that companies can't use data from their business customers that is either provided by the customers or generated by them while using the company's cloud service or app store. However, the company can use this data in a collective, or ""aggregated,"" form to offer other services related to their main platform, like data analytics. But they must do this while following other EU regulations, including Regulation (EU) 2016/679 and Directive 2002/58/EC, and the rules in the DMA about such services."
Digital Markets Act (DMA) - Article 6 Obligations for gatekeepers susceptible of being further specified under Article 8,0.719752431,"Details of Article 6 Obligations for gatekeepers susceptible of being further specified under Article 8 in the Digital Markets Act (DMA): 1. The Gatekeeper shall comply with all obligations set out in this Article with respect to each of its core platform services listed in the designation decision pursuant to Article 3(9). 2. The gatekeeper shall not use, in competition with business users, any data that is not publicly available that is generated or provided by those business users in the context of their use of the relevant core platform services or of the services provided together with, or in support of, the relevant core platform services, including data generated or provided by the customers of those business users. For the purposes of the first subparagraph, the data that is not publicly available shall include any aggregated and nonaggregated data generated by business users that can be inferred from, or collected through, the commercial activities of business users or their customers, including click, search, view and voice data, on the relevant core platform services or on services provided together with, or in support of, the relevant core platform services of the gatekeeper. 3. The gatekeeper shall allow and technically enable end users to easily un-install any software applications on the operating system of the gatekeeper, without prejudice to the possibility for that gatekeeper to restrict such un-installation in relation to software applications that are essential for the functioning of the operating system or of the device and which cannot technically be offered on a standalone basis by third parties. The gatekeeper shall allow and technically enable end users to easily change default settings on the operating system, virtual assistant and web browser of the gatekeeper that direct or steer end users to products or services provided by the gatekeeper. That includes prompting end users, at the moment of the end users"" first use of an online search engine, virtual assistant or web browser of the gatekeeper listed in the designation decision pursuant to Article 3(9), to choose, from a list of the main available service providers, the online search engine, virtual assistant or web browser to which the operating system of the gatekeeper directs or steers users by default, and the online search engine to which the virtual assistant and the web browser of the gatekeeper directs or steers users by default. 4. The gatekeeper shall allow and technically enable the installation and effective use of third-party software applications or software application stores using, or interoperating with, its operating system and allow those software applications or software application stores to be accessed by means other than the relevant core platform services of that gatekeeper. The gatekeeper shall, where applicable, not prevent the downloaded third-party software applications or software application stores from prompting end users to decide whether they want to set that downloaded software application or software application store as their default. The gatekeeper shall technically enable end users who decide to set that downloaded software application or software application store as their default to carry out that change easily. The gatekeeper shall not be prevented from taking, to the extent that they are strictly necessary and proportionate, measures to ensure that third-party software applications or software application stores do not endanger the integrity of the hardware or operating system provided by the gatekeeper, provided that such measures are duly justified by the gatekeeper. Furthermore, the gatekeeper shall not be prevented from applying, to the extent that they are strictly necessary and proportionate, measures and settings other than default settings, enabling end users to effectively protect security in relation to third-party software applications or software application stores, provided that such measures and settings other than default settings are duly justified by the gatekeeper. 5. The gatekeeper shall not treat more favourably, in ranking and related indexing and crawling, services and products offered by the gatekeeper itself than similar services or products of a third party. The gatekeeper shall apply transparent, fair and non-discriminatory conditions to such ranking. 6. The gatekeeper shall not restrict technically or otherwise the ability of end users to switch between, and subscribe to, different software applications and services that are accessed using the core platform services of the gatekeeper, including as regards the choice of Internet access services for end users. 7. The gatekeeper shall allow providers of services and providers of hardware, free of charge, effective interoperability with, and access for the purposes of interoperability to, the same hardware and software features accessed or controlled via the operating system or virtual assistant listed in the designation decision pursuant to Article 3(9) as are available to services or hardware provided by the gatekeeper. Furthermore, the gatekeeper shall allow business users and alternative providers of services provided together with, or in support of, core platform services, free of charge, effective interoperability with, and access for the purposes of interoperability to, the same operating system, hardware or software features, regardless of whether those features are part of the operating system, as are available to, or used by, that gatekeeper when providing such services. The gatekeeper shall not be prevented from taking strictly necessary and proportionate measures to ensure that interoperability does not compromise the integrity of the operating system, virtual assistant, hardware or software features provided by the gatekeeper, provided that such measures are duly justified by the gatekeeper. 8. The gatekeeper shall provide advertisers and publishers, as well as third parties authorised by advertisers and publishers, upon their request and free of charge, with access to the performance measuring tools of the gatekeeper and the data necessary for advertisers and publishers to carry out their own independent verification of the advertisements inventory, including aggregated and non-aggregated data. Such data shall be provided in a manner that enables advertisers and publishers to run their own verification and measurement tools to assess the performance of the core platform services provided for by the gatekeepers. 9. The gatekeeper shall provide end users and third parties authorised by an end user, at their request and free of charge, with effective portability of data provided by the end user or generated through the activity of the end user in the context of the use of the relevant core platform service, including by providing, free of charge, tools to facilitate the effective exercise of such data portability, and including by the provision of continuous and real-time access to such data. 10. The gatekeeper shall provide business users and third parties authorised by a business user, at their request, free of charge, with effective, high-quality, continuous and real-time access to, and use of, aggregated and non-aggregated data, including personal data, that is provided for or generated in the context of the use of the relevant core platform services or services provided together with, or in support of, the relevant core platform services by those business users and the end users engaging with the products or services provided by those business users. With regard to personal data, the gatekeeper shall provide for such access to, and use of, personal data only where the data are directly connected with the use effectuated by the end users in respect of the products or services offered by the relevant business user through the relevant core platform service, and when the end users opt in to such sharing by giving their consent. 11. The gatekeeper shall provide to any third-party undertaking providing online search engines, at its request, with access on fair, reasonable and non-discriminatory terms to ranking, query, click and view data in relation to free and paid search generated by end users on its online search engines. Any such query, click and view data that constitutes personal data shall be anonymised. 12. The gatekeeper shall apply fair, reasonable, and non-discriminatory general conditions of access for business users to its software application stores, online search engines and online social networking services listed in the designation decision pursuant to Article 3(9). For that purpose, the gatekeeper shall publish general conditions of access, including an alternative dispute settlement mechanism. The Commission shall assess whether the published general conditions of access comply with this paragraph. 13. The gatekeeper shall not have general conditions for terminating the provision of a core platform service that are disproportionate. The gatekeeper shall ensure that the conditions of termination can be exercised without undue difficulty.",article,"The Digital Markets Act (DMA) sets out several obligations for ""gatekeepers"" - large tech companies that control major online platforms. These include:

1. Not using non-public data from business users to compete against them.
2. Allowing users to easily uninstall software applications and change default settings.
3. Allowing the installation and use of third-party software applications or app stores.
4. Not favoring their own services or products over those of third parties in rankings.
5. Not restricting users' ability to switch between different software applications and services.
6. Allowing service and hardware providers free and effective interoperability with the gatekeeper's systems.
7. Providing advertisers, publishers, and authorized third parties free access to performance measuring tools and data.
8. Providing users and authorized third parties free access to data portability tools.
9. Providing business users and authorized third parties free access to aggregated and non-aggregated data, including personal data, with user consent.
10. Providing third-party search engines access to ranking, query, click, and view data.
11. Applying fair, reasonable, and non-discriminatory conditions for business users to access their platforms.
12. Not having disproportionate conditions for terminating the provision of a core platform service."
Digital Services Act (DSA) - Article 57 Mutual assistance,0.719752312,"Article 57 Mutual assistance in the Digital Services Act (DSA):  1.   Digital Services Coordinators and the Commission shall cooperate closely and provide each other with mutual assistance in order to apply this Regulation in a consistent and efficient manner. Mutual assistance shall include, in particular, exchange of information in accordance with this Article and the duty of the Digital Services Coordinator of establishment to inform all Digital Services Coordinators of destination, the Board and the Commission about the opening of an investigation and the intention to take a final decision, including its assessment, in respect of a specific provider of intermediary services.

2.   For the purpose of an investigation, the Digital Services Coordinator of establishment may request other Digital Services Coordinators to provide specific information in their possession as regards a specific provider of intermediary services or to exercise their investigative powers referred to in Article 51(1) with regard to specific information located in their Member State. Where appropriate, the Digital Services Coordinator receiving the request may involve other competent authorities or other public authorities of the Member State in question.

3.   The Digital Services Coordinator receiving the request pursuant to paragraph 2 shall comply with such request and inform the Digital Services Coordinator of establishment about the action taken, without undue delay and no later than two months after its receipt, unless:

(a) the scope or the subject matter of the request is not sufficiently specified, justified or proportionate in view of the investigative purposes; or
(b) neither the requested Digital Service Coordinator nor other competent authority or other public authority of that Member State is in possession of the requested information nor can have access to it; or
(c) the request cannot be complied with without infringing Union or national law.

The Digital Services Coordinator receiving the request shall justify its refusal by submitting a reasoned reply, within the period set out in the first subparagraph.",article,"The Digital Services Act (DSA) requires Digital Services Coordinators and the Commission to work together and assist each other in applying the law consistently and efficiently. This includes sharing information and notifying each other about investigations and decisions regarding specific digital service providers. If necessary for an investigation, a Coordinator can ask others for specific information or to use their investigative powers. The Coordinator receiving the request must comply and inform the requesting Coordinator about their actions within two months, unless the request is not specific, justified or proportionate, they don't have the requested information or can't access it, or complying would break Union or national law. If refusing a request, the Coordinator must provide a reasoned reply within the two-month period."
California Consumer Privacy Act Regulations (CCPA) - Definition of Affirmative,0.719688714,"Details of Definition of Affirmative authorization in the California Consumer Privacy Act Regulations (CCPA): Affirmative authorization means an action that demonstrates the intentional decision by the consumer to opt-in to the sale of personal information. Within the context of a parent or guardian acting on behalf of a consumer under 13 years of age, it means that the parent or guardian has provided consent to the sale of the consumers personal information in accordance with the methods set forth in section 999.330. For consumers 13 years of age and older, it is demonstrated through a two-step process whereby the consumer shall first, clearly request to opt-in and then second, separately confirm their choice to opt-in.",recital,"The California Consumer Privacy Act (CCPA) has a new rule about ""Affirmative authorization"". This means that a person has to intentionally decide to allow the sale of their personal information. If the person is under 13, their parent or guardian must give consent. If the person is 13 or older, they must first clearly ask to opt-in, then confirm their decision in a separate step. This is to ensure that people understand and agree to their information being sold."
General Data Protection Regulation (GDPR) - Definition of relevant and reasoned objection,0.719653547,"Details of the Definition of relevant and reasoned objection in the General Data Protection Regulation (GDPR): ""relevant and reasoned objection"" means an objection to a draft decision as to whether there is an infringement of this Regulation, or whether envisaged action in relation to the controller or processor complies with this Regulation, which clearly demonstrates the significance of the risks posed by the draft decision as regards the fundamental rights and freedoms of data subjects and, where applicable, the free flow of personal data within the Union;",recital,"The General Data Protection Regulation (GDPR) introduces the concept of a ""relevant and reasoned objection."" This refers to an objection against a proposed decision, questioning if it violates the GDPR or if the actions planned concerning the data controller or processor are in line with the GDPR. The objection must clearly highlight the potential risks the decision could have on the basic rights and freedoms of individuals whose data is being processed. It should also consider, if applicable, the free movement of personal data within the European Union."
Digital Services Act (DSA) - Contextual paragraph (41),0.719632685,"Details of the contextual paragraph (41) of the Digital Services Act (DSA): In that regard, it is important that the due diligence obligations are adapted to the type, size and nature of the intermediary service concerned. This Regulation therefore sets out basic obligations applicable to all providers of intermediary services, as well as additional obligations for providers of hosting services and, more specifically, providers of online platforms and of very large online platforms and of very large online search engines. To the extent that providers of intermediary services fall within a number of different categories in view of the nature of their services and their size, they should comply with all the corresponding obligations of this Regulation in relation to those services. Those harmonised due diligence obligations, which should be reasonable and non-arbitrary, are needed to address the identified public policy concerns, such as safeguarding the legitimate interests of the recipients of the service, addressing illegal practices and protecting the fundamental rights enshrined in the Charter. The due diligence obligations are independent from the question of liability of providers of intermediary services which need therefore to be assessed separately.",recital,"The Digital Services Act (DSA) requires all online intermediary services, such as hosting services and large online platforms, to follow certain rules. These rules vary depending on the type, size, and nature of the service. The DSA aims to protect the interests of users, stop illegal practices, and uphold fundamental rights. It calls for reasonable and non-arbitrary practices. The DSA's rules are separate from any liability issues, which must be evaluated independently."
California Consumer Privacy Act Regulations (CCPA) - Article 3. Business Practices for Handling Consumer Requests -  999.315 Requests to Opt-Out,0.719621718,"Details of Article 3. Business Practices for Handling Consumer Requests -  999.315 Requests to Opt-Out in the California Consumer Privacy Act Regulations (CCPA): (a) A business shall provide two or more designated methods for submitting requests to opt-out, including an interactive form accessible via a clear and conspicuous link titled Do Not Sell My Personal Information, on the businesss website or mobile application. Other acceptable methods for submitting these requests include, but are not limited to, a toll-free phone number, a designated email address, a form submitted in person, a form submitted through the mail, and user-enabled global privacy controls, such as a browser plug-in or privacy setting, device setting, or other mechanism, that communicate or signal the consumers choice to opt-out of the sale of their personal information. (b) A business shall consider the methods by which it interacts with consumers, the manner in which the business sells personal information to third parties, available technology, and ease of use by the consumer when determining which methods consumers may use to submit requests to opt-out. At least one method offered shall reflect the manner in which the business primarily interacts with the consumer. (c) If a business collects personal information from consumers online, the business shall treat user-enabled global privacy controls, such as a browser plug-in or privacy setting, device setting, or other mechanism, that communicate or signal the consumers choice to opt-out of the sale of their personal information as a valid request submitted pursuant to Civil Code section 1798.120 for that browser or device, or, if known, for the consumer. (1) Any privacy control developed in accordance with these regulations shall clearly communicate or signal that a consumer intends to opt-out of the sale of personal information. (2) If a global privacy control conflicts with a consumers existing business-specific privacy setting or their participation in a businesss financial incentive program, the business shall respect the global privacy control but may notify the consumer of the conflict and give the consumer the choice to confirm the business-specific privacy setting or participation in the financial incentive program. (d) In responding to a request to opt-out, a business may present the consumer with the choice to opt-out of sale for certain uses of personal information as long as a global option to opt- out of the sale of all personal information is more prominently presented than the other choices. (e) A business shall comply with a request to opt-out as soon as feasibly possible, but no later than 15 business days from the date the business receives the request. If a business sells a consumers personal information to any third parties after the consumer submits their request but before the business complies with that request, it shall notify those third parties that the consumer has exercised their right to opt-out and shall direct those third parties not to sell that consumers information. (f) A consumer may use an authorized agent to submit a request to opt-out on the consumers behalf if the consumer provides the authorized agent written permission signed by the consumer. A business may deny a request from an authorized agent if the agent cannot provide to the business the consumers signed permission demonstrating that they have been authorized by the consumer to act on the consumers behalf. User-enabled global privacy controls, such as a browser plug-in or privacy setting, device setting, or other mechanism, that communicate or signal the consumers choice to opt-out of the sale of their personal information shall be considered a request directly from the consumer, not through an authorized agent. (g) A request to opt-out need not be a verifiable consumer request. If a business, however, has a good-faith, reasonable, and documented belief that a request to opt-out is fraudulent, the business may deny the request. The business shall inform the requestor that it will not comply with the request and shall provide an explanation why it believes the request is fraudulent.",article,"The California Consumer Privacy Act (CCPA) requires businesses to offer multiple ways for consumers to opt out of their personal information being sold, such as via an interactive form on their website or a toll-free number. If a business primarily interacts with consumers online, it must also accept global privacy controls (like browser settings) as a valid opt-out request. If a consumer opts out, the business must comply within 15 business days and inform any third parties it sold the consumer's information to. Consumers can also use an authorized agent to opt out on their behalf, provided they give written permission. If a business suspects a fraudulent opt-out request, it can deny it but must explain why."
Artifical Inellegence Act (AI Act) - Overview paragraph 79,0.719570279,"Aritifical Intelligence Act (AI Act) overview paragraph (79): In order to ensure an appropriate and effective enforcement of the requirements and obligations set out by this Regulation, which is Union harmonisation legislation, the system of market surveillance and compliance of products established by Regulation (EU) 2019/1020 should apply in its entirety. Where necessary for their mandate, national public authorities or bodies, which supervise the application of Union law protecting fundamental rights, including equality bodies, should also have access to any documentation created under this Regulation.",recital,"The Artificial Intelligence Act (AI Act) requires that the market surveillance and compliance system established by Regulation (EU) 2019/1020 be fully applied to enforce the obligations and requirements of the AI Act. This is to ensure that AI products are in line with Union harmonisation legislation. National public authorities or bodies, including equality bodies, that oversee the application of Union law protecting fundamental rights, should have access to any documents created under this Act, if necessary for their work."
General Data Protection Regulation (GDPR) - Article 49 Derogations for specific situations,0.719493866,"Details of Article 49 Derogations for specific situations in the General Data Protection Regulation (GDPR): 1. In the absence of an adequacy decision pursuant to Article 45(3), or of appropriate safeguards pursuant to Article 46, including binding corporate rules, a transfer or a set of transfers of personal data to a third country or an international organisation shall take place only on one of the following conditions: (a) the data subject has explicitly consented to the proposed transfer, after having been informed of the possible risks of such transfers for the data subject due to the absence of an adequacy decision and appropriate safeguards; (b) the transfer is necessary for the performance of a contract between the data subject and the controller or the implementation of pre-contractual measures taken at the data subject's request; (c) the transfer is necessary for the conclusion or performance of a contract concluded in the interest of the data subject between the controller and another natural or legal person; (d) the transfer is necessary for important reasons of public interest; (e) the transfer is necessary for the establishment, exercise or defence of legal claims; (f) the transfer is necessary in order to protect the vital interests of the data subject or of other persons, where the data subject is physically or legally incapable of giving consent; (g) the transfer is made from a register which according to Union or Member State law is intended to provide information to the public and which is open to consultation either by the public in general or by any person who can demonstrate a legitimate interest, but only to the extent that the conditions laid down by Union or Member State law for consultation are fulfilled in the particular case. Where a transfer could not be based on a provision in Article 45 or 46, including the provisions on binding corporate rules, and none of the derogations for a specific situation referred to in the first subparagraph of this paragraph is applicable, a transfer to a third country or an international organisation may take place only if the transfer is not repetitive, concerns only a limited number of data subjects, is necessary for the purposes of compelling legitimate interests pursued by the controller which are not overridden by the interests or rights and freedoms of the data subject, and the controller has assessed all the circumstances surrounding the data transfer and has on the basis of that assessment provided suitable safeguards with regard to the protection of personal data. The controller shall inform the supervisory authority of the transfer. The controller shall, in addition to providing the information referred to in Articles 13 and 14, inform the data subject of the transfer and on the compelling legitimate interests pursued. 2. A transfer pursuant to point (g) of the first subparagraph of paragraph 1 shall not involve the entirety of the personal data or entire categories of the personal data contained in the register. Where the register is intended for consultation by persons having a legitimate interest, the transfer shall be made only at the request of those persons or if they are to be the recipients. 3. Points (a), (b) and (c) of the first subparagraph of paragraph 1 and the second subparagraph thereof shall not apply to activities carried out by public authorities in the exercise of their public powers. 4. The public interest referred to in point (d) of the first subparagraph of paragraph 1 shall be recognised in Union law or in the law of the Member State to which the controller is subject. 5. In the absence of an adequacy decision, Union or Member State law may, for important reasons of public interest, expressly set limits to the transfer of specific categories of personal data to a third country or an international organisation. Member States shall notify such provisions to the Commission. 6. The controller or processor shall document the assessment as well as the suitable safeguards referred to in the second subparagraph of paragraph 1 of this Article in the records referred to in Article 30.",article,"The General Data Protection Regulation (GDPR) Article 49 outlines conditions for transferring personal data to third countries or international organizations. This can only occur if: the person has given explicit consent; the transfer is necessary for a contract; it's in the person's interest; it's for public interest or legal claims; it's to protect the person's vital interests; or it's from a public register. If none of these apply, the transfer can still happen if it's not repetitive, involves a limited number of people, is for compelling legitimate interests, and suitable safeguards are provided. The controller must inform the supervisory authority and the person about the transfer. Public authorities' activities are exempt from some conditions. Any public interest must be recognized in Union or Member State law. In the absence of an adequacy decision, the law may limit the transfer of certain data for public interest reasons. The controller or processor must document the assessment and safeguards."
General Data Protection Regulation (GDPR) - Contextual Paragraph (70),0.719481826,"Details of the Contextual Paragraph (70) in the General Data Protection Regulation (GDPR): Where personal data are processed for the purposes of direct marketing, the data subject should have the right to object to such processing, including profiling to the extent that it is related to such direct marketing, whether with regard to initial or further processing, at any time and free of charge. That right should be explicitly brought to the attention of the data subject and presented clearly and separately from any other information.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 70) that gives individuals the right to object to the use of their personal data for direct marketing purposes. This includes any profiling related to such marketing. This right can be exercised at any time and is free of charge. The law requires that this right be clearly communicated to individuals, separate from any other information."
Digital Markets Act (DMA) - Definition of consent,0.719480038,"Details of the Definition of consent in the Digital Markets Act (DMA): ""consent"" means consent as defined in Article 4, point (11), of Regulation (EU) 2016/679;",rectial,"The Digital Markets Act (DMA) defines ""consent"" using the guidelines from Article 4, point (11), of Regulation (EU) 2016/679. Essentially, for the DMA, ""consent"" means that a user has given clear agreement to the processing of their personal data. This consent must be freely given, specific, informed, and unambiguous. It cannot be assumed or implied, and the user has the right to withdraw their consent at any time."
Digital Markets Act (DMA) - Contextual Paragraph (103),0.719475746,"Details of the Contextual Paragraph (103) in the Digital Markets Act (DMA): To enhance legal certainty, the applicability, pursuant to this Regulation, of Directive (EU) 2019/1937 to reports of breaches of this Regulation and to the protection of persons reporting such breaches should be reflected in that Directive. The Annex to Directive (EU) 2019/1937 should therefore be amended accordingly. It is for the Member States to ensure that that amendment is reflected in their transposition measures adopted in accordance with Directive (EU) 2019/1937, although the adoption of national transposition measures is not a condition for the applicability of that Directive to the reporting of breaches of this Regulation and to the protection of reporting persons from the date of application of this Regulation.",rectial,"The Digital Markets Act (DMA) has a new provision, Paragraph (103), which aims to increase legal certainty. It states that the EU Directive 2019/1937 will apply to reports of DMA violations and to the protection of those who report such violations. This Directive will be amended accordingly. It's up to individual member states to ensure this change is reflected in their own laws, but this doesn't affect the Directive's application to reporting DMA breaches and protecting reporters from the moment the DMA comes into effect."
General Data Protection Regulation (GDPR) - Article 50 International cooperation for the protection of personal data,0.719422698,"Details of Article 50 International cooperation for the protection of personal data in the General Data Protection Regulation (GDPR): In relation to third countries and international organisations, the Commission and supervisory authorities shall take appropriate steps to: (a) develop international cooperation mechanisms to facilitate the effective enforcement of legislation for the protection of personal data; (b) provide international mutual assistance in the enforcement of legislation for the protection of personal data, including through notification, complaint referral, investigative assistance and information exchange, subject to appropriate safeguards for the protection of personal data and other fundamental rights and freedoms; (c) engage relevant stakeholders in discussion and activities aimed at furthering international cooperation in the enforcement of legislation for the protection of personal data; (d) promote the exchange and documentation of personal data protection legislation and practice, including on jurisdictional conflicts with third countries.",article,"The General Data Protection Regulation (GDPR) has introduced Article 50, which focuses on international cooperation for personal data protection. This means that the Commission and supervisory authorities will work together to create global cooperation mechanisms to effectively enforce data protection laws. They will also provide international assistance in enforcing these laws, including notifying relevant parties, referring complaints, assisting investigations, and exchanging information, while ensuring personal data and fundamental rights are protected. Furthermore, they will engage stakeholders in discussions and activities to enhance global cooperation in data protection law enforcement. Lastly, they will encourage sharing and documenting data protection laws and practices, including resolving jurisdictional conflicts with other countries."
California Consumer Privacy Act Regulations (CCPA) - Definition of Request to opt-in,0.719409823,"Details of Definition of Request to opt-in in the California Consumer Privacy Act Regulations (CCPA): Request to opt-in means the affirmative authorization that the business may sell personal information about the consumer by a parent or guardian of a consumer less than 13 years of age, by a consumer at least 13 and less than 16 years of age, or by a consumer who had previously opted out of the sale of their personal information.",recital,"The California Consumer Privacy Act (CCPA) introduces a new term, ""Request to opt-in"". This means that a business can only sell a person's personal information if they have explicit permission. If the person is under 13, a parent or guardian must give this permission. If the person is aged 13 to 15, they can give the permission themselves. If a person had previously chosen not to allow their information to be sold (""opted out""), they can change their mind and allow it (""opt in"")."
Artifical Inellegence Act (AI Act) - Overview paragraph 68,0.719365299,"Aritifical Intelligence Act (AI Act) overview paragraph (68): Under certain conditions, rapid availability of innovative technologies may be crucial for health and safety of persons and for society as a whole. It is thus appropriate that under exceptional reasons of public security or protection of life and health of natural persons and the protection of industrial and commercial property, Member States could authorise the placing on the market or putting into service of AI systems which have not undergone a conformity assessment.",recital,"The Artificial Intelligence Act (AI Act) allows for the quick release of new technologies in special circumstances where they could be vital for public safety, health, or the protection of business property. This means that in certain situations, Member States can approve the use of AI systems that haven't been through a standard evaluation process."
Digital Markets Act (DMA) - Contextual Paragraph (47),0.719350517,"Details of the Contextual Paragraph (47) in the Digital Markets Act (DMA): Business users can also purchase online advertising services from an undertaking providing core platform services for the purpose of providing goods and services to end users. In this case, it can happen that the data are not generated on the core platform service, but are provided to the core platform service by the business user or are generated based on its operations through the core platform service concerned. In certain instances, that core platform service providing advertising can have a dual role as both an undertaking providing online advertising services and an undertaking providing services competing with business users. Accordingly, the obligation prohibiting a dual role gatekeeper from using data of business users should apply also with respect to the data that a core platform service has received from businesses for the purpose of providing online advertising services related to that core platform service.",rectial,"The Digital Markets Act (DMA) has a new rule, Contextual Paragraph (47), which relates to online advertising. Businesses can buy ad services from platforms that also offer other services. Sometimes, these platforms get data from the businesses or generate it themselves. In some cases, these platforms can act in two roles - as an ad service provider and as a competitor to the businesses. The DMA now says that these dual-role platforms can't use the business data they've received for their own benefit when providing online advertising services. This is to ensure fair competition."
General Data Protection Regulation (GDPR) - Contextual Paragraph (96),0.719307601,"Details of the Contextual Paragraph (96) in the General Data Protection Regulation (GDPR): A consultation of the supervisory authority should also take place in the course of the preparation of a legislative or regulatory measure which provides for the processing of personal data, in order to ensure compliance of the intended processing with this Regulation and in particular to mitigate the risk involved for the data subject.",recital,The General Data Protection Regulation (GDPR) includes a rule (Paragraph 96) that requires any new law or regulation involving the handling of personal data to be reviewed by a supervisory authority. This is to make sure that the new law complies with GDPR rules and minimizes any risk to the individual whose data is being processed.
General Data Protection Regulation (GDPR) - Article 74 Tasks of the Chair,0.719300568,"Details of Article 74 Tasks of the Chair in the General Data Protection Regulation (GDPR): 1. The Chair shall have the following tasks: (a) to convene the meetings of the Board and prepare its agenda; (b) to notify decisions adopted by the Board pursuant to Article 65 to the lead supervisory authority and the supervisory authorities concerned; (c) to ensure the timely performance of the tasks of the Board, in particular in relation to the consistency mechanism referred to in Article 63. 2. The Board shall lay down the allocation of tasks between the Chair and the deputy chairs in its rules of procedure.",article,"The General Data Protection Regulation (GDPR) Article 74 outlines the responsibilities of the Chairperson. They are responsible for organizing and preparing the agenda for board meetings. They must also communicate any decisions made by the board to the relevant supervisory authorities. Additionally, they must ensure that the board's tasks are completed on time, especially those related to the consistency mechanism mentioned in Article 63. The distribution of tasks between the Chairperson and deputy chairs is determined by the board's rules of procedure."
Artifical Inellegence Act (AI Act) - Overview paragraph 67,0.71929276,Aritifical Intelligence Act (AI Act) overview paragraph (67): High-risk AI systems should bear the CE marking to indicate their conformity with this Regulation so that they can move freely within the internal market. Member States should not create unjustified obstacles to the placing on the market or putting into service of high-risk AI systems that comply with the requirements laid down in this Regulation and bear the CE marking.,recital,"The Artificial Intelligence Act (AI Act) states that high-risk AI systems must have a CE marking. This marking shows that the AI system meets the standards set by this law, allowing it to be sold or used freely within the market. Member states are not allowed to create unnecessary barriers for these high-risk AI systems that meet the law's requirements and have the CE marking."
General Data Protection Regulation (GDPR) - Article 75 Secretariat,0.719289899,"Details of Article 75 Secretariat in the General Data Protection Regulation (GDPR): 1. The Board shall have a secretariat, which shall be provided by the European Data Protection Supervisor. 2. The secretariat shall perform its tasks exclusively under the instructions of the Chair of the Board. 3. The staff of the European Data Protection Supervisor involved in carrying out the tasks conferred on the Board by this Regulation shall be subject to separate reporting lines from the staff involved in carrying out tasks conferred on the European Data Protection Supervisor. 4. Where appropriate, the Board and the European Data Protection Supervisor shall establish and publish a Memorandum of Understanding implementing this Article, determining the terms of their cooperation, and applicable to the staff of the European Data Protection Supervisor involved in carrying out the tasks conferred on the Board by this Regulation. 5. The secretariat shall provide analytical, administrative and logistical support to the Board. 6. The secretariat shall be responsible in particular for: (a) the day-to-day business of the Board; (b) communication between the members of the Board, its Chair and the Commission; (c) communication with other institutions and the public; (d) the use of electronic means for the internal and external communication; (e) the translation of relevant information; (f) the preparation and follow-up of the meetings of the Board; (g) the preparation, drafting and publication of opinions, decisions on the settlement of disputes between supervisory authorities and other texts adopted by the Board.",article,"Article 75 of the General Data Protection Regulation (GDPR) establishes a secretariat for the Board, provided by the European Data Protection Supervisor. The secretariat will work under the Board Chair's instructions and will have separate reporting lines from other staff. The Board and the Supervisor may publish a Memorandum of Understanding outlining their cooperation terms. The secretariat's role includes providing analytical, administrative, and logistical support, handling daily operations, facilitating communication within the Board and with the public, using electronic means for communication, translating relevant information, and preparing and publishing Board texts."
Artifical Inellegence Act (AI Act) - Article 64,0.719265103,"Aritifical Intelligence Act (AI Act) Article 64 Access to data and documentation:

1.Access to data and documentation in the context of their activities, the market surveillance authorities shall be granted full access to the training, validation and testing datasets used by the provider, including through application programming interfaces (API) or other appropriate technical means and tools enabling remote access.

2.Where necessary to assess the conformity of the high-risk AI system with the requirements set out in Title III, Chapter 2 and upon a reasoned request, the market surveillance authorities shall be granted access to the source code of the AI system.

3.National public authorities or bodies which supervise or enforce the respect of obligations under Union law protecting fundamental rights in relation to the use of high-risk AI systems referred to in Annex III shall have the power to request and access any documentation created or maintained under this Regulation when access to that documentation is necessary for the fulfilment of the competences under their mandate within the limits of their jurisdiction. The relevant public authority or body shall inform the market surveillance authority of the Member State concerned of any such request.

4.By 3 months after the entering into force of this Regulation, each Member State shall identify the public authorities or bodies referred to in paragraph 3 and make a list publicly available on the website of the national supervisory authority. Member States shall notify the list to the Commission and all other Member States and keep the list up to date.

5.Where the documentation referred to in paragraph 3 is insufficient to ascertain whether a breach of obligations under Union law intended to protect fundamental rights has occurred, the public authority or body referred to paragraph 3 may make a reasoned request to the market surveillance authority to organise testing of the high-risk AI system through technical means. The market surveillance authority shall organise the testing with the close involvement of the requesting public authority or body within reasonable time following the request.

6.Any information and documentation obtained by the national public authorities or bodies referred to in paragraph 3 pursuant to the provisions of this Article shall be treated in compliance with the confidentiality obligations set out in Article 70.",article,"The Artificial Intelligence Act (AI Act) allows market surveillance authorities to fully access the data and documents used by AI providers, including training, validation, and testing datasets, through APIs or other technical means. If needed to check the AI system's compliance with certain requirements, these authorities can also access the system's source code. Public authorities that enforce laws protecting fundamental rights can request access to any relevant documentation. Within three months of this law coming into effect, each member state must identify these public authorities and make a list available online. If documentation is insufficient to determine a breach of rights, these authorities can request testing of the AI system. Any information obtained must be treated confidentially."
Artifical Inellegence Act (AI Act) - Overview paragraph 8,0.719254375,"Aritifical Intelligence Act (AI Act) overview paragraph (8): The notion of remote biometric identification system as used in this Regulation should be defined functionally, asan AI systemintended for the identification of natural persons at a distance through the comparison of a persons biometric data with the biometric data contained in a reference database, and without prior knowledge whether the targeted person will be present and can be identified, irrespectively of the particular technology, processes or types of biometric data used. Considering their different characteristics and manners in which they are used, as well as the different risks involved, a distinction should be made between real-time and post remote biometric identification systems. In the case of real-time systems, the capturing of the biometric data, the comparison and the identification occur all instantaneously, near-instantaneously or in any event without a significant delay. In this regard, there should be no scope for circumventing the rules of this Regulation on the real-time use of the AI systems in question by providing for minor delays. Real-time systems involve the use of live or near-live material, such as video footage, generated by a camera or other device with similar functionality. In the case of post systems, in contrast, the biometric data have already been captured and the comparison and identification occur only after a significant delay. This involves material, such as pictures or video footage generated byclosed circuit television cameras or private devices, which has been generated before the use of the system in respect of the natural persons concerned.",recital,"The Artificial Intelligence Act (AI Act) defines a remote biometric identification system as an AI system designed to recognize individuals from a distance by comparing their biometric data to a reference database, without knowing if the person will be present or identifiable. The Act distinguishes between 'real-time' and 'post' systems. 'Real-time' systems capture, compare, and identify biometric data almost instantly, using live or near-live footage from cameras or similar devices. The Act prohibits any attempt to bypass its rules by introducing minor delays in real-time systems. 'Post' systems, on the other hand, compare and identify biometric data after a significant delay, using previously captured material like pictures or video footage from CCTV cameras or private devices."
General Data Protection Regulation (GDPR) - Article 45 Transfers on the basis of an adequacy decision,0.71925211,"Details of Article 45 Transfers on the basis of an adequacy decision in the General Data Protection Regulation (GDPR): 1. A transfer of personal data to a third country or an international organisation may take place where the Commission has decided that the third country, a territory or one or more specified sectors within that third country, or the international organisation in question ensures an adequate level of protection. Such a transfer shall not require any specific authorisation. 2. When assessing the adequacy of the level of protection, the Commission shall, in particular, take account of the following elements: (a) the rule of law, respect for human rights and fundamental freedoms, relevant legislation, both general and sectoral, including concerning public security, defence, national security and criminal law and the access of public authorities to personal data, as well as the implementation of such legislation, data protection rules, professional rules and security measures, including rules for the onward transfer of personal data to another third country or international organisation which are complied with in that country or international organisation, case-law, as well as effective and enforceable data subject rights and effective administrative and judicial redress for the data subjects whose personal data are being transferred; (b) the existence and effective functioning of one or more independent supervisory authorities in the third country or to which an international organisation is subject, with responsibility for ensuring and enforcing compliance with the data protection rules, including adequate enforcement powers, for assisting and advising the data subjects in exercising their rights and for cooperation with the supervisory authorities of the Member States; and (c) the international commitments the third country or international organisation concerned has entered into, or other obligations arising from legally binding conventions or instruments as well as from its participation in multilateral or regional systems, in particular in relation to the protection of personal data. 3. The Commission, after assessing the adequacy of the level of protection, may decide, by means of implementing act, that a third country, a territory or one or more specified sectors within a third country, or an international organisation ensures an adequate level of protection within the meaning of paragraph 2 of this Article. The implementing act shall provide for a mechanism for a periodic review, at least every four years, which shall take into account all relevant developments in the third country or international organisation. The implementing act shall specify its territorial and sectoral application and, where applicable, identify the supervisory authority or authorities referred to in point (b) of paragraph 2 of this Article. The implementing act shall be adopted in accordance with the examination procedure referred to in Article 93(2). 4. The Commission shall, on an ongoing basis, monitor developments in third countries and international organisations that could affect the functioning of decisions adopted pursuant to paragraph 3 of this Article and decisions adopted on the basis of Article 25(6) of Directive 95/46/EC. 5. The Commission shall, where available information reveals, in particular following the review referred to in paragraph 3 of this Article, that a third country, a territory or one or more specified sectors within a third country, or an international organisation no longer ensures an adequate level of protection within the meaning of paragraph 2 of this Article, to the extent necessary, repeal, amend or suspend the decision referred to in paragraph 3 of this Article by means of implementing acts without retro-active effect. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 93(2). On duly justified imperative grounds of urgency, the Commission shall adopt immediately applicable implementing acts in accordance with the procedure referred to in Article 93(3). 6. The Commission shall enter into consultations with the third country or international organisation with a view to remedying the situation giving rise to the decision made pursuant to paragraph 5. 7. A decision pursuant to paragraph 5 of this Article is without prejudice to transfers of personal data to the third country, a territory or one or more specified sectors within that third country, or the international organisation in question pursuant to Articles 46 to 49. 8. The Commission shall publish in the Official Journal of the European Union and on its website a list of the third countries, territories and specified sectors within a third country and international organisations for which it has decided that an adequate level of protection is or is no longer ensured. 9. Decisions adopted by the Commission on the basis of Article 25(6) of Directive 95/46/EC shall remain in force until amended, replaced or repealed by a Commission Decision adopted in accordance with paragraph 3 or 5 of this Article.",article,"The General Data Protection Regulation (GDPR) Article 45 allows personal data to be transferred to a third country or international organization if the European Commission decides that they provide an adequate level of protection. Factors considered include respect for human rights, relevant legislation, data protection rules, and the existence of independent supervisory authorities. The Commission will review these decisions at least every four years and can amend, suspend, or repeal them if the level of protection is no longer adequate. The Commission will also consult with the third country or organization to remedy any issues and will publish a list of countries and organizations with adequate protection. Existing decisions will remain in force until they are amended, replaced, or repealed."
Digital Services Act (DSA) - Article 41 Compliance function,0.719246209,"Article 41 Compliance function in the Digital Services Act (DSA):  1.   Providers of very large online platforms or of very large online search engines shall establish a compliance function, which is independent from their operational functions and composed of one or more compliance officers, including the head of the compliance function. That compliance function shall have sufficient authority, stature and resources, as well as access to the management body of the provider of the very large online platform or of the very large online search engine to monitor the compliance of that provider with this Regulation.

2.   The management body of the provider of the very large online platform or of the very large online search engine shall ensure that compliance officers have the professional qualifications, knowledge, experience and ability necessary to fulfil the tasks referred to in paragraph 3.

The management body of the provider of the very large online platform or of the very large online search engine shall ensure that the head of the compliance function is an independent senior manager with distinct responsibility for the compliance function.

The head of the compliance function shall report directly to the management body of the provider of the very large online platform or of the very large online search engine, and may raise concerns and warn that body where risks referred to in Article 34 or non-compliance with this Regulation affect or may affect the provider of the very large online platform or of the very large online search engine concerned, without prejudice to the responsibilities of the management body in its supervisory and managerial functions.

The head of the compliance function shall not be removed without prior approval of the management body of the provider of the very large online platform or of the very large online search engine.

3.   Compliance officers shall have the following tasks:

(a) cooperating with the Digital Services Coordinator of establishment and the Commission for the purpose of this Regulation;
(b) ensuring that all risks referred to in Article 34 are identified and properly reported on and that reasonable, proportionate and effective risk-mitigation measures are taken pursuant to Article 35;
(c) organising and supervising the activities of the provider of the very large online platform or of the very large online search engine relating to the independent audit pursuant to Article 37;
(d) informing and advising the management and employees of the provider of the very large online platform or of the very large online search engine about relevant obligations under this Regulation;
(e) monitoring the compliance of the provider of the very large online platform or of the very large online search engine with its obligations under this Regulation;
(f) where applicable, monitoring the compliance of the provider of the very large online platform or of the very large online search engine with commitments made under the codes of conduct pursuant to Articles 45 and 46 or the crisis protocols pursuant to Article 48.

4.   Providers of very large online platforms or of very large online search engines shall communicate the name and contact details of the head of the compliance function to the Digital Services Coordinator of establishment and to the Commission.

5.   The management body of the provider of the very large online platform or of the very large online search engine shall define, oversee and be accountable for the implementation of the provider's governance arrangements that ensure the independence of the compliance function, including the division of responsibilities within the organisation of the provider of very large online platform or of very large online search engine, the prevention of conflicts of interest, and sound management of systemic risks identified pursuant to Article 34.

6.   The management body shall approve and review periodically, at least once a year, the strategies and policies for taking up, managing, monitoring and mitigating the risks identified pursuant to Article 34 to which the very large online platform or the very large online search engine is or might be exposed to.

7.   The management body shall devote sufficient time to the consideration of the measures related to risk management. It shall be actively involved in the decisions related to risk management, and shall ensure that adequate resources are allocated to the management of the risks identified in accordance with Article 34.",article,"The new Digital Services Act (DSA) requires large online platforms and search engines to establish a compliance function. This function, led by a compliance officer, is separate from other operations and has the authority to monitor the company's adherence to the DSA. The management team must ensure the compliance officer has the necessary qualifications and independence. The compliance officer's duties include cooperating with the Digital Services Coordinator, identifying and managing risks, overseeing audits, advising on DSA obligations, and monitoring adherence to the DSA and any codes of conduct. The company must share the compliance officer's contact information with the Digital Services Coordinator. The management team is responsible for ensuring the independence of the compliance function and for managing risks. They must review risk management strategies at least annually."
Artifical Inellegence Act (AI Act) - Article 38,0.719157815,"Aritifical Intelligence Act (AI Act) Article 38 Coordination of notified bodies:

1.The Commission shall ensure that, with regard to the areas covered by this Regulation, appropriate coordination and cooperation between notified bodies active in the conformity assessment procedures of AI systems pursuant to this Regulation are put in place and properly operated in the form of a sectoral group of notified bodies.

2.Member States shall ensure that the bodies notified by them participate in the work of that group, directly or by means of designated representatives.",article,"The Artificial Intelligence Act (AI Act) requires the Commission to make sure that all notified bodies involved in assessing AI systems work together effectively. This cooperation will be organized through a specific group. The law also mandates that Member States ensure their notified bodies are part of this group, either directly or through appointed representatives."
Artifical Inellegence Act (AI Act) - Overview paragraph 62,0.719111681,"Aritifical Intelligence Act (AI Act) overview paragraph (62): In order to ensure a high level of trustworthiness of high-risk AI systems, those systems should be subject to a conformity assessment prior to their placing on the market or putting into service.",recital,"The Artificial Intelligence Act (AI Act) requires high-risk AI systems to undergo a thorough evaluation, known as a conformity assessment, before they can be sold or used. This is to ensure these systems are reliable and can be trusted."
Digital Markets Act (DMA) - Contextual Paragraph (46),0.719083905,"Details of the Contextual Paragraph (46) in the Digital Markets Act (DMA): In certain circumstances, a gatekeeper has a dual role as an undertaking providing core platform services, whereby it provides a core platform service, and possibly other services provided together with, or in support of, that core platform service to its business users, while also competing or intending to compete with those same business users in the provision of the same or similar services or products to the same end users. In those circumstances, a gatekeeper can take advantage of its dual role to use data, generated or provided by its business users in the context of activities by those business users when using the core platform services or the services provided together with, or in support of, those core platform services, for the purpose of its own services or products. The data of the business user can also include any data generated by or provided during the activities of its end users. This can be the case, for instance, where a gatekeeper provides an online marketplace or a software application store to business users, and at the same time provides services as an undertaking providing online retail services or software applications. To prevent gatekeepers from unfairly benefitting from their dual role, it is necessary to ensure that they do not use any aggregated or non-aggregated data, which could include anonymised and personal data that is not publicly available to provide similar services to those of their business users. That obligation should apply to the gatekeeper as a whole, including but not limited to its business unit that competes with the business users of a core platform service.",rectial,"The Digital Markets Act (DMA) addresses situations where large online platforms, known as 'gatekeepers', provide services to businesses while also competing with them. Gatekeepers may use data from these businesses to improve their own competing services or products. This data could include information generated by the business or its customers. This is often seen in online marketplaces or app stores, where the platform also sells its own products or apps. To prevent unfair competition, the DMA requires gatekeepers not to use any data (even anonymised or non-public personal data) that could help them provide similar services to their business users. This rule applies to the entire gatekeeper organization, especially units that compete with the businesses using their platform."
Artifical Inellegence Act (AI Act) - Overview paragraph 61,0.719073296,"Aritifical Intelligence Act (AI Act) overview paragraph (61): Standardisation should play a key role to provide technical solutions to providers to ensure compliance with this Regulation. Compliance with harmonised standards as defined in Regulation (EU) No 1025/2012 of the European Parliament and of the Council54should be a means for providers to demonstrate conformity with the requirements of this Regulation. However, the Commission could adopt common technical specifications in areas where no harmonised standards exist or where they are insufficient.",recital,"The Artificial Intelligence Act (AI Act) suggests that standardization is crucial for tech providers to ensure they are following the rules. Providers can show they're complying with the law by adhering to harmonized standards, as outlined in the EU's Regulation No 1025/2012. If there are no existing standards or if they're inadequate, the Commission has the power to establish common technical specifications."
Digital Markets Act (DMA) - Definition of software application,0.719072342,"Details of the Definition of software application in the Digital Markets Act (DMA): ""software application"" means any digital product or service that runs on an operating system;",rectial,"The Digital Markets Act (DMA) has introduced a new definition for ""software application"". According to this law, a software application refers to any digital product or service that operates on a system software. This could be anything from a game on your phone to a program on your computer. Essentially, if it's digital and runs on an operating system, it's considered a software application under this law."
General Data Protection Regulation (GDPR) - Contextual Paragraph (85),0.719045818,"Details of the Contextual Paragraph (85) in the General Data Protection Regulation (GDPR): A personal data breach may, if not addressed in an appropriate and timely manner, result in physical, material or non-material damage to natural persons such as loss of control over their personal data or limitation of their rights, discrimination, identity theft or fraud, financial loss, unauthorised reversal of pseudonymisation, damage to reputation, loss of confidentiality of personal data protected by professional secrecy or any other significant economic or social disadvantage to the natural person concerned. Therefore, as soon as the controller becomes aware that a personal data breach has occurred, the controller should notify the personal data breach to the supervisory authority without undue delay and, where feasible, not later than 72 hours after having become aware of it, unless the controller is able to demonstrate, in accordance with the accountability principle, that the personal data breach is unlikely to result in a risk to the rights and freedoms of natural persons. Where such notification cannot be achieved within 72 hours, the reasons for the delay should accompany the notification and information may be provided in phases without undue further delay.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph (85), about personal data breaches. If a company doesn't handle a data breach properly and quickly, it could lead to problems for individuals, like identity theft, financial loss, or damage to reputation. So, when a company realizes there's been a data breach, they need to tell the supervisory authority as soon as possible, ideally within 72 hours. If they can't do this, they need to explain why. However, if they can show that the breach is unlikely to harm individuals' rights or freedoms, they may not have to report it."
Artifical Inellegence Act (AI Act) - Article 44,0.719044328,"Aritifical Intelligence Act (AI Act) Article 44 Certificates:

1.Certificates issued by notified bodies in accordance with Annex VII shall be drawn-up in an official Union language determined by the Member State in which the notified body is established or in an official Union language otherwise acceptable to the notified body.

2.Certificates shall be valid for the period they indicate, which shall not exceed five years. On application by the provider, the validity of a certificate may be extended for further periods, each not exceeding five years, based on a re-assessment in accordance with the applicable conformity assessment procedures.

3.Where a notified body finds that an AI system no longer meets the requirements set out in Chapter 2 of this Title, it shall, taking account of the principle of proportionality, suspend or withdraw the certificate issued or impose any restrictions on it, unless compliance with those requirements is ensured by appropriate corrective action taken by the provider of the system within an appropriate deadline set by the notified body. The notified body shall give reasons for its decision.",article,"The Artificial Intelligence Act (AI Act) Article 44 Certificates outlines the rules for AI system certification. Certificates are issued by designated bodies in a language chosen by the country where the body is based. These certificates are valid for up to five years, but can be extended on request, following a reassessment. If the AI system no longer meets the necessary requirements, the issuing body can suspend or withdraw the certificate, or place restrictions on it. However, this can be avoided if the provider takes corrective action within a set deadline. The issuing body must provide reasons for any decisions made."
Digital Markets Act (DMA) - Article 27 Information by third parties,0.718966126,"Details of Article 27 Information by third parties in the Digital Markets Act (DMA): 1. Any third party, including business users, competitors or end-users of the core platform services listed in the designation decision pursuant to Article 3(9), as well as their representatives, may inform the national competent authority of the Member State, enforcing the rules referred to in Article 1(6), or the Commission directly, about any practice or behaviour by gatekeepers that falls within the scope of this Regulation. 2. The national competent authority of the Member State, enforcing the rules referred to in Article 1(6), and the Commission shall have full discretion as regards the appropriate measures and are under no obligation to follow-up on the information received. 3. Where the national competent authority of the Member State, enforcing the rules referred to in Article 1(6), determines, based on the information received pursuant to paragraph 1 of this Article, that there may be an issue of noncompliance with this Regulation, it shall transfer that information to the Commission.",article,"The Digital Markets Act (DMA) allows any third party, including businesses, competitors, and end-users of certain digital platforms, to report any suspicious or inappropriate behavior by gatekeepers (major tech companies) to their national authority or the European Commission. However, these authorities have the full right to decide whether to act on this information or not. If a national authority believes there might be a violation of the DMA based on the information received, it must share this information with the Commission."
Artifical Inellegence Act (AI Act) - Overview paragraph 52,0.718934,"Aritifical Intelligence Act (AI Act) overview paragraph (52): As part of Union harmonisation legislation, rules applicable to the placing on the market, putting into service and use of high-risk AI systems should be laid down consistently with Regulation (EC) No 765/2008 of the European Parliament and of the Council51setting out the requirements for accreditation and the market surveillance of products, Decision No 768/2008/EC of the European Parliament and of the Council52on a common framework for the marketing of products and Regulation (EU) 2019/1020 of the European Parliament and of the Council53on market surveillance and compliance of products(New Legislative Framework for the marketing of products).",recital,"The Artificial Intelligence Act (AI Act) is a new law that aims to regulate the sale, operation, and use of high-risk AI systems in the European Union. It aligns with existing EU regulations, such as Regulation (EC) No 765/2008, Decision No 768/2008/EC, and Regulation (EU) 2019/1020, which set standards for product accreditation, market surveillance, and compliance. These laws collectively form the 'New Legislative Framework for the marketing of products'. The AI Act is part of the EU's effort to harmonize its legislation across member states."
Digital Markets Act (DMA) - Article 38 Cooperation and coordination with national competent authorities enforcing competition rules,0.718857288,"Details of Article 38 Cooperation and coordination with national competent authorities enforcing competition rules in the Digital Markets Act (DMA): 1. The Commission and the national competent authorities of the Member States enforcing the rules referred to in Article 1(6) shall cooperate with each other and inform each other about their respective enforcement actions through the European Competition Network (ECN). They shall have the power to provide one another with any information regarding a matter of fact or of law, including confidential information. Where the competent authority is not a member of the ECN, the Commission shall make the necessary arrangements for cooperation and exchange of information on cases concerning the enforcement of this Regulation and the enforcement of cases referred to in Article 1(6) of such authorities. The Commission may lay down such arrangements in an implementing act as referred to in Article 46(1), point (l). 2. Where a national competent authority of the Member States enforcing the rules referred to in Article 1(6) intends to launch an investigation on gatekeepers based on national laws referred to in Article 1(6), it shall inform the Commission in writing of the first formal investigative measure, before or immediately after the start of such measure. This information may also be made available to the national competent authorities enforcing the rules referred to in Article 1(6) of the other Member States. 3. Where a national competent authority of the Member States enforcing the rules referred to in Article 1(6) intends to impose obligations on gatekeepers based on national laws referred to in Article 1(6), it shall, no later than 30 days before its adoption, communicate the draft measure to the Commission stating the reasons for the measure. In the case of interim measures, the national competent authority of the Member States enforcing the rules referred to in Article 1(6) shall communicate to the Commission the draft measures envisaged as soon as possible, and at the latest immediately after the adoption of such measures. This information may also be made available to the national competent authorities enforcing the rules referred to in Article 1(6) of the other Member States. 4. The information mechanisms provided for in paragraphs 2 and 3 shall not apply to decisions envisaged pursuant to national merger rules. 5. Information exchanged pursuant to paragraphs 1 to 3 of this Article shall only be exchanged and used for the purpose of coordination of the enforcement of this Regulation and the rules referred to in Article 1(6). 6. The Commission may ask national competent authorities of the Member States enforcing the rules referred to in Article 1(6) to support any of its market investigations pursuant to this Regulation. 7. Where it has the competence and investigative powers to do so under national law, a national competent authority of the Member States enforcing the rules referred to in Article 1(6) may, on its own initiative, conduct an investigation into a case of possible non-compliance with Articles 5, 6 and 7 of this Regulation on its territory. Before taking a first formal investigative measure, that authority shall inform the Commission in writing. The opening of proceedings by the Commission pursuant to Article 20 shall relieve the national competent authorities of the Member States enforcing the rules referred to in Article 1(6) of the possibility to conduct such an investigation or end it where it is already ongoing. Those authorities shall report to the Commission on the findings of such investigation in order to support the Commission in its role as sole enforcer of this Regulation.",article,"The Digital Markets Act (DMA) mandates cooperation between the European Commission and national authorities in enforcing competition rules. They must share information about their actions, including confidential details, through the European Competition Network (ECN). If an authority isn't part of the ECN, the Commission will arrange for cooperation. Before launching an investigation or imposing obligations on gatekeepers (major digital companies), the authority must inform the Commission and potentially other authorities. This doesn't apply to decisions related to national merger rules. Information exchanged is solely for coordinating enforcement. The Commission can request support from national authorities for market investigations. National authorities can independently investigate possible non-compliance within their territory, but they must inform the Commission before starting and report their findings to support the Commission's enforcement role."
Artifical Inellegence Act (AI Act) - Article 66,0.718851864,"Aritifical Intelligence Act (AI Act) Article 66 Union safeguard procedure:

1.Where, within three months of receipt of the notification referred to in Article 65(5), objections are raised by a Member State against a measure taken by another Member State, or where the Commission considers the measure to be contrary to Union law, the Commission shall without delay enter into consultation with the relevant Member State and operator or operators and shall evaluate the national measure. On the basis of the results of that evaluation, the Commission shall decide whether the national measure is justified or not within 9 months from the notification referred to in Article 65(5) and notify such decision to the Member State concerned.

2.If the national measure is considered justified, all Member States shall take the measures necessary to ensure that the non-compliant AI system is withdrawn from their market, and shall inform the Commission accordingly. If the national measure is considered unjustified, the Member State concerned shall withdraw the measure.

3.Where the national measure is considered justified and the non-compliance of the AI system is attributed to shortcomings in the harmonised standards or common specifications referred to in Articles 40 and 41 of this Regulation, the Commission shall apply the procedure provided for in Article 11 of Regulation (EU) No 1025/2012.",article,"The Artificial Intelligence Act (AI Act) Article 66 details how disagreements between Member States or between a Member State and the Commission about AI measures are handled. If a Member State or the Commission objects to a measure within three months of its notification, the Commission will consult with the relevant parties and decide within nine months if the measure is justified. If justified, all Member States must ensure the non-compliant AI system is removed from their markets. If unjustified, the Member State must withdraw the measure. If the AI system's non-compliance is due to issues with harmonised standards or common specifications, the Commission will follow the procedure in Article 11 of Regulation (EU) No 1025/2012."
General Data Protection Regulation (GDPR) - Contextual Paragraph (54),0.718850851,"Details of the Contextual Paragraph (54) in the General Data Protection Regulation (GDPR): The processing of special categories of personal data may be necessary for reasons of public interest in the areas of public health without consent of the data subject. Such processing should be subject to suitable and specific measures so as to protect the rights and freedoms of natural persons. In that context, ""public health"" should be interpreted as defined in Regulation (EC) No 1338/2008 of the European Parliament and of the Council ( 1 ), namely all elements related to health, namely health status, including morbidity and disability, the determinants having an effect on that health status, health care needs, resources allocated to health care, the provision of, and universal access to, health care as well as health care expenditure and financing, and the causes of mortality. Such processing of data concerning health for reasons of public interest should not result in personal data being processed for other purposes by third parties such as employers or insurance and banking companies.",recital,"The General Data Protection Regulation (GDPR) allows for the processing of special categories of personal data, such as health information, without the individual's consent if it's necessary for public health reasons. However, this must be done in a way that protects the individual's rights and freedoms. ""Public health"" includes all aspects of health, such as health status, health care needs, and health care resources. Importantly, this law prevents third parties like employers or insurance companies from using this health data for their own purposes."
Artifical Inellegence Act (AI Act) - Article 55,0.718821287,"Aritifical Intelligence Act (AI Act) Article 55 Measures for small-scale providers and users:

1.Member States shall undertake the following actions:

(a)provide small-scale providers and start-ups with priority access to the AI regulatory sandboxes to the extent that they fulfil the eligibility conditions;

(b)organise specific awareness raising activities about the application of this Regulation tailored to the needs of the small-scale providers and users;

(c)where appropriate, establish a dedicated channel for communication with small-scale providers and user and other innovators to provide guidance and respond to queries about the implementation of this Regulation.

2.The specific interests and needs of the small-scale providers shall be taken into account when setting the fees for conformity assessment under Article 43, reducing those fees proportionately to their size and market size.",article,"The Artificial Intelligence Act (AI Act) is a new law that includes measures to support small-scale providers and start-ups. It mandates that these smaller entities should be given priority access to AI regulatory sandboxes if they meet certain conditions. The law also requires the organization of activities to increase awareness about the regulation among these small-scale providers and users. A dedicated communication channel may also be established to guide these entities and answer their queries about the regulation. Furthermore, the law stipulates that the fees for compliance assessment should be set considering the specific interests and needs of these small-scale providers, and should be reduced in proportion to their size and market size."
Digital Markets Act (DMA) - Contextual Paragraph (2),0.718759954,"Details of the Contextual Paragraph (2) in the Digital Markets Act (DMA): At the same time, among those digital services, core platform services feature a number of characteristics that can be exploited by the undertakings providing them. An example of such characteristics of core platform services is extreme scale economies, which often result from nearly zero marginal costs to add business users or end users. Other such characteristics of core platform services are very strong network effects, an ability to connect many business users with many end users through the multisidedness of these services, a significant degree of dependence of both business users and end users, lock-in effects, a lack of multi-homing for the same purpose by end users, vertical integration, and data driven-advantages. All these characteristics, combined with unfair practices by undertakings providing the core platform services, can have the effect of substantially undermining the contestability of the core platform services, as well as impacting the fairness of the commercial relationship between undertakings providing such services and their business users and end users. In practice, this leads to rapid and potentially far-reaching decreases in business users"" and end users"" choice, and therefore can confer on the provider of those services the position of a so-called gatekeeper. At the same time, it should be recognised that services which act in a non-commercial purpose capacity such as collaborative projects should not be considered as core platform services for the purpose of this Regulation.",rectial,"The Digital Markets Act (DMA) addresses issues with digital services, specifically core platform services. These platforms can exploit certain features like their large scale, ability to connect many users, and data-driven advantages. This can lead to unfair practices that limit competition and affect the fairness of business relationships between the service provider and users. This can also limit the choices for business and end users, giving the service provider a gatekeeper role. However, services used for non-commercial purposes, like collaborative projects, are not considered core platform services under this law."
General Data Protection Regulation (GDPR) - Definition of consent,0.718700767,"Details of the Definition of consent in the General Data Protection Regulation (GDPR): ""consent"" of the data subject means any freely given, specific, informed and unambiguous indication of the data subject's wishes by which he or she, by a statement or by a clear affirmative action, signifies agreement to the processing of personal data relating to him or her;",recital,"The General Data Protection Regulation (GDPR) defines ""consent"" as a clear, informed, and voluntary agreement from a person (data subject) for their personal data to be processed. This means that the person must fully understand what they are agreeing to, and they must actively show their agreement, either through a statement or a clear action. They should not be forced or tricked into giving consent."
Digital Services Act (DSA) - Article 80 Publication of decisions,0.718691,"Article 80 Publication of decisions in the Digital Services Act (DSA):  1.   The Commission shall publish the decisions it adopts pursuant to Article 70(1), Article 71(1) and Articles 73 to 76. Such publication shall state the names of the parties and the main content of the decision, including any penalties imposed.

2.   The publication shall have regard to the rights and legitimate interests of the provider of the very large online platform or of the very large online search engine concerned, any other person referred to in Article 67(1) and any third parties in the protection of their confidential information.",article,"The Digital Services Act (DSA) requires the Commission to publicly share its decisions related to certain articles. These publications will include the names of involved parties and key details of the decision, including any penalties. However, the DSA also ensures that these publications respect the rights and interests of large online platform providers, search engines, and other parties mentioned in Article 67(1). This includes protecting their confidential information."
Digital Markets Act (DMA) - Article 31 Periodic penalty payments,0.718681216,"Details of Article 31 Periodic penalty payments in the Digital Markets Act (DMA): 1. The Commission may adopt a decision imposing on undertakings, including gatekeepers where applicable, and associations of undertakings periodic penalty payments not exceeding 5 % of the average daily worldwide turnover in the preceding financial year per day, calculated from the date set by that decision, in order to compel them: (a) to comply with the measures specified by the Commission in a decision adopted pursuant to Article 8(2); (b) to comply with the decision pursuant to Article 18(1); (c) to supply correct and complete information within the time limit required by a request for information made by decision pursuant to Article 21; (d) to ensure access to data, algorithms and information about testing in response to a request made pursuant to Article 21(3) and to supply explanations on those as required by a decision pursuant to Article 21; (e) to submit to an inspection which was ordered by a decision taken pursuant to Article 23; (f) to comply with a decision ordering interim measures taken pursuant to Article 24; (g) to comply with commitments made legally binding by a decision pursuant to Article 25(1); (h) to comply with a decision pursuant to Article 29(1). 2. Where the undertakings, or associations of undertakings, have satisfied the obligation which the periodic penalty payment was intended to enforce, the Commission may adopt an implementing act, setting the definitive amount of the periodic penalty payment at a figure lower than that which would arise under the original decision. That implementing act shall be adopted in accordance with the advisory procedure referred to in Article 50(2).",article,"The Digital Markets Act (DMA) includes Article 31, which allows the Commission to impose fines on businesses, including major digital platforms, if they fail to comply with certain rules. These fines can be up to 5% of the company's daily global turnover from the previous financial year. The rules include complying with specific measures, providing accurate and timely information, allowing access to data and algorithms, submitting to inspections, complying with interim measures, and adhering to legally binding commitments. If a company fulfills its obligations, the Commission may reduce the fine. The final amount of the fine will be determined through a specific advisory procedure."
Artifical Inellegence Act (AI Act) - Context Section 3.5,0.718657136,"Aritifical Intelligence Act (AI Act) context section 3.5.Fundamental rights: 

The use of AI with its specific characteristics (e.g. opacity, complexity, dependency on data, autonomous behaviour) can adversely affect a number of fundamental rights enshrined in the EU Charter of Fundamental Rights (the Charter). This proposal seeks to ensure a high level of protection for those fundamental rights and aims to address various sources of risks through a clearly defined risk-based approach. With a set of requirements for trustworthy AI and proportionate obligations on all value chain participants, the proposal will enhance and promote the protection of the rights protected by the Charter: the right to human dignity (Article 1), respect for private life and protection of personal data (Articles 7 and 8), non-discrimination (Article 21) and equality between women and men (Article 23). It aims to prevent a chilling effect on the rights to freedom of expression (Article 11) and freedom of assembly (Article 12), to ensure protection of the right to an effective remedy and to a fair trial, the rights of defence and the presumption of innocence (Articles 47 and 48), as well as the general principle of good administration. Furthermore, as applicable in certain domains, the proposal will positively affect the rights of a number of special groups, such as the workers rights to fair and just working conditions (Article 31), a high level of consumer protection (Article 28), the rights of the child (Article 24) and the integration of persons with disabilities (Article 26). The right to a high level of environmental protection and the improvement of the quality of the environment (Article 37) is also relevant, including in relation to the health and safety of people. The obligations for ex ante testing, risk management and human oversight will also facilitate the respect of other fundamental rights by minimising the risk of erroneous or biased AI-assisted decisions in critical areas such as education and training, employment, important services, law enforcement and the judiciary. In case infringements of fundamental rights still happen, effective redress for affected persons will be made possible by ensuring transparency and traceability of the AI systems coupled with strong ex post controls.

This proposal imposes some restrictions on the freedom to conduct business (Article 16) and the freedom of art and science (Article 13) to ensure compliance with overriding reasons of public interest such as health, safety, consumer protection and the protection of other fundamental rights (responsible innovation) when high-risk AI technology is developed and used. Those restrictions are proportionate and limited to the minimum necessary to prevent and mitigate serious safety risks and likely infringements of fundamental rights.3.5.Fundamental rights:

The use of AI with its specific characteristics (e.g. opacity, complexity, dependency on data, autonomous behaviour) can adversely affect a number of fundamental rights enshrined in the EU Charter of Fundamental Rights (the Charter). This proposal seeks to ensure a high level of protection for those fundamental rights and aims to address various sources of risks through a clearly defined risk-based approach. With a set of requirements for trustworthy AI and proportionate obligations on all value chain participants, the proposal will enhance and promote the protection of the rights protected by the Charter: the right to human dignity (Article 1), respect for private life and protection of personal data (Articles 7 and 8), non-discrimination (Article 21) and equality between women and men (Article 23). It aims to prevent a chilling effect on the rights to freedom of expression (Article 11) and freedom of assembly (Article 12), to ensure protection of the right to an effective remedy and to a fair trial, the rights of defence and the presumption of innocence (Articles 47 and 48), as well as the general principle of good administration. Furthermore, as applicable in certain domains, the proposal will positively affect the rights of a number of special groups, such as the workers rights to fair and just working conditions (Article 31), a high level of consumer protection (Article 28), the rights of the child (Article 24) and the integration of persons with disabilities (Article 26). The right to a high level of environmental protection and the improvement of the quality of the environment (Article 37) is also relevant, including in relation to the health and safety of people. The obligations for ex ante testing, risk management and human oversight will also facilitate the respect of other fundamental rights by minimising the risk of erroneous or biased AI-assisted decisions in critical areas such as education and training, employment, important services, law enforcement and the judiciary. In case infringements of fundamental rights still happen, effective redress for affected persons will be made possible by ensuring transparency and traceability of the AI systems coupled with strong ex post controls.

This proposal imposes some restrictions on the freedom to conduct business (Article 16) and the freedom of art and science (Article 13) to ensure compliance with overriding reasons of public interest such as health, safety, consumer protection and the protection of other fundamental rights (responsible innovation) when high-risk AI technology is developed and used. Those restrictions are proportionate and limited to the minimum necessary to prevent and mitigate serious safety risks and likely infringements of fundamental rights.",recital,"The Artificial Intelligence Act (AI Act) aims to protect fundamental rights outlined in the EU Charter of Fundamental Rights. The Act recognizes that AI can potentially harm these rights due to its opacity, complexity, and autonomous behavior. To address these risks, the Act proposes a risk-based approach, with clear requirements for AI and obligations for all participants in the AI value chain. The Act aims to protect rights such as human dignity, privacy, non-discrimination, equality, freedom of expression, and the right to a fair trial. It also aims to protect the rights of special groups, such as workers, consumers, children, and people with disabilities. The Act proposes measures like testing, risk management, and human oversight to prevent biased or incorrect AI decisions. If rights are violated, the Act ensures redress through transparency and traceability of AI systems. The Act also imposes some restrictions on business and the arts to ensure public safety and protection of rights when high-risk AI technology is used."
General Data Protection Regulation (GDPR) - Definition of supervisory authority,0.718625546,"Details of the Definition of supervisory authority in the General Data Protection Regulation (GDPR): ""supervisory authority"" means an independent public authority which is established by a Member State pursuant to Article 51;",recital,"The General Data Protection Regulation (GDPR) introduces a term called ""supervisory authority"". This refers to an independent public body, set up by a member state as per Article 51 of the GDPR. This body's role is to oversee and enforce the application of data protection law. Its main aim is to protect your personal data and privacy rights."
General Data Protection Regulation (GDPR) - Contextual Paragraph (33),0.718616605,"Details of the Contextual Paragraph (33) in the General Data Protection Regulation (GDPR): It is often not possible to fully identify the purpose of personal data processing for scientific research purposes at the time of data collection. Therefore, data subjects should be allowed to give their consent to certain areas of scientific research when in keeping with recognised ethical standards for scientific research. Data subjects should have the opportunity to give their consent only to certain areas of research or parts of research projects to the extent allowed by the intended purpose.",recital,"The General Data Protection Regulation (GDPR) includes a provision (Paragraph 33) for scientific research. It acknowledges that the specific use of personal data may not be clear when it's first collected for research. Therefore, people should be able to consent to their data being used for specific areas of scientific research, in line with ethical standards. They should also have the option to consent to only certain parts of a research project, as long as it aligns with the project's purpose."
General Data Protection Regulation (GDPR) - Article 46 Transfers subject to appropriate safeguards,0.718610168,"Details of Article 46 Transfers subject to appropriate safeguards in the General Data Protection Regulation (GDPR): 1. In the absence of a decision pursuant to Article 45(3), a controller or processor may transfer personal data to a third country or an international organisation only if the controller or processor has provided appropriate safeguards, and on condition that enforceable data subject rights and effective legal remedies for data subjects are available. 2. The appropriate safeguards referred to in paragraph 1 may be provided for, without requiring any specific authorisation from a supervisory authority, by: (a) a legally binding and enforceable instrument between public authorities or bodies; (b) binding corporate rules in accordance with Article 47; (c) standard data protection clauses adopted by the Commission in accordance with the examination procedure referred to in Article 93(2); (d) standard data protection clauses adopted by a supervisory authority and approved by the Commission pursuant to the examination procedure referred to in Article 93(2); (e) an approved code of conduct pursuant to Article 40 together with binding and enforceable commitments of the controller or processor in the third country to apply the appropriate safeguards, including as regards data subjects' rights; or (f) an approved certification mechanism pursuant to Article 42 together with binding and enforceable commitments of the controller or processor in the third country to apply the appropriate safeguards, including as regards data subjects' rights. 3. Subject to the authorisation from the competent supervisory authority, the appropriate safeguards referred to in paragraph 1 may also be provided for, in particular, by: (a) contractual clauses between the controller or processor and the controller, processor or the recipient of the personal data in the third country or international organisation; or (b) provisions to be inserted into administrative arrangements between public authorities or bodies which include enforceable and effective data subject rights. 4. The supervisory authority shall apply the consistency mechanism referred to in Article 63 in the cases referred to in paragraph 3 of this Article. 5. Authorisations by a Member State or supervisory authority on the basis of Article 26(2) of Directive 95/46/EC shall remain valid until amended, replaced or repealed, if necessary, by that supervisory authority. Decisions adopted by the Commission on the basis of Article 26(4) of Directive 95/46/EC shall remain in force until amended, replaced or repealed, if necessary, by a Commission Decision adopted in accordance with paragraph 2 of this Article.",article,"Article 46 of the General Data Protection Regulation (GDPR) states that personal data can only be transferred to a third country or international organization if there are proper safeguards in place. These safeguards must ensure that individuals' rights are protected and that they have access to legal remedies. Safeguards can be provided by legal agreements between public bodies, corporate rules, standard data protection clauses, approved codes of conduct or certification mechanisms. In some cases, approval from a supervisory authority may be required. Existing authorizations based on previous laws will remain valid until they are replaced or repealed."
Artifical Inellegence Act (AI Act) - Article 16,0.718599737,"Aritifical Intelligence Act (AI Act) Article 16 Obligations of providers of high-risk AI systems:

Providers of high-risk AI systems shall:

(a)ensure that their high-risk AI systems are compliant with the requirements set out in Chapter 2 of this Title;

(b)have a quality management system in place which complies with Article 17;

(c)draw-up the technical documentation of the high-risk AI system;

(d)when under their control, keep the logs automatically generated by their high-risk AI systems;

(e)ensure that the high-risk AI system undergoes the relevant conformity assessment procedure, prior to its placing on the market or putting into service;

(f)comply with the registration obligations referred to in Article 51;

(g)take the necessary corrective actions, if the high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title;

(h)inform the national competent authorities of the Member States in which they made the AI system available or put it into service and, where applicable, the notified body of the non-compliance and of any corrective actions taken;

(i)to affix the CE marking to their high-risk AI systems to indicate the conformity with this Regulation in accordance with Article 49;

(j)upon request of a national competent authority, demonstrate the conformity of the high-risk AI system with the requirements set out in Chapter 2 of this Title.",article,"The Artificial Intelligence Act (AI Act) obligates providers of high-risk AI systems to ensure their products meet certain standards. These include having a quality management system, providing technical documentation, and keeping logs of system activity. Before launching, these AI systems must undergo a conformity assessment procedure to ensure they meet the necessary requirements. They also need to be registered as per the AI Act. If the system doesn't meet the standards, corrective action must be taken. Authorities in the countries where the AI systems are used must be informed about any non-compliance and corrective actions. The AI systems must bear a CE marking to indicate they meet the regulations. If asked by a national authority, providers must prove their AI system meets the required standards."
Digital Services Act (DSA) - Definition of 'substantial connection to the Union',0.718579,"Definition of 'substantial connection to the Union' in the Digital Services Act (DSA): a connection of a provider of intermediary services with the Union resulting either from its establishment in the Union or from specific factual criteria, such as:
-   a significant number of recipients of the service in one or more Member States in relation to its or their population. or
-  the targeting of activities towards one or more Member States.",recital,"The Digital Services Act (DSA) introduces a term 'substantial connection to the Union'. This means a service provider is significantly linked to the European Union (EU) either because it's based there or due to certain facts. These facts could be having a large number of service users in one or more EU countries compared to the population, or specifically aiming their activities at one or more EU countries."
General Data Protection Regulation (GDPR) - Article 76 Confidentiality,0.718551576,"Details of Article 76 Confidentiality in the General Data Protection Regulation (GDPR): 1. The discussions of the Board shall be confidential where the Board deems it necessary, as provided for in its rules of procedure. 2. Access to documents submitted to members of the Board, experts and representatives of third parties shall be governed by Regulation (EC) No 1049/2001 of the European Parliament and of the Council ( 1 ).",article,"Article 76 of the General Data Protection Regulation (GDPR) is about confidentiality. It states that the discussions of the Board can be kept confidential if they think it's needed, according to their rules. Also, the access to documents given to board members, experts, and third-party representatives is controlled by a specific regulation, Regulation (EC) No 1049/2001, set by the European Parliament and Council."
Digital Markets Act (DMA) - Article 26 Monitoring of obligations and measures,0.718521953,"Details of Article 26 Monitoring of obligations and measures in the Digital Markets Act (DMA): 1. The Commission shall take the necessary actions to monitor the effective implementation and compliance with the obligations laid down in Articles 5, 6 and 7 and the decisions taken pursuant to Articles 8, 18, 24, 25 and 29. Those actions may include, in particular, the imposition of an obligation on the gatekeeper to retain all documents deemed to be relevant to assess the implementation of, and compliance with, those obligations and decisions. 2. The actions pursuant to paragraph 1 may include the appointment of independent external experts and auditors, as well as the appointment of officials from national competent authorities of the Member States, to assist the Commission to monitor the obligations and measures and to provide specific expertise or knowledge to the Commission.",article,"The Digital Markets Act (DMA) Article 26 outlines how the Commission will ensure that companies are following the rules set out in the DMA. This includes checking that companies are implementing and complying with obligations and decisions from specific articles in the law. The Commission may require companies, referred to as gatekeepers, to keep all relevant documents. The Commission may also hire independent experts and auditors, or appoint officials from national authorities of Member States, to help monitor companies and provide expert knowledge."
Artifical Inellegence Act (AI Act) - Article 33,0.718490124,"Aritifical Intelligence Act (AI Act) Article 33 Notified bodies:

1.Notified bodies shall verify the conformity of high-risk AI system in accordance with the conformity assessment procedures referred to in Article 43.

2.Notified bodies shall satisfy the organisational, quality management, resources and process requirements that are necessary to fulfil their tasks.

3.The organisational structure, allocation of responsibilities, reporting lines and operation of notified bodies shall be such as to ensure that there is confidence in the performance by and in the results of the conformity assessment activities that the notified bodies conduct.

4.Notified bodies shall be independent of the provider of a high-risk AI system in relation to which it performs conformity assessment activities. Notified bodies shall also be independent of any other operator having an economic interest in the high-risk AI system that is assessed, as well as of any competitors of the provider.

5.Notified bodies shall be organised and operated so as to safeguard the independence, objectivity and impartiality of their activities. Notified bodies shall document and implement a structure and procedures to safeguard impartiality and to promote and apply the principles of impartiality throughout their organisation, personnel and assessment activities.

6.Notified bodies shall have documented procedures in place ensuring that their personnel, committees, subsidiaries, subcontractors and any associated body or personnel of external bodies respect the confidentiality of the information which comes into their possession during the performance of conformity assessment activities, except when disclosure is required by law. The staff of notified bodies shall be bound to observe professional secrecy with regard to all information obtained in carrying out their tasks under this Regulation, except in relation to the notifying authorities of the Member State in which their activities are carried out.

7.Notified bodies shall have procedures for the performance of activities which take due account of the size of an undertaking, the sector in which it operates, its structure, the degree of complexity of the AI system in question.

8.Notified bodies shall take out appropriate liability insurance for their conformity assessment activities, unless liability is assumed by the Member State concerned in accordance with national law or that Member State is directly responsible for the conformity assessment.

9.Notified bodies shall be capable of carrying out all the tasks falling to them under this Regulation with the highest degree of professional integrity and the requisite competence in the specific field, whether those tasks are carried out by notified bodies themselves or on their behalf and under their responsibility.

10.Notified bodies shall have sufficient internal competences to be able to effectively evaluate the tasks conducted by external parties on their behalf. To that end, at all times and for each conformity assessment procedure and each type of high-risk AI system in relation to which they have been designated, the notified body shall have permanent availability of sufficient administrative, technical and scientific personnel who possess experience and knowledge relating to the relevant artificial intelligence technologies, data and data computing and to the requirements set out in Chapter 2 of this Title.

11.Notified bodies shall participate in coordination activities as referred to in Article 38. They shall also take part directly or be represented in European standardisation organisations, or ensure that they are aware and up to date in respect of relevant standards.

12.Notified bodies shall make available and submit upon request all relevant documentation, including the providers documentation, to the notifying authority referred to in Article 30 to allow it to conduct its assessment, designation, notification, monitoring and surveillance activities and to facilitate the assessment outlined in this Chapter.",article,"The Artificial Intelligence Act (AI Act) outlines the responsibilities and requirements for notified bodies, which are organizations that assess high-risk AI systems. These bodies must ensure these systems meet certain standards (Article 43), and have the necessary resources and processes to do this. They must operate independently from the AI system provider and any other party with a financial interest in the system. They must also maintain confidentiality unless required by law to disclose information. They should consider the size, sector, and complexity of the AI system when performing assessments. They must have liability insurance for their assessments, unless the member state assumes liability. They must have the necessary skills and knowledge to evaluate AI technologies and data. They must participate in coordination activities and standardization organizations, and provide all relevant documentation to the notifying authority when requested."
Digital Services Act (DSA) - Contextual paragraph (68),0.718457937,"Details of the contextual paragraph (68) of the Digital Services Act (DSA): Online advertising plays an important role in the online environment, including in relation to the provision of online platforms, where the provision of the service is sometimes in whole or in part remunerated directly or indirectly, through advertising revenues. Online advertising can contribute to significant risks, ranging from advertisements that are themselves illegal content, to contributing to financial incentives for the publication or amplification of illegal or otherwise harmful content and activities online, or the discriminatory presentation of advertisements with an impact on the equal treatment and opportunities of citizens. In addition to the requirements resulting from Article 6 of Directive 2000/31/EC, providers of online platforms should therefore be required to ensure that the recipients of the service have certain individualised information necessary for them to understand when and on whose behalf the advertisement is presented. They should ensure that the information is salient, including through standardised visual or audio marks, clearly identifiable and unambiguous for the average recipient of the service, and should be adapted to the nature of the individual service's online interface. In addition, recipients of the service should have information directly accessible from the online interface where the advertisement is presented, on the main parameters used for determining that a specific advertisement is presented to them, providing meaningful explanations of the logic used to that end, including when this is based on profiling.
Such explanations should include information on the method used for presenting the advertisement, for example whether it is contextual or other type of advertising, and, where applicable, the main profiling criteria used; it should also inform the recipient about any means available for them to change such criteria. The requirements of this Regulation on the provision of information relating to advertising is without prejudice to the application of the relevant provisions of Regulation (EU) 2016/679, in particular those regarding the right to object, automated individual decision-making, including profiling, and specifically the need to obtain consent of the data subject prior to the processing of personal data for targeted advertising. Similarly, it is without prejudice to the provisions laid down in Directive 2002/58/EC in particular those regarding the storage of information in terminal equipment and the access to information stored therein. Finally, this Regulation complements the application of the Directive 2010/13/EU which imposes measures to enable users to declare audiovisual commercial communications in user-generated videos. It also complements the obligations for traders regarding the disclosure of commercial communications deriving from Directive 2005/29/EC.",recital,"The Digital Services Act (DSA) addresses the role and risks of online advertising. It requires online platforms to provide clear, easily understood information about advertisements, including who is presenting the ad and why it's being shown to the user. This includes explaining the logic behind why a specific ad is shown, including any profiling used. Users should also be informed about how they can change these criteria. The DSA also emphasizes the need for user consent prior to processing personal data for targeted advertising, and complements other regulations regarding commercial communications and user-generated videos. The law aims to ensure equal treatment and opportunities for all citizens and prevent the spread of illegal or harmful content."
Artifical Inellegence Act (AI Act) - Overview paragraph 71,0.71843493,"Aritifical Intelligence Act (AI Act) overview paragraph (71): Artificial intelligence is a rapidly developing family of technologies that requires novel forms of regulatory oversight and a safe space for experimentation, while ensuring responsible innovation and integration of appropriate safeguards and risk mitigation measures. To ensure a legal framework that is innovation-friendly, future-proof and resilient to disruption, national competent authorities from one or more Member States should be encouraged to establish artificial intelligence regulatory sandboxes to facilitate the development and testing of innovative AI systems under strict regulatory oversight before these systems are placed on the market or otherwise put into service.",recital,"The Artificial Intelligence Act (AI Act) is a new law that aims to regulate the fast-growing field of AI technology. It encourages the creation of ""regulatory sandboxes"" by authorities in member states. These sandboxes are safe spaces where AI systems can be developed and tested under strict supervision before they are released to the market. The aim is to foster innovation while ensuring that appropriate safety measures and risk controls are in place. This law is designed to be adaptable to future changes and resilient to disruption in the AI industry."
Artifical Inellegence Act (AI Act) - Overview paragraph 86,0.718387067,"Aritifical Intelligence Act (AI Act) overview paragraph (86): In order to ensure uniform conditions for the implementation of this Regulation, implementing powers should be conferred on the Commission. Those powers should be exercised in accordance with Regulation (EU) No 182/2011 of the European Parliament and of the Council59.",recital,"The Artificial Intelligence Act (AI Act) is a new law that aims to standardize the use of artificial intelligence (AI). This law gives the European Commission the power to implement the regulations. The Commission must follow the guidelines set out in another law, the Regulation (EU) No 182/2011, to ensure that the AI Act is applied fairly and consistently across the European Union."
Artifical Inellegence Act (AI Act) - Overview paragraph 47,0.718380451,"Aritifical Intelligence Act (AI Act) overview paragraph (47): To address the opacity that may make certain AI systems incomprehensible to or too complex for natural persons, a certain degree of transparency should be required for high-risk AI systems. Users should be able to interpret the system output and use it appropriately. High-risk AI systems should therefore be accompanied by relevant documentation and instructions of use and include concise and clear information, including in relation to possible risks to fundamental rights and discrimination, where appropriate.",recital,"The Artificial Intelligence Act (AI Act) aims to make high-risk AI systems more transparent and understandable for users. It requires these systems to come with clear instructions and information, including potential risks to fundamental rights and possible discrimination. The goal is to ensure users can interpret the system's output and use it correctly."
Artifical Inellegence Act (AI Act) - Overview paragraph 27,0.71835506,"Aritifical Intelligence Act (AI Act) overview paragraph (27): High-riskAI systems should only be placed on the Union market or put into service if they comply with certain mandatory requirements. Those requirements should ensure that high-risk AI systems available in the Union or whose output is otherwise used in the Union do not pose unacceptable risks to important Union public interestsas recognised and protected by Union law. AI systems identified as high-risk should be limited to those that have a significant harmful impact on the health, safety and fundamental rights of persons in the Union and such limitation minimises any potential restriction to international trade, if any.",recital,"The Artificial Intelligence Act (AI Act) states that AI systems considered high-risk can only be used in the Union if they meet certain requirements. These requirements are designed to protect public interests within the Union, as recognized by Union law. High-risk AI systems are those that could significantly harm people's health, safety, and basic rights within the Union. The law aims to minimize any potential restrictions on international trade."
General Data Protection Regulation (GDPR) - Article 24 Responsibility of the controller,0.718331099,"Details of Article 24 Responsibility of the controller in the General Data Protection Regulation (GDPR): 1. Taking into account the nature, scope, context and purposes of processing as well as the risks of varying likelihood and severity for the rights and freedoms of natural persons, the controller shall implement appropriate technical and organisational measures to ensure and to be able to demonstrate that processing is performed in accordance with this Regulation. Those measures shall be reviewed and updated where necessary. 2. Where proportionate in relation to processing activities, the measures referred to in paragraph 1 shall include the implementation of appropriate data protection policies by the controller. 3. Adherence to approved codes of conduct as referred to in Article 40 or approved certification mechanisms as referred to in Article 42 may be used as an element by which to demonstrate compliance with the obligations of the controller.",article,"The General Data Protection Regulation (GDPR) Article 24 states that those in charge of handling personal data (the controller) must take appropriate steps to ensure that data is processed in a way that respects this law. This includes considering the type, extent, context, and purpose of the data processing, as well as the risks to individuals' rights and freedoms. The controller must regularly review and update these measures. If relevant to the data processing activities, the controller should also have suitable data protection policies in place. Adhering to approved codes of conduct or certification mechanisms can be used to show that the controller is meeting their obligations under the law."
Digital Services Act (DSA) - Article 73 Non-compliance,0.718296647,"Article 73 Non-compliance in the Digital Services Act (DSA):  1.   The Commission shall adopt a non-compliance decision where it finds that the provider of the very large online platform or of the very large online search engine concerned does not comply with one or more of the following:

(a) the relevant provisions of this Regulation;
(b) interim measures ordered pursuant to Article 70;
(c) commitments made binding pursuant to Article 71.

2.   Before adopting the decision pursuant to paragraph 1, the Commission shall communicate its preliminary findings to the provider of the very large online platform or of the very large online search engine concerned. In the preliminary findings, the Commission shall explain the measures that it considers taking, or that it considers that the provider of the very large online platform or of the very large online search engine concerned should take, in order to effectively address the preliminary findings.

3.   In the decision adopted pursuant to paragraph 1 the Commission shall order the provider of the very large online platform or of the very large online search engine concerned to take the necessary measures to ensure compliance with the decision pursuant to paragraph 1 within a reasonable period specified therein and to provide information on the measures that that provider intends to take to comply with the decision.

4.   The provider of the very large online platform or of the very large online search engine concerned shall provide the Commission with a description of the measures it has taken to ensure compliance with the decision pursuant to paragraph 1 upon their implementation.

5.   Where the Commission finds that the conditions of paragraph 1 are not met, it shall close the investigation by a decision. The decision shall apply with immediate effect.",article,"The Digital Services Act (DSA) says that if a large online platform or search engine doesn't follow the rules of the Act, or any interim measures or commitments they've agreed to, the Commission can take action. Before doing this, the Commission will share its initial findings with the platform or search engine and suggest steps to fix the problem. If the platform or search engine doesn't comply, the Commission will order them to take necessary actions within a certain timeframe and ask for information about how they plan to comply. The platform or search engine must then tell the Commission what they've done to comply. If the platform or search engine meets all the conditions, the Commission will close the investigation immediately."
Artifical Inellegence Act (AI Act) - Definition of 'notified body',0.718279541,"Within the Aritifical Intelligence Act (AI Act), the Definition of notified body means a conformity assessment body designated in accordance with this Regulation and other relevant Union harmonisation legislation;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'notified body'. This refers to an organization that checks if certain products, services, or systems meet specific standards or requirements. This body is officially recognized under this law and other related European Union laws."
Digital Markets Act (DMA) - Contextual Paragraph (20),0.718188822,"Details of the Contextual Paragraph (20) in the Digital Markets Act (DMA): Having a very high number of business users that depend on a core platform service to reach a very high number of monthly active end users enables the undertaking providing that service to influence the operations of a substantial part of business users to its advantage and indicate, in principle, that that undertaking is an important gateway. The respective relevant levels for those numbers should be set representing a substantive percentage of the entire population of the Union when it comes to end users and of the entire population of businesses using core platform services to determine the threshold for business users. Active end users and business users should be identified and calculated in such a way as to adequately represent the role and reach of the specific core platform service in question. In order to provide legal certainty for gatekeepers, the elements to determine the number of active end users and business users per core platform service should be set out in an Annex to this Regulation. Such elements can be affected by technological and other developments. The Commission should therefore be empowered to adopt delegated acts to amend this Regulation by updating the methodology and the list of indicators used to determine the number of active end users and active business users.",rectial,"The Digital Markets Act (DMA) states that if a digital platform has a significant number of business users and monthly active users, it can greatly influence business operations. The DMA sets thresholds for these numbers, which should represent a substantial percentage of the EU's population and businesses using these platforms. The DMA also provides guidelines for identifying and calculating these users to accurately reflect the platform's influence. To ensure legal clarity, the DMA includes an Annex detailing how to calculate these user numbers. The Commission can update this Annex to reflect technological changes."
Digital Services Act (DSA) - Article 13 Legal representatives,0.718177736,"Article 13 Legal representatives in the Digital Services Act (DSA):  1.   Providers of intermediary services which do not have an establishment in the Union but which offer services in the Union shall designate, in writing, a legal or natural person to act as their legal representative in one of the Member States where the provider offers its services.
2.   Providers of intermediary services shall mandate their legal representatives for the purpose of being addressed in addition to or instead of such providers, by the Member States' competent authorities, the Commission and the Board, on all issues necessary for the receipt of, compliance with and enforcement of decisions issued in relation to this Regulation. Providers of intermediary services shall provide their legal representative with necessary powers and sufficient resources to guarantee their efficient and timely cooperation with the Member States' competent authorities, the Commission and the Board, and to comply with such decisions.
3.   It shall be possible for the designated legal representative to be held liable for non-compliance with obligations under this Regulation, without prejudice to the liability and legal actions that could be initiated against the provider of intermediary services.
4.   Providers of intermediary services shall notify the name, postal address, email address and telephone number of their legal representative to the Digital Services Coordinator in the Member State where that legal representative resides or is established. They shall ensure that that information is publicly available, easily accessible, accurate and kept up to date.
5.   The designation of a legal representative within the Union pursuant to paragraph 1 shall not constitute an establishment in the Union.",article,"The Digital Services Act (DSA) requires providers of intermediary services, even those not based in the EU, but offering services there, to appoint a legal representative in a member state where they operate. This representative will be responsible for liaising with authorities on compliance and enforcement of regulations. They could also be held liable for non-compliance. The service providers must provide their representatives with the necessary resources to perform their duties efficiently. The providers must also share the contact details of their representatives with the Digital Services Coordinator in the relevant member state and ensure this information is publicly available and updated. The appointment of a representative does not mean the provider has established a base in the EU."
Digital Markets Act (DMA) - Article 43 Reporting of breaches and protection of reporting persons,0.718109667,Details of Article 43 Reporting of breaches and protection of reporting persons in the Digital Markets Act (DMA): Directive (EU) 2019/1937 shall apply to the reporting of all breaches of this Regulation and the protection of persons reporting such breaches.,article,"The Digital Markets Act (DMA) includes Article 43, which is about reporting violations and protecting those who report them. This article follows the guidelines of Directive (EU) 2019/1937. In simple terms, if someone notices a breach or violation of the rules set by the DMA, they can report it. Also, the person who reports such violations is protected under this law, meaning they shouldn't face any negative consequences for reporting the breach."
General Data Protection Regulation (GDPR) - Contextual Paragraph (87),0.717996061,Details of the Contextual Paragraph (87) in the General Data Protection Regulation (GDPR): It should be ascertained whether all appropriate technological protection and organisational measures have been implemented to establish immediately whether a personal data breach has taken place and to inform promptly the supervisory authority and the data subject. The fact that the notification was made without undue delay should be established taking into account in particular the nature and gravity of the personal data breach and its consequences and adverse effects for the data subject. Such notification may result in an intervention of the supervisory authority in accordance with its tasks and powers laid down in this Regulation.,recital,"The General Data Protection Regulation (GDPR) requires companies to have proper technology and procedures in place to quickly identify and report any breaches of personal data. The speed of this notification depends on how serious the breach is and its potential negative impact on the individual whose data was breached. If a breach is reported, the supervisory authority may step in to take action according to the rules of the GDPR."
General Data Protection Regulation (GDPR) - Article 21 Right to object,0.717983782,"Details of Article 21 Right to object in the General Data Protection Regulation (GDPR): 1. The data subject shall have the right to object, on grounds relating to his or her particular situation, at any time to processing of personal data concerning him or her which is based on point (e) or (f) of Article 6(1), including profiling based on those provisions. The controller shall no longer process the personal data unless the controller demonstrates compelling legitimate grounds for the processing which override the interests, rights and freedoms of the data subject or for the establishment, exercise or defence of legal claims. 2. Where personal data are processed for direct marketing purposes, the data subject shall have the right to object at any time to processing of personal data concerning him or her for such marketing, which includes profiling to the extent that it is related to such direct marketing. 3. Where the data subject objects to processing for direct marketing purposes, the personal data shall no longer be processed for such purposes. 4. At the latest at the time of the first communication with the data subject, the right referred to in paragraphs 1 and 2 shall be explicitly brought to the attention of the data subject and shall be presented clearly and separately from any other information. 5. In the context of the use of information society services, and notwithstanding Directive 2002/58/EC, the data subject may exercise his or her right to object by automated means using technical specifications. 6. Where personal data are processed for scientific or historical research purposes or statistical purposes pursuant to Article 89(1), the data subject, on grounds relating to his or her particular situation, shall have the right to object to processing of personal data concerning him or her, unless the processing is necessary for the performance of a task carried out for reasons of public interest.",article,"The General Data Protection Regulation (GDPR) Article 21 gives individuals the right to object to the processing of their personal data in certain situations. This includes when data is used for direct marketing or profiling related to marketing. If an individual objects, the company must stop processing their data unless they can show a compelling reason to continue. This objection right must be clearly communicated to the individual when they first interact with the company. Individuals can also object to their data being used for scientific, historical research or statistical purposes unless it's necessary for public interest."
Artifical Inellegence Act (AI Act) - Article 65,0.717975795,"Aritifical Intelligence Act (AI Act) Article 65 Procedure for dealing with AI systems presenting a risk at national level:

1.AI systems presenting a risk shall be understood as a product presenting a risk defined in Article 3, point 19 of Regulation (EU) 2019/1020 insofar as risks to the health or safety or to the protection of fundamental rights of persons are concerned.

2.Where the market surveillance authority of a Member State has sufficient reasons to consider that an AI system presents a risk as referred to in paragraph 1, they shall carry out an evaluation of the AI system concerned in respect of its compliance with all the requirements and obligations laid down in this Regulation. When risks to the protection of fundamental rights are present, the market surveillance authority shall also inform the relevant national public authorities or bodies referred to in Article 64(3). The relevant operators shall cooperate as necessary with the market surveillance authorities and the other national public authorities or bodies referred to in Article 64(3).

Where, in the course of that evaluation, the market surveillance authority finds that the AI system does not comply with the requirements and obligations laid down in this Regulation, it shall without delay require the relevant operator to take all appropriate corrective actions to bring the AI system into compliance, to withdraw the AI system from the market, or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.

The market surveillance authority shall inform the relevant notified body accordingly. Article 18 of Regulation (EU) 2019/1020 shall apply to the measures referred to in the second subparagraph.

3.Where the market surveillance authority considers that non-compliance is not restricted to its national territory, it shall inform the Commission and the other Member States of the results of the evaluation and of the actions which it has required the operator to take.

4.The operator shall ensure that all appropriate corrective action is taken in respect of all the AI systems concerned that it has made available on the market throughout the Union.

5.Where the operator of an AI system does not take adequate corrective action within the period referred to in paragraph 2, the market surveillance authority shall take all appropriate provisional measures to prohibit or restrict the AI system's being made available on its national market, to withdraw the product from that market or to recall it. That authority shall inform the Commission and the other Member States, without delay, of those measures.

6.The information referred to in paragraph 5 shall include all available details, in particular the data necessary for the identification of the non-compliant AI system, the origin of the AI system, the nature of the non-compliance alleged and the risk involved, the nature and duration of the national measures taken and the arguments put forward by the relevant operator. In particular, the market surveillance authorities shall indicate whether the non-compliance is due to one or more of the following:

(a)a failure of the AI system to meet requirements set out in Title III, Chapter 2;

(b)shortcomings in the harmonised standards or common specifications referred to in Articles 40 and 41 conferring a presumption of conformity.

7.The market surveillance authorities of the Member States other than the market surveillance authority of the Member State initiating the procedure shall without delay inform the Commission and the other Member States of any measures adopted and of any additional information at their disposal relating to the non-compliance of the AI system concerned, and, in the event of disagreement with the notified national measure, of their objections.

8.Where, within three months of receipt of the information referred to in paragraph 5, no objection has been raised by either a Member State or the Commission in respect of a provisional measure taken by a Member State, that measure shall be deemed justified. This is without prejudice to the procedural rights of the concerned operator in accordance with Article 18 of Regulation (EU) 2019/1020.

9.The market surveillance authorities of all Member States shall ensure that appropriate restrictive measures are taken in respect of the product concerned, such as withdrawal of the product from their market, without delay.",article,"The Artificial Intelligence Act (AI Act) outlines the process for handling AI systems that pose a risk at the national level. If a Member State's market surveillance authority believes an AI system could harm the health, safety, or fundamental rights of people, they must evaluate the system for compliance with the AI Act. If the system is found non-compliant, the authority can require the system's operator to correct the issues, remove the system from the market, or recall it. If the operator doesn't take adequate corrective action, the authority can restrict or prohibit the system's availability in its national market. If non-compliance isn't limited to one nation, the authority must inform the Commission and other Member States. All Member States must ensure appropriate restrictive measures are taken, such as withdrawing the product from their markets."
California Consumer Privacy Act Regulations (CCPA) - Article 5. Special Rules Regarding Consumers Under 16 Years of Age -  999.330 Consumers Under 13 Years of Age,0.717942655,"Details of Article 5. Special Rules Regarding Consumers Under 16 Years of Age -  999.330 Consumers Under 13 Years of Age in the California Consumer Privacy Act Regulations (CCPA): (a) Process for Opting-In to Sale of Personal Information (1) A business that has actual knowledge that it sells the personal information of a consumer under the age of 13 shall establish, document, and comply with a reasonable method for determining that the person affirmatively authorizing the sale of the personal information about the child is the parent or guardian of that child. This affirmative authorization is in addition to any verifiable parental consent required under COPPA. (2) Methods that are reasonably calculated to ensure that the person providing consent is the childs parent or guardian include, but are not limited to: a. Providing a consent form to be signed by the parent or guardian under penalty of perjury and returned to the business by postal mail, facsimile, or electronic scan; b. Requiring a parent or guardian, in connection with a monetary transaction, to use a credit card, debit card, or other online payment system that provides notification of each discrete transaction to the primary account holder; c. Having a parent or guardian call a toll-free telephone number staffed by trained personnel; d. Having a parent or guardian connect to trained personnel via video-conference; e. Having a parent or guardian communicate in person with trained personnel; and f. Verifying a parent or guardians identity by checking a form of governmentissued identification against databases of such information, as long as the parent or guardians identification is deleted by the business from its records promptly after such verification is complete. (b) When a business receives an affirmative authorization pursuant to subsection (a), the business shall inform the parent or guardian of the right to opt-out and of the process for doing so on behalf of their child pursuant to section 999.315, subsections (a)-(f). (c) A business shall establish, document, and comply with a reasonable method, in accordance with the methods set forth in subsection (a)(2), for determining that a person submitting a request to know or a request to delete the personal information of a child under the age of 13 is the parent or guardian of that child.",article,"The California Consumer Privacy Act (CCPA) has a new rule, Article 5, specifically for consumers under 16 years old. If a business knows it sells personal information of a child under 13, it must have a reliable way to confirm that the person giving permission for the sale is the child's parent or guardian. This can be done through methods like signed consent forms, credit card transactions, phone calls, video-conferences, in-person meetings, or ID checks. The business must also inform the parent or guardian about their right to withdraw permission and how to do so. Lastly, the business must have a reliable way to confirm that a person requesting to view or delete a child's personal information is the child's parent or guardian."
Artifical Inellegence Act (AI Act) - Article 47,0.71787107,"Aritifical Intelligence Act (AI Act) Article 47 Derogation from conformity assessment procedure:

1.By way of derogation from Article 43, any market surveillance authority may authorise the placing on the market or putting into service of specific high-risk AI systems within the territory of the Member State concerned, for exceptional reasons of public security or the protection of life and health of persons, environmental protection and the protection of key industrial and infrastructural assets. That authorisation shall be for a limited period of time, while the necessary conformity assessment procedures are being carried out, and shall terminate once those procedures have been completed. The completion of those procedures shall be undertaken without undue delay.

2.The authorisation referred to in paragraph 1 shall be issued only if the market surveillance authority concludes that the high-risk AI system complies with the requirements of Chapter 2 of this Title. The market surveillance authority shall inform the Commission and the other Member States of any authorisation issued pursuant to paragraph 1.

3.Where, within 15 calendar days of receipt of the information referred to in paragraph 2, no objection has been raised by either a Member State or the Commission in respect of an authorisation issued by a market surveillance authority of a Member State in accordance with paragraph 1, that authorisation shall be deemed justified.

4.Where, within 15 calendar days of receipt of the notification referred to in paragraph 2, objections are raised by a Member State against an authorisation issued by a market surveillance authority of another Member State, or where the Commission considers the authorisation to be contrary to Union law or the conclusion of the Member States regarding the compliance of the system as referred to in paragraph 2 to be unfounded, the Commission shall without delay enter into consultation with the relevant Member State; the operator(s) concerned shall be consulted and have the possibility to present their views. In view thereof, the Commission shall decide whether the authorisation is justified or not. The Commission shall address its decision to the Member State concerned and the relevant operator or operators.

5.If the authorisation is considered unjustified, this shall be withdrawn by the market surveillance authority of the Member State concerned.

6.By way of derogation from paragraphs 1 to 5, for high-risk AI systems intended to be used as safety components of devices, or which are themselves devices, covered by Regulation (EU) 2017/745 and Regulation (EU) 2017/746, Article 59 of Regulation (EU) 2017/745 and Article 54 of Regulation (EU) 2017/746 shall apply also with regard to the derogation from the conformity assessment of the compliance with the requirements set out in Chapter 2 of this Title.",article,"The Artificial Intelligence Act (AI Act) Article 47 allows market surveillance authorities to temporarily approve high-risk AI systems for public security, health, environmental protection, and key industrial and infrastructure reasons. This approval is only valid until the necessary safety checks are completed. The AI system must meet the requirements set out in Chapter 2 of the AI Act. The authority must inform the Commission and other Member States about the approval. If no objections are raised within 15 days, the approval is deemed justified. If objections are raised, the Commission will consult with the relevant parties and decide if the approval is justified. If it's not, it will be withdrawn. For high-risk AI systems used as safety components or devices, different regulations apply."
General Data Protection Regulation (GDPR) - Article 37 Designation of the data protection officer,0.717825234,"Details of Article 37 Designation of the data protection officer in the General Data Protection Regulation (GDPR): 1. The controller and the processor shall designate a data protection officer in any case where: (a) the processing is carried out by a public authority or body, except for courts acting in their judicial capacity; (b) the core activities of the controller or the processor consist of processing operations which, by virtue of their nature, their scope and/or their purposes, require regular and systematic monitoring of data subjects on a large scale; or (c) the core activities of the controller or the processor consist of processing on a large scale of special categories of data pursuant to Article 9 and personal data relating to criminal convictions and offences referred to in Article 10. 2. A group of undertakings may appoint a single data protection officer provided that a data protection officer is easily accessible from each establishment. 3. Where the controller or the processor is a public authority or body, a single data protection officer may be designated for several such authorities or bodies, taking account of their organisational structure and size. 4. In cases other than those referred to in paragraph 1, the controller or processor or associations and other bodies representing categories of controllers or processors may or, where required by Union or Member State law shall, designate a data protection officer. The data protection officer may act for such associations and other bodies representing controllers or processors. 5. The data protection officer shall be designated on the basis of professional qualities and, in particular, expert knowledge of data protection law and practices and the ability to fulfil the tasks referred to in Article 39. 6. The data protection officer may be a staff member of the controller or processor, or fulfil the tasks on the basis of a service contract. 7. The controller or the processor shall publish the contact details of the data protection officer and communicate them to the supervisory authority.",article,"The General Data Protection Regulation (GDPR) Article 37 requires organizations to designate a data protection officer (DPO) in certain situations. These include when data processing is done by a public body, when an organization's main activities involve large-scale data processing, or when they process special categories of data like criminal records. Multiple organizations can share a DPO as long as they are easily accessible. The DPO must be a professional with expert knowledge of data protection law and practices. They can be an employee or an external service provider. The organization must publicly share the DPO's contact details and provide them to the supervisory authority."
General Data Protection Regulation (GDPR) - Article 94 Repeal of Directive 95/46/EC,0.717801869,Details of Article 94 Repeal of Directive 95/46/EC in the General Data Protection Regulation (GDPR): 1. Directive 95/46/EC is repealed with effect from 25 May 2018. 2. References to the repealed Directive shall be construed as references to this Regulation. References to the Working Party on the Protection of Individuals with regard to the Processing of Personal Data established by Article 29 of Directive 95/46/EC shall be construed as references to the European Data Protection Board established by this Regulation.,article,"The General Data Protection Regulation (GDPR) has replaced the previous law, Directive 95/46/EC, effective from May 25, 2018. Any references to the old law are now considered references to the GDPR. The Working Party on the Protection of Individuals with regard to the Processing of Personal Data, established by the old law, is now known as the European Data Protection Board under the new GDPR."
California Consumer Privacy Act Regulations (CCPA) - Article 4. Verification of Requests -  999.325 Verification for Non-Accountholders,0.717801213,"Details of Article 4. Verification of Requests -  999.325 Verification for Non-Accountholders in the California Consumer Privacy Act Regulations (CCPA): (a) If a consumer does not have or cannot access a password-protected account with a business, the business shall comply with this section, in addition to section 999.323. (b) A businesss compliance with a request to know categories of personal information requires that the business verify the identity of the consumer making the request to a reasonable degree of certainty. A reasonable degree of certainty may include matching at least two data points provided by the consumer with data points maintained by the business that it has determined to be reliable for the purpose of verifying the consumer. (c) A businesss compliance with a request to know specific pieces of personal information requires that the business verify the identity of the consumer making the request to a reasonably high degree of certainty. A reasonably high degree of certainty may include matching at least three pieces of personal information provided by the consumer with personal information maintained by the business that it has determined to be reliable for the purpose of verifying the consumer together with a signed declaration under penalty of perjury that the requestor is the consumer whose personal information is the subject of the request. If a business uses this method for verification, the business shall maintain all signed declarations as part of its record-keeping obligations. (d) A businesss compliance with a request to delete may require that the business verify the identity of the consumer to a reasonable or reasonably high degree of certainty depending on the sensitivity of the personal information and the risk of harm to the consumer posed by unauthorized deletion. For example, the deletion of family photographs may require a reasonably high degree of certainty, while the deletion of browsing history may require only a reasonable degree of certainty. A business shall act in good faith when determining the appropriate standard to apply when verifying the consumer in accordance with these regulations. (e) Illustrative examples follow: (1) Example 1: If a business maintains personal information in a manner associated with a named actual person, the business may verify the consumer by requiring the consumer to provide evidence that matches the personal information maintained by the business. For example, if a retailer maintains a record of purchases made by a consumer, the business may require the consumer to identify items that they recently purchased from the store or the dollar amount of their most recent purchase to verify their identity to a reasonable degree of certainty. (2) Example 2: If a business maintains personal information in a manner that is not associated with a named actual person, the business may verify the consumer by requiring the consumer to demonstrate that they are the sole consumer associated with the personal information. For example, a business may have a mobile application that collects personal information about the consumer but does not require an account. The business may determine whether, based on the facts and considering the factors set forth in section 999.323, subsection (b)(3), it may reasonably verify a consumer by asking them to provide information that only the person who used the mobile application may know or by requiring the consumer to respond to a notification sent to their device. (f) A business shall deny a request to know specific pieces of personal information if it cannot verify the identity of the requestor pursuant to these regulations. (g) If there is no reasonable method by which a business can verify the identity of the consumer to the degree of certainty required by this section, the business shall state so in response to any request and explain why it has no reasonable method by which it can verify the identity of the requestor. If the business has no reasonable method by which it can verify any consumer, the business shall explain why it has no reasonable verification method in its privacy policy. The business shall evaluate and document whether a reasonable method can be established at least once every 12 months, in connection with the requirement to update the privacy policy set forth in Civil Code section 1798.130, subdivision (a)(5).",article,"The California Consumer Privacy Act (CCPA) requires businesses to verify the identity of consumers who request access to or deletion of their personal data. For non-account holders, businesses must match at least two or three data points (depending on the request type) provided by the consumer with their own records. In some cases, a signed declaration from the consumer may be needed. The level of verification required depends on the sensitivity of the data and the potential harm to the consumer if it's mishandled. If a business can't verify a consumer's identity, it must deny the request and explain why. Businesses must also review their verification methods annually and update their privacy policy accordingly."
Digital Markets Act (DMA) - Definition of profiling,0.717772543,"Details of the Definition of profiling in the Digital Markets Act (DMA): ""profiling"" means profiling as defined in Article 4, point (4), of Regulation (EU) 2016/679;",rectial,"The Digital Markets Act (DMA) introduces a new definition for ""profiling"". It refers to the same definition provided in Article 4, point (4), of Regulation (EU) 2016/679. In simpler terms, ""profiling"" involves analyzing personal data to evaluate certain aspects about an individual, such as their preferences, interests, behavior, location, or movements. This law aims to regulate how companies use your personal data for such profiling activities."
Artifical Inellegence Act (AI Act) - Article 22,0.71776861,"Aritifical Intelligence Act (AI Act) Article 22 Duty of information:

Where the high-risk AI system presents a risk within the meaning of Article 65(1) and that risk is known to the provider of the system, that provider shall immediately inform the national competent authorities of the Member States in which it made the system available and, where applicable, the notified body that issued a certificate for the high-risk AI system, in particular of the non-compliance and of any corrective actions taken.",article,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems to promptly inform relevant authorities if their system poses a risk. If the provider knows of any risks, they must immediately notify the national authorities in the countries where the system is available. They must also inform the organization that certified the system, if applicable. This notification should include details of any non-compliance and corrective actions taken."
General Data Protection Regulation (GDPR) - Definition of personal data,0.717764258,"Details of the Definition of personal data in the General Data Protection Regulation (GDPR): ""personal data"" means any information relating to an identified or identifiable natural person (""data subject""); an identifiable natural person is one who can be identified, directly or indirectly, in particular by reference to an identifier such as a name, an identification number, location data, an online identifier or to one or more factors specific to the physical, physiological, genetic, mental, economic, cultural or social identity of that natural person;",recital,"The General Data Protection Regulation (GDPR) defines ""personal data"" as any information that can be used to identify a person, either directly or indirectly. This can include things like names, identification numbers, location data, online identifiers, or any other factors that are specific to a person's physical, physiological, genetic, mental, economic, cultural or social identity."
Digital Services Act (DSA) - Article 52,0.717760742,"Article 52 Penalties in the Digital Services Act (DSA):  1.   Member States shall lay down the rules on penalties applicable to infringements of this Regulation by providers of intermediary services within their competence and shall take all the necessary measures to ensure that they are implemented in accordance with Article 51.

2.   Penalties shall be effective, proportionate and dissuasive. Member States shall notify the Commission of those rules and of those measures and shall notify it, without delay, of any subsequent amendments affecting them.

3.   Member States shall ensure that the maximum amount of fines that may be imposed for a failure to comply with an obligation laid down in this Regulation shall be 6 % of the annual worldwide turnover of the provider of intermediary services concerned in the preceding financial year. Member States shall ensure that the maximum amount of the fine that may be imposed for the supply of incorrect, incomplete or misleading information, failure to reply or rectify incorrect, incomplete or misleading information and failure to submit to an inspection shall be 1 % of the annual income or worldwide turnover of the provider of intermediary services or person concerned in the preceding financial year.

4.   Member States shall ensure that the maximum amount of a periodic penalty payment shall be 5 % of the average daily worldwide turnover or income of the provider of intermediary services concerned in the preceding financial year per day, calculated from the date specified in the decision concerned.",article,"The new Digital Services Act (DSA) requires each member country to establish rules for penalties related to violations by digital service providers. These penalties must be effective, proportionate, and discouraging. Any changes to these rules must be reported to the Commission promptly. Maximum fines for non-compliance can be up to 6% of the service provider's annual global turnover from the previous financial year. For providing incorrect or misleading information, or failure to cooperate with an inspection, fines can be up to 1% of the provider's annual income or global turnover. Additionally, a daily penalty of up to 5% of the provider's average daily global turnover or income can be imposed, calculated from the date specified in the decision."
General Data Protection Regulation (GDPR) - Article 30 Records of processing activities,0.717705,"Details of Article 30 Records of processing activities in the General Data Protection Regulation (GDPR): 1. Each controller and, where applicable, the controller's representative, shall maintain a record of processing activities under its responsibility. That record shall contain all of the following information: (a) the name and contact details of the controller and, where applicable, the joint controller, the controller's representative and the data protection officer; (b) the purposes of the processing; (c) a description of the categories of data subjects and of the categories of personal data; (d) the categories of recipients to whom the personal data have been or will be disclosed including recipients in third countries or international organisations; (e) where applicable, transfers of personal data to a third country or an international organisation, including the identification of that third country or international organisation and, in the case of transfers referred to in the second subparagraph of Article 49(1), the documentation of suitable safeguards; (f) where possible, the envisaged time limits for erasure of the different categories of data; (g) where possible, a general description of the technical and organisational security measures referred to in Article 32(1). 2. Each processor and, where applicable, the processor's representative shall maintain a record of all categories of processing activities carried out on behalf of a controller, containing: (a) the name and contact details of the processor or processors and of each controller on behalf of which the processor is acting, and, where applicable, of the controller's or the processor's representative, and the data protection officer; (b) the categories of processing carried out on behalf of each controller; (c) where applicable, transfers of personal data to a third country or an international organisation, including the identification of that third country or international organisation and, in the case of transfers referred to in the second subparagraph of Article 49(1), the documentation of suitable safeguards; (d) where possible, a general description of the technical and organisational security measures referred to in Article 32(1). 3. The records referred to in paragraphs 1 and 2 shall be in writing, including in electronic form. 4. The controller or the processor and, where applicable, the controller's or the processor's representative, shall make the record available to the supervisory authority on request. 5. The obligations referred to in paragraphs 1 and 2 shall not apply to an enterprise or an organisation employing fewer than 250 persons unless the processing it carries out is likely to result in a risk to the rights and freedoms of data subjects, the processing is not occasional, or the processing includes special categories of data as referred to in Article 9(1) or personal data relating to criminal convictions and offences referred to in Article 10.",article,"Article 30 of the General Data Protection Regulation (GDPR) requires companies that process personal data to keep detailed records of their activities. These records must include contact details of the data controller, the purpose of data processing, descriptions of the data and recipients, any data transfers abroad, intended data deletion times, and security measures. The records must be written and made available to authorities upon request. However, companies with fewer than 250 employees are exempt from this requirement unless their data processing activities pose a risk to individuals' rights and freedoms, are not occasional, or involve special categories of data."
Artifical Inellegence Act (AI Act) - Article 48,0.717671335,"Aritifical Intelligence Act (AI Act) Article 48 EU declaration of conformity:

1.The provider shall draw up a written EU declaration of conformity for each AI system and keep it at the disposal of the national competent authorities for 10 years after the AI system has been placed on the market or put into service. The EU declaration of conformity shall identify the AI system for which it has been drawn up. A copy of the EU declaration of conformity shall be given to the relevant national competent authorities upon request.

2.The EU declaration of conformity shall state that the high-risk AI system in question meets the requirements set out in Chapter 2 of this Title. The EU declaration of conformity shall contain the information set out in Annex V and shall be translated into an official Union language or languages required by the Member State(s) in which the high-risk AI system is made available.

3.Where high-risk AI systems are subject to other Union harmonisation legislation which also requires an EU declaration of conformity, a single EU declaration of conformity shall be drawn up in respect of all Union legislations applicable to the high-risk AI system. The declaration shall contain all the information required for identification of the Union harmonisation legislation to which the declaration relates.

4.By drawing up the EU declaration of conformity, the provider shall assume responsibility for compliance with the requirements set out in Chapter 2 of this Title. The provider shall keep the EU declaration of conformity up-to-date as appropriate.

5.The Commission shall be empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating the content of the EU declaration of conformity set out in Annex V in order to introduce elements that become necessary in light of technical progress.",article,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems to create a written EU declaration of conformity for each system. This declaration must be kept for 10 years and provided to national authorities upon request. The declaration confirms that the AI system meets all necessary requirements and includes specific information outlined in Annex V. If the AI system falls under other EU laws, a single declaration covering all applicable laws is needed. By creating this declaration, the provider takes responsibility for the system's compliance. The declaration must be kept current and may be updated by the Commission to reflect technical advancements."
Artifical Inellegence Act (AI Act) - Article 30,0.717671037,"Aritifical Intelligence Act (AI Act) Article 30  Notifying authorities:

1.Each Member State shall designate or establish a notifying authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring.

2.Member States may designate a national accreditation body referred to in Regulation (EC) No 765/2008 as a notifying authority.

3.Notifying authorities shall be established, organised and operated in such a way that no conflict of interest arises with conformity assessment bodies and the objectivity and impartiality of their activities are safeguarded.

4.Notifying authorities shall be organised in such a way that decisions relating to the notification of conformity assessment bodies are taken by competent persons different from those who carried out the assessment of those bodies.

5.Notifying authorities shall not offer or provide any activities that conformity assessment bodies perform or any consultancy services on a commercial or competitive basis.

6.Notifying authorities shall safeguard the confidentiality of the information they obtain.

7.Notifying authorities shall have a sufficient number of competent personnel at their disposal for the proper performance of their tasks.

8.Notifying authorities shall make sure that conformity assessments are carried out in a proportionate manner, avoiding unnecessary burdens for providers and that notified bodies perform their activities taking due account of the size of an undertaking, the sector in which it operates, its structure and the degree of complexity of the AI system in question.",article,"The Artificial Intelligence Act (AI Act) Article 30 requires each member state to appoint a notifying authority. This authority is responsible for assessing and monitoring conformity assessment bodies, which ensure AI systems meet certain standards. The authority must operate impartially, without conflicts of interest, and its activities must be separated from those of the conformity assessment bodies. It cannot offer commercial services similar to those provided by the assessment bodies. The authority must keep all information confidential and employ enough skilled staff to perform its duties. It must also ensure that assessments are proportionate and considerate of the size, sector, structure, and complexity of the AI system."
Digital Services Act (DSA) - Contextual paragraph (14),0.717641115,"Details of the contextual paragraph (14) of the Digital Services Act (DSA): The concept of 'dissemination to the public', as used in this Regulation, should entail the making available of information to a potentially unlimited number of persons, meaning making the information easily accessible to recipients of the service in general without further action by the recipient of the service providing the information being required, irrespective of whether those persons actually access the information in question. Accordingly, where access to information requires registration or admittance to a group of recipients of the service, that information should be considered to be disseminated to the public only where recipients of the service seeking to access the information are automatically registered or admitted without a human decision or selection of whom to grant access. Interpersonal communication services, as defined in Directive (EU) 2018/1972 of the European Parliament and of the Council (24), such as emails or private messaging services, fall outside the scope of the definition of online platforms as they are used for interpersonal communication between a finite number of persons determined by the sender of the communication. However, the obligations set out in this Regulation for providers of online platforms may apply to services that allow the making available of information to a potentially unlimited number of recipients, not determined by the sender of the communication, such as through public groups or open channels. Information should be considered disseminated to the public within the meaning of this Regulation only where that dissemination occurs upon the direct request by the recipient of the service that provided the information.",recital,"The Digital Services Act (DSA) defines 'dissemination to the public' as making information accessible to an unlimited number of people, without requiring any further action from the provider of the information. This includes situations where users can access the information automatically, without needing approval or registration. However, private communication services like emails or private messages are not considered as public dissemination because they involve a limited number of recipients chosen by the sender. The DSA's rules may apply to services that allow public sharing of information, such as public groups or open channels. Information is only considered publicly disseminated if the recipient of the service directly requested it."
Artifical Inellegence Act (AI Act) - Overview paragraph 59,0.717628837,"Aritifical Intelligence Act (AI Act) overview paragraph (59): It is appropriate to envisage that the user of the AI system should be the natural or legal person, public authority, agency or other body under whose authority the AI system is operated except where the use is made in the course of a personal non-professional activity.",recital,"The Artificial Intelligence Act (AI Act) states that the user of an AI system should be an individual, company, public authority, agency, or other organization that has control over how the AI system is used. However, this doesn't apply if the AI system is being used for personal, non-professional activities."
Digital Services Act (DSA) - Article 48 Crisis protocols for accessibility,0.717628062,"Article 48 Crisis protocols for accessibility in the Digital Services Act (DSA):  1.   The Board may recommend that the Commission initiate the drawing up, in accordance with paragraphs 2, 3 and 4, of voluntary crisis protocols for addressing crisis situations. Those situations shall be strictly limited to extraordinary circumstances affecting public security or public health.

2.   The Commission shall encourage and facilitate the providers of very large online platforms, of very large online search engines and, where appropriate, the providers of other online platforms or of other online search engines, to participate in the drawing up, testing and application of those crisis protocols. The Commission shall aim to ensure that those crisis protocols include one or more of the following measures:

(a) prominently displaying information on the crisis situation provided by Member States' authorities or at Union level, or, depending on the context of the crisis, by other relevant reliable bodies;
(b) ensuring that the provider of intermediary services designates a specific point of contact for crisis management; where relevant, this may be the electronic point of contact referred to in Article 11 or, in the case of providers of very large online platforms or of very large online search engines, the compliance officer referred to in Article 41;
(c) where applicable, adapt the resources dedicated to compliance with the obligations set out in Articles 16, 20, 22, 23 and 35 to the needs arising from the crisis situation.

3.   The Commission shall, as appropriate, involve Member States' authorities, and may also involve Union bodies, offices and agencies in drawing up, testing and supervising the application of the crisis protocols. The Commission may, where necessary and appropriate, also involve civil society organisations or other relevant organisations in drawing up the crisis protocols.

4.   The Commission shall aim to ensure that the crisis protocols set out clearly all of the following:
(a) the specific parameters to determine what constitutes the specific extraordinary circumstance the crisis protocol seeks to address and the objectives it pursues;
(b) the role of each participant and the measures they are to put in place in preparation and once the crisis protocol has been activated;
(c) a clear procedure for determining when the crisis protocol is to be activated;
(d) a clear procedure for determining the period during which the measures to be taken once the crisis protocol has been activated are to be taken, which is strictly limited to what is necessary for addressing the specific extraordinary circumstances concerned;
(e) safeguards to address any negative effects on the exercise of the fundamental rights enshrined in the Charter, in particular the freedom of expression and information and the right to non-discrimination;
(f) a process to publicly report on any measures taken, their duration and their outcomes, upon the termination of the crisis situation.

5.   If the Commission considers that a crisis protocol fails to effectively address the crisis situation, or to safeguard the exercise of fundamental rights as referred to in paragraph 4, point (e), it shall request the participants to revise the crisis protocol, including by taking additional measures.",article,"The Digital Services Act (DSA) introduces Article 48, which allows for voluntary crisis protocols in extraordinary situations affecting public health or public security. These protocols involve large online platforms and search engines, and may include measures such as displaying crisis information, designating a crisis contact point, and adapting resources for the crisis. The European Commission will involve member states and possibly civil society organizations in creating these protocols. The protocols must clearly define the crisis, the roles of participants, activation procedures, and measures to protect fundamental rights such as freedom of expression. They must also include a process for public reporting on the measures taken. If a protocol is ineffective or infringes on fundamental rights, the Commission can request revisions."
Digital Markets Act (DMA) - Contextual Paragraph (60),0.717605114,"Details of the Contextual Paragraph (60) in the Digital Markets Act (DMA): Business users that use core platform services provided by gatekeepers, and end users of such business users provide and generate a vast amount of data. In order to ensure that business users have access to the relevant data thus generated, the gatekeeper should, upon their request, provide effective access, free of charge, to such data. Such access should also be given to third parties contracted by the business user, who are acting as processors of this data for the business user. The access should include access to data provided or generated by the same business users and the same end users of those business users in the context of other services provided by the same gatekeeper, including services provided together with or in support of core platform services, where this is inextricably linked to the relevant request. To this end, a gatekeeper should not use any contractual or other restrictions to prevent business users from accessing relevant data and should enable business users to obtain consent of their end users for such data access and retrieval, where such consent is required under Regulation (EU) 2016/679 and Directive 2002/58/EC. Gatekeepers should also ensure the continuous and real time access to such data by means of appropriate technical measures, for example by putting in place high quality application programming interfaces or integrated tools for small volume business users.",rectial,"The Digital Markets Act (DMA) requires companies that control major online platforms (gatekeepers) to provide free access to user data when requested by businesses using their services. This includes data generated by the business's own customers. This access should also extend to third parties working on behalf of the business. The gatekeeper cannot use contracts or other means to block this data access. They must also help businesses get consent from their customers for data access if needed under existing EU regulations. Gatekeepers must ensure constant, real-time access to this data through technical means, like high-quality programming interfaces or tools for smaller businesses."
Digital Services Act (DSA) - Article 90 Amendment to Directive (EU) 2020/1828,0.717594564,"Article 90 Amendment to Directive (EU) 2020/1828 in the Digital Services Act (DSA):  In Annex I to Directive (EU) 2020/1828, the following point is added:

'(68) Regulation (EU) 2022/2065 of the European Parliament and of the Council of 19 October 2022 on a Single Market for Digital Services and amending Directive 2000/31/EC (Digital Services Act) (OJ L 277, 27.10.2022, p. 1).'.",article,"The Digital Services Act (DSA) has been updated with a new amendment, specifically Article 90 of Directive (EU) 2020/1828. This amendment introduces Regulation (EU) 2022/2065, which was established by the European Parliament and the Council on October 19, 2022. This regulation is designed to create a single market for digital services, and it also makes changes to Directive 2000/31/EC."
Digital Markets Act (DMA) - Definition of online intermediation services,0.717524707,"Details of the Definition of online intermediation services in the Digital Markets Act (DMA): ""online intermediation services"" means online intermediation services as defined in Article 2, point (2), of Regulation (EU) 2019/1150;",rectial,"The Digital Markets Act (DMA) has a specific definition for ""online intermediation services"". This term refers to services that are defined in Article 2, point (2), of Regulation (EU) 2019/1150. In simpler terms, the DMA is using a specific definition from a previous regulation to explain what it means by ""online intermediation services"". To fully understand what this term means, one would need to refer to the mentioned regulation."
General Data Protection Regulation (GDPR) - Article 83 General conditions for imposing administrative fines,0.717510402,"Details of Article 83 General conditions for imposing administrative fines in the General Data Protection Regulation (GDPR): 1. Each supervisory authority shall ensure that the imposition of administrative fines pursuant to this Article in respect of infringements of this Regulation referred to in paragraphs 4, 5 and 6 shall in each individual case be effective, proportionate and dissuasive. 2. Administrative fines shall, depending on the circumstances of each individual case, be imposed in addition to, or instead of, measures referred to in points (a) to (h) and (j) of Article 58(2). When deciding whether to impose an administrative fine and deciding on the amount of the administrative fine in each individual case due regard shall be given to the following: (a) the nature, gravity and duration of the infringement taking into account the nature scope or purpose of the processing concerned as well as the number of data subjects affected and the level of damage suffered by them; (b) the intentional or negligent character of the infringement; (c) any action taken by the controller or processor to mitigate the damage suffered by data subjects; (d) the degree of responsibility of the controller or processor taking into account technical and organisational measures implemented by them pursuant to Articles 25 and 32; (e) any relevant previous infringements by the controller or processor; (f) the degree of cooperation with the supervisory authority, in order to remedy the infringement and mitigate the possible adverse effects of the infringement; (g) the categories of personal data affected by the infringement; (h) the manner in which the infringement became known to the supervisory authority, in particular whether, and if so to what extent, the controller or processor notified the infringement; (i) where measures referred to in Article 58(2) have previously been ordered against the controller or processor concerned with regard to the same subject-matter, compliance with those measures; (j) adherence to approved codes of conduct pursuant to Article 40 or approved certification mechanisms pursuant to Article 42; and (k) any other aggravating or mitigating factor applicable to the circumstances of the case, such as financial benefits gained, or losses avoided, directly or indirectly, from the infringement. 3. If a controller or processor intentionally or negligently, for the same or linked processing operations, infringes several provisions of this Regulation, the total amount of the administrative fine shall not exceed the amount specified for the gravest infringement. 4. Infringements of the following provisions shall, in accordance with paragraph 2, be subject to administrative fines up to 10 000 000 EUR, or in the case of an undertaking, up to 2 % of the total worldwide annual turnover of the preceding financial year, whichever is higher: (a) the obligations of the controller and the processor pursuant to Articles 8, 11, 25 to 39 and 42 and 43; (b) the obligations of the certification body pursuant to Articles 42 and 43; (c) the obligations of the monitoring body pursuant to Article 41(4). 5. Infringements of the following provisions shall, in accordance with paragraph 2, be subject to administrative fines up to 20 000 000 EUR, or in the case of an undertaking, up to 4 % of the total worldwide annual turnover of the preceding financial year, whichever is higher: (a) the basic principles for processing, including conditions for consent, pursuant to Articles 5, 6, 7 and 9; (b) the data subjects' rights pursuant to Articles 12 to 22; (c) the transfers of personal data to a recipient in a third country or an international organisation pursuant to Articles 44 to 49; (d) any obligations pursuant to Member State law adopted under Chapter IX; (e) non-compliance with an order or a temporary or definitive limitation on processing or the suspension of data flows by the supervisory authority pursuant to Article 58(2) or failure to provide access in violation of Article 58(1). 6. Non-compliance with an order by the supervisory authority as referred to in Article 58(2) shall, in accordance with paragraph 2 of this Article, be subject to administrative fines up to 20 000 000 EUR, or in the case of an undertaking, up to 4 % of the total worldwide annual turnover of the preceding financial year, whichever is higher. 7. Without prejudice to the corrective powers of supervisory authorities pursuant to Article 58(2), each Member State may lay down the rules on whether and to what extent administrative fines may be imposed on public authorities and bodies established in that Member State. 8. The exercise by the supervisory authority of its powers under this Article shall be subject to appropriate procedural safeguards in accordance with Union and Member State law, including effective judicial remedy and due process. 9. Where the legal system of the Member State does not provide for administrative fines, this Article may be applied in such a manner that the fine is initiated by the competent supervisory authority and imposed by competent national courts, while ensuring that those legal remedies are effective and have an equivalent effect to the administrative fines imposed by supervisory authorities. In any event, the fines imposed shall be effective, proportionate and dissuasive. Those Member States shall notify to the Commission the provisions of their laws which they adopt pursuant to this paragraph by 25 May 2018 and, without delay, any subsequent amendment law or amendment affecting them.",article,"The General Data Protection Regulation (GDPR) Article 83 outlines conditions for imposing fines for data protection breaches. Fines are to be effective, proportionate, and dissuasive, and can be imposed in addition to or instead of other measures. Factors considered when deciding on fines include the nature, severity, and duration of the breach, whether it was intentional or negligent, actions taken to mitigate damage, previous infringements, and cooperation with authorities. Fines can reach up to 10 million or 2% of global annual turnover for certain breaches, and up to 20 million or 4% of global annual turnover for others. Each EU member state can determine whether and to what extent fines can be imposed on its public authorities and bodies. The law ensures appropriate procedural safeguards, including effective judicial remedy and due process. If a member state's legal system doesn't provide for administrative fines, the fine can be initiated by the supervisory authority and imposed by national courts."
Digital Markets Act (DMA) - Article 30 Fines,0.71742785,"Details of Article 30 Fines in the Digital Markets Act (DMA): 1. In the non-compliance decision, the Commission may impose on a gatekeeper fines not exceeding 10 % of its total worldwide turnover in the preceding financial year where it finds that the gatekeeper, intentionally or negligently, fails to comply with: (a) any of the obligations laid down in Articles 5, 6 and 7; (b) measures specified by the Commission in a decision adopted pursuant to Article 8(2); (c) remedies imposed pursuant to Article 18(1); (d) interim measures ordered pursuant to Article 24; or (e) commitments made legally binding pursuant to Article 25. 2. Notwithstanding paragraph 1 of this Article, in the non-compliance decision the Commission may impose on a gatekeeper fines up to 20 % of its total worldwide turnover in the preceding financial year where it finds that a gatekeeper has committed the same or a similar infringement of an obligation laid down in Article 5, 6 or 7 in relation to the same core platform service as it was found to have committed in a non-compliance decision adopted in the 8 preceding years. 3. The Commission may adopt a decision, imposing on undertakings, including gatekeepers where applicable, and associations of undertakings, fines not exceeding 1 % of their total worldwide turnover in the preceding financial year where they intentionally or negligently: (a) fail to provide within the time limit information that is required for assessing their designation as gatekeepers pursuant to Article 3 or supply incorrect, incomplete or misleading information; (b) fail to comply with the obligation to notify the Commission according to Article 3(3); (c) fail to notify information or supply incorrect, incomplete or misleading information that is required pursuant to Article 14; (d) fail to submit the description or supply incorrect, incomplete or misleading information that is required pursuant to Article 15; (e) fail to provide access to data, algorithms or information about testing in response to a request made pursuant to Article 21(3); (f) fail to supply the information requested within the time limit fixed pursuant to Article 21(3) or supply incorrect, incomplete or misleading information or explanations that are requested pursuant to Article 21 or given in an interview pursuant to Article 22; (g) fail to rectify within a time limit set by the Commission, incorrect, incomplete or misleading information given by a representative or a member of staff, or fail or refuse to provide complete information on facts relating to the subjectmatter and purpose of an inspection, pursuant to Article 23; (h) refuse to submit to an inspection pursuant to Article 23; (i) fail to comply with the obligations imposed by the Commission pursuant to Article 26; (j) fail to introduce a compliance function in accordance with Article 28; or (k) fail to comply with the conditions for access to the Commission""s file pursuant to Article 34(4). 4. In fixing the amount of a fine, the Commission shall take into account the gravity, duration, recurrence, and, for fines imposed pursuant to paragraph 3, delay caused to the proceedings. 5. When a fine is imposed on an association of undertakings taking account of the worldwide turnover of its members and that association is not solvent, it shall be obliged to call for contributions from its members to cover the amount of the fine. Where such contributions have not been made to the association of undertakings within a time limit set by the Commission, the Commission may require payment of the fine directly by any of the undertakings whose representatives were members of the decision-making bodies concerned of that association. After having required payment in accordance with the second subparagraph, the Commission may require payment of the balance by any of the members of the association of undertakings, where necessary to ensure full payment of the fine. However, the Commission shall not require payment pursuant to the second or the third subparagraph from undertakings which show that they have not implemented the decision of the association of undertakings that infringed this Regulation, and either were not aware of its existence, or have actively distanced themselves from it before the Commission opened proceedings under Article 20. The financial liability of each undertaking in respect of the payment of the fine shall not exceed 20 % of its total worldwide turnover in the preceding financial year.",article,"The Digital Markets Act (DMA) imposes fines on ""gatekeepers"" - large online platforms - for non-compliance with its rules. If a gatekeeper intentionally or negligently fails to meet its obligations under the DMA, it can be fined up to 10% of its total global turnover from the previous financial year. If the same or similar violation is repeated within 8 years, the fine can increase to 20%. The DMA also imposes fines up to 1% of total global turnover if a gatekeeper intentionally or negligently provides incorrect, incomplete, or misleading information, fails to notify the Commission of certain matters, or fails to comply with other specific obligations. The amount of the fine depends on the severity and duration of the violation, and whether it's a repeat offense. If a fined association of companies can't pay, its members may be required to contribute towards the fine, unless they can prove they weren't involved in the violation."
General Data Protection Regulation (GDPR) - Contextual Paragraph (74),0.717213631,"Details of the Contextual Paragraph (74) in the General Data Protection Regulation (GDPR): The responsibility and liability of the controller for any processing of personal data carried out by the controller or on the controller's behalf should be established. In particular, the controller should be obliged to implement appropriate and effective measures and be able to demonstrate the compliance of processing activities with this Regulation, including the effectiveness of the measures. Those measures should take into account the nature, scope, context and purposes of the processing and the risk to the rights and freedoms of natural persons.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 74) that makes it clear who is responsible for protecting personal data. This responsibility falls on the 'controller' - the person or organization that decides why and how personal data is processed. They must put in place suitable measures to protect this data and must be able to prove that they're following the rules set out by the GDPR. These measures should consider the type of data, how much is being processed, why it's being processed, and the potential risks to individuals' rights and freedoms."
General Data Protection Regulation (GDPR) - Contextual Paragraph (45),0.717186928,"Details of the Contextual Paragraph (45) in the General Data Protection Regulation (GDPR): Where processing is carried out in accordance with a legal obligation to which the controller is subject or where processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority, the processing should have a basis in Union or Member State law. This Regulation does not require a specific law for each individual processing. A law as a basis for several processing operations based on a legal obligation to which the controller is subject or where processing is necessary for the performance of a task carried out in the public interest or in the exercise of an official authority may be sufficient. It should also be for Union or Member State law to determine the purpose of processing. Furthermore, that law could specify the general conditions of this Regulation governing the lawfulness of personal data processing, establish specifications for determining the controller, the type of personal data which are subject to the processing, the data subjects concerned, the entities to which the personal data may be disclosed, the purpose limitations, the storage period and other measures to ensure lawful and fair processing. It should also be for Union or Member State law to determine whether the controller performing a task carried out in the public interest or in the exercise of official authority should be a public authority or another natural or legal person governed by public law, or, where it is in the public interest to do so, including for health purposes such as public health and social protection and the management of health care services, by private law, such as a professional association.",recital,"The General Data Protection Regulation (GDPR) allows for data processing when it's legally required or serves the public interest. This doesn't mean each individual processing action needs its own law; one law can cover multiple processing actions. The law should also define the purpose of processing. It may also outline the rules for legal data processing, such as who controls the data, what type of data is processed, who is affected, who the data can be shared with, how long it can be stored, and other measures to ensure fair and lawful processing. The law can also determine if the data controller should be a public authority or a private entity, such as a professional association, especially when it serves public interest, like for health and social protection purposes."
Digital Markets Act (DMA) - Contextual Paragraph (72),0.71718514,"Details of the Contextual Paragraph (72) in the Digital Markets Act (DMA): The data protection and privacy interests of end users are relevant to any assessment of potential negative effects of the observed practice of gatekeepers to collect and accumulate large amounts of data from end users. Ensuring an adequate level of transparency of profiling practices employed by gatekeepers, including, but not limited to, profiling within the meaning of Article 4, point (4), of Regulation (EU) 2016/679, facilitates contestability of core platform services. Transparency puts external pressure on gatekeepers not to make deep consumer profiling the industry standard, given that potential entrants or start-ups cannot access data to the same extent and depth, and at a similar scale. Enhanced transparency should allow other undertakings providing core platform services to differentiate themselves better through the use of superior privacy guarantees. To ensure a minimum level of effectiveness of this transparency obligation, gatekeepers should at least provide an independently audited description of the basis upon which profiling is performed, including whether personal data and data derived from user activity in line with Regulation (EU) 2016/679 is relied on, the processing applied, the purpose for which the profile is prepared and eventually used, the duration of the profiling, the impact of such profiling on the gatekeeper""s services, and the steps taken to effectively enable end users to be aware of the relevant use of such profiling, as well as steps to seek their consent or provide them with the possibility of denying or withdrawing consent. The Commission should transfer the audited description to the European Data Protection Board to inform the enforcement of Union data protection rules. The Commission should be empowered to develop the methodology and procedure for the audited description, in consultation with the European Data Protection Supervisor, the European Data Protection Board, civil society and experts, in line with Regulations (EU) No 182/2011 ( 16) and (EU) 2018/1725 ( 17) of the European Parliament and of the Council.",rectial,"The Digital Markets Act (DMA) states that companies that control large amounts of user data (gatekeepers) must be transparent about how they profile users. This transparency is important because it can discourage deep consumer profiling and help smaller companies differentiate themselves by offering better privacy protections. Gatekeepers must provide a clear, independently audited description of how they profile users, including what data they use, how they process it, why they do it, how long they do it for, how it affects their services, and how they get user consent. This audited description should be sent to the European Data Protection Board to help enforce data protection rules. The European Commission will develop the methodology and procedure for the audited description, in consultation with the European Data Protection Supervisor, the European Data Protection Board, civil society, and experts."
California Consumer Privacy Act Regulations (CCPA) - Article 4. Verification of Requests -  999.323 General Rules Regarding Verification,0.717148066,"Details of Article 4. Verification of Requests -  999.323 General Rules Regarding Verification in the California Consumer Privacy Act Regulations (CCPA): (a) A business shall establish, document, and comply with a reasonable method for verifying that the person making a request to know or a request to delete is the consumer about whom the business has collected information. (b) In determining the method by which the business will verify the consumers identity, the business shall: (1) Whenever feasible, match the identifying information provided by the consumer to the personal information of the consumer already maintained by the business, or use a third-party identity verification service that complies with this section. (2) Avoid collecting the types of personal information identified in Civil Code section 1798.81.5, subdivision (d), unless necessary for the purpose of verifying the consumer. (3) Consider the following factors: a. The type, sensitivity, and value of the personal information collected and maintained about the consumer. Sensitive or valuable personal information shall warrant a more stringent verification process. The types of personal information identified in Civil Code section 1798.81.5, subdivision (d), shall be considered presumptively sensitive; b. The risk of harm to the consumer posed by any unauthorized access or deletion. A greater risk of harm to the consumer by unauthorized access or deletion shall warrant a more stringent verification process; c. The likelihood that fraudulent or malicious actors would seek the personal information. The higher the likelihood, the more stringent the verification process shall be; d. Whether the personal information to be provided by the consumer to verify their identity is sufficiently robust to protect against fraudulent requests or being spoofed or fabricated; e. The manner in which the business interacts with the consumer; and f. Available technology for verification. (c) A business shall generally avoid requesting additional information from the consumer for purposes of verification. If, however, the business cannot verify the identity of the consumer from the information already maintained by the business, the business may request additional information from the consumer, which shall only be used for the purposes of verifying the identity of the consumer seeking to exercise their rights under the CCPA, security, or fraud-prevention. The business shall delete any new personal information collected for the purposes of verification as soon as practical after processing the consumers request, except as required to comply with section 999.317. (d) A business shall not require the consumer or the consumers authorized agent to pay a fee for the verification of their request to know or request to delete. For example, a business may not require a consumer to provide a notarized affidavit to verify their identity unless the business compensates the consumer for the cost of notarization. (e) A business shall implement reasonable security measures to detect fraudulent identityverification activity and prevent the unauthorized access to or deletion of a consumers personal information. (f) If a business maintains consumer information that is deidentified, a business is not obligated to provide or delete this information in response to a consumer request or to re-identify individual data to verify a consumer request.",article,"The California Consumer Privacy Act Regulations (CCPA) Article 4 requires businesses to have a reasonable method to confirm that a person requesting information or deletion is the actual consumer. This could involve matching provided details with existing data, or using a third-party service. Businesses should avoid collecting certain types of personal information unless necessary for verification. The verification process should consider factors such as the sensitivity of the data, risk of unauthorized access or deletion, likelihood of fraud, and available technology. Businesses should avoid asking for additional information for verification, but if needed, it should be deleted after use. Consumers should not be charged for verification, and businesses should have measures to prevent fraudulent activity. If a business holds deidentified consumer data, they are not required to provide or delete this in response to a request."
General Data Protection Regulation (GDPR) - Definition of filing system,0.717131257,"Details of the Definition of filing system in the General Data Protection Regulation (GDPR): ""filing system"" means any structured set of personal data which are accessible according to specific criteria, whether centralised, decentralised or dispersed on a functional or geographical basis;",recital,"The General Data Protection Regulation (GDPR) has defined a ""filing system"" as any organized collection of personal data that can be accessed based on certain criteria. This includes data that is stored centrally, spread out, or organized based on function or location."
Digital Markets Act (DMA) - Article 48 Standardisation,0.717118621,"Details of Article 48 Standardisation in the Digital Markets Act (DMA): Where appropriate and necessary, the Commission may mandate European standardisation bodies to facilitate the implementation of the obligations set out in this Regulation by developing appropriate standards.",article,"The Digital Markets Act (DMA) has a new rule, Article 48, which is about standardization. This rule allows the Commission to instruct European standardization bodies to help implement the obligations in the DMA by creating suitable standards. This will only happen when the Commission deems it necessary and appropriate. In simpler terms, this rule helps ensure that the DMA is followed correctly by setting standards through European organizations."
Digital Services Act (DSA) - Article 88 Committee procedure,0.717072189,"Article 88 Committee procedure in the Digital Services Act (DSA):  1.   The Commission shall be assisted by a committee ('the Digital Services Committee'). That Committee shall be a Committee within the meaning of Regulation (EU) No 182/2011.

2.   Where reference is made to this paragraph, Article 4 of Regulation (EU) No 182/2011 shall apply.",article,"The Digital Services Act (DSA) establishes a new committee, known as the Digital Services Committee, to assist the Commission. This committee is defined according to the rules of Regulation (EU) No 182/2011. Additionally, the DSA refers to Article 4 of Regulation (EU) No 182/2011, which means that the rules outlined in that article will also apply to the workings of this committee."
General Data Protection Regulation (GDPR) - Article 15 Right of access by the data subject,0.717059493,"Details of Article 15 Right of access by the data subject in the General Data Protection Regulation (GDPR): 1. The data subject shall have the right to obtain from the controller confirmation as to whether or not personal data concerning him or her are being processed, and, where that is the case, access to the personal data and the following information: (a) the purposes of the processing; (b) the categories of personal data concerned; (c) the recipients or categories of recipient to whom the personal data have been or will be disclosed, in particular recipients in third countries or international organisations; (d) where possible, the envisaged period for which the personal data will be stored, or, if not possible, the criteria used to determine that period; (e) the existence of the right to request from the controller rectification or erasure of personal data or restriction of processing of personal data concerning the data subject or to object to such processing; (f) the right to lodge a complaint with a supervisory authority; (g) where the personal data are not collected from the data subject, any available information as to their source; (h) the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) and, at least in those cases, meaningful information about the logic involved, as well as the significance and the envisaged consequences of such processing for the data subject. 2. Where personal data are transferred to a third country or to an international organisation, the data subject shall have the right to be informed of the appropriate safeguards pursuant to Article 46 relating to the transfer. 3. The controller shall provide a copy of the personal data undergoing processing. For any further copies requested by the data subject, the controller may charge a reasonable fee based on administrative costs. Where the data subject makes the request by electronic means, and unless otherwise requested by the data subject, the information shall be provided in a commonly used electronic form. 4. The right to obtain a copy referred to in paragraph 3 shall not adversely affect the rights and freedoms of others.",article,"The General Data Protection Regulation (GDPR) Article 15 gives individuals the right to access their personal data held by a company. They can ask if their data is being processed and for what purpose. They can also find out who has received their data and how long it will be stored. If the data wasn't collected directly from the individual, they can ask where it came from. They can also ask about any automated decision-making processes, like profiling, and how these work. If their data is sent to another country or international organization, they can ask about the safety measures in place. The company must provide a copy of the data if asked, although they can charge for additional copies. This right doesn't affect the rights of others."
General Data Protection Regulation (GDPR) - Article 36 Prior consultation,0.716995239,"Details of Article 36 Prior consultation in the General Data Protection Regulation (GDPR): 1. The controller shall consult the supervisory authority prior to processing where a data protection impact assessment under Article 35 indicates that the processing would result in a high risk in the absence of measures taken by the controller to mitigate the risk. 2. Where the supervisory authority is of the opinion that the intended processing referred to in paragraph 1 would infringe this Regulation, in particular where the controller has insufficiently identified or mitigated the risk, the supervisory authority shall, within period of up to eight weeks of receipt of the request for consultation, provide written advice to the controller and, where applicable to the processor, and may use any of its powers referred to in Article 58. That period may be extended by six weeks, taking into account the complexity of the intended processing. The supervisory authority shall inform the controller and, where applicable, the processor, of any such extension within one month of receipt of the request for consultation together with the reasons for the delay. Those periods may be suspended until the supervisory authority has obtained information it has requested for the purposes of the consultation. 3. When consulting the supervisory authority pursuant to paragraph 1, the controller shall provide the supervisory authority with: (a) where applicable, the respective responsibilities of the controller, joint controllers and processors involved in the processing, in particular for processing within a group of undertakings; (b) the purposes and means of the intended processing; (c) the measures and safeguards provided to protect the rights and freedoms of data subjects pursuant to this Regulation; (d) where applicable, the contact details of the data protection officer; (e) the data protection impact assessment provided for in Article 35; and (f) any other information requested by the supervisory authority. 4. Member States shall consult the supervisory authority during the preparation of a proposal for a legislative measure to be adopted by a national parliament, or of a regulatory measure based on such a legislative measure, which relates to processing. 5. Notwithstanding paragraph 1, Member State law may require controllers to consult with, and obtain prior authorisation from, the supervisory authority in relation to processing by a controller for the performance of a task carried out by the controller in the public interest, including processing in relation to social protection and public health.",article,"The General Data Protection Regulation (GDPR) Article 36 states that if a data protection impact assessment suggests a high risk, the data controller must consult with a supervisory authority before processing data. If the authority believes the processing could violate the GDPR, they have up to eight weeks to provide written advice to the controller, which can be extended by six weeks for complex cases. The controller must provide the authority with information about the processing, including the purpose, the measures to protect data subjects' rights, and the contact details of the data protection officer. Member States must also consult the authority when creating legislation related to data processing. In some cases, controllers may be required to get prior authorization from the authority for processing data in the public interest."
Artifical Inellegence Act (AI Act) - Context Section 5.2.6,0.716986477,"Aritifical Intelligence Act (AI Act) context section 5.2.6.GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII): 

Title VI sets up the governance systems at Union and national level. At Union level, the proposal establishes a European Artificial Intelligence Board (the Board), composed of representatives from the Member States and the Commission. The Board will facilitate a smooth, effective and harmonised implementation of this regulation by contributing to the effective cooperation of the national supervisory authorities and the Commission and providing advice and expertise to the Commission. It will also collect and share best practices among the Member States.

At national level, Member States will have to designate one or more national competent authorities and, among them, the national supervisory authority, for the purpose of supervising the application and implementation of the regulation. The European Data Protection Supervisor will act as the competent authority for the supervision of the Union institutions, agencies and bodies when they fall within the scope of this regulation.

Title VII aims to facilitate the monitoring work of the Commission and national authorities through the establishment of an EU-wide database for stand-alone high-risk AI systems with mainly fundamental rights implications. The database will be operated by the Commission and provided with data by the providers of the AI systems, who will be required to register their systems before placing them on the market or otherwise putting them into service.

Title VIII sets out the monitoring and reporting obligations for providers of AI systems with regard to post-market monitoring and reporting and investigating on AI-related incidents and malfunctioning. Market surveillance authorities would also control the market and investigate compliance with the obligations and requirements for all high-risk AI systems already placed on the market. Market surveillance authorities would have all powers under Regulation (EU) 2019/1020 on market surveillance. Ex-post enforcement should ensure that once the AI system has been put on the market, public authorities have the powers and resources to intervene in case AI systems generate unexpected risks, which warrant rapid action. They will also monitor compliance of operators with their relevant obligations under the regulation. The proposal does not foresee the automatic creation of any additional bodies or authorities at Member State level. Member States may therefore appoint (and draw upon the expertise of) existing sectorial authorities, who would be entrusted also with the powers to monitor and enforce the provisions of the regulation.

All this is without prejudice to the existing system and allocation of powers of ex-post enforcement of obligations regarding fundamental rights in the Member States. When necessary for their mandate, existing supervision and enforcement authorities will also have the power to request and access any documentation maintained following this regulation and, where needed, request market surveillance authorities to organise testing of the high-risk AI system through technical means.5.2.6.GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII):

Title VI sets up the governance systems at Union and national level. At Union level, the proposal establishes a European Artificial Intelligence Board (the Board), composed of representatives from the Member States and the Commission. The Board will facilitate a smooth, effective and harmonised implementation of this regulation by contributing to the effective cooperation of the national supervisory authorities and the Commission and providing advice and expertise to the Commission. It will also collect and share best practices among the Member States.

At national level, Member States will have to designate one or more national competent authorities and, among them, the national supervisory authority, for the purpose of supervising the application and implementation of the regulation. The European Data Protection Supervisor will act as the competent authority for the supervision of the Union institutions, agencies and bodies when they fall within the scope of this regulation.

Title VII aims to facilitate the monitoring work of the Commission and national authorities through the establishment of an EU-wide database for stand-alone high-risk AI systems with mainly fundamental rights implications. The database will be operated by the Commission and provided with data by the providers of the AI systems, who will be required to register their systems before placing them on the market or otherwise putting them into service.

Title VIII sets out the monitoring and reporting obligations for providers of AI systems with regard to post-market monitoring and reporting and investigating on AI-related incidents and malfunctioning. Market surveillance authorities would also control the market and investigate compliance with the obligations and requirements for all high-risk AI systems already placed on the market. Market surveillance authorities would have all powers under Regulation (EU) 2019/1020 on market surveillance. Ex-post enforcement should ensure that once the AI system has been put on the market, public authorities have the powers and resources to intervene in case AI systems generate unexpected risks, which warrant rapid action. They will also monitor compliance of operators with their relevant obligations under the regulation. The proposal does not foresee the automatic creation of any additional bodies or authorities at Member State level. Member States may therefore appoint (and draw upon the expertise of) existing sectorial authorities, who would be entrusted also with the powers to monitor and enforce the provisions of the regulation.

All this is without prejudice to the existing system and allocation of powers of ex-post enforcement of obligations regarding fundamental rights in the Member States. When necessary for their mandate, existing supervision and enforcement authorities will also have the power to request and access any documentation maintained following this regulation and, where needed, request market surveillance authorities to organise testing of the high-risk AI system through technical means.",recital,"The Artificial Intelligence Act (AI Act) establishes a new system for managing and monitoring artificial intelligence (AI) in the European Union. It creates a European AI Board, made up of representatives from each member state, to oversee the implementation of the law. Each member state will also appoint its own authorities to supervise AI within their borders. The law also establishes a database for high-risk AI systems that could affect fundamental rights. Providers of these systems must register them before they can be used. After these systems are on the market, they will be monitored for any incidents or malfunctions. If a system poses unexpected risks, authorities can take action. The law doesn't create new bodies or authorities at the member state level, but allows existing authorities to monitor and enforce the new rules. These authorities can also request documentation or testing of high-risk AI systems if needed."
General Data Protection Regulation (GDPR) - Contextual Paragraph (86),0.716984,"Details of the Contextual Paragraph (86) in the General Data Protection Regulation (GDPR): The controller should communicate to the data subject a personal data breach, without undue delay, where that personal data breach is likely to result in a high risk to the rights and freedoms of the natural person in order to allow him or her to take the necessary precautions. The communication should describe the nature of the personal data breach as well as recommendations for the natural person concerned to mitigate potential adverse effects. Such communications to data subjects should be made as soon as reasonably feasible and in close cooperation with the supervisory authority, respecting guidance provided by it or by other relevant authorities such as law-enforcement authorities. For example, the need to mitigate an immediate risk of damage would call for prompt communication with data subjects whereas the need to implement appropriate measures against continuing or similar personal data breaches may justify more time for communication.",recital,"Under the General Data Protection Regulation (GDPR), if there's a data breach that could seriously risk your rights and freedoms, the company (controller) must quickly let you know. They should explain what happened and give advice on how to lessen any potential harm. This should be done as soon as possible, with guidance from relevant authorities. If there's immediate risk of damage, they need to communicate quickly. If the breach requires ongoing or similar measures, they may take more time to communicate."
General Data Protection Regulation (GDPR) - Article 93 Committee procedure,0.71698,"Details of Article 93 Committee procedure in the General Data Protection Regulation (GDPR): 1. The Commission shall be assisted by a committee. That committee shall be a committee within the meaning of Regulation (EU) No 182/2011. 2. Where reference is made to this paragraph, Article 5 of Regulation (EU) No 182/2011 shall apply. 3. Where reference is made to this paragraph, Article 8 of Regulation (EU) No 182/2011, in conjunction with Article 5 thereof, shall apply.",article,"The General Data Protection Regulation (GDPR) has a new procedure, Article 93, which establishes a committee to assist the Commission. This committee will operate under the guidelines of Regulation (EU) No 182/2011. The rules and procedures outlined in Article 5 and Article 8 of this regulation will be applied in the committee's operations."
Digital Markets Act (DMA) - Article 41 Request for a market investigation,0.7169047,"Details of Article 41 Request for a market investigation in the Digital Markets Act (DMA): 1. Three or more Member States may request the Commission to open a market investigation pursuant to Article 17 because they consider that there are reasonable grounds to suspect that an undertaking should be designated as a gatekeeper. 2. One or more Member States may request the Commission to open a market investigation pursuant to Article 18 because they consider that there are reasonable grounds to suspect that a gatekeeper has systematically infringed one or more of the obligations laid down in Articles 5, 6 and 7 and has maintained, strengthened or extended its gatekeeper position in relation to the requirements under Article 3(1). 3. Three or more Member States may request the Commission to conduct a market investigation pursuant to Article 19 because they consider that there are reasonable grounds to suspect that: (a) one or more services within the digital sector should be added to the list of core platform services laid down in Article 2, point (2), or (b) one or more practices are not effectively addressed by this Regulation and might limit the contestability of core platform services or be unfair. 4. Member States shall submit evidence in support of their requests pursuant to paragraphs 1, 2 and 3. For requests pursuant to paragraph 3, such evidence may include information on newly introduced offers of products, services, software or features which raise concerns of contestability or fairness, whether implemented in the context of existing core platform services or otherwise. 5. Within 4 months of receiving a request pursuant to this Article, the Commission shall examine whether there are reasonable grounds to open a market investigation pursuant to paragraph 1, 2 or 3. The Commission shall publish the results of its assessment.",article,"The Digital Markets Act (DMA) allows three or more member states to request an investigation if they suspect a company is unfairly dominating the market (a ""gatekeeper""). A single member state can request an investigation if they believe a gatekeeper is violating the DMA's rules and using its position to gain an unfair advantage. Three or more member states can also request an investigation if they think a service should be added to the list of core platform services, or if a practice is not being properly addressed by the DMA and may be unfair. Member states must provide evidence to support their requests. The Commission has four months to decide whether to open an investigation and must publish its decision."
Artifical Inellegence Act (AI Act) - Article 19,0.716888428,"Aritifical Intelligence Act (AI Act) Article 20 Automatically generated logs:

1.Providers of high-risk AI systems shall keep the logs automatically generated by their high-risk AI systems, to the extent such logs are under their control by virtue of a contractual arrangement with the user or otherwise by law. The logs shall be kept for a period that is appropriate in the light of the intended purpose of high-risk AI system and applicable legal obligations under Union or national law.

2.Providers that are credit institutions regulated by Directive 2013/36/EU shall maintain the logs automatically generated by their high-risk AI systems as part of the documentation under Articles 74 of that Directive.",article,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems to keep automatically generated logs, as long as they have control over these logs via a contract or other legal means. The logs should be stored for a time period suitable for the AI system's intended purpose and in accordance with any relevant laws. If the provider is a credit institution regulated by Directive 2013/36/EU, the logs must be maintained as part of the documentation required by Article 74 of that directive."
Artifical Inellegence Act (AI Act) - Article 42,0.716876626,"Aritifical Intelligence Act (AI Act) Article 42 Presumption of conformity with certain requirements:

1.Taking into account their intended purpose, high-risk AI systems that have been trained and tested on data concerning the specific geographical, behavioural and functional setting within which they are intended to be used shall be presumed to be in compliance with the requirement set out in Article 10(4).

2.High-risk AI systems that have been certified or for which a statement of conformity has been issued under a cybersecurity scheme pursuant to Regulation (EU) 2019/881 of the European Parliament and of the Council 63 and the references of which have been published in the Official Journal of the European Union shall be presumed to be in compliance with the cybersecurity requirements set out in Article 15 of this Regulation in so far as the cybersecurity certificate or statement of conformity or parts thereof cover those requirements.",article,"The Artificial Intelligence Act (AI Act) Article 42 states that high-risk AI systems are assumed to meet certain standards under two conditions. Firstly, if they have been trained and tested on data that accurately reflects the environment they will be used in, they are presumed to meet the requirements of Article 10(4). Secondly, if they have been certified or given a statement of conformity under a cybersecurity scheme in line with Regulation (EU) 2019/881, and this has been published in the Official Journal of the European Union, they are assumed to meet the cybersecurity requirements of Article 15, as long as the certificate or statement covers these requirements."
Digital Services Act (DSA) - Article 63 Tasks of the Board,0.716702163,"Article 63 Tasks of the Board in the Digital Services Act (DSA):  1.   Where necessary to meet the objectives set out in Article 61(2), the Board shall in particular:

(a) support the coordination of joint investigations;
(b) support the competent authorities in the analysis of reports and results of audits of very large online platforms or of very large online search engines to be transmitted pursuant to this Regulation;
(c) issue opinions, recommendations or advice to Digital Services Coordinators in accordance with this Regulation, taking into account, in particular, the freedom to provide services of the providers of intermediary service;
(d) advise the Commission on the measures referred to in Article 66 and, adopt opinions concerning very large online platforms or very large online search engines in accordance with this Regulation;
(e) support and promote the development and implementation of European standards, guidelines, reports, templates and code of conducts in cooperation with relevant stakeholders as provided for in this Regulation, including by issuing opinions or recommendations on matters related to Article 44, as well as the identification of emerging issues, with regard to matters covered by this Regulation.

2.   Digital Services Coordinators and, where applicable, other competent authorities that do not follow the opinions, requests or recommendations addressed to them adopted by the Board shall provide the reasons for this choice, including an explanation on the investigations, actions and the measures that they have implemented, when reporting pursuant to this Regulation or when adopting their relevant decisions, as appropriate.",article,"The Digital Services Act (DSA) outlines the responsibilities of a new governing body, the Board. The Board's main duties include supporting investigations and audits of large online platforms and search engines, giving advice and recommendations to Digital Services Coordinators, and advising the Commission on specific measures. The Board will also help develop and implement European standards, guidelines, and codes of conduct. If Digital Services Coordinators or other authorities choose not to follow the Board's advice or recommendations, they must provide a detailed explanation for their decision."
General Data Protection Regulation (GDPR) - Article 58 Powers,0.71670115,"Details of Article 58 Powers in the General Data Protection Regulation (GDPR): 1. Each supervisory authority shall have all of the following investigative powers: (a) to order the controller and the processor, and, where applicable, the controller's or the processor's representative to provide any information it requires for the performance of its tasks; (b) to carry out investigations in the form of data protection audits; (c) to carry out a review on certifications issued pursuant to Article 42(7); (d) to notify the controller or the processor of an alleged infringement of this Regulation; (e) to obtain, from the controller and the processor, access to all personal data and to all information necessary for the performance of its tasks; (f) to obtain access to any premises of the controller and the processor, including to any data processing equipment and means, in accordance with Union or Member State procedural law. 2. Each supervisory authority shall have all of the following corrective powers: (a) to issue warnings to a controller or processor that intended processing operations are likely to infringe provisions of this Regulation; (b) to issue reprimands to a controller or a processor where processing operations have infringed provisions of this Regulation; (c) to order the controller or the processor to comply with the data subject's requests to exercise his or her rights pursuant to this Regulation; (d) to order the controller or processor to bring processing operations into compliance with the provisions of this Regulation, where appropriate, in a specified manner and within a specified period; (e) to order the controller to communicate a personal data breach to the data subject; (f) to impose a temporary or definitive limitation including a ban on processing; (g) to order the rectification or erasure of personal data or restriction of processing pursuant to Articles 16, 17 and 18 and the notification of such actions to recipients to whom the personal data have been disclosed pursuant to Article 17(2) and Article 19; (h) to withdraw a certification or to order the certification body to withdraw a certification issued pursuant to Articles 42 and 43, or to order the certification body not to issue certification if the requirements for the certification are not or are no longer met; (i) to impose an administrative fine pursuant to Article 83, in addition to, or instead of measures referred to in this paragraph, depending on the circumstances of each individual case; (j) to order the suspension of data flows to a recipient in a third country or to an international organisation. 3. Each supervisory authority shall have all of the following authorisation and advisory powers: (a) to advise the controller in accordance with the prior consultation procedure referred to in Article 36; (b) to issue, on its own initiative or on request, opinions to the national parliament, the Member State government or, in accordance with Member State law, to other institutions and bodies as well as to the public on any issue related to the protection of personal data; (c) to authorise processing referred to in Article 36(5), if the law of the Member State requires such prior authorisation; (d) to issue an opinion and approve draft codes of conduct pursuant to Article 40(5); (e) to accredit certification bodies pursuant to Article 43; (f) to issue certifications and approve criteria of certification in accordance with Article 42(5); (g) to adopt standard data protection clauses referred to in Article 28(8) and in point (d) of Article 46(2); (h) to authorise contractual clauses referred to in point (a) of Article 46(3); (i) to authorise administrative arrangements referred to in point (b) of Article 46(3); (j) to approve binding corporate rules pursuant to Article 47. 4. The exercise of the powers conferred on the supervisory authority pursuant to this Article shall be subject to appropriate safeguards, including effective judicial remedy and due process, set out in Union and Member State law in accordance with the Charter. 5. Each Member State shall provide by law that its supervisory authority shall have the power to bring infringements of this Regulation to the attention of the judicial authorities and where appropriate, to commence or engage otherwise in legal proceedings, in order to enforce the provisions of this Regulation. 6. Each Member State may provide by law that its supervisory authority shall have additional powers to those referred to in paragraphs 1, 2 and 3. The exercise of those powers shall not impair the effective operation of Chapter VII.",article,"The General Data Protection Regulation (GDPR) Article 58 outlines the powers of supervisory authorities. These include the ability to request information, conduct audits, issue warnings or reprimands, and enforce compliance with data protection rules. They can also order the correction or deletion of personal data, impose fines, and suspend data transfers to third parties. They can advise on data protection issues, authorize certain types of data processing, and approve codes of conduct and certification criteria. They can also bring legal proceedings for GDPR violations. These powers must be exercised with safeguards such as due process and effective judicial remedy. Member states can grant their authorities additional powers, as long as it doesn't affect the operation of the GDPR."
Digital Services Act (DSA) - Article 2,0.716698825,"Scope (Article 2) details in the Digital Services Act (DSA): 1.   This Regulation shall apply to intermediary services offered to recipients of the service that have their place of establishment or are located in the Union, irrespective of where the providers of those intermediary services have their place of establishment.
2.   This Regulation shall not apply to any service that is not an intermediary service or to any requirements imposed in respect of such a service, irrespective of whether the service is provided through the use of an intermediary service.
3.   This Regulation shall not affect the application of Directive 2000/31/EC.
4.   This Regulation is without prejudice to the rules laid down by other Union legal acts regulating other aspects of the provision of intermediary services in the internal market or specifying and complementing this Regulation, in particular, the following:

(a) Directive 2010/13/EU;
(b) Union law on copyright and related rights;
(c) Regulation (EU) 2021/784;
(d) Regulation (EU) 2019/1148;
(e) Regulation (EU) 2019/1150;
(f) Union law on consumer protection and product safety, including Regulations (EU) 2017/2394 and (EU) 2019/1020 and Directives 2001/95/EC and 2013/11/EU;
(g) Union law on the protection of personal data, in particular Regulation (EU) 2016/679 and Directive 2002/58/EC;
(h) Union law in the field of judicial cooperation in civil matters, in particular Regulation (EU) No 1215/2012 or any Union legal act laying down the rules on law applicable to contractual and non-contractual obligations;
(i) Union law in the field of judicial cooperation in criminal matters, in particular a Regulation on European Production and Preservation Orders for electronic evidence in criminal matters;
(j) a Directive laying down harmonised rules on the appointment of legal representatives for the purpose of gathering evidence in criminal proceedings.",article,"The Digital Services Act (DSA) applies to online intermediary services used by individuals or businesses based in the EU, regardless of where the service providers are located. It doesn't apply to non-intermediary services or any rules related to them. The DSA doesn't affect the application of Directive 2000/31/EC and doesn't override other EU laws regulating intermediary services. These include laws related to broadcasting, copyright, consumer protection, product safety, personal data protection, judicial cooperation in civil and criminal matters, and the appointment of legal representatives in criminal proceedings."
Artifical Inellegence Act (AI Act) - Overview paragraph 85,0.716621757,"Aritifical Intelligence Act (AI Act) overview paragraph (85): In order to ensure that the regulatory framework can be adapted where necessary, the power to adopt acts in accordance with Article 290 TFEU should be delegated to the Commission to amend the techniques and approaches referred to in Annex I to define AI systems, the Union harmonisation legislation listed in Annex II, the high-risk AI systems listed in Annex III, the provisions regarding technical documentation listed in Annex IV, the content of the EU declaration of conformity in Annex V, the provisions regarding the conformity assessment procedures in Annex VI and VII and the provisions establishing the high-risk AI systems to which the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation should apply. It is of particular importance that the Commission carry out appropriate consultations during its preparatory work, including at expert level, and that those consultations be conducted in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making58. In particular, to ensure equal participation in the preparation of delegated acts, the European Parliament and the Council receive all documents at the same time as Member States experts, and their experts systematically have access to meetings of Commission expert groups dealing with the preparation of delegated acts.",recital,"The Artificial Intelligence Act (AI Act) allows the Commission to update the regulations as needed. This includes changes to the definitions of AI systems, the list of high-risk AI systems, and the requirements for technical documentation and conformity assessments. The Commission must consult with experts and follow the principles of the Interinstitutional Agreement on Better Law-Making. The European Parliament, the Council, and Member States' experts should all have equal access to documents and meetings related to these changes."
California Consumer Privacy Act Regulations (CCPA) - Article 2 Notice to Consumers -  999.304 Overview of Required Notices,0.716604352,Details of Article 2 Notice to Consumers -  999.304 Overview of Required Notices. in the California Consumer Privacy Act Regulations (CCPA): (a) Every business that must comply with the CCPA and these regulations shall provide a privacy policy in accordance with the CCPA and section 999.308. (b) A business that collects personal information from a consumer shall provide a notice at collection in accordance with the CCPA and section 999.305. (c) A business that sells personal information shall provide a notice of right to opt-out in accordance with the CCPA and section 999.306. (d) A business that offers a financial incentive or price or service difference shall provide a notice of financial incentive in accordance with the CCPA and section 999.307.,article,"The California Consumer Privacy Act (CCPA) requires businesses to be transparent about their data practices. Every business that falls under the CCPA must provide a privacy policy. If a business collects personal information, it must notify consumers when this collection occurs. If a business sells personal information, it must inform consumers and give them the choice to opt out. Additionally, if a business offers financial incentives or different prices/services based on personal data, it must inform consumers about these incentives."
General Data Protection Regulation (GDPR) - Article 2 Material scope,0.716598928,"Details of Article 2 Material scope in the General Data Protection Regulation (GDPR): 1. This Regulation applies to the processing of personal data wholly or partly by automated means and to the processing other than by automated means of personal data which form part of a filing system or are intended to form part of a filing system. 2. This Regulation does not apply to the processing of personal data: (a) in the course of an activity which falls outside the scope of Union law; (b) by the Member States when carrying out activities which fall within the scope of Chapter 2 of Title V of the TEU; (c) by a natural person in the course of a purely personal or household activity; (d) by competent authorities for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security. 3. For the processing of personal data by the Union institutions, bodies, offices and agencies, Regulation (EC) No 45/2001 applies. Regulation (EC) No 45/2001 and other Union legal acts applicable to such processing of personal data shall be adapted to the principles and rules of this Regulation in accordance with Article 98. 4. This Regulation shall be without prejudice to the application of Directive 2000/31/EC, in particular of the liability rules of intermediary service providers in Articles 12 to 15 of that Directive.",article,"The General Data Protection Regulation (GDPR) applies to the collection and use of personal data, whether done automatically or manually, as long as the data is part of, or intended to be part of, a filing system. However, it doesn't apply to data processing outside EU law, by member states in certain activities, by individuals for personal or household use, or by authorities for criminal investigation or public security. For EU institutions, a different regulation (EC No 45/2001) applies, but it must align with GDPR principles. The GDPR doesn't affect the application of Directive 2000/31/EC, especially regarding the liability of intermediary service providers."
Digital Services Act (DSA) - Article 58 Cross-border cooperation among Digital Services Coordinators,0.716595173,"Article 58 Cross-border cooperation among Digital Services Coordinators in the Digital Services Act (DSA):  1.   Unless the Commission has initiated an investigation for the same alleged infringement, where a Digital Services Coordinator of destination has reason to suspect that a provider of an intermediary service has infringed this Regulation in a manner negatively affecting the recipients of the service in the Member State of that Digital Services Coordinator, it may request the Digital Services Coordinator of establishment to assess the matter and to take the necessary investigatory and enforcement measures to ensure compliance with this Regulation.

2.   Unless the Commission has initiated an investigation for the same alleged infringement, and at the request of at least three Digital Services Coordinators of destination that have reason to suspect that a specific provider of intermediary services infringed this Regulation in a manner negatively affecting recipients of the service in their Member States, the Board may request the Digital Services Coordinator of establishment to assess the matter and take the necessary investigatory and enforcement measures to ensure compliance with this Regulation.

3.   A request pursuant to paragraph 1 or 2 shall be duly reasoned, and shall at least indicate:

(a) the point of contact of the provider of the intermediary services concerned as provided for in Article 11;
(b) a description of the relevant facts, the provisions of this Regulation concerned and the reasons why the Digital Services Coordinator that sent the request, or the Board, suspects that the provider infringed this Regulation, including the description of the negative effects of the alleged infringement;
(c) any other information that the Digital Services Coordinator that sent the request, or the Board, considers relevant, including, where appropriate, information gathered on its own initiative or suggestions for specific investigatory or enforcement measures to be taken, including interim measures.

4.   The Digital Services Coordinator of establishment shall take utmost account of the request pursuant to paragraphs 1 or 2 of this Article. Where it considers that it has insufficient information to act upon the request and has reasons to consider that the Digital Services Coordinator that sent the request, or the Board, could provide additional information, the Digital Services Coordinator of establishment may either request such information in accordance with Article 57 or, alternatively, may launch a joint investigation pursuant to Article 60(1) involving at least the requesting Digital Services Coordinator. The period laid down in paragraph 5 of this Article shall be suspended until that additional information is provided or until the invitation to participate in the joint investigation is refused.

5.   The Digital Services Coordinator of establishment shall, without undue delay and in any event not later than two months following receipt of the request pursuant to paragraph 1 or 2, communicate to the Digital Services Coordinator that sent the request, and the Board, the assessment of the suspected infringement and an explanation of any investigatory or enforcement measures taken or envisaged in relation thereto to ensure compliance with this Regulation.",article,"The Digital Services Act (DSA) allows for cross-border cooperation among Digital Services Coordinators. If a Coordinator suspects that a service provider is breaking the rules in a way that harms users in their country, they can ask the Coordinator in the provider's home country to investigate and enforce the rules. If at least three Coordinators have the same suspicion, the Board can make the same request. These requests must be well-reasoned and include certain information, like the contact for the service provider and a description of the suspected rule-breaking. The home-country Coordinator must take these requests seriously. If they need more information, they can ask for it or start a joint investigation. They must respond to the request within two months with their assessment and any actions they plan to take."
Digital Services Act (DSA) - Article 17 Statement of reasons,0.716582358,"Article 17 Statement of reasons in the Digital Services Act (DSA):  1.   Providers of hosting services shall provide a clear and specific statement of reasons to any affected recipients of the service for any of the following restrictions imposed on the ground that the information provided by the recipient of the service is illegal content or incompatible with their terms and conditions:
(a) any restrictions of the visibility of specific items of information provided by the recipient of the service, including removal of content, disabling access to content, or demoting content;
(b) suspension, termination or other restriction of monetary payments;
(c) suspension or termination of the provision of the service in whole or in part;
(d) suspension or termination of the recipient of the service's account.
2.   Paragraph 1 shall only apply where the relevant electronic contact details are known to the provider. It shall apply at the latest from the date that the restriction is imposed, regardless of why or how it was imposed.
Paragraph 1 shall not apply where the information is deceptive high-volume commercial content.
3.   The statement of reasons referred to in paragraph 1 shall at least contain the following information:
(a) information on whether the decision entails either the removal of, the disabling of access to, the demotion of or the restriction of the visibility of the information, or the suspension or termination of monetary payments related to that information, or imposes other measures referred to in paragraph 1 with regard to the information, and, where relevant, the territorial scope of the decision and its duration;
(b) the facts and circumstances relied on in taking the decision, including, where relevant, information on whether the decision was taken pursuant to a notice submitted in accordance with Article 16 or based on voluntary own-initiative investigations and, where strictly necessary, the identity of the notifier;
(c) where applicable, information on the use made of automated means in taking the decision, including information on whether the decision was taken in respect of content detected or identified using automated means;
(d) where the decision concerns allegedly illegal content, a reference to the legal ground relied on and explanations as to why the information is considered to be illegal content on that ground;
(e) where the decision is based on the alleged incompatibility of the information with the terms and conditions of the provider of hosting services, a reference to the contractual ground relied on and explanations as to why the information is considered to be incompatible with that ground;
(f) clear and user-friendly information on the possibilities for redress available to the recipient of the service in respect of the decision, in particular, where applicable through internal complaint-handling mechanisms, out-of-court dispute settlement and judicial redress.
4.   The information provided by the providers of hosting services in accordance with this Article shall be clear and easily comprehensible and as precise and specific as reasonably possible under the given circumstances. The information shall, in particular, be such as to reasonably allow the recipient of the service concerned to effectively exercise the possibilities for redress referred to in of paragraph 3, point (f).
5.   This Article shall not apply to any orders referred to in Article 9.",article,"The Digital Services Act (DSA) requires online service providers to clearly explain why they are restricting or removing a user's content or access. This could be due to the content being illegal or violating the provider's terms and conditions. The law applies when the provider knows the user's contact details and from the moment the restriction is imposed. However, it doesn't apply to deceptive commercial content. The explanation must include details about the decision, the facts and circumstances leading to it, the use of automated decision-making, the legal or contractual ground for the decision and how the user can appeal. The information must be clear and understandable, allowing the user to effectively appeal. This law doesn't apply to orders referred to in Article 9 of the DSA."
Digital Services Act (DSA) - Article 85 Information sharing system,0.716577232,"Article 85 Information sharing system in the Digital Services Act (DSA):  1.   The Commission shall establish and maintain a reliable and secure information sharing system supporting communications between Digital Services Coordinators, the Commission and the Board. Other competent authorities may be granted access to this system where necessary for them to carry out the tasks conferred to them in accordance with this Regulation.

2.   The Digital Services Coordinators, the Commission and the Board shall use the information sharing system for all communications pursuant to this Regulation.

3.   The Commission shall adopt implementing acts laying down the practical and operational arrangements for the functioning of the information sharing system and its interoperability with other relevant systems. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.",article,"The Digital Services Act (DSA) introduces a new system for sharing information. This system, managed by the Commission, is designed to facilitate communication between Digital Services Coordinators, the Commission, and the Board. Other relevant authorities may also have access if necessary for their duties. All communications under this law must use this system. The Commission will also provide practical guidelines for how the system will operate and interact with other systems. These guidelines will be adopted following the advisory procedure outlined in Article 88 of the DSA."
Artifical Inellegence Act (AI Act) - Definition of 'conformity assessment body',0.716565847,"Within the Aritifical Intelligence Act (AI Act), the Definition of conformity assessment body means a body that performs third-party conformity assessment activities, including testing, certification and inspection;",recital,"The Artificial Intelligence Act (AI Act) introduces a new term, 'conformity assessment body'. This refers to an organization that carries out checks to ensure that artificial intelligence systems meet certain standards. These checks can include testing, certification, and inspection."
Artifical Inellegence Act (AI Act) - Article 67,0.716563463,"Aritifical Intelligence Act (AI Act) Article 67 Compliant AI systems which present a risk:

1.Where, having performed an evaluation under Article 65, the market surveillance authority of a Member State finds that although an AI system is in compliance with this Regulation, it presents a risk to the health or safety of persons, to the compliance with obligations under Union or national law intended to protect fundamental rights or to other aspects of public interest protection, it shall require the relevant operator to take all appropriate measures to ensure that the AI system concerned, when placed on the market or put into service, no longer presents that risk, to withdraw the AI system from the market or to recall it within a reasonable period, commensurate with the nature of the risk, as it may prescribe.

2.The provider or other relevant operators shall ensure that corrective action is taken in respect of all the AI systems concerned that they have made available on the market throughout the Union within the timeline prescribed by the market surveillance authority of the Member State referred to in paragraph 1.

3.The Member State shall immediately inform the Commission and the other Member States. That information shall include all available details, in particular the data necessary for the identification of the AI system concerned, the origin and the supply chain of the AI system, the nature of the risk involved and the nature and duration of the national measures taken.

4.The Commission shall without delay enter into consultation with the Member States and the relevant operator and shall evaluate the national measures taken. On the basis of the results of that evaluation, the Commission shall decide whether the measure is justified or not and, where necessary, propose appropriate measures.

5.The Commission shall address its decision to the Member States.",article,"The Artificial Intelligence Act (AI Act) Article 67 states that if an AI system, despite complying with regulations, poses a risk to people's health, safety, or fundamental rights, the market surveillance authority of a member state must require the operator to mitigate the risk, remove the system from the market, or recall it within a reasonable time frame. The provider must ensure corrective action is taken for all such systems across the Union within a set timeline. The member state must inform the Commission and other member states about the issue, including details about the AI system, its origin, supply chain, the risk involved, and the measures taken. The Commission will consult with member states and the operator, evaluate the measures taken, and decide if they are justified or if other measures are necessary. This decision will be communicated to all member states."
Digital Services Act (DSA) - Article 26 Advertising on online platforms,0.716524363,"Article 26 Advertising on online platforms in the Digital Services Act (DSA):  1.   Providers of online platforms that present advertisements on their online interfaces shall ensure that, for each specific advertisement presented to each individual recipient, the recipients of the service are able to identify, in a clear, concise and unambiguous manner and in real time, the following:

(a) that the information is an advertisement, including through prominent markings, which might follow standards pursuant to Article 44;
(b) the natural or legal person on whose behalf the advertisement is presented;
(c) the natural or legal person who paid for the advertisement if that person is different from the natural or legal person referred to in point (b);
(d) meaningful information directly and easily accessible from the advertisement about the main parameters used to determine the recipient to whom the advertisement is presented and, where applicable, about how to change those parameters.

2.   Providers of online platforms shall provide recipients of the service with a functionality to declare whether the content they provide is or contains commercial communications.

When the recipient of the service submits a declaration pursuant to this paragraph, the provider of online platforms shall ensure that other recipients of the service can identify in a clear and unambiguous manner and in real time, including through prominent markings, which might follow standards pursuant to Article 44, that the content provided by the recipient of the service is or contains commercial communications, as described in that declaration.

3.   Providers of online platforms shall not present advertisements to recipients of the service based on profiling as defined in Article 4, point (4), of Regulation (EU) 2016/679 using special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016/679.",article,"The Digital Services Act (DSA) has a new rule, Article 26, about advertising on online platforms. It says that online platforms must clearly show that an item is an advertisement and who is responsible for it. If someone else paid for the ad, this must be clear too. The ad must also explain why it's being shown to the viewer, and if possible, how to change this. The platforms must also allow users to say if their content is commercial, and make sure others can see this. Lastly, the platforms can't show ads based on personal data that falls under special categories."
General Data Protection Regulation (GDPR) - Contextual Paragraph (39),0.716518044,"Details of the Contextual Paragraph (39) in the General Data Protection Regulation (GDPR): Any processing of personal data should be lawful and fair. It should be transparent to natural persons that personal data concerning them are collected, used, consulted or otherwise processed and to what extent the personal data are or will be processed. The principle of transparency requires that any information and communication relating to the processing of those personal data be easily accessible and easy to understand, and that clear and plain language be used. That principle concerns, in particular, information to the data subjects on the identity of the controller and the purposes of the processing and further information to ensure fair and transparent processing in respect of the natural persons concerned and their right to obtain confirmation and communication of personal data concerning them which are being processed. Natural persons should be made aware of risks, rules, safeguards and rights in relation to the processing of personal data and how to exercise their rights in relation to such processing. In particular, the specific purposes for which personal data are processed should be explicit and legitimate and determined at the time of the collection of the personal data. The personal data should be adequate, relevant and limited to what is necessary for the purposes for which they are processed. This requires, in particular, ensuring that the period for which the personal data are stored is limited to a strict minimum. Personal data should be processed only if the purpose of the processing could not reasonably be fulfilled by other means. In order to ensure that the personal data are not kept longer than necessary, time limits should be established by the controller for erasure or for a periodic review. Every reasonable step should be taken to ensure that personal data which are inaccurate are rectified or deleted. Personal data should be processed in a manner that ensures appropriate security and confidentiality of the personal data, including for preventing unauthorised access to or use of personal data and the equipment used for the processing.",recital,"The General Data Protection Regulation (GDPR) mandates that any collection, use, or processing of personal data must be lawful, fair, and transparent. It requires that individuals be clearly informed about what data is collected, how it's used, and for what purpose. This information should be easy to access and understand. The law also emphasizes that personal data should only be collected and processed for explicit and legitimate purposes, and should be limited to what is necessary. The data should be stored for the minimum time possible and should be deleted or corrected if inaccurate. The law also requires that all personal data be processed securely to prevent unauthorized access or use. It aims to make individuals aware of their rights and how to exercise them in relation to their personal data."
Artifical Inellegence Act (AI Act) - Article 1,0.716517031,"Aritifical Intelligence Act (AI Act) Article 1 Subject matter:
This Regulation lays down:

(a)harmonised rules for the placing on the market, the putting into service and the use of artificial intelligence systems (AI systems) in the Union;

(a)prohibitions of certain artificial intelligence practices;

(b)specific requirements for high-risk AI systems and obligations for operators of such systems;

(c)harmonised transparency rules for AI systems intended to interact with natural persons, emotion recognition systems and biometric categorisation systems, and AI systems used to generate or manipulate image, audio or video content;

(d)rules on market monitoring and surveillance.",article,"The Artificial Intelligence Act (AI Act) is a new law that sets out rules for the use, sale, and service of artificial intelligence (AI) systems in the Union. It bans certain AI practices and sets specific requirements for high-risk AI systems, including obligations for those who operate them. The law also establishes transparency rules for AI systems that interact with people, recognize emotions, categorize biometrics, or manipulate images, audio, or video content. Lastly, it provides rules for monitoring and overseeing the AI market."
Artifical Inellegence Act (AI Act) - Article 53,0.716488,"Aritifical Intelligence Act (AI Act) Article 53 AI regulatory sandboxes:

1.AI regulatory sandboxes established by one or more Member States competent authorities or the European Data Protection Supervisor shall provide a controlled environment that facilitates the development, testing and validation of innovative AI systems for a limited time before their placement on the market or putting into service pursuant to a specific plan. This shall take place under the direct supervision and guidance by the competent authorities with a view to ensuring compliance with the requirements of this Regulation and, where relevant, other Union and Member States legislation supervised within the sandbox.

2.Member States shall ensure that to the extent the innovative AI systems involve the processing of personal data or otherwise fall under the supervisory remit of other national authorities or competent authorities providing or supporting access to data, the national data protection authorities and those other national authorities are associated to the operation of the AI regulatory sandbox.

3.The AI regulatory sandboxes shall not affect the supervisory and corrective powers of the competent authorities. Any significant risks to health and safety and fundamental rights identified during the development and testing of such systems shall result in immediate mitigation and, failing that, in the suspension of the development and testing process until such mitigation takes place.

4.Participants in the AI regulatory sandbox shall remain liable under applicable Union and Member States liability legislation for any harm inflicted on third parties as a result from the experimentation taking place in the sandbox.

5.Member States competent authorities that have established AI regulatory sandboxes shall coordinate their activities and cooperate within the framework of the European Artificial Intelligence Board. They shall submit annual reports to the Board and the Commission on the results from the implementation of those scheme, including good practices, lessons learnt and recommendations on their setup and, where relevant, on the application of this Regulation and other Union legislation supervised within the sandbox.

6.The modalities and the conditions of the operation of the AI regulatory sandboxes, including the eligibility criteria and the procedure for the application, selection, participation and exiting from the sandbox, and the rights and obligations of the participants shall be set out in implementing acts. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).",article,"The Artificial Intelligence Act (AI Act) has introduced AI regulatory sandboxes. These are controlled environments where new AI systems can be developed, tested, and validated for a limited time before being launched. This is done under the supervision of competent authorities to ensure compliance with the AI Act and other relevant laws. If these AI systems involve personal data, national data protection authorities will be involved. The sandbox doesn't affect the powers of these authorities, and any significant risks identified must be immediately addressed. Participants in the sandbox remain liable for any harm caused during experimentation. Authorities that have established sandboxes must cooperate with the European Artificial Intelligence Board and submit annual reports on their results. The specific rules and conditions for the operation of the sandboxes will be set out in implementing acts."
Artifical Inellegence Act (AI Act) - Definition of 'law enforcement authority',0.71643,"Within the Aritifical Intelligence Act (AI Act), the Definition of law enforcement authority means:
(a)any public authority competent for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security; or
(b)any other body or entity entrusted by Member State law to exercise public authority and public powers for the purposes of the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;",recital,"The Artificial Intelligence Act (AI Act) defines 'law enforcement authority' as any public body or entity that has the power to prevent, investigate, detect or prosecute criminal offenses, execute criminal penalties, or safeguard against and prevent threats to public security. This can be a public authority or any other body entrusted by a Member State to exercise these powers."
General Data Protection Regulation (GDPR) - Contextual Paragraph (160),0.716395855,"Details of the Contextual Paragraph (160) in the General Data Protection Regulation (GDPR): Where personal data are processed for historical research purposes, this Regulation should also apply to that processing. This should also include historical research and research for genealogical purposes, bearing in mind that this Regulation should not apply to deceased persons.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Paragraph (160), which applies to the use of personal data for historical research. This includes studies into history and family ancestry. However, it's important to note that this rule doesn't apply to data of people who have passed away."
Digital Services Act (DSA) - Article 42 Transparency reporting obligations,0.716387,"Article 42 Transparency reporting obligations in the Digital Services Act (DSA):  1.   Providers of very large online platforms or of very large online search engines shall publish the reports referred to in Article 15 at the latest by two months from the date of application referred to in Article 33(6), second subparagraph, and thereafter at least every six months.

2.   The reports referred to in paragraph 1 of this Article published by providers of very large online platforms shall, in addition to the information referred to in Article 15 and Article 24(1), specify:

(a) the human resources that the provider of very large online platforms dedicates to content moderation in respect of the service offered in the Union, broken down by each applicable official language of the Member States, including for compliance with the obligations set out in Articles 16 and 22, as well as for compliance with the obligations set out in Article 20;
(b) the qualifications and linguistic expertise of the persons carrying out the activities referred to in point (a), as well as the training and support given to such staff;
(c) the indicators of accuracy and related information referred to in Article 15(1), point (e), broken down by each official language of the Member States.

The reports shall be published in at least one of the official languages of the Member States.

3.   In addition to the information referred to in Articles 24(2), the providers of very large online platforms or of very large online search engines shall include in the reports referred to in paragraph 1 of this Article the information on the average monthly recipients of the service for each Member State.

4.   Providers of very large online platforms or of very large online search engines shall transmit to the Digital Services Coordinator of establishment and the Commission, without undue delay upon completion, and make publicly available at the latest three months after the receipt of each audit report pursuant to Article 37(4):

(a) a report setting out the results of the risk assessment pursuant to Article 34;
(b) the specific mitigation measures put in place pursuant to Article 35(1);
(c) the audit report provided for in Article 37(4);
(d) the audit implementation report provided for in Article 37(6);
(e) where applicable, information about the consultations conducted by the provider in support of the risk assessments and design of the risk mitigation measures.

5.   Where a provider of very large online platform or of very large online search engine considers that the publication of information pursuant to paragraph 4 might result in the disclosure of confidential information of that provider or of the recipients of the service, cause significant vulnerabilities for the security of its service, undermine public security or harm recipients, the provider may remove such information from the publicly available reports. In that case, the provider shall transmit the complete reports to the Digital Services Coordinator of establishment and the Commission, accompanied by a statement of the reasons for removing the information from the publicly available reports.",article,"The Digital Services Act (DSA) requires major online platforms and search engines to publish reports every six months. These reports must detail their content moderation resources, including the qualifications and language skills of their staff, and their compliance with various articles of this Act. They also need to provide information on the average number of monthly users in each EU member state. 

Within three months of receiving an audit report, these platforms must also publicly share the results of their risk assessments, the steps they've taken to mitigate those risks, and any relevant consultations. 

If they believe publishing certain information could compromise confidentiality, security, public safety, or harm users, they can exclude it from public reports. However, they must still send the complete reports to the Digital Services Coordinator and the European Commission, explaining why they withheld certain information."
Artifical Inellegence Act (AI Act) - Context Section 5.1,0.716376603,"Aritifical Intelligence Act (AI Act) context section 5.1.Implementation plans and monitoring, evaluation and reporting arrangements: 

Providing for a robust monitoring and evaluation mechanism is crucial to ensure that the proposal will be effective in achieving its specific objectives. The Commission will be in charge of monitoring the effects of the proposal. It will establish a system for registering stand-alone high-risk AI applications in a public EU-wide database. This registration will also enable competent authorities, users and other interested people to verify if the high-risk AI system complies with the requirements laid down in the proposal and to exercise enhanced oversight over those AI systems posing high risks to fundamental rights. To feed this database, AI providers will be obliged to provide meaningful information about their systems and the conformity assessment carried out on those systems.

Moreover, AI providers will be obliged to inform national competent authorities about serious incidents or malfunctioning that constitute a breach of fundamental rights obligations as soon as they become aware of them, as well as any recalls or withdrawals of AI systems from the market. National competent authorities will then investigate the incidents/or malfunctioning, collect all the necessary information and regularly transmit it to the Commission with adequate metadata. The Commission will complement this information on the incidents by a comprehensive analysis of the overall market for AI.

The Commission will publish a report evaluating and reviewing the proposed AI framework five years following the date on which it becomes applicable.5.1.Implementation plans and monitoring, evaluation and reporting arrangements:

Providing for a robust monitoring and evaluation mechanism is crucial to ensure that the proposal will be effective in achieving its specific objectives. The Commission will be in charge of monitoring the effects of the proposal. It will establish a system for registering stand-alone high-risk AI applications in a public EU-wide database. This registration will also enable competent authorities, users and other interested people to verify if the high-risk AI system complies with the requirements laid down in the proposal and to exercise enhanced oversight over those AI systems posing high risks to fundamental rights. To feed this database, AI providers will be obliged to provide meaningful information about their systems and the conformity assessment carried out on those systems.

Moreover, AI providers will be obliged to inform national competent authorities about serious incidents or malfunctioning that constitute a breach of fundamental rights obligations as soon as they become aware of them, as well as any recalls or withdrawals of AI systems from the market. National competent authorities will then investigate the incidents/or malfunctioning, collect all the necessary information and regularly transmit it to the Commission with adequate metadata. The Commission will complement this information on the incidents by a comprehensive analysis of the overall market for AI.

The Commission will publish a report evaluating and reviewing the proposed AI framework five years following the date on which it becomes applicable.",recital,"The Artificial Intelligence Act (AI Act) requires the Commission to monitor high-risk AI applications. These applications must be registered in a public EU-wide database, allowing authorities and users to check their compliance with regulations. AI providers must supply information about their systems and any assessments made on them. They must also report serious incidents, malfunctions, or breaches of fundamental rights to national authorities as soon as they become aware of them, as well as any recalls or withdrawals of AI systems from the market. The Commission will analyze this information and the overall AI market. Five years after the law is implemented, the Commission will publish a report evaluating the AI framework."
General Data Protection Regulation (GDPR) - Article 35 Data protection impact assessment,0.716367185,"Details of Article 35 Data protection impact assessment in the General Data Protection Regulation (GDPR): 1. Where a type of processing in particular using new technologies, and taking into account the nature, scope, context and purposes of the processing, is likely to result in a high risk to the rights and freedoms of natural persons, the controller shall, prior to the processing, carry out an assessment of the impact of the envisaged processing operations on the protection of personal data. A single assessment may address a set of similar processing operations that present similar high risks. 2. The controller shall seek the advice of the data protection officer, where designated, when carrying out a data protection impact assessment. 3. A data protection impact assessment referred to in paragraph 1 shall in particular be required in the case of: (a) a systematic and extensive evaluation of personal aspects relating to natural persons which is based on automated processing, including profiling, and on which decisions are based that produce legal effects concerning the natural person or similarly significantly affect the natural person; (b) processing on a large scale of special categories of data referred to in Article 9(1), or of personal data relating to criminal convictions and offences referred to in Article 10; or (c) a systematic monitoring of a publicly accessible area on a large scale. 4. The supervisory authority shall establish and make public a list of the kind of processing operations which are subject to the requirement for a data protection impact assessment pursuant to paragraph 1. The supervisory authority shall communicate those lists to the Board referred to in Article 68. 5. The supervisory authority may also establish and make public a list of the kind of processing operations for which no data protection impact assessment is required. The supervisory authority shall communicate those lists to the Board. 6. Prior to the adoption of the lists referred to in paragraphs 4 and 5, the competent supervisory authority shall apply the consistency mechanism referred to in Article 63 where such lists involve processing activities which are related to the offering of goods or services to data subjects or to the monitoring of their behaviour in several Member States, or may substantially affect the free movement of personal data within the Union. 7. The assessment shall contain at least: (a) a systematic description of the envisaged processing operations and the purposes of the processing, including, where applicable, the legitimate interest pursued by the controller; (b) an assessment of the necessity and proportionality of the processing operations in relation to the purposes; (c) an assessment of the risks to the rights and freedoms of data subjects referred to in paragraph 1; and (d) the measures envisaged to address the risks, including safeguards, security measures and mechanisms to ensure the protection of personal data and to demonstrate compliance with this Regulation taking into account the rights and legitimate interests of data subjects and other persons concerned. 8. Compliance with approved codes of conduct referred to in Article 40 by the relevant controllers or processors shall be taken into due account in assessing the impact of the processing operations performed by such controllers or processors, in particular for the purposes of a data protection impact assessment. 9. Where appropriate, the controller shall seek the views of data subjects or their representatives on the intended processing, without prejudice to the protection of commercial or public interests or the security of processing operations. 10. Where processing pursuant to point (c) or (e) of Article 6(1) has a legal basis in Union law or in the law of the Member State to which the controller is subject, that law regulates the specific processing operation or set of operations in question, and a data protection impact assessment has already been carried out as part of a general impact assessment in the context of the adoption of that legal basis, paragraphs 1 to 7 shall not apply unless Member States deem it to be necessary to carry out such an assessment prior to processing activities. 11. Where necessary, the controller shall carry out a review to assess if processing is performed in accordance with the data protection impact assessment at least when there is a change of the risk represented by processing operations.",article,"The General Data Protection Regulation (GDPR) Article 35 requires companies to conduct a Data Protection Impact Assessment (DPIA) before processing personal data that could pose a high risk to individuals' privacy rights. This includes automated processing, large-scale processing of sensitive data, or large-scale systematic monitoring. The DPIA should describe the data processing, assess its necessity and proportionality, evaluate the risks to individuals, and outline measures to mitigate those risks. Companies should consult their data protection officer, if one exists, and consider the views of the individuals affected where appropriate. The supervisory authority will provide lists of processing operations that require or do not require a DPIA. If a legal basis for the processing already exists in Union or Member State law, and a DPIA has already been conducted, a new one may not be necessary unless the risk changes."
Artifical Inellegence Act (AI Act) - Overview paragraph 81,0.716366768,"Aritifical Intelligence Act (AI Act) overview paragraph (81): The development of AI systems other than high-risk AI systems in accordance with the requirements of this Regulation may lead to a larger uptake of trustworthy artificial intelligence in the Union. Providers of non-high-risk AI systems should be encouraged to create codes of conduct intended to foster the voluntary application of the mandatory requirements applicable to high-risk AI systems. Providers should also be encouraged to apply on a voluntary basis additional requirements related, for example, to environmental sustainability, accessibility to persons with disability, stakeholders participation in the design and development of AI systems, and diversity of the development teams. The Commission may develop initiatives, including of a sectorialnature, to facilitate the lowering of technical barriers hindering cross-border exchange of data for AI development, including on data access infrastructure, semantic and technical interoperability of different types of data.",recital,"The Artificial Intelligence Act (AI Act) encourages developers of non-high-risk AI systems to voluntarily adopt the stricter rules that apply to high-risk AI systems. This could increase the use of trustworthy AI across the Union. The Act also encourages these developers to consider additional factors like environmental sustainability, accessibility for disabled individuals, stakeholder involvement, and diverse development teams. The Commission may also create initiatives to reduce technical barriers that prevent cross-border data exchange for AI development, including issues related to data access infrastructure and data interoperability."
Artifical Inellegence Act (AI Act) - Article 51,0.716365695,"Aritifical Intelligence Act (AI Act) Article 51 Registration:

Before placing on the market or putting into service a high-risk AI system referred to in Article 6(2), the provider or, where applicable, the authorised representative shall register that system in the EU database referred to in Article 60.",article,"The Artificial Intelligence Act (AI Act) requires that before any high-risk AI system is launched or used, it must be registered in the EU database. This responsibility falls on the provider or, if applicable, the authorized representative. This registration is a necessary step as outlined in Article 6(2) and the EU database is further explained in Article 60."
Digital Services Act (DSA) - Article 51 Powers of Digital Services Coordinators,0.716347039,"Article 51 Powers of Digital Services Coordinators in the Digital Services Act (DSA):  1.   Where needed in order to carry out their tasks under this Regulation, Digital Services Coordinators shall have the following powers of investigation, in respect of conduct by providers of intermediary services falling within the competence of their Member State:

(a) the power to require those providers, as well as any other persons acting for purposes related to their trade, business, craft or profession that may reasonably be aware of information relating to a suspected infringement of this Regulation, including organisations performing the audits referred to in Article 37 and Article 75(2), to provide such information without undue delay;
(b) the power to carry out, or to request a judicial authority in their Member State to order, inspections of any premises that those providers or those persons use for purposes related to their trade, business, craft or profession, or to request other public authorities to do so, in order to examine, seize, take or obtain copies of information relating to a suspected infringement in any form, irrespective of the storage medium;
(c) the power to ask any member of staff or representative of those providers or those persons to give explanations in respect of any information relating to a suspected infringement and to record the answers with their consent by any technical means.

2.   Where needed for carrying out their tasks under this Regulation, Digital Services Coordinators shall have the following enforcement powers, in respect of providers of intermediary services falling within the competence of their Member State:

(a) the power to accept the commitments offered by those providers in relation to their compliance with this Regulation and to make those commitments binding;
(b) the power to order the cessation of infringements and, where appropriate, to impose remedies proportionate to the infringement and necessary to bring the infringement effectively to an end, or to request a judicial authority in their Member State to do so;
(c) the power to impose fines, or to request a judicial authority in their Member State to do so, in accordance with Article 52 for failure to comply with this Regulation, including with any of the investigative orders issued pursuant to paragraph 1 of this Article;
(d) the power to impose a periodic penalty payment, or to request a judicial authority in their Member State to do so, in accordance with Article 52 to ensure that an infringement is terminated in compliance with an order issued pursuant to point (b) of this subparagraph or for failure to comply with any of the investigative orders issued pursuant to paragraph 1 of this Article;
(e) the power to adopt interim measures or to request the competent national judicial authority in their Member State to do so, to avoid the risk of serious harm.

As regards the first subparagraph, points (c) and (d), Digital Services Coordinators shall also have the enforcement powers set out in those points in respect of the other persons referred to in paragraph 1 for failure to comply with any of the orders issued to them pursuant to that paragraph. They shall only exercise those enforcement powers after providing those other persons in good time with all relevant information relating to such orders, including the applicable period, the fines or periodic payments that may be imposed for failure to comply and the possibilities for redress.

3.   Where needed for carrying out their tasks under this Regulation, Digital Services Coordinators shall, in respect of providers of intermediary services falling within the competence of their Member State, where all other powers pursuant to this Article to bring about the cessation of an infringement have been exhausted and the infringement has not been remedied or is continuing and is causing serious harm which cannot be avoided through the exercise of other powers available under Union or national law, also have the power to take the following measures:

(a) to require the management body of those providers, without undue delay, to examine the situation, adopt and submit an action plan setting out the necessary measures to terminate the infringement, ensure that the provider takes those measures, and report on the measures taken;
(b) where the Digital Services Coordinator considers that a provider of intermediary services has not sufficiently complied with the requirements referred to in point (a), that the infringement has not been remedied or is continuing and is causing serious harm, and that that infringement entails a criminal offence involving a threat to the life or safety of persons, to request that the competent judicial authority of its Member State order the temporary restriction of access of recipients to the service concerned by the infringement or, only where that is not technically feasible, to the online interface of the provider of intermediary services on which the infringement takes place.

The Digital Services Coordinator shall, except where it acts upon the Commission's request referred to in Article 82, prior to submitting the request referred to in the first subparagraph, point (b), of this paragraph invite interested parties to submit written observations within a period that shall not be less than two weeks, describing the measures that it intends to request and identifying the intended addressee or addressees thereof. The provider of intermediary services, the intended addressee or addressees and any other third party demonstrating a legitimate interest shall be entitled to participate in the proceedings before the competent judicial authority. Any measure ordered shall be proportionate to the nature, gravity, recurrence and duration of the infringement, without unduly restricting access to lawful information by recipients of the service concerned.

The restriction of access shall be for a period of four weeks, subject to the possibility for the competent judicial authority, in its order, to allow the Digital Services Coordinator to extend that period for further periods of the same lengths, subject to a maximum number of extensions set by that judicial authority. The Digital Services Coordinator shall only extend the period where, having regard to the rights and interests of all parties affected by that restriction and all relevant circumstances, including any information that the provider of intermediary services, the addressee or addressees and any other third party that demonstrated a legitimate interest may provide to it, it considers that both of the following conditions have been met:

(a) the provider of intermediary services has failed to take the necessary measures to terminate the infringement;
(b) the temporary restriction does not unduly restrict access to lawful information by recipients of the service, having regard to the number of recipients affected and whether any adequate and readily accessible alternatives exist.

Where the Digital Services Coordinator considers that the conditions set out in the third subparagraph, points (a) and (b), have been met but it cannot further extend the period pursuant to the third subparagraph, it shall submit a new request to the competent judicial authority, as referred to in the first subparagraph, point (b).

4.   The powers listed in paragraphs 1, 2 and 3 shall be without prejudice to Section 3.

5.   The measures taken by the Digital Services Coordinators in the exercise of their powers listed in paragraphs 1, 2 and 3 shall be effective, dissuasive and proportionate, having regard, in particular, to the nature, gravity, recurrence and duration of the infringement or suspected infringement to which those measures relate, as well as the economic, technical and operational capacity of the provider of the intermediary services concerned where relevant.

6.   Member States shall lay down specific rules and procedures for the exercise of the powers pursuant to paragraphs 1, 2 and 3 and shall ensure that any exercise of those powers is subject to adequate safeguards laid down in the applicable national law in compliance with the Charter and with the general principles of Union law. In particular, those measures shall only be taken in accordance with the right to respect for private life and the rights of defence, including the rights to be heard and of access to the file, and subject to the right to an effective judicial remedy of all affected parties.",article,"The Digital Services Act (DSA) gives Digital Services Coordinators new powers to regulate online service providers. They can now demand information from these providers related to any suspected violation of the DSA, conduct inspections, and record explanations from staff. They can also enforce compliance by accepting commitments from providers, ordering the cessation of infringements, imposing fines or penalties, and adopting interim measures to prevent serious harm. If a violation continues and causes serious harm, the coordinators can require the provider to submit an action plan, and if not complied with, they can request a court to restrict access to the service. These powers must be exercised in a way that respects private life and the rights of defense, and any measures taken should be effective, dissuasive, and proportionate to the violation. Member States must establish specific rules and procedures for the exercise of these powers."
Digital Markets Act (DMA) - Article 20 Opening of proceedings,0.716314077,"Details of Article 20 Opening of proceedings in the Digital Markets Act (DMA): 1. Where the Commission intends to open proceedings with a view to the possible adoption of decisions pursuant to Articles 8, 29 and 30, it shall adopt a decision opening a proceeding. 2. Notwithstanding paragraph 1, the Commission may exercise its investigative powers under this Regulation before opening proceedings pursuant to that paragraph.",article,"The Digital Markets Act (DMA) has a new rule, Article 20, about starting legal proceedings. If the Commission plans to make decisions under Articles 8, 29, and 30 of the DMA, it must first officially start a legal proceeding. However, even before officially starting these proceedings, the Commission has the right to start investigating under the DMA rules."
Digital Services Act (DSA) - Definition of 'Digital Services Coordinator of establishment',0.716285229,Definition of 'Digital Services Coordinator of establishment' in the Digital Services Act (DSA): the Digital Services Coordinator of the Member State where the main establishment of a provider of an intermediary service is located or its legal representative resides or is established.,recital,"The Digital Services Act (DSA) introduces a role called 'Digital Services Coordinator.' This person is based in the country where the main office of a digital service provider is located, or where its legal representative lives or has a business. This coordinator will be responsible for overseeing the provider's compliance with the DSA."
Digital Markets Act (DMA) - Definition of non-personal data,0.71628052,"Details of the Definition of non-personal data in the Digital Markets Act (DMA): ""non-personal data"" means data other than personal data;",rectial,"The Digital Markets Act (DMA) introduces the term ""non-personal data"". This simply refers to any data that is not personal. In other words, it's any information that can't be used to directly identify you. This could include data about the weather, traffic conditions, or statistics about a large group of people, for example. The DMA is concerned with how this kind of data is used and protected."
Digital Markets Act (DMA) - Definition of personal data,0.716274142,"Details of the Definition of personal data in the Digital Markets Act (DMA): ""personal data"" means personal data as defined in Article 4, point (1), of Regulation (EU) 2016/679;",rectial,"The Digital Markets Act (DMA) defines ""personal data"" in line with the definition provided in Article 4, point (1), of Regulation (EU) 2016/679. This essentially means that any information that can be used to identify a person directly or indirectly is considered personal data. This could be anything from your name, photo, email address, bank details, posts on social networking websites, medical information, or your computer's IP address. The law is designed to protect this personal data."
Artifical Inellegence Act (AI Act) - Article 15,0.716247499,"Aritifical Intelligence Act (AI Act) Article 15 Accuracy, robustness and cybersecurity:

1.High-risk AI systems shall be designed and developed in such a way that they achieve, in the light of their intended purpose, an appropriate level of accuracy, robustness and cybersecurity, and perform consistently in those respects throughout their lifecycle.

2.The levels of accuracy and the relevant accuracy metrics of high-risk AI systems shall be declared in the accompanying instructions of use.

3.High-risk AI systems shall be resilient as regards errors, faults or inconsistencies that may occur within the system or the environment in which the system operates, in particular due to their interaction with natural persons or other systems.

The robustness of high-risk AI systems may be achieved through technical redundancy solutions, which may include backup or fail-safe plans.

High-risk AI systems that continue to learn after being placed on the market or put into service shall be developed in such a way to ensure that possibly biased outputs due to outputs used as an input for future operations (feedback loops) are duly addressed with appropriate mitigation measures.

4.High-risk AI systems shall be resilient as regards attempts by unauthorised third parties to alter their use or performance by exploiting the system vulnerabilities.

The technical solutions aimed at ensuring the cybersecurity of high-risk AI systems shall be appropriate to the relevant circumstances and the risks.

The technical solutions to address AI specific vulnerabilities shall include, where appropriate, measures to prevent and control for attacks trying to manipulate the training dataset (data poisoning), inputs designed to cause the model to make a mistake (adversarial examples), or model flaws.",article,"The Artificial Intelligence Act (AI Act) requires that high-risk AI systems be designed to perform accurately, robustly, and securely. The accuracy of these systems should be clearly stated in the user instructions. These systems should be able to handle errors and inconsistencies, and have backup plans for added robustness. If the AI system continues to learn after being launched, it should be designed to address and mitigate any biased results. The AI system should also be resistant to unauthorized attempts to exploit its vulnerabilities. The cybersecurity measures should be suitable for the specific risks and circumstances. This includes measures to prevent and control attacks that try to manipulate the AI's training data, inputs designed to cause errors, or exploit model flaws."
Artifical Inellegence Act (AI Act) - Overview paragraph 32,0.716246247,"Aritifical Intelligence Act (AI Act) overview paragraph (32): As regards stand-alone AI systems, meaning high-risk AI systems other than those that are safety components of products, or which are themselves products, it is appropriate to classify them as high-risk if, in the light of their intended purpose, they pose a high risk of harm to the health and safety or the fundamental rights of persons, taking into account both the severity of the possible harm and its probability of occurrence and they are used in a number of specifically pre-defined areas specified in the Regulation. The identification of those systems is based on the same methodology and criteria envisaged also for any future amendments of the list of high-risk AI systems.",recital,"The Artificial Intelligence Act (AI Act) classifies certain AI systems as high-risk, particularly if they could potentially harm people's health, safety, or fundamental rights. This classification is based on how severe the possible harm could be and how likely it is to happen. These high-risk AI systems are those that operate independently, not as part of other products, and are used in specific areas outlined in the Act. The same criteria will be used to identify high-risk AI systems in any future changes to the Act."
General Data Protection Regulation (GDPR) - Definition of international organisation:,0.716216087,"Details of the Definition of international organisation: in the General Data Protection Regulation (GDPR): ""international organisation"" means an organisation and its subordinate bodies governed by public international law, or any other body which is set up by, or on the basis of, an agreement between two or more countries.",recital,"The General Data Protection Regulation (GDPR) defines an ""international organization"" as a group that is governed by international public law. This can also include any body that is established through an agreement between two or more countries. This new law is designed to regulate how such organizations handle personal data."
Artifical Inellegence Act (AI Act) - Definition of 'small-scale provider',0.716167629,"Within the Aritifical Intelligence Act (AI Act), the Definition of small-scale provider means a provider that is a micro or small enterprise within the meaning of Commission Recommendation2003/361/EC61;",recital,"The Artificial Intelligence Act (AI Act) introduces a new term, 'small-scale provider'. This refers to a service provider that is considered a micro or small business, as defined by the Commission Recommendation 2003/361/EC. In simpler terms, if a company is small or micro-sized according to the standards set in the mentioned recommendation, it is classified as a 'small-scale provider' under this new AI Act."
General Data Protection Regulation (GDPR) - Article 64 Opinion of the Board,0.716165245,"Details of Article 64 Opinion of the Board in the General Data Protection Regulation (GDPR): 1. The Board shall issue an opinion where a competent supervisory authority intends to adopt any of the measures below. To that end, the competent supervisory authority shall communicate the draft decision to the Board, when it: (a) aims to adopt a list of the processing operations subject to the requirement for a data protection impact assessment pursuant to Article 35(4); (b) concerns a matter pursuant to Article 40(7) whether a draft code of conduct or an amendment or extension to a code of conduct complies with this Regulation; (c) aims to approve the criteria for accreditation of a body pursuant to Article 41(3) or a certification body pursuant to Article 43(3); (d) aims to determine standard data protection clauses referred to in point (d) of Article 46(2) and in Article 28(8); (e) aims to authorise contractual clauses referred to in point (a) of Article 46(3); or (f) aims to approve binding corporate rules within the meaning of Article 47. 2. Any supervisory authority, the Chair of the Board or the Commission may request that any matter of general application or producing effects in more than one Member State be examined by the Board with a view to obtaining an opinion, in particular where a competent supervisory authority does not comply with the obligations for mutual assistance in accordance with Article 61 or for joint operations in accordance with Article 62. 3. In the cases referred to in paragraphs 1 and 2, the Board shall issue an opinion on the matter submitted to it provided that it has not already issued an opinion on the same matter. That opinion shall be adopted within eight weeks by simple majority of the members of the Board. That period may be extended by a further six weeks, taking into account the complexity of the subject matter. Regarding the draft decision referred to in paragraph 1 circulated to the members of the Board in accordance with paragraph 5, a member which has not objected within a reasonable period indicated by the Chair, shall be deemed to be in agreement with the draft decision. 4. Supervisory authorities and the Commission shall, without undue delay, communicate by electronic means to the Board, using a standardised format any relevant information, including as the case may be a summary of the facts, the draft decision, the grounds which make the enactment of such measure necessary, and the views of other supervisory authorities concerned. 5. The Chair of the Board shall, without undue, delay inform by electronic means: (a) the members of the Board and the Commission of any relevant information which has been communicated to it using a standardised format. The secretariat of the Board shall, where necessary, provide translations of relevant information; and (b) the supervisory authority referred to, as the case may be, in paragraphs 1 and 2, and the Commission of the opinion and make it public. 6. The competent supervisory authority shall not adopt its draft decision referred to in paragraph 1 within the period referred to in paragraph 3. 7. The supervisory authority referred to in paragraph 1 shall take utmost account of the opinion of the Board and shall, within two weeks after receiving the opinion, communicate to the Chair of the Board by electronic means whether it will maintain or amend its draft decision and, if any, the amended draft decision, using a standardised format. 8. Where the supervisory authority concerned informs the Chair of the Board within the period referred to in paragraph 7 of this Article that it does not intend to follow the opinion of the Board, in whole or in part, providing the relevant grounds, Article 65(1) shall apply.",article,"The General Data Protection Regulation (GDPR) Article 64 states that the Board must give an opinion when a supervisory authority plans to adopt certain measures related to data protection. These measures may include adopting a list of processing operations, approving accreditation criteria, determining standard data protection clauses, authorising contractual clauses, or approving corporate rules. If a matter affects more than one Member State, the Board, the Chair, or the Commission can request an opinion. The Board must issue an opinion within eight weeks, extendable by six weeks for complex matters. The supervisory authority must wait for the Board's opinion before adopting its decision and must consider the Board's opinion when finalising its decision. If the supervisory authority decides not to follow the Board's opinion, it must provide reasons, and further procedures apply."
Artifical Inellegence Act (AI Act) - Definition of 'putting into service',0.71614778,"Within the Aritifical Intelligence Act (AI Act), the Definition of putting into service means the supply of an AI system for first use directly to the user or for own use on the Union market for its intended purpose;",recital,The Artificial Intelligence Act (AI Act) introduces a term called 'putting into service.' This refers to the first time an AI system is supplied for use either directly to the user or for personal use in the Union market. The system must be used for its intended purpose.
General Data Protection Regulation (GDPR) - Article 18 Right to restriction of processing,0.716143072,"Details of Article 18 Right to restriction of processing in the General Data Protection Regulation (GDPR): 1. The data subject shall have the right to obtain from the controller restriction of processing where one of the following applies: (a) the accuracy of the personal data is contested by the data subject, for a period enabling the controller to verify the accuracy of the personal data; (b) the processing is unlawful and the data subject opposes the erasure of the personal data and requests the restriction of their use instead; (c) the controller no longer needs the personal data for the purposes of the processing, but they are required by the data subject for the establishment, exercise or defence of legal claims; (d) the data subject has objected to processing pursuant to Article 21(1) pending the verification whether the legitimate grounds of the controller override those of the data subject. 2. Where processing has been restricted under paragraph 1, such personal data shall, with the exception of storage, only be processed with the data subject's consent or for the establishment, exercise or defence of legal claims or for the protection of the rights of another natural or legal person or for reasons of important public interest of the Union or of a Member State. 3. A data subject who has obtained restriction of processing pursuant to paragraph 1 shall be informed by the controller before the restriction of processing is lifted.",article,"Under the General Data Protection Regulation (GDPR), Article 18, you have the right to limit how your personal data is used. This can happen if you question the accuracy of your data, if your data is being used unlawfully, if the data is no longer needed but you still require it for legal reasons, or if you object to your data being processed and are waiting for a resolution. If your data use is limited, it can only be used with your permission, for legal reasons, to protect others' rights, or for significant public interest. If you've requested your data use be limited, you must be informed before this restriction is lifted."
Digital Markets Act (DMA) - Article 13 Anti-circumvention,0.716142654,"Details of Article 13 Anti-circumvention in the Digital Markets Act (DMA): 1. An undertaking providing core platform services shall not segment, divide, subdivide, fragment or split those services through contractual, commercial, technical or any other means in order to circumvent the quantitative thresholds laid down in Article 3(2). No such practice of an undertaking shall prevent the Commission from designating it as a gatekeeper pursuant to Article 3(4). 2. The Commission may, when it suspects that an undertaking providing core platform services is engaged in a practice laid down in paragraph 1, require from that undertaking any information that it deems necessary to determine whether that undertaking has engaged in such a practice. 3. The gatekeeper shall ensure that the obligations of Articles 5, 6 and 7 are fully and effectively complied with. 4. The gatekeeper shall not engage in any behaviour that undermines effective compliance with the obligations of Articles 5, 6 and 7 regardless of whether that behaviour is of a contractual, commercial or technical nature, or of any other nature, or consists in the use of behavioural techniques or interface design. 5. Where consent for collecting, processing, cross-using and sharing of personal data is required to ensure compliance with this Regulation, a gatekeeper shall take the necessary steps either to enable business users to directly obtain the required consent to their processing, where that consent is required under Regulation (EU) 2016/679 or Directive 2002/ 58/EC, or to comply with Union data protection and privacy rules and principles in other ways, including by providing business users with duly anonymised data where appropriate. The gatekeeper shall not make the obtaining of that consent by the business user more burdensome than for its own services. 6. The gatekeeper shall not degrade the conditions or quality of any of the core platform services provided to business users or end users who avail themselves of the rights or choices laid down in Articles 5, 6 and 7, or make the exercise of those rights or choices unduly difficult, including by offering choices to the end-user in a non-neutral manner, or by subverting end users"" or business users' autonomy, decision-making, or free choice via the structure, design, function or manner of operation of a user interface or a part thereof. 7. Where the gatekeeper circumvents or attempts to circumvent any of the obligations in Article 5, 6, or 7 in a manner described in paragraphs 4, 5 and 6 of this Article, the Commission may open proceedings pursuant to Article 20 and adopt an implementing act referred to in Article 8(2) in order to specify the measures that the gatekeeper is to implement. 8. Paragraph 6 of this Article is without prejudice to the powers of the Commission under Articles 29, 30 and 31.",article,"The Digital Markets Act (DMA) Article 13, also known as the Anti-circumvention law, prevents large tech companies (referred to as ""gatekeepers"") from breaking up their services to avoid regulations. The law allows the Commission to investigate if they suspect a company is trying to circumvent the rules. Gatekeepers must comply with obligations set out in Articles 5, 6 and 7, and avoid any actions that might undermine this compliance. They must also ensure that user consent for data collection and processing is obtained in line with EU data protection laws. Gatekeepers cannot make it harder for business users to obtain consent than for their own services. They also can't degrade the quality of their services or make it difficult for users to exercise their rights. If a gatekeeper tries to avoid these obligations, the Commission can take action to enforce compliance. This law does not affect the Commission's existing powers."
Digital Markets Act (DMA) - Definition of business user,0.716115654,"Details of the Definition of business user in the Digital Markets Act (DMA): ""business user"" means any natural or legal person acting in a commercial or professional capacity using core platform services for the purpose of or in the course of providing goods or services to end users;",rectial,"The Digital Markets Act (DMA) introduces a term called ""business user"". This refers to any individual or company using core online platform services for business or professional reasons. These services are used to provide goods or services to customers, also known as end users."
Artifical Inellegence Act (AI Act) - Article 29,0.71601212,"Aritifical Intelligence Act (AI Act) Article 29 Obligations of users of high-risk AI systems:

1.Users of high-risk AI systems shall use such systems in accordance with the instructions of use accompanying the systems, pursuant to paragraphs 2 and 5.

2.The obligations in paragraph 1 are without prejudice to other user obligations under Union or national law and to the users discretion in organising its own resources and activities for the purpose of implementing the human oversight measures indicated by the provider.

3.Without prejudice to paragraph 1, to the extent the user exercises control over the input data, that user shall ensure that input data is relevant in view of the intended purpose of the high-risk AI system.

4.Users shall monitor the operation of the high-risk AI system on the basis of the instructions of use. When they have reasons to consider that the use in accordance with the instructions of use may result in the AI system presenting a risk within the meaning of Article 65(1) they shall inform the provider or distributor and suspend the use of the system. They shall also inform the provider or distributor when they have identified any serious incident or any malfunctioning within the meaning of Article 62 and interrupt the use of the AI system. In case the user is not able to reach the provider, Article 62 shall apply mutatis mutandis.

For users that are credit institutions regulated by Directive 2013/36/EU, the monitoring obligation set out in the first subparagraph shall be deemed to be fulfilled by complying with the rules on internal governance arrangements, processes and mechanisms pursuant to Article 74 of that Directive.

5.Users of high-risk AI systems shall keep the logs automatically generated by that high-risk AI system, to the extent such logs are under their control. The logs shall be kept for a period that is appropriate in the light of the intended purpose of the high-risk AI system and applicable legal obligations under Union or national law.

Users that are credit institutions regulated by Directive 2013/36/EU shall maintain the logs as part of the documentation concerning internal governance arrangements, processes and mechanisms pursuant to Article 74 of that Directive.

6.Users of high-risk AI systems shall use the information provided under Article 13 to comply with their obligation to carry out a data protection impact assessment under Article 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680, where applicable.",article,"The Artificial Intelligence Act (AI Act) Article 29 outlines the responsibilities of users of high-risk AI systems. Users must follow the system's usage instructions, comply with other relevant laws, and ensure the input data is appropriate for the system's purpose. They must monitor the system's operation and report any risks, serious incidents, or malfunctions to the provider or distributor. If they can't reach the provider, they should follow the process outlined in Article 62. Users must also keep logs generated by the AI system for an appropriate time period. If users are credit institutions regulated by Directive 2013/36/EU, they satisfy the monitoring requirement by complying with internal governance rules, and should maintain logs as part of their internal governance documentation. Users must use the information provided under Article 13 to comply with data protection impact assessment obligations under Regulation (EU) 2016/679 or Directive (EU) 2016/680, if applicable."
Digital Services Act (DSA) - Article 87 Exercise of the delegation,0.716002405,"Article 87 Exercise of the delegation in the Digital Services Act (DSA):  1.   The power to adopt delegated acts is conferred on the Commission subject to the conditions laid down in this Article.

2.   The delegation of power referred to in Articles 24, 33, 37, 40 and 43 shall be conferred on the Commission for five years starting from 16 November 2022. The Commission shall draw up a report in respect of the delegation of power not later than nine months before the end of the five-year period. The delegation of power shall be tacitly extended for periods of an identical duration, unless the European Parliament or the Council opposes such extension not later than three months before the end of each period.

3.   The delegation of power referred to in Articles 24, 33, 37, 40 and 43 may be revoked at any time by the European Parliament or by the Council. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force.

4.   Before adopting a delegated act, the Commission shall consult experts designated by each Member State in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making.

5.   As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council.

6.   A delegated act adopted pursuant to Articles 24, 33, 37, 40 and 43 shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.",article,"The Digital Services Act (DSA) grants the European Commission the authority to adopt delegated acts, subject to specific conditions. This authority is given for five years from November 16, 2022, and can be extended unless the European Parliament or Council objects. The Parliament or Council can revoke this power at any time, and any revocation takes effect the day after its publication in the Official Journal of the European Union. Before adopting a delegated act, the Commission must consult with experts from each Member State. Once an act is adopted, it is notified to the Parliament and Council. The act only comes into force if neither the Parliament nor the Council objects within three months of notification. This period can be extended by three months if either body initiates it."
Digital Markets Act (DMA) - Definition of search results,0.715980887,"Details of the Definition of search results in the Digital Markets Act (DMA): ""search results"" means any information in any format, including textual, graphic, vocal or other outputs, returned in response to, and related to, a search query, irrespective of whether the information returned is a paid or an unpaid result, a direct answer or any product, service or information offered in connection with the organic results, or displayed along with or partly or entirely embedded in them;",rectial,"The Digital Markets Act (DMA) defines ""search results"" as any type of information (text, images, voice, etc.) that comes up in response to a search query. This can include both paid and unpaid results, direct answers, and any product, service or information related to the search. This information can be displayed alongside, partially or fully integrated with the original search results."
Artifical Inellegence Act (AI Act) - Overview paragraph 6,0.715979457,"Aritifical Intelligence Act (AI Act) overview paragraph (6): The notion of AI system should be clearly defined to ensure legal certainty, while providing the flexibility to accommodate future technological developments. The definition should be based on the key functional characteristics of the software, in particular the ability, for a given set of human-defined objectives, to generate outputs such as content, predictions, recommendations, or decisions which influence the environment with which the system interacts, be it in a physical or digital dimension. AI systems can be designed to operate with varying levels of autonomy and be used on a stand-alone basis or as a component of a product, irrespective of whether the system is physically integrated into the product (embedded) or serve the functionality of the product without being integrated therein (non-embedded). The definition of AI system should be complemented by a list of specific techniques and approaches used for its development, which should be kept up-todate in the light of market and technologicaldevelopments through the adoption of delegated acts by the Commission to amend that list.",recital,"The Artificial Intelligence Act (AI Act) states that the term ""AI system"" needs to be clearly defined for legal purposes, but flexible enough to include future technologies. An AI system is defined by its ability to create outputs like content, predictions, or decisions that affect its environment, whether physical or digital. These systems can function with different levels of independence and can be standalone or part of another product. The definition should also include a list of techniques used to develop AI systems, which should be updated regularly to keep pace with technological advancements. This list will be updated by the Commission through the adoption of delegated acts."
General Data Protection Regulation (GDPR) - Article 43 Certification bodies,0.715949,"Details of Article 43 Certification bodies in the General Data Protection Regulation (GDPR): 1. Without prejudice to the tasks and powers of the competent supervisory authority under Articles 57 and 58, certification bodies which have an appropriate level of expertise in relation to data protection shall, after informing the supervisory authority in order to allow it to exercise its powers pursuant to point (h) of Article 58(2) where necessary, issue and renew certification. Member States shall ensure that those certification bodies are accredited by one or both of the following: (a) the supervisory authority which is competent pursuant to Article 55 or 56; (b) the national accreditation body named in accordance with Regulation (EC) No 765/2008 of the European Parliament and of the Council ( 1 ) in accordance with EN-ISO/IEC 17065/2012 and with the additional requirements established by the supervisory authority which is competent pursuant to Article 55 or 56. 2. Certification bodies referred to in paragraph 1 shall be accredited in accordance with that paragraph only where they have: (a) demonstrated their independence and expertise in relation to the subject-matter of the certification to the satisfaction of the competent supervisory authority; (b) undertaken to respect the criteria referred to in Article 42(5) and approved by the supervisory authority which is competent pursuant to Article 55 or 56 or by the Board pursuant to Article 63; (c) established procedures for the issuing, periodic review and withdrawal of data protection certification, seals and marks; (d) established procedures and structures to handle complaints about infringements of the certification or the manner in which the certification has been, or is being, implemented by the controller or processor, and to make those procedures and structures transparent to data subjects and the public; and (e) demonstrated, to the satisfaction of the competent supervisory authority, that their tasks and duties do not result in a conflict of interests. 3. The accreditation of certification bodies as referred to in paragraphs 1 and 2 of this Article shall take place on the basis of criteria approved by the supervisory authority which is competent pursuant to Article 55 or 56 or by the Board pursuant to Article 63. In the case of accreditation pursuant to point (b) of paragraph 1 of this Article, those requirements shall complement those envisaged in Regulation (EC) No 765/2008 and the technical rules that describe the methods and procedures of the certification bodies. 4. The certification bodies referred to in paragraph 1 shall be responsible for the proper assessment leading to the certification or the withdrawal of such certification without prejudice to the responsibility of the controller or processor for compliance with this Regulation. The accreditation shall be issued for a maximum period of five years and may be renewed on the same conditions provided that the certification body meets the requirements set out in this Article. 5. The certification bodies referred to in paragraph 1 shall provide the competent supervisory authorities with the reasons for granting or withdrawing the requested certification. 6. The requirements referred to in paragraph 3 of this Article and the criteria referred to in Article 42(5) shall be made public by the supervisory authority in an easily accessible form. The supervisory authorities shall also transmit those requirements and criteria to the Board. The Board shall collate all certification mechanisms and data protection seals in a register and shall make them publicly available by any appropriate means. 7. Without prejudice to Chapter VIII, the competent supervisory authority or the national accreditation body shall revoke an accreditation of a certification body pursuant to paragraph 1 of this Article where the conditions for the accreditation are not, or are no longer, met or where actions taken by a certification body infringe this Regulation. 8. The Commission shall be empowered to adopt delegated acts in accordance with Article 92 for the purpose of specifying the requirements to be taken into account for the data protection certification mechanisms referred to in Article 42(1). 9. The Commission may adopt implementing acts laying down technical standards for certification mechanisms and data protection seals and marks, and mechanisms to promote and recognise those certification mechanisms, seals and marks. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 93(2).",article,"The General Data Protection Regulation (GDPR) Article 43 sets out rules for certification bodies. These bodies, which need to have expertise in data protection, can issue and renew certifications after informing the supervisory authority. They must be accredited by either the supervisory authority or the national accreditation body. To get accredited, they must prove their independence and expertise, commit to certain criteria, establish procedures for issuing, reviewing and withdrawing certifications, handle complaints transparently, and ensure no conflict of interests. The accreditation lasts up to five years and can be renewed if the body still meets the requirements. They must inform the supervisory authorities why they granted or withdrew a certification. The requirements and criteria for accreditation will be made public. If a certification body doesn't meet the conditions or infringes the regulation, their accreditation can be revoked. The Commission can adopt acts to specify requirements for data protection certification mechanisms."
Artifical Inellegence Act (AI Act) - Context Section 1.1,0.71592629,"Aritifical Intelligence Act (AI Act) context section 1.1.Reasons for and objectives of the proposal: 

This explanatory memorandum accompanies the proposal for a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence (AI) is a fast evolving family of technologies that can bring a wide array of economic and societal benefits across the entire spectrum of industries and social activities. By improving prediction, optimising operations and resource allocation, and personalising service delivery, the use of artificial intelligence can support socially and environmentally beneficial outcomes and provide key competitive advantages to companies and the European economy. Such action is especially needed in high-impact sectors, including climate change, environment and health, the public sector, finance, mobility, home affairs and agriculture. However, the same elements and techniques that power the socio-economic benefits of AI can also bring about new risks or negative consequences for individuals or the society. In light of the speed of technological change and possible challenges, the EU is committed to strive for a balanced approach. It is in the Union interest to preserve the EUs technological leadership and to ensure that Europeans can benefit from new technologies developed and functioning according to Union values, fundamental rights and principles.

This proposal delivers on the political commitment by President von der Leyen, who announced in her political guidelines for the 2019-2024 Commission A Union that strives for more 1 , that the Commission would put forward legislation for a coordinated European approach on the human and ethical implications of AI. Following on that announcement, on 19 February 2020 the Commission published the White Paper on AI - A European approach to excellence and trust 2 . The White Paper sets out policy options on how to achieve the twin objective of promoting the uptake of AI and of addressing the risks associated with certain uses of such technology. This proposal aims to implement the second objective for the development of an ecosystem of trust by proposing a legal framework for trustworthy AI. The proposal is based on EU values and fundamental rights and aims to give people and other users the confidence to embrace AI-based solutions, while encouraging businesses to develop them. AI should be a tool for people and be a force for good in society with the ultimate aim of increasing human well-being. Rules for AI available in the Union market or otherwise affecting people in the Union should therefore be human centric, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights. Following the publication of the White Paper, the Commission launched a broad stakeholder consultation, which was met with a great interest by a large number of stakeholders who were largely supportive of regulatory intervention to address the challenges and concerns raised by the increasing use of AI.1.1.Reasons for and objectives of the proposal:

This explanatory memorandum accompanies the proposal for a Regulation laying down harmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence (AI) is a fast evolving family of technologies that can bring a wide array of economic and societal benefits across the entire spectrum of industries and social activities. By improving prediction, optimising operations and resource allocation, and personalising service delivery, the use of artificial intelligence can support socially and environmentally beneficial outcomes and provide key competitive advantages to companies and the European economy. Such action is especially needed in high-impact sectors, including climate change, environment and health, the public sector, finance, mobility, home affairs and agriculture. However, the same elements and techniques that power the socio-economic benefits of AI can also bring about new risks or negative consequences for individuals or the society. In light of the speed of technological change and possible challenges, the EU is committed to strive for a balanced approach. It is in the Union interest to preserve the EUs technological leadership and to ensure that Europeans can benefit from new technologies developed and functioning according to Union values, fundamental rights and principles.

This proposal delivers on the political commitment by President von der Leyen, who announced in her political guidelines for the 2019-2024 Commission A Union that strives for more 1 , that the Commission would put forward legislation for a coordinated European approach on the human and ethical implications of AI. Following on that announcement, on 19 February 2020 the Commission published the White Paper on AI - A European approach to excellence and trust 2 . The White Paper sets out policy options on how to achieve the twin objective of promoting the uptake of AI and of addressing the risks associated with certain uses of such technology. This proposal aims to implement the second objective for the development of an ecosystem of trust by proposing a legal framework for trustworthy AI. The proposal is based on EU values and fundamental rights and aims to give people and other users the confidence to embrace AI-based solutions, while encouraging businesses to develop them. AI should be a tool for people and be a force for good in society with the ultimate aim of increasing human well-being. Rules for AI available in the Union market or otherwise affecting people in the Union should therefore be human centric, so that people can trust that the technology is used in a way that is safe and compliant with the law, including the respect of fundamental rights. Following the publication of the White Paper, the Commission launched a broad stakeholder consultation, which was met with a great interest by a large number of stakeholders who were largely supportive of regulatory intervention to address the challenges and concerns raised by the increasing use of AI.",recital,"The Artificial Intelligence Act (AI Act) is a proposed regulation that aims to create a balanced approach to the use of AI in the European Union (EU). The Act recognizes the potential benefits of AI, such as improving prediction, optimizing operations, and personalizing service delivery, which can provide competitive advantages across various sectors. However, it also acknowledges the potential risks and negative impacts of AI on individuals and society. The Act is designed to ensure that AI technologies developed in the EU are in line with Union values, fundamental rights, and principles. The goal is to make AI a tool for people and a force for good in society, ultimately increasing human well-being. The Act also aims to build an ecosystem of trust, giving people confidence to use AI-based solutions and encouraging businesses to develop them. The Act is based on a broad consultation with stakeholders, who largely support regulatory intervention to address the challenges and concerns raised by the increasing use of AI."
Artifical Inellegence Act (AI Act) - Overview paragraph 44,0.715906143,"Aritifical Intelligence Act (AI Act) overview paragraph (44): High data quality is essential for the performance of many AI systems, especially when techniques involving the training of models are used, with a view to ensure that the high-risk AI system performs as intended and safely and it does not become the source of discrimination prohibited by Union law. High quality training, validation and testing data sets require the implementation of appropriate data governance and management practices. Training, validation and testing data sets should be sufficiently relevant, representative and free of errors and complete in view of the intended purpose of the system. They should also have the appropriate statistical properties, including as regards the persons or groups of persons on which the high-risk AI system is intended to be used. In particular, training, validation and testing data sets should take into account, to the extent required in the light of their intended purpose, the features, characteristics or elements that are particular to the specific geographical, behavioural or functional setting or context within which the AI system is intended to be used.In order to protect the right of others from the discrimination that might result from the bias in AI systems, the providers shouldbe able to process also special categories of personal data, as a matter of substantial public interest, in order to ensure the bias monitoring, detection and correction in relation to high-risk AI systems.",recital,"The Artificial Intelligence Act (AI Act) emphasizes the importance of high-quality data for AI systems, particularly those that pose high risks. The data used for training, validating, and testing these systems must be relevant, representative, error-free, complete, and statistically appropriate for the intended users or groups. It should also consider specific geographical, behavioural, or functional contexts. This is to ensure that the AI system performs safely and as expected, and doesn't cause discrimination. To prevent potential bias in AI systems, providers may need to process special categories of personal data. This is seen as a significant public interest to monitor, detect, and correct any bias in high-risk AI systems."
Artifical Inellegence Act (AI Act) - Overview paragraph 54,0.715848744,"Aritifical Intelligence Act (AI Act) overview paragraph (54): The provider should establish a sound quality management system, ensure the accomplishment of the required conformity assessment procedure, draw up the relevant documentation and establish a robust post-market monitoring system. Public authorities which put into service high-risk AI systems for their own use may adopt and implement the rules for the quality management system as part of the quality management system adopted at a national or regional level, as appropriate, taking into account the specificities of the sector and the competences and organisation of the public authority in question.",recital,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems to create a strong quality management system. This includes conducting necessary assessments, creating relevant documents, and setting up a post-use monitoring system. If public authorities use these AI systems, they can adopt these quality management rules within their existing national or regional quality management systems. This needs to consider the specifics of the sector and the public authority's competences and organization."
Artifical Inellegence Act (AI Act) - Definition of 'remote biometric identification system',0.715847194,"Within the Aritifical Intelligence Act (AI Act), the Definition of remote biometric identification system meansan AI systemfor the purpose of identifying natural persons at a distance through the comparison of a persons biometric data with the biometric data contained in a reference database, and without prior knowledge of the user of the AI system whether the person will be present and can be identified ;",recital,The Artificial Intelligence Act (AI Act) defines a 'remote biometric identification system' as an AI program that identifies individuals from a distance by comparing their biometric data (like fingerprints or facial recognition) with data stored in a reference database. This system operates without the user knowing in advance if the person can be identified or will even be present.
Artifical Inellegence Act (AI Act) - Article 73,0.715836823,"Aritifical Intelligence Act (AI Act) Article 73 Exercise of the delegation:

1.The power to adopt delegated acts is conferred on the Commission subject to the conditions laid down in this Article.

2.The delegation of power referred to in Article 4, Article 7(1), Article 11(3), Article 43(5) and (6) and Article 48(5) shall be conferred on the Commission for an indeterminate period of time from [entering into force of the Regulation].

3.The delegation of power referred to in Article 4, Article 7(1), Article 11(3), Article 43(5) and (6) and Article 48(5) may be revoked at any time by the European Parliament or by the Council. A decision of revocation shall put an end to the delegation of power specified in that decision. It shall take effect the day following that of its publication in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force.

4.As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council.

5.Any delegated act adopted pursuant to Article 4, Article 7(1), Article 11(3), Article 43(5) and (6) and Article 48(5) shall enter into force only if no objection has been expressed by either the European Parliament or the Council within a period of three months of notification of that act to the European Parliament and the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by three months at the initiative of the European Parliament or of the Council.",article,"The Artificial Intelligence Act (AI Act) Article 73 details the delegation of power to the Commission. This power, as outlined in various articles, can be given to the Commission indefinitely and can be revoked by the European Parliament or the Council at any time. If revoked, the decision takes effect the day after its publication in the Official Journal of the European Union. The validity of previously enforced acts is not affected. Upon adopting a delegated act, the Commission must notify the European Parliament and the Council. The act only comes into force if neither the Parliament nor the Council object within three months of notification, or if both inform the Commission they won't object before the three months are up. This period can be extended by three months if needed."
Artifical Inellegence Act (AI Act) - Context Section 2.1,0.715781868,"Aritifical Intelligence Act (AI Act) context section 2.1.Legal basis: 

The legal basis for the proposal is in the first place Article 114 of the Treaty on the Functioning of the European Union (TFEU), which provides for the adoption of measures to ensure the establishment and functioning of the internal market.

This proposal constitutes a core part of the EU digital single market strategy. The primary objective of this proposal is to ensure the proper functioning of the internal market by setting harmonised rules in particular on the development, placing on the Union market and the use of products and services making use of AI technologies or provided as stand-alone AI systems. Some Member States are already considering national rules to ensure that AI is safe and is developed and used in compliance with fundamental rights obligations. This will likely lead to two main problems: i) a fragmentation of the internal market on essential elements regarding in particular the requirements for the AI products and services, their marketing, their use, the liability and the supervision by public authorities, and ii) the substantial diminishment of legal certainty for both providers and users of AI systems on how existing and new rules will apply to those systems in the Union. Given the wide circulation of products and services across borders, these two problems can be best solved through EU harmonizing legislation.

Indeed, the proposal defines common mandatory requirements applicable to the design and development of certain AI systems before they are placed on the market that will be further operationalised through harmonised technical standards. The proposal also addresses the situation after AI systems have been placed on the market by harmonising the way in which ex-post controls are conducted.

In addition, considering that this proposal contains certain specific rules on the protection of individuals with regard to the processing of personal data, notably restrictions of the use of AI systems for real-time remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU.2.1.Legal basis: 

The legal basis for the proposal is in the first place Article 114 of the Treaty on the Functioning of the European Union (TFEU), which provides for the adoption of measures to ensure the establishment and functioning of the internal market.

This proposal constitutes a core part of the EU digital single market strategy. The primary objective of this proposal is to ensure the proper functioning of the internal market by setting harmonised rules in particular on the development, placing on the Union market and the use of products and services making use of AI technologies or provided as stand-alone AI systems. Some Member States are already considering national rules to ensure that AI is safe and is developed and used in compliance with fundamental rights obligations. This will likely lead to two main problems: i) a fragmentation of the internal market on essential elements regarding in particular the requirements for the AI products and services, their marketing, their use, the liability and the supervision by public authorities, and ii) the substantial diminishment of legal certainty for both providers and users of AI systems on how existing and new rules will apply to those systems in the Union. Given the wide circulation of products and services across borders, these two problems can be best solved through EU harmonizing legislation.

Indeed, the proposal defines common mandatory requirements applicable to the design and development of certain AI systems before they are placed on the market that will be further operationalised through harmonised technical standards. The proposal also addresses the situation after AI systems have been placed on the market by harmonising the way in which ex-post controls are conducted.

In addition, considering that this proposal contains certain specific rules on the protection of individuals with regard to the processing of personal data, notably restrictions of the use of AI systems for real-time remote biometric identification in publicly accessible spaces for the purpose of law enforcement, it is appropriate to base this regulation, in as far as those specific rules are concerned, on Article 16 of the TFEU.",recital,"The Artificial Intelligence Act (AI Act) is a new law that aims to regulate the development and use of AI technologies and systems in the European Union (EU). The main goal is to create uniform rules across the EU to avoid confusion and inconsistency. These rules will cover everything from the design and development of AI systems to their use and marketing. The law also aims to ensure that AI technologies are safe and respect fundamental rights. It addresses potential issues such as the fragmentation of the internal market and the lack of legal clarity for AI providers and users. The law also includes specific rules for the protection of personal data, including restrictions on the use of AI for real-time remote biometric identification in public spaces for law enforcement purposes."
Digital Services Act (DSA) - Contextual paragraph (77),0.715730548,"Details of the contextual paragraph (77) of the Digital Services Act (DSA): In order to determine the reach of a given online platform or online search engine, it is necessary to establish the average number of active recipients of each service individually. Accordingly, the number of average monthly active recipients of an online platform should reflect all the recipients actually engaging with the service at least once in a given period of time, by being exposed to information disseminated on the online interface of the online platform, such as viewing it or listening to it, or by providing information, such as traders on an online platforms allowing consumers to conclude distance contracts with traders.
For the purposes of this Regulation, engagement is not limited to interacting with information by clicking on, commenting, linking, sharing, purchasing or carrying out transactions on an online platform. Consequently, the concept of active recipient of the service does not necessarily coincide with that of a registered user of a service. As regards online search engines, the concept of active recipients of the service should cover those who view information on their online interface, but not, for example, the owners of the websites indexed by an online search engine, as they do not actively engage with the service. The number of active recipients of a service should include all unique recipients of the service that engage with the specific service. To this effect, a recipient of the service that uses different online interfaces, such as websites or applications, including where the services are accessed through different uniform resource locators (URLs) or domain names, should, where possible, be counted only once. However, the concept of active recipient of the service should not include incidental use of the service by recipients of other providers of intermediary services that indirectly make available information hosted by the provider of online platforms through linking or indexing by a provider of online search engine. Further, this Regulation does not require providers of online platforms or of online search engines to perform specific tracking of individuals online. Where such providers are able to discount automated users such as bots or scrapers without further processing of personal data and tracking, they may do so. The determination of the number of active recipients of the service can be impacted by market and technical developments and therefore the Commission should be empowered to supplement the provisions of this Regulation by adopting delegated acts laying down the methodology to determine the active recipients of an online platform or of an online search engine, where necessary, reflecting the nature of the service and the way recipients of the service interact with it.",recital,"The Digital Services Act (DSA) requires online platforms and search engines to calculate the average number of active users they have each month. An active user is defined as anyone who interacts with the service, such as viewing, listening, or providing information. This doesn't only include registered users, but anyone who engages with the platform. For search engines, active users are those who view information, not website owners indexed by the search engine. If a user accesses the service through different interfaces (websites, apps, URLs, domain names), they should be counted as one user. However, incidental use of the service by users of other intermediary services doesn't count. The DSA doesn't require tracking of individuals online and automated users like bots can be excluded. The method for determining active users may change due to market and technical developments."
General Data Protection Regulation (GDPR) - Article 71 Reports,0.715658605,"Details of Article 71 Reports in the General Data Protection Regulation (GDPR): 1. The Board shall draw up an annual report regarding the protection of natural persons with regard to processing in the Union and, where relevant, in third countries and international organisations. The report shall be made public and be transmitted to the European Parliament, to the Council and to the Commission. 2. The annual report shall include a review of the practical application of the guidelines, recommendations and best practices referred to in point (l) of Article 70(1) as well as of the binding decisions referred to in Article 65.",article,"The General Data Protection Regulation (GDPR) requires the Board to create a yearly report about how people's personal data is being handled within the Union, and potentially in third countries and international organisations. This report, which will be made public and sent to the European Parliament, Council, and Commission, will review how well guidelines, recommendations, and best practices are being applied, as well as any binding decisions made under the GDPR."
Artifical Inellegence Act (AI Act) - Article 46,0.715602875,"Aritifical Intelligence Act (AI Act) Article 46 Information obligations of notified bodies:

1.Notified bodies shall inform the notifying authority of the following:

(a)any Union technical documentation assessment certificates, any supplements to those certificates, quality management system approvals issued in accordance with the requirements of Annex VII;

(b)any refusal, restriction, suspension or withdrawal of a Union technical documentation assessment certificate or a quality management system approval issued in accordance with the requirements of Annex VII;

(c)any circumstances affecting the scope of or conditions for notification;

(d)any request for information which they have received from market surveillance authorities regarding conformity assessment activities;

(e)on request, conformity assessment activities performed within the scope of their notification and any other activity performed, including cross-border activities and subcontracting.

2.Each notified body shall inform the other notified bodies of:

(a)quality management system approvals which it has refused, suspended or withdrawn, and, upon request, of quality system approvals which it has issued;

(b)EU technical documentation assessment certificates or any supplements thereto which it has refused, withdrawn, suspended or otherwise restricted, and, upon request, of the certificates and/or supplements thereto which it has issued.

3.Each notified body shall provide the other notified bodies carrying out similar conformity assessment activities covering the same artificial intelligence technologies with relevant information on issues relating to negative and, on request, positive conformity assessment results.",article,"The Artificial Intelligence Act (AI Act) Article 46 requires notified bodies (organizations that assess the conformity of certain products before being placed on the market) to share certain information with the notifying authority and other notified bodies. This includes details about any issued, refused, or altered certificates or approvals related to technical documentation or quality management systems. They must also inform about any changes affecting their notification scope or conditions and respond to information requests from market surveillance authorities. Furthermore, they are required to share information about any negative (and, when asked, positive) assessment results with other bodies that carry out similar assessments for the same AI technologies."
Artifical Inellegence Act (AI Act) - Article 27,0.71560204,"Aritifical Intelligence Act (AI Act) Article 27 Obligations of distributors:

1.Before making a high-risk AI system available on the market, distributors shall verify that the high-risk AI system bears the required CE conformity marking, that it is accompanied by the required documentation and instruction of use, and that the provider and the importer of the system, as applicable, have complied with the obligations set out in this Regulation.

2.Where a distributor considers or has reason to consider that a high-risk AI system is not in conformity with the requirements set out in Chapter 2 of this Title, it shall not make the high-risk AI system available on the market until that system has been brought into conformity with those requirements. Furthermore, where the system presents a risk within the meaning of Article 65(1), the distributor shall inform the provider or the importer of the system, as applicable, to that effect.

3.Distributors shall ensure that, while a high-risk AI system is under their responsibility, where applicable, storage or transport conditions do not jeopardise the compliance of the system with the requirements set out in Chapter 2 of this Title.

4.A distributor that considers or has reason to consider that a high-risk AI system which it has made available on the market is not in conformity with the requirements set out in Chapter 2 of this Title shall take the corrective actions necessary to bring that system into conformity with those requirements, to withdraw it or recall it or shall ensure that the provider, the importer or any relevant operator, as appropriate, takes those corrective actions. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the distributor shall immediately inform the national competent authorities of the Member States in which it has made the product available to that effect, giving details, in particular, of the non-compliance and of any corrective actions taken.

5.Upon a reasoned request from a national competent authority, distributors of high-risk AI systems shall provide that authority with all the information and documentation necessary to demonstrate the conformity of a high-risk system with the requirements set out in Chapter 2 of this Title. Distributors shall also cooperate with that national competent authority on any action taken by that authority.",article,"The Artificial Intelligence Act (AI Act) requires distributors of high-risk AI systems to ensure these systems meet certain standards before they are sold. These systems must have the necessary CE conformity marking and documentation. If a distributor thinks a system doesn't meet the required standards, they must not sell it until it does. If a system is found to be non-compliant after being sold, the distributor must correct the issue, withdraw the system, or inform the provider or importer. If a system poses a risk, the distributor must inform the relevant national authorities. Distributors must also provide any requested information to national authorities to prove a system's compliance with the law."
Artifical Inellegence Act (AI Act) - Article 26,0.715571,"Aritifical Intelligence Act (AI Act) Article 26 Obligations of importers:

1.Before placing a high-risk AI system on the market, importers of such system shall ensure that:

(a)the appropriate conformity assessment procedure has been carried out by the provider of that AI system

(b)the provider has drawn up the technical documentation in accordance with Annex IV;

(c)the system bears the required conformity marking and is accompanied by the required documentation and instructions of use.

2.Where an importer considers or has reason to consider that a high-risk AI system is not in conformity with this Regulation, it shall not place that system on the market until that AI system has been brought into conformity. Where the high-risk AI system presents a risk within the meaning of Article 65(1), the importer shall inform the provider of the AI system and the market surveillance authorities to that effect.

3.Importers shall indicate their name, registered trade name or registered trade mark, and the address at which they can be contacted on the high-risk AI system or, where that is not possible, on its packaging or its accompanying documentation, as applicable.

4.Importers shall ensure that, while a high-risk AI system is under their responsibility, where applicable, storage or transport conditions do not jeopardise its compliance with the requirements set out in Chapter 2 of this Title.

5.Importers shall provide national competent authorities, upon a reasoned request, with all necessary information and documentation to demonstrate the conformity of a high-risk AI system with the requirements set out in Chapter 2 of this Title in a language which can be easily understood by that national competent authority, including access to the logs automatically generated by the high-risk AI system to the extent such logs are under the control of the provider by virtue of a contractual arrangement with the user or otherwise by law. They shall also cooperate with those authorities on any action national competent authority takes in relation to that system.",article,"The Artificial Intelligence Act (AI Act) sets new rules for importers of high-risk AI systems. Before selling these systems, importers must ensure that the provider has properly tested the system, prepared the necessary technical documents, and included the correct markings and instructions. If an importer thinks a system doesn't meet these standards, they can't sell it until it does. If the system poses a risk, the importer must inform the provider and market authorities. Importers must also label the system with their name and contact information. They have to make sure that storage or transport doesn't affect the system's compliance with the law. If asked by national authorities, importers must provide information and documents showing the system meets the law's requirements. They must also cooperate with any actions these authorities take regarding the system."
Digital Services Act (DSA) - Article 49 Competent authorities and Digital Services Coordinators,0.715542376,"Article 49 Competent authorities and Digital Services Coordinators in the Digital Services Act (DSA):  1.   Member States shall designate one or more competent authorities to be responsible for the supervision of providers of intermediary services and enforcement of this Regulation ('competent authorities').

2.   Member States shall designate one of the competent authorities as their Digital Services Coordinator. The Digital Services Coordinator shall be responsible for all matters relating to supervision and enforcement of this Regulation in that Member State, unless the Member State concerned has assigned certain specific tasks or sectors to other competent authorities. The Digital Services Coordinator shall in any event be responsible for ensuring coordination at national level in respect of those matters and for contributing to the effective and consistent supervision and enforcement of this Regulation throughout the Union.

For that purpose, Digital Services Coordinators shall cooperate with each other, other national competent authorities, the Board and the Commission, without prejudice to the possibility for Member States to provide for cooperation mechanisms and regular exchanges of views between the Digital Services Coordinator and other national authorities where relevant for the performance of their respective tasks.

Where a Member State designates one or more competent authorities in addition to the Digital Services Coordinator, it shall ensure that the respective tasks of those authorities and of the Digital Services Coordinator are clearly defined and that they cooperate closely and effectively when performing their tasks.

3.   Member States shall designate the Digital Services Coordinators by 17 February 2024.

Member States shall make publicly available, and communicate to the Commission and the Board, the name of their competent authority designated as Digital Services Coordinator and information on how it can be contacted. The Member State concerned shall communicate to the Commission and the Board the name of the other competent authorities referred to in paragraph 2, as well as their respective tasks.

4.   The provisions applicable to Digital Services Coordinators set out in Articles 50, 51 and 56 shall also apply to any other competent authorities that the Member States designate pursuant to paragraph 1 of this Article.",article,"The Digital Services Act (DSA) requires each EU member state to appoint one or more authorities to supervise online service providers and enforce the DSA. Each state must also assign a Digital Services Coordinator to oversee all DSA-related matters, unless specific tasks are allocated to other authorities. This coordinator will also ensure national coordination and contribute to consistent enforcement of the DSA across the EU. They will cooperate with other national authorities, the Board, and the Commission. If a state appoints additional authorities, their roles must be clearly defined and they must cooperate effectively. All Digital Services Coordinators must be appointed by 17 February 2024, and their contact details made public. The same rules that apply to Digital Services Coordinators also apply to any other designated authorities."
Artifical Inellegence Act (AI Act) - Definition of 'market surveillance authority',0.715538681,"Within the Aritifical Intelligence Act (AI Act), the Definition of market surveillance authority means the national authority carrying out the activities and taking the measures pursuant to Regulation (EU) 2019/1020;",recital,"The Artificial Intelligence Act (AI Act) defines 'market surveillance authority' as a national organization that conducts activities and implements measures according to the EU Regulation 2019/1020. In simpler terms, it's the government body that monitors and regulates the market, specifically in relation to artificial intelligence, based on the rules set out in the 2019 EU regulation."
General Data Protection Regulation (GDPR) - Article 68 European Data Protection Board,0.715532482,"Details of Article 68 European Data Protection Board in the General Data Protection Regulation (GDPR): 1. The European Data Protection Board (the Board) is hereby established as a body of the Union and shall have legal personality. 2. The Board shall be represented by its Chair. 3. The Board shall be composed of the head of one supervisory authority of each Member State and of the European Data Protection Supervisor, or their respective representatives. 4. Where in a Member State more than one supervisory authority is responsible for monitoring the application of the provisions pursuant to this Regulation, a joint representative shall be appointed in accordance with that Member State's law. 5. The Commission shall have the right to participate in the activities and meetings of the Board without voting right. The Commission shall designate a representative. The Chair of the Board shall communicate to the Commission the activities of the Board. 6. In the cases referred to in Article 65, the European Data Protection Supervisor shall have voting rights only on decisions which concern principles and rules applicable to the Union institutions, bodies, offices and agencies which correspond in substance to those of this Regulation.",article,"Article 68 of the General Data Protection Regulation (GDPR) establishes the European Data Protection Board (the Board). This body, which has legal status, is made up of a representative from each EU member state's data protection authority. If a member state has multiple authorities, they must appoint a joint representative. The Board is represented by its Chair. The European Commission can participate in the Board's activities and meetings but doesn't have voting rights. The European Data Protection Supervisor can only vote on decisions affecting EU institutions. The Chair must keep the Commission informed of the Board's activities."
Artifical Inellegence Act (AI Act) - Article 21,0.715453207,"Aritifical Intelligence Act (AI Act) Article 21 Corrective actions:

Providers of high-risk AI systems which consider or have reason to consider that a high-risk AI system which they have placed on the market or put into service is not in conformity with this Regulation shall immediately take the necessary corrective actions to bring that system into conformity, to withdraw it or to recall it, as appropriate. They shall inform the distributors of the high-risk AI system in question and, where applicable, the authorised representative and importers accordingly.",article,"The Artificial Intelligence Act (AI Act) Article 21 states that if companies providing high-risk AI systems think their system doesn't comply with this law, they must immediately fix it, withdraw it, or recall it. They also need to inform any distributors, authorized representatives, and importers about the issue and their actions."
Artifical Inellegence Act (AI Act) - Definition of 'user',0.715382457,"Within the Aritifical Intelligence Act (AI Act), the Definition of user means any natural or legal person, public authority, agency or other body using an AI system under its authority, except where the AI system is used in the course of a personal non-professional activity;",recital,"The Artificial Intelligence Act (AI Act) defines a 'user' as any individual, company, government body, or other organization that uses an AI system under its control. However, this does not include anyone using an AI system for personal, non-work-related activities."
Digital Markets Act (DMA) - Definition of payment service,0.715363562,"Details of the Definition of payment service in the Digital Markets Act (DMA): ""payment service"" means a payment service as defined in Article 4, point (3) of Directive (EU) 2015/2366;",rectial,"The Digital Markets Act (DMA) defines a ""payment service"" based on the specifications in Article 4, point (3) of Directive (EU) 2015/2366. Essentially, this law is clarifying what is meant by the term ""payment service"" in the context of digital markets. The specifics of this definition can be found in the referenced EU directive."
General Data Protection Regulation (GDPR) - Article 98 Review of other Union legal acts on data protection,0.715360761,"Details of Article 98 Review of other Union legal acts on data protection in the General Data Protection Regulation (GDPR): The Commission shall, if appropriate, submit legislative proposals with a view to amending other Union legal acts on the protection of personal data, in order to ensure uniform and consistent protection of natural persons with regard to processing. This shall in particular concern the rules relating to the protection of natural persons with regard to processing by Union institutions, bodies, offices and agencies and on the free movement of such data.",article,"The General Data Protection Regulation (GDPR) Article 98 states that the Commission may propose changes to other Union laws related to personal data protection. The aim is to provide consistent and uniform protection for individuals when their data is processed. This is particularly relevant to rules about how Union institutions, bodies, offices, and agencies handle personal data and how such data can be freely moved."
California Consumer Privacy Act Regulations (CCPA) - Article 3. Business Practices for Handling Consumer Requests -  999.31 Methods for Submitting Requests to Know and Requests to Delete,0.715348721,"Details of Article 3. Business Practices for Handling Consumer Requests -  999.31 Methods for Submitting Requests to Know and Requests to Delete in the California Consumer Privacy Act Regulations (CCPA): (a) A business that operates exclusively online and has a direct relationship with a consumer from whom it collects personal information shall only be required to provide an email address for submitting requests to know. All other businesses shall provide two or more designated methods for submitting requests to know, including, at a minimum, a toll-free telephone number. Other acceptable methods for submitting these requests include, but are not limited to, a designated email address, a form submitted in person, and a form submitted through the mail. (b) A business shall provide two or more designated methods for submitting requests to delete. Acceptable methods for submitting these requests include, but are not limited to, a toll-free phone number, a link or form available online through a businesss website, a designated email address, a form submitted in person, and a form submitted through the mail. (c) A business shall consider the methods by which it primarily interacts with consumers when determining which methods to provide for submitting requests to know and requests to delete. If the business interacts with consumers in person, the business shall consider providing an in-person method such as a printed form the consumer can directly submit or send by mail, a tablet or computer portal that allows the consumer to complete and submit an online form, or a telephone with which the consumer can call the businesss toll-free number. (d) A business may use a two-step process for online requests to delete where the consumer must first, submit the request to delete and then second, separately confirm that they want their personal information deleted. (e) If a consumer submits a request in a manner that is not one of the designated methods of submission, or is deficient in some manner unrelated to the verification process, the business shall either: (1) Treat the request as if it had been submitted in accordance with the businesss designated manner, or (2) Provide the consumer with information on how to submit the request or remedy any deficiencies with the request, if applicable. Note: Authority cited: Section 1798.185, Civil Code. Reference: Sections 1798.100, 1798.105, 1798.110, 1798.115, 1798.130, 1798.140 and 1798.185, Civil Code.",article,"The California Consumer Privacy Act (CCPA) has introduced new rules for businesses regarding consumer requests to access or delete their personal information. Online-only businesses need to provide an email address for these requests. Other businesses must offer at least two methods, including a toll-free number. Other options could be a designated email, in-person form, or mailed form. Businesses should consider how they mainly interact with customers when deciding which methods to provide. For online deletion requests, a two-step process is allowed, where consumers first request deletion, then confirm it. If a request is made in a non-designated way or is incomplete, businesses must either treat it as valid or guide the consumer on how to correct it."
Artifical Inellegence Act (AI Act) - Article 28,0.715333,"Aritifical Intelligence Act (AI Act) Article 28 Obligations of distributors, importers, users or any other third-party:

1.Any distributor, importer, user or other third-party shall be considered a provider for the purposes of this Regulation and shall be subject to the obligations of the provider under Article 16, in any of the following circumstances:

(a)they place on the market or put into service a high-risk AI system under their name or trademark;

(b)they modify the intended purpose of a high-risk AI system already placed on the market or put into service;

(c)they make a substantial modification to the high-risk AI system.

2.Where the circumstances referred to in paragraph 1, point (b) or (c), occur, the provider that initially placed the high-risk AI system on the market or put it into service shall no longer be considered a provider for the purposes of this Regulation.",article,"The Artificial Intelligence Act (AI Act) stipulates that any distributor, importer, user, or third-party becomes a provider if they market or use a high-risk AI system under their name, change its intended purpose, or significantly modify it. As a provider, they must follow the obligations outlined in Article 16. If the intended purpose of the AI system is changed or it's significantly modified, the original provider is no longer considered a provider under this law."
California Consumer Privacy Act Regulations (CCPA) - Definition of Notice of right to opt-out,0.715252578,Details of Definition of Notice of right to opt-out in the California Consumer Privacy Act Regulations (CCPA): Notice of right to opt-out means the notice given by a business informing consumers of their right to opt-out of the sale of their personal information as required by Civil Code sections 1798.120 and 1798.135 and specified in these regulations.,recital,"The California Consumer Privacy Act Regulations (CCPA) includes a provision called ""Notice of right to opt-out."" This means that businesses are required to inform consumers that they have the right to choose not to have their personal information sold. This is in accordance with sections 1798.120 and 1798.135 of the Civil Code. The specifics of this requirement are detailed in the CCPA regulations."
Digital Services Act (DSA) - Definition of 'active recipient of an online platform',0.715209484,Definition of 'active recipient of an online platform' in the Digital Services Act (DSA): a recipient of the service that has engaged with an online platform by either requesting the online platform to host information or being exposed to information hosted by the online platform and disseminated through its online interface.,recital,"The Digital Services Act (DSA) introduces a term called 'active recipient of an online platform'. This refers to anyone who uses an online platform in two specific ways. First, if you ask the platform to host (store and display) your information. Second, if you view or interact with information that's already hosted on the platform. So, basically, if you're using the platform to share or access information, you're considered an 'active recipient' under this law."
General Data Protection Regulation (GDPR) - Article 28 Processor,0.715188086,"Details of Article 28 Processor in the General Data Protection Regulation (GDPR): 1. Where processing is to be carried out on behalf of a controller, the controller shall use only processors providing sufficient guarantees to implement appropriate technical and organisational measures in such a manner that processing will meet the requirements of this Regulation and ensure the protection of the rights of the data subject. 2. The processor shall not engage another processor without prior specific or general written authorisation of the controller. In the case of general written authorisation, the processor shall inform the controller of any intended changes concerning the addition or replacement of other processors, thereby giving the controller the opportunity to object to such changes. 3. Processing by a processor shall be governed by a contract or other legal act under Union or Member State law, that is binding on the processor with regard to the controller and that sets out the subject-matter and duration of the processing, the nature and purpose of the processing, the type of personal data and categories of data subjects and the obligations and rights of the controller. That contract or other legal act shall stipulate, in particular, that the processor: (a) processes the personal data only on documented instructions from the controller, including with regard to transfers of personal data to a third country or an international organisation, unless required to do so by Union or Member State law to which the processor is subject; in such a case, the processor shall inform the controller of that legal requirement before processing, unless that law prohibits such information on important grounds of public interest; (b) ensures that persons authorised to process the personal data have committed themselves to confidentiality or are under an appropriate statutory obligation of confidentiality; (c) takes all measures required pursuant to Article 32; (d) respects the conditions referred to in paragraphs 2 and 4 for engaging another processor; (e) taking into account the nature of the processing, assists the controller by appropriate technical and organisational measures, insofar as this is possible, for the fulfilment of the controller's obligation to respond to requests for exercising the data subject's rights laid down in Chapter III; (f) assists the controller in ensuring compliance with the obligations pursuant to Articles 32 to 36 taking into account the nature of processing and the information available to the processor; (g) at the choice of the controller, deletes or returns all the personal data to the controller after the end of the provision of services relating to processing, and deletes existing copies unless Union or Member State law requires storage of the personal data; (h) makes available to the controller all information necessary to demonstrate compliance with the obligations laid down in this Article and allow for and contribute to audits, including inspections, conducted by the controller or another auditor mandated by the controller. With regard to point (h) of the first subparagraph, the processor shall immediately inform the controller if, in its opinion, an instruction infringes this Regulation or other Union or Member State data protection provisions. 4. Where a processor engages another processor for carrying out specific processing activities on behalf of the controller, the same data protection obligations as set out in the contract or other legal act between the controller and the processor as referred to in paragraph 3 shall be imposed on that other processor by way of a contract or other legal act under Union or Member State law, in particular providing sufficient guarantees to implement appropriate technical and organisational measures in such a manner that the processing will meet the requirements of this Regulation. Where that other processor fails to fulfil its data protection obligations, the initial processor shall remain fully liable to the controller for the performance of that other processor's obligations. 5. Adherence of a processor to an approved code of conduct as referred to in Article 40 or an approved certification mechanism as referred to in Article 42 may be used as an element by which to demonstrate sufficient guarantees as referred to in paragraphs 1 and 4 of this Article. 6. Without prejudice to an individual contract between the controller and the processor, the contract or the other legal act referred to in paragraphs 3 and 4 of this Article may be based, in whole or in part, on standard contractual clauses referred to in paragraphs 7 and 8 of this Article, including when they are part of a certification granted to the controller or processor pursuant to Articles 42 and 43. 7. The Commission may lay down standard contractual clauses for the matters referred to in paragraph 3 and 4 of this Article and in accordance with the examination procedure referred to in Article 93(2). 8. A supervisory authority may adopt standard contractual clauses for the matters referred to in paragraph 3 and 4 of this Article and in accordance with the consistency mechanism referred to in Article 63. 9. The contract or the other legal act referred to in paragraphs 3 and 4 shall be in writing, including in electronic form. 10. Without prejudice to Articles 82, 83 and 84, if a processor infringes this Regulation by determining the purposes and means of processing, the processor shall be considered to be a controller in respect of that processing",article,"Under the General Data Protection Regulation (GDPR), a company (the controller) can only use data processors that provide enough security measures to protect the rights of the individual whose data is being processed. The processor must have written permission from the controller before using another processor and must inform the controller of any changes. The relationship between the controller and the processor must be governed by a contract that outlines the specifics of the data processing and ensures the processor only uses the data as instructed by the controller. If the processor uses another processor, the same data protection obligations apply. The processor must also assist the controller in complying with GDPR regulations. If the processor fails to meet these requirements, they may be considered a controller and could face penalties under the GDPR."
Artifical Inellegence Act (AI Act) - Definition of 'law enforcement',0.715177536,"Within the Aritifical Intelligence Act (AI Act), the Definition of law enforcement means activities carried out by law enforcement authorities for the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security;",recital,"The Artificial Intelligence Act (AI Act) defines 'law enforcement' as the actions taken by law enforcement authorities to prevent, investigate, detect, or prosecute criminal activities. This also includes executing criminal penalties and taking measures to protect against and prevent threats to public safety."
General Data Protection Regulation (GDPR) - Article 70 Tasks of the Board,0.715127587,"Details of Article 70 Tasks of the Board in the General Data Protection Regulation (GDPR): 1. The Board shall ensure the consistent application of this Regulation. To that end, the Board shall, on its own initiative or, where relevant, at the request of the Commission, in particular: (a) monitor and ensure the correct application of this Regulation in the cases provided for in Articles 64 and 65 without prejudice to the tasks of national supervisory authorities; (b) advise the Commission on any issue related to the protection of personal data in the Union, including on any proposed amendment of this Regulation; (c) advise the Commission on the format and procedures for the exchange of information between controllers, processors and supervisory authorities for binding corporate rules; (d) issue guidelines, recommendations, and best practices on procedures for erasing links, copies or replications of personal data from publicly available communication services as referred to in Article 17(2); (e) examine, on its own initiative, on request of one of its members or on request of the Commission, any question covering the application of this Regulation and issue guidelines, recommendations and best practices in order to encourage consistent application of this Regulation; (f) issue guidelines, recommendations and best practices in accordance with point (e) of this paragraph for further specifying the criteria and conditions for decisions based on profiling pursuant to Article 22(2); (g) issue guidelines, recommendations and best practices in accordance with point (e) of this paragraph for establishing the personal data breaches and determining the undue delay referred to in Article 33(1) and (2) and for the particular circumstances in which a controller or a processor is required to notify the personal data breach; (h) issue guidelines, recommendations and best practices in accordance with point (e) of this paragraph as to the circumstances in which a personal data breach is likely to result in a high risk to the rights and freedoms of the natural persons referred to in Article 34(1). (i) issue guidelines, recommendations and best practices in accordance with point (e) of this paragraph for the purpose of further specifying the criteria and requirements for personal data transfers based on binding corporate rules adhered to by controllers and binding corporate rules adhered to by processors and on further necessary requirements to ensure the protection of personal data of the data subjects concerned referred to in Article 47; (j) issue guidelines, recommendations and best practices in accordance with point (e) of this paragraph for the purpose of further specifying the criteria and requirements for the personal data transfers on the basis of Article 49(1); (k) draw up guidelines for supervisory authorities concerning the application of measures referred to in Article 58(1), (2) and (3) and the setting of administrative fines pursuant to Article 83; (l) review the practical application of the guidelines, recommendations and best practices referred to in points (e) and (f); (m) issue guidelines, recommendations and best practices in accordance with point (e) of this paragraph for establishing common procedures for reporting by natural persons of infringements of this Regulation pursuant to Article 54(2); (n) encourage the drawing-up of codes of conduct and the establishment of data protection certification mechanisms and data protection seals and marks pursuant to Articles 40 and 42; (o) carry out the accreditation of certification bodies and its periodic review pursuant to Article 43 and maintain a public register of accredited bodies pursuant to Article 43(6) and of the accredited controllers or processors established in third countries pursuant to Article 42(7); (p) specify the requirements referred to in Article 43(3) with a view to the accreditation of certification bodies under Article 42; (q) provide the Commission with an opinion on the certification requirements referred to in Article 43(8); (r) provide the Commission with an opinion on the icons referred to in Article 12(7); (s) provide the Commission with an opinion for the assessment of the adequacy of the level of protection in a third country or international organisation, including for the assessment whether a third country, a territory or one or more specified sectors within that third country, or an international organisation no longer ensures an adequate level of protection. To that end, the Commission shall provide the Board with all necessary documentation, including correspondence with the government of the third country, with regard to that third country, territory or specified sector, or with the international organisation. (t) issue opinions on draft decisions of supervisory authorities pursuant to the consistency mechanism referred to in Article 64(1), on matters submitted pursuant to Article 64(2) and to issue binding decisions pursuant to Article 65, including in cases referred to in Article 66; (u) promote the cooperation and the effective bilateral and multilateral exchange of information and best practices between the supervisory authorities; (v) promote common training programmes and facilitate personnel exchanges between the supervisory authorities and, where appropriate, with the supervisory authorities of third countries or with international organisations; (w) promote the exchange of knowledge and documentation on data protection legislation and practice with data protection supervisory authorities worldwide. (x) issue opinions on codes of conduct drawn up at Union level pursuant to Article 40(9); and (y) maintain a publicly accessible electronic register of decisions taken by supervisory authorities and courts on issues handled in the consistency mechanism. 2. Where the Commission requests advice from the Board, it may indicate a time limit, taking into account the urgency of the matter. 3. The Board shall forward its opinions, guidelines, recommendations, and best practices to the Commission and to the committee referred to in Article 93 and make them public. 4. The Board shall, where appropriate, consult interested parties and give them the opportunity to comment within a reasonable period. The Board shall, without prejudice to Article 76, make the results of the consultation procedure publicly available.",article,"The General Data Protection Regulation (GDPR) Article 70 outlines the responsibilities of the Board, which is tasked with ensuring the consistent application of the GDPR. The Board's duties include monitoring and ensuring the correct application of the GDPR, advising the Commission on issues related to personal data protection, and issuing guidelines and recommendations on various aspects of data protection. This includes procedures for erasing personal data, criteria for decisions based on profiling, and requirements for personal data transfers. The Board also encourages the creation of codes of conduct and data protection certification mechanisms, reviews the application of guidelines, and promotes cooperation and information exchange between supervisory authorities. The Board must make its opinions, guidelines, and recommendations public, and may consult interested parties for their input."
Digital Services Act (DSA) - Article 16 Notice and action mechanisms,0.715057969,"Article 16 Notice and action mechanisms in the Digital Services Act (DSA):  1.   Providers of hosting services shall put mechanisms in place to allow any individual or entity to notify them of the presence on their service of specific items of information that the individual or entity considers to be illegal content. Those mechanisms shall be easy to access and user-friendly, and shall allow for the submission of notices exclusively by electronic means.
2.   The mechanisms referred to in paragraph 1 shall be such as to facilitate the submission of sufficiently precise and adequately substantiated notices. To that end, the providers of hosting services shall take the necessary measures to enable and to facilitate the submission of notices containing all of the following elements:
(a) a sufficiently substantiated explanation of the reasons why the individual or entity alleges the information in question to be illegal content;
(b) a clear indication of the exact electronic location of that information, such as the exact URL or URLs, and, where necessary, additional information enabling the identification of the illegal content adapted to the type of content and to the specific type of hosting service;
(c) the name and email address of the individual or entity submitting the notice, except in the case of information considered to involve one of the offences referred to in Articles 3 to 7 of Directive 2011/93/EU;
(d) a statement confirming the bona fide belief of the individual or entity submitting the notice that the information and allegations contained therein are accurate and complete.
3.   Notices referred to in this Article shall be considered to give rise to actual knowledge or awareness for the purposes of Article 6 in respect of the specific item of information concerned where they allow a diligent provider of hosting services to identify the illegality of the relevant activity or information without a detailed legal examination.
4.   Where the notice contains the electronic contact information of the individual or entity that submitted it, the provider of hosting services shall, without undue delay, send a confirmation of receipt of the notice to that individual or entity.
5.   The provider shall also, without undue delay, notify that individual or entity of its decision in respect of the information to which the notice relates, providing information on the possibilities for redress in respect of that decision.
6.   Providers of hosting services shall process any notices that they receive under the mechanisms referred to in paragraph 1 and take their decisions in respect of the information to which the notices relate, in a timely, diligent, non-arbitrary and objective manner. Where they use automated means for that processing or decision-making, they shall include information on such use in the notification referred to in paragraph 5.",article,"The Digital Services Act (DSA) requires online hosting providers to establish easy-to-use systems for users to report illegal content. These systems must allow for electronic submissions detailing why the user believes the content is illegal, the exact location of the content (like a URL), and the user's contact info, unless the report involves certain offenses. The hosting provider must promptly acknowledge receipt of the report and inform the user of any decisions made about the reported content, including options for contesting the decision. Hosting providers must handle these reports objectively and promptly. If they use automated systems to process reports, they must disclose this. The DSA considers a report as giving the hosting provider knowledge of the illegal content."
Digital Markets Act (DMA) - Article 54 Entry into force and application,0.71503818,"Details of Article 54 Entry into force and application in the Digital Markets Act (DMA): This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union. It shall apply from 2 May 2023. However, Article 3(6) and (7) and Articles 40, 46, 47, 48, 49 and 50 shall apply from 1 November 2022 and Article 42 and Article 43 shall apply from 25 June 2023. Nevertheless, if the date of 25 June 2023 precedes the date of application referred to in the second paragraph of this Article, the application of Article 42 and Article 43 shall be postponed until the date of application referred to in the second paragraph of this Article.",article,"The Digital Markets Act (DMA) will officially become law 20 days after it's published in the Official Journal of the European Union. It will start to be enforced from May 2, 2023. However, some parts of it, specifically Article 3(6) and (7) and Articles 40, 46, 47, 48, 49, and 50, will be applied earlier, from November 1, 2022. Additionally, Article 42 and Article 43 will be applied from June 25, 2023. If for some reason June 25, 2023, comes before the overall application date mentioned earlier, the enforcement of Article 42 and 43 will be delayed until the overall application date."
Artifical Inellegence Act (AI Act) - Overview paragraph 55,0.715008259,"Aritifical Intelligence Act (AI Act) overview paragraph (55): Where a high-risk AI system that is a safety component of a product which is covered by a relevant New Legislative Framework sectorial legislation is not placed on the market or put into service independently from the product, the manufacturer of the final product as defined under the relevant New Legislative Framework legislation should comply with the obligations of the provider established in this Regulation and notably ensure that the AI system embedded in the final product complies with the requirements of this Regulation.",recital,"The Artificial Intelligence Act (AI Act) states that if a high-risk AI system is part of a product covered by new legislative rules, and it's not sold or used separately from the product, the product's manufacturer must meet the provider's responsibilities outlined in this law. Importantly, the manufacturer must ensure that the AI system within the product meets the requirements of this law."
Digital Markets Act (DMA) - Definition of web browser,0.714991748,"Details of the Definition of web browser in the Digital Markets Act (DMA): ""web browser"" means a software application that enables end users to access and interact with web content hosted on servers that are connected to networks such as the Internet, including standalone web browsers as well as web browsers integrated or embedded in software or similar;",rectial,"The Digital Markets Act (DMA) has a new definition for a ""web browser"". According to the DMA, a web browser is a type of software that lets people use and interact with content on the internet. This includes both standalone web browsers (like Google Chrome or Firefox) and web browsers that are part of other software."
California Consumer Privacy Act Regulations (CCPA) - Definition of Request to opt-out,0.714965284,"Details of Definition of Request to opt-out in the California Consumer Privacy Act Regulations (CCPA): Request to opt-out means a consumer request that a business not sell the consumers personal information to third parties, pursuant to Civil Code section 1798.120, subdivision (a).",recital,"The California Consumer Privacy Act Regulations (CCPA) has a new rule called ""Request to opt-out"". This rule allows consumers to ask businesses not to sell their personal information to third parties. This is a right granted to consumers under the law."
Artifical Inellegence Act (AI Act) - Article 17,0.714908481,"Aritifical Intelligence Act (AI Act) Article 17 Quality management system:

1.Providers of high-risk AI systems shall put a quality management system in place that ensures compliance with this Regulation. That system shall be documented in a systematic and orderly manner in the form of written policies, procedures and instructions, and shall include at least the following aspects:

(a)a strategy for regulatory compliance, including compliance with conformity assessment procedures and procedures for the management of modifications to the high-risk AI system;

(b)techniques, procedures and systematic actions to be used for the design, design control and design verification of the high-risk AI system;

(c)techniques, procedures and systematic actions to be used for the development, quality control and quality assurance of the high-risk AI system;

(d)examination, test and validation procedures to be carried out before, during and after the development of the high-risk AI system, and the frequency with which they have to be carried out;

(e)technical specifications, including standards, to be applied and, where the relevant harmonised standards are not applied in full, the means to be used to ensure that the high-risk AI system complies with the requirements set out in Chapter 2 of this Title;

(f)systems and procedures for data management, including data collection, data analysis, data labelling, data storage, data filtration, data mining, data aggregation, data retention and any other operation regarding the data that is performed before and for the purposes of the placing on the market or putting into service of high-risk AI systems;

(g)the risk management system referred to in Article 9;

(h)the setting-up, implementation and maintenance of a post-market monitoring system, in accordance with Article 61;

(i)procedures related to the reporting of serious incidents and of malfunctioning in accordance with Article 62;

(j)the handling of communication with national competent authorities, competent authorities, including sectoral ones, providing or supporting the access to data, notified bodies, other operators, customers or other interested parties;

(k)systems and procedures for record keeping of all relevant documentation and information;

(l)resource management, including security of supply related measures;

(m)an accountability framework setting out the responsibilities of the management and other staff with regard to all aspects listed in this paragraph.

2.The implementation of aspects referred to in paragraph 1 shall be proportionate to the size of the providers organisation.

3.For providers that are credit institutions regulated by Directive 2013/36/ EU, the obligation to put a quality management system in place shall be deemed to be fulfilled by complying with the rules on internal governance arrangements, processes and mechanisms pursuant to Article 74 of that Directive. In that context, any harmonised standards referred to in Article 40 of this Regulation shall be taken into account.",article,"The Artificial Intelligence Act (AI Act) mandates that providers of high-risk AI systems must establish a quality management system to ensure compliance with the law. This system must be well-documented and include strategies for regulatory compliance, design and development procedures, testing and validation methods, technical specifications, data management processes, risk management systems, post-market monitoring, incident reporting, communication processes, record-keeping, resource management, and an accountability framework. The complexity of the system should be proportional to the size of the provider's organization. For credit institutions regulated by Directive 2013/36/EU, compliance with internal governance rules fulfills the requirement for a quality management system."
Digital Services Act (DSA) - Article 34 Risk assessment,0.714906871,"Article 34 Risk assessment in the Digital Services Act (DSA):  1.   Providers of very large online platforms and of very large online search engines shall diligently identify, analyse and assess any systemic risks in the Union stemming from the design or functioning of their service and its related systems, including algorithmic systems, or from the use made of their services.

They shall carry out the risk assessments by the date of application referred to in Article 33(6), second subparagraph, and at least once every year thereafter, and in any event prior to deploying functionalities that are likely to have a critical impact on the risks identified pursuant to this Article. This risk assessment shall be specific to their services and proportionate to the systemic risks, taking into consideration their severity and probability, and shall include the following systemic risks:

(a) the dissemination of illegal content through their services;
(b) any actual or foreseeable negative effects for the exercise of fundamental rights, in particular the fundamental rights to human dignity enshrined in Article 1 of the Charter, to respect for private and family life enshrined in Article 7 of the Charter, to the protection of personal data enshrined in Article 8 of the Charter, to freedom of expression and information, including the freedom and pluralism of the media, enshrined in Article 11 of the Charter, to non-discrimination enshrined in Article 21 of the Charter, to respect for the rights of the child enshrined in Article 24 of the Charter and to a high-level of consumer protection enshrined in Article 38 of the Charter;
(c) any actual or foreseeable negative effects on civic discourse and electoral processes, and public security;
(d) any actual or foreseeable negative effects in relation to gender-based violence, the protection of public health and minors and serious negative consequences to the person's physical and mental well-being.

2.   When conducting risk assessments, providers of very large online platforms and of very large online search engines shall take into account, in particular, whether and how the following factors influence any of the systemic risks referred to in paragraph 1:

(a) the design of their recommender systems and any other relevant algorithmic system;
(b) their content moderation systems;
(c) the applicable terms and conditions and their enforcement;
(d) systems for selecting and presenting advertisements;
(e) data related practices of the provider.

The assessments shall also analyse whether and how the risks pursuant to paragraph 1 are influenced by intentional manipulation of their service, including by inauthentic use or automated exploitation of the service, as well as the amplification and potentially rapid and wide dissemination of illegal content and of information that is incompatible with their terms and conditions.

The assessment shall take into account specific regional or linguistic aspects, including when specific to a Member State.

3.   Providers of very large online platforms and of very large online search engines shall preserve the supporting documents of the risk assessments for at least three years after the performance of risk assessments, and shall, upon request, communicate them to the Commission and to the Digital Services Coordinator of establishment.",article,"The Digital Services Act (DSA) requires large online platforms and search engines to regularly assess potential risks related to their services. These risks include the spread of illegal content, negative effects on fundamental rights (like privacy, freedom of expression, non-discrimination, child rights, consumer protection), negative impacts on public discourse, elections, public security, and negative effects related to gender-based violence, public health, and well-being. Factors to consider in these assessments include the design of their recommendation systems, content moderation systems, terms and conditions, ad presentation systems, and data practices. They also need to consider the possibility of intentional manipulation of their service. These assessments should consider regional or linguistic aspects, and documents related to these assessments should be kept for at least three years and shared with the Commission and the Digital Services Coordinator upon request."
Digital Services Act (DSA) - Definition of 'advertisement',0.714895427,"Definition of 'advertisement' in the Digital Services Act (DSA): information designed to promote the message of a legal or natural person, irrespective of whether to achieve commercial or non-commercial purposes, and presented by an online platform on its online interface against remuneration specifically for promoting that information.",recital,"The Digital Services Act (DSA) has a new definition for 'advertisement'. According to this law, an advertisement is any information that is used to spread the message of a person or a legal entity (like a company), whether it's for business or non-business reasons. This information is shown on an online platform, like a website or an app, and the platform gets paid specifically for showing this information."
Artifical Inellegence Act (AI Act) - Overview paragraph 42,0.714815617,"Aritifical Intelligence Act (AI Act) overview paragraph (42): To mitigate the risks from high-risk AI systems placed or otherwise put into service on the Union market for users and affected persons, certain mandatory requirements should apply, taking into account the intended purpose of the use of the system and according to the risk management system to be established by the provider.",recital,The Artificial Intelligence Act (AI Act) is a new law designed to manage the risks of advanced AI systems that are used within the Union market. This law requires that certain rules must be followed by the providers of these AI systems. These rules will depend on what the AI system is intended to be used for and the risk management system the provider has in place. The aim is to protect users and those impacted by these AI systems.
Digital Services Act (DSA) - Article 36 Crisis response mechanism,0.714814723,"Article 36 Crisis response mechanism in the Digital Services Act (DSA):  1.   Where a crisis occurs, the Commission, acting upon a recommendation of the Board may adopt a decision, requiring one or more providers of very large online platforms or of very large online search engines to take one or more of the following actions:

(a) assess whether, and if so to what extent and how, the functioning and use of their services significantly contribute to a serious threat as referred to in paragraph 2, or are likely to do so;
(b) identify and apply specific, effective and proportionate measures, such as any of those provided for in Article 35(1) or Article 48(2), to prevent, eliminate or limit any such contribution to the serious threat identified pursuant to point (a) of this paragraph;
(c) report to the Commission by a certain date or at regular intervals specified in the decision, on the assessments referred to in point (a), on the precise content, implementation and qualitative and quantitative impact of the specific measures taken pursuant to point (b) and on any other issue related to those assessments or those measures, as specified in the decision.

When identifying and applying measures pursuant to point (b) of this paragraph, the service provider or providers shall take due account of the gravity of the serious threat referred to in paragraph 2, of the urgency of the measures and of the actual or potential implications for the rights and legitimate interests of all parties concerned, including the possible failure of the measures to respect the fundamental rights enshrined in the Charter.

2.   For the purpose of this Article, a crisis shall be deemed to have occurred where extraordinary circumstances lead to a serious threat to public security or public health in the Union or in significant parts of it.

3.   When taking the decision referred to in paragraph 1, the Commission shall ensure that all of the following requirements are met:

(a) the actions required by the decision are strictly necessary, justified and proportionate, having regard in particular to the gravity of the serious threat referred to in paragraph 2, the urgency of the measures and the actual or potential implications for the rights and legitimate interests of all parties concerned, including the possible failure of the measures to respect the fundamental rights enshrined in the Charter;
(b) the decision specifies a reasonable period within which specific measures referred to in paragraph 1, point (b), are to be taken, having regard, in particular, to the urgency of those measures and the time needed to prepare and implement them;
(c) the actions required by the decision are limited to a period not exceeding three months.

4.   After adopting the decision referred to in paragraph 1, the Commission shall, without undue delay, take the following steps:

(a) notify the decision to the provider or providers to which the decision is addressed;
(b) make the decision publicly available; and
(c) inform the Board of the decision, invite it to submit its views thereon, and keep it informed of any subsequent developments relating to the decision.

5.   The choice of specific measures to be taken pursuant to paragraph 1, point (b), and to paragraph 7, second subparagraph, shall remain with the provider or providers addressed by the Commission's decision.

6.   The Commission may on its own initiative or at the request of the provider, engage in a dialogue with the provider to determine whether, in light of the provider's specific circumstances, the intended or implemented measures referred to in paragraph 1, point (b), are effective and proportionate in achieving the objectives pursued. In particular, the Commission shall ensure that the measures taken by the service provider under paragraph 1, point (b), meet the requirements referred to in paragraph 3, points (a) and (c).

7.   The Commission shall monitor the application of the specific measures taken pursuant to the decision referred to in paragraph 1 of this Article on the basis of the reports referred to in point (c) of that paragraph and any other relevant information, including information it may request pursuant to Article 40 or 67, taking into account the evolution of the crisis. The Commission shall report regularly to the Board on that monitoring, at least on a monthly basis.

Where the Commission considers that the intended or implemented specific measures pursuant to paragraph 1, point (b), are not effective or proportionate it may, after consulting the Board, adopt a decision requiring the provider to review the identification or application of those specific measures.

8.   Where appropriate in view of the evolution of the crisis, the Commission, acting on the Board's recommendation, may amend the decision referred to in paragraph 1 or in paragraph 7, second subparagraph, by:

(a) revoking the decision and, where appropriate, requiring the very large online platform or very large online search engine to cease to apply the measures identified and implemented pursuant to paragraph 1, point (b), or paragraph 7, second subparagraph, in particular where the grounds for such measures do not exist anymore;
(b) extending the period referred to paragraph 3, point (c), by a period of no more than three months;
(c) taking account of experience gained in applying the measures, in particular the possible failure of the measures to respect the fundamental rights enshrined in the Charter.

9.   The requirements of paragraphs 1 to 6 shall apply to the decision and to the amendment thereof referred to in this Article.

10.   The Commission shall take utmost account of the recommendation of the Board issued pursuant to this Article.

11.   The Commission shall report to the European Parliament and to the Council on a yearly basis following the adoption of decisions in accordance with this Article, and, in any event, three months after the end of the crisis, on the application of the specific measures taken pursuant to those decisions.",article,"The Digital Services Act (DSA) includes a crisis response mechanism (Article 36) which allows the Commission to require large online platforms and search engines to take action during a crisis. A crisis is defined as extraordinary circumstances that pose a serious threat to public security or health. The Commission can require these companies to assess their contribution to the threat, implement measures to mitigate it, and report on their actions. Any actions taken must be necessary, justified, and proportionate, considering the threat's severity and the potential impact on the rights and interests of all parties involved. The Commission will monitor the effectiveness of these measures and can require changes if needed. The Commission is also required to report to the European Parliament and the Council on the application of these measures on a yearly basis and three months after the end of a crisis."
Artifical Inellegence Act (AI Act) - Article 60,0.714800239,"Aritifical Intelligence Act (AI Act) Article 60 EU database for stand-alone high-risk AI systems:

1.The Commission shall, in collaboration with the Member States, set up and maintain a EU database containing information referred to in paragraph 2 concerning high-risk AI systems referred to in Article 6(2) which are registered in accordance with Article 51.

2.The data listed in Annex VIII shall be entered into the EU database by the providers. The Commission shall provide them with technical and administrative support.

3.Information contained in the EU database shall be accessible to the public.

4.The EU database shall contain personal data only insofar as necessary for collecting and processing information in accordance with this Regulation. That information shall include the names and contact details of natural persons who are responsible for registering the system and have the legal authority to represent the provider.

5.The Commission shall be the controller of the EU database. It shall also ensure to providers adequate technical and administrative support.",article,"The Artificial Intelligence Act (AI Act) Article 60 requires the establishment of an EU database for high-risk AI systems. This database, managed by the Commission in collaboration with Member States, will contain information about these systems, provided by the system providers. The Commission will offer technical and administrative support to these providers. The database will be open to the public and will only contain personal data necessary for its function, such as the names and contact details of those responsible for registering the system. The Commission will oversee the database and ensure adequate support for providers."
California Consumer Privacy Act Regulations (CCPA) - Definition of Employment benefits,0.714657068,"Details of Definition of Employment benefits in the California Consumer Privacy Act Regulations (CCPA): Employment benefits means retirement, health, and other benefit programs, services, or products to which consumers and their dependents or their beneficiaries receive access through the consumers employer.",recital,"The California Consumer Privacy Act Regulations (CCPA) defines ""Employment benefits"" as programs, services, or products related to retirement, health, and other benefits. These are benefits that employees, their dependents, or beneficiaries can access through their employer."
Artifical Inellegence Act (AI Act) - Overview paragraph 5,0.714603722,"Aritifical Intelligence Act (AI Act) overview paragraph (5): A Union legal framework laying down harmonised rules on artificial intelligence is therefore needed to foster the development, use and uptake of artificial intelligence in the internal market that at the same time meets a high level of protection of public interests, such as health and safety and the protection of fundamental rights, as recognised and protected by Union law. To achieve that objective, rules regulating the placing on the market and putting into service of certain AI systems should be laid down, thus ensuring the smooth functioning of the internal market and allowing those systems to benefit from the principle of free movement of goods and services.By laying down those rules, this Regulation supports the objective of the Union of being a global leader in the development of secure, trustworthy and ethical artificial intelligence, as stated by the European Council33, and it ensures the protection of ethical principles, as specifically requested by the European Parliament34.",recital,"The Artificial Intelligence Act (AI Act) is a new law that aims to regulate the use of artificial intelligence (AI) within the European Union. Its goal is to promote the development and use of AI, while ensuring public interests like health, safety, and fundamental rights are protected. The law sets rules for introducing certain AI systems in the market, ensuring they operate smoothly and benefit from the free movement of goods and services. The AI Act supports the EU's goal of being a global leader in developing secure, trustworthy, and ethical AI, and safeguards ethical principles as requested by the European Parliament."
Artifical Inellegence Act (AI Act) - Article 62,0.714594424,"Aritifical Intelligence Act (AI Act) Article 62 Reporting of serious incidents and of malfunctioning:

1.Providers of high-risk AI systems placed on the Union market shall report any serious incident or any malfunctioning of those systems which constitutes a breach of obligations under Union law intended to protect fundamental rights to the market surveillance authorities of the Member States where that incident or breach occurred.

Such notification shall be made immediately after the provider has established a causal link between the AI system and the incident or malfunctioning or the reasonable likelihood of such a link, and, in any event, not later than 15 days after the providers becomes aware of the serious incident or of the malfunctioning.

2.Upon receiving a notification related to a breach of obligations under Union law intended to protect fundamental rights, the market surveillance authority shall inform the national public authorities or bodies referred to in Article 64(3). The Commission shall develop dedicated guidance to facilitate compliance with the obligations set out in paragraph 1. That guidance shall be issued 12 months after the entry into force of this Regulation, at the latest.

3.For high-risk AI systems referred to in point 5(b) of Annex III which are placed on the market or put into service by providers that are credit institutions regulated by Directive 2013/36/EU and for high-risk AI systems which are safety components of devices, or are themselves devices, covered by Regulation (EU) 2017/745 and Regulation (EU) 2017/746, the notification of serious incidents or malfunctioning shall be limited to those that that constitute a breach of obligations under Union law intended to protect fundamental rights.",article,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems in the EU to report any serious incidents or malfunctions that violate EU laws protecting fundamental rights. These reports must be made to the appropriate market surveillance authorities within 15 days of becoming aware of the incident. If a breach is reported, the surveillance authority will inform national public authorities. The Commission will provide guidance to help comply with these rules within a year of the law being enforced. For AI systems used by credit institutions or as safety components of devices, only incidents that violate fundamental rights need to be reported."
General Data Protection Regulation (GDPR) - Article 40 Codes of conduct,0.714525223,"Details of Article 40 Codes of conduct in the General Data Protection Regulation (GDPR): 1. The Member States, the supervisory authorities, the Board and the Commission shall encourage the drawing up of codes of conduct intended to contribute to the proper application of this Regulation, taking account of the specific features of the various processing sectors and the specific needs of micro, small and medium-sized enterprises. 2. Associations and other bodies representing categories of controllers or processors may prepare codes of conduct, or amend or extend such codes, for the purpose of specifying the application of this Regulation, such as with regard to: (a) fair and transparent processing; (b) the legitimate interests pursued by controllers in specific contexts; (c) the collection of personal data; (d) the pseudonymisation of personal data; (e) the information provided to the public and to data subjects; (f) the exercise of the rights of data subjects; (g) the information provided to, and the protection of, children, and the manner in which the consent of the holders of parental responsibility over children is to be obtained; (h) the measures and procedures referred to in Articles 24 and 25 and the measures to ensure security of processing referred to in Article 32; (i) the notification of personal data breaches to supervisory authorities and the communication of such personal data breaches to data subjects; (j) the transfer of personal data to third countries or international organisations; or (k) out-of-court proceedings and other dispute resolution procedures for resolving disputes between controllers and data subjects with regard to processing, without prejudice to the rights of data subjects pursuant to Articles 77 and 79. 3. In addition to adherence by controllers or processors subject to this Regulation, codes of conduct approved pursuant to paragraph 5 of this Article and having general validity pursuant to paragraph 9 of this Article may also be adhered to by controllers or processors that are not subject to this Regulation pursuant to Article 3 in order to provide appropriate safeguards within the framework of personal data transfers to third countries or international organisations under the terms referred to in point (e) of Article 46(2). Such controllers or processors shall make binding and enforceable commitments, via contractual or other legally binding instruments, to apply those appropriate safeguards including with regard to the rights of data subjects. 4. A code of conduct referred to in paragraph 2 of this Article shall contain mechanisms which enable the body referred to in Article 41(1) to carry out the mandatory monitoring of compliance with its provisions by the controllers or processors which undertake to apply it, without prejudice to the tasks and powers of supervisory authorities competent pursuant to Article 55 or 56. 5. Associations and other bodies referred to in paragraph 2 of this Article which intend to prepare a code of conduct or to amend or extend an existing code shall submit the draft code, amendment or extension to the supervisory authority which is competent pursuant to Article 55. The supervisory authority shall provide an opinion on whether the draft code, amendment or extension complies with this Regulation and shall approve that draft code, amendment or extension if it finds that it provides sufficient appropriate safeguards. 6. Where the draft code, or amendment or extension is approved in accordance with paragraph 5, and where the code of conduct concerned does not relate to processing activities in several Member States, the supervisory authority shall register and publish the code. 7. Where a draft code of conduct relates to processing activities in several Member States, the supervisory authority which is competent pursuant to Article 55 shall, before approving the draft code, amendment or extension, submit it in the procedure referred to in Article 63 to the Board which shall provide an opinion on whether the draft code, amendment or extension complies with this Regulation or, in the situation referred to in paragraph 3 of this Article, provides appropriate safeguards. 8. Where the opinion referred to in paragraph 7 confirms that the draft code, amendment or extension complies with this Regulation, or, in the situation referred to in paragraph 3, provides appropriate safeguards, the Board shall submit its opinion to the Commission. 9. The Commission may, by way of implementing acts, decide that the approved code of conduct, amendment or extension submitted to it pursuant to paragraph 8 of this Article have general validity within the Union. Those implementing acts shall be adopted in accordance with the examination procedure set out in Article 93(2). 10. The Commission shall ensure appropriate publicity for the approved codes which have been decided as having general validity in accordance with paragraph 9. 11. The Board shall collate all approved codes of conduct, amendments and extensions in a register and shall make them publicly available by way of appropriate means.",article,"Article 40 of the General Data Protection Regulation (GDPR) encourages the creation of codes of conduct to ensure proper application of the law. These codes should consider the specific needs of different sectors and sizes of businesses. Associations or bodies representing data controllers or processors can create these codes, which should address issues such as fair data processing, data collection, pseudonymisation, information provision, data subject rights, child protection, data security, data breach notifications, data transfers, and dispute resolution. These codes can be followed by controllers or processors not subject to the GDPR, as long as they make binding commitments to apply appropriate safeguards. The codes should include mechanisms for monitoring compliance. Draft codes must be submitted to the relevant supervisory authority for approval and, if approved, registered and published. If a code relates to multiple Member States, it must be submitted to the Board for an opinion before approval. The Commission can decide if an approved code has general validity within the Union. All approved codes will be collated in a register and made publicly available."
Digital Markets Act (DMA) - Definition of number-independent interpersonal communications service,0.71452266,"Details of the Definition of number-independent interpersonal communications service in the Digital Markets Act (DMA): ""number-independent interpersonal communications service"" means a number-independent interpersonal communications service as defined in Article 2, point (7), of Directive (EU) 2018/1972;",rectial,"The Digital Markets Act (DMA) introduces a term called ""number-independent interpersonal communications service"". This term, as defined in Article 2, point (7), of Directive (EU) 2018/1972, refers to any communication service that doesn't rely on numbers for communication. This could include services like email or instant messaging apps, where you don't need a specific phone number to communicate with others. The DMA includes regulations for these types of services."
Artifical Inellegence Act (AI Act) - Context Section 5.2.2,0.714480579,"Aritifical Intelligence Act (AI Act) context section 5.2.2.PROHIBITED ARTIFICIAL INTELLIGENCE PRACTICES (TITLE II): 

Title II establishes a list of prohibited AI. The regulation follows a risk-based approach, differentiating between uses of AI that create (i) an unacceptable risk, (ii) a high risk, and (iii) low or minimal risk. The list of prohibited practices in Title II comprises all those AI systems whose use is considered unacceptable as contravening Union values, for instance by violating fundamental rights. The prohibitions covers practices that have a significant potential to manipulate persons through subliminal techniques beyond their consciousness or exploit vulnerabilities of specific vulnerable groups such as children or persons with disabilities in order to materially distort their behaviour in a manner that is likely to cause them or another person psychological or physical harm. Other manipulative or exploitative practices affecting adults that might be facilitated by AI systems could be covered by the existing data protection, consumer protection and digital service legislation that guarantee that natural persons are properly informed and have free choice not to be subject to profiling or other practices that might affect their behaviour. The proposal also prohibits AI-based social scoring for general purposes done by public authorities. Finally, the use of real time remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement is also prohibited unless certain limited exceptions apply.5.2.2.PROHIBITED ARTIFICIAL INTELLIGENCE PRACTICES (TITLE II):

Title II establishes a list of prohibited AI. The regulation follows a risk-based approach, differentiating between uses of AI that create (i) an unacceptable risk, (ii) a high risk, and (iii) low or minimal risk. The list of prohibited practices in Title II comprises all those AI systems whose use is considered unacceptable as contravening Union values, for instance by violating fundamental rights. The prohibitions covers practices that have a significant potential to manipulate persons through subliminal techniques beyond their consciousness or exploit vulnerabilities of specific vulnerable groups such as children or persons with disabilities in order to materially distort their behaviour in a manner that is likely to cause them or another person psychological or physical harm. Other manipulative or exploitative practices affecting adults that might be facilitated by AI systems could be covered by the existing data protection, consumer protection and digital service legislation that guarantee that natural persons are properly informed and have free choice not to be subject to profiling or other practices that might affect their behaviour. The proposal also prohibits AI-based social scoring for general purposes done by public authorities. Finally, the use of real time remote biometric identification systems in publicly accessible spaces for the purpose of law enforcement is also prohibited unless certain limited exceptions apply.",recital,"The Artificial Intelligence Act (AI Act) sets rules for the use of AI. It categorizes AI uses into three risk levels: unacceptable, high, and low or minimal. The Act bans AI uses that are deemed unacceptable due to violation of fundamental rights or Union values. This includes AI systems that manipulate people subconsciously or exploit vulnerable groups like children or disabled people, causing potential psychological or physical harm. The Act also covers manipulative or exploitative practices on adults by AI systems, ensuring people are informed and can opt out of profiling or behavior-affecting practices. The Act prohibits AI-based social scoring by public authorities and the use of real-time remote biometric identification in public spaces for law enforcement, with limited exceptions."
Artifical Inellegence Act (AI Act) - Definition of 'making available on the market',0.714458704,"Within the Aritifical Intelligence Act (AI Act), the Definition of making available on the market means any supply of an AI system for distribution or use on the Union market in the course of a commercial activity, whether in return for payment or free of charge;",recital,The Artificial Intelligence Act (AI Act) defines 'making available on the market' as any instance where an AI system is provided for use or distribution within the Union market as part of a business activity. This can happen whether the AI system is sold for a price or given away for free.
Digital Markets Act (DMA) - Article 44 Publication of decisions,0.714428306,"Details of Article 44 Publication of decisions in the Digital Markets Act (DMA): 1. The Commission shall publish the decisions which it takes pursuant to Articles 3 and 4, Article 8(2), Articles 9, 10, 16 to 20 and 24, Article 25(1), Articles 29, 30 and 31. Such publication shall state the names of the parties and the main content of the decision, including any penalties imposed. 2. The publication shall have regard to the legitimate interest of gatekeepers or third parties in the protection of their confidential information.",article,"The Digital Markets Act (DMA) requires that the Commission publish its decisions related to several articles of the Act. These publications will include the names of the involved parties, the main content of the decision, and any penalties imposed. However, the Act also ensures that the confidential information of gatekeepers or third parties is protected during this publication process."
Artifical Inellegence Act (AI Act) - Article 31,0.714423537,"Aritifical Intelligence Act (AI Act) Article 31 Application of a conformity assessment body for notification:

1.Conformity assessment bodies shall submit an application for notification to the notifying authority of the Member State in which they are established.

2.The application for notification shall be accompanied by a description of the conformity assessment activities, the conformity assessment module or modules and the artificial intelligence technologies for which the conformity assessment body claims to be competent, as well as by an accreditation certificate, where one exists, issued by a national accreditation body attesting that the conformity assessment body fulfils the requirements laid down in Article 33. Any valid document related to existing designations of the applicant notified body under any other Union harmonisation legislation shall be added.

3.Where the conformity assessment body concerned cannot provide an accreditation certificate, it shall provide the notifying authority with the documentary evidence necessary for the verification, recognition and regular monitoring of its compliance with the requirements laid down in Article 33. For notified bodies which are designated under any other Union harmonisation legislation, all documents and certificates linked to those designations may be used to support their designation procedure under this Regulation, as appropriate.",article,"The Artificial Intelligence Act (AI Act) requires AI assessment bodies to apply for a notification from the authority in the state they're based in. This application should include a description of their AI assessment activities, the AI technologies they're competent in, and any relevant accreditation certificates. If they don't have a certificate, they need to provide other proof that they meet the requirements of Article 33. Documents related to existing designations under other Union laws can be used to support their application."
Artifical Inellegence Act (AI Act) - Article 40,0.714336634,"Aritifical Intelligence Act (AI Act) Article 40 Harmonised standards: 

High-risk AI systems which are in conformity with harmonised standards or parts thereof the references of which have been published in the Official Journal of the European Union shall be presumed to be in conformity with the requirements set out in Chapter 2 of this Title, to the extent those standards cover those requirements.",article,"The Artificial Intelligence Act (AI Act) Article 40 states that high-risk AI systems that meet the standards published in the Official Journal of the European Union are assumed to meet the requirements set out in Chapter 2 of this Title. This is as long as the standards cover those requirements. In simpler terms, if a high-risk AI system follows the rules published in the EU's official journal, it's considered to be following the AI Act's requirements."
General Data Protection Regulation (GDPR) - Article 19 Notification obligation regarding rectification or erasure of personal data or restriction of processing,0.714336216,"Details of Article 19 Notification obligation regarding rectification or erasure of personal data or restriction of processing in the General Data Protection Regulation (GDPR): The controller shall communicate any rectification or erasure of personal data or restriction of processing carried out in accordance with Article 16, Article 17(1) and Article 18 to each recipient to whom the personal data have been disclosed, unless this proves impossible or involves disproportionate effort. The controller shall inform the data subject about those recipients if the data subject requests it.",article,"Article 19 of the General Data Protection Regulation (GDPR) requires companies (data controllers) to notify all parties (recipients) who have received your personal data if there have been any corrections, deletions, or restrictions made to your data. This is unless it's impossible or requires too much effort. If you ask, the company must also tell you who these recipients are."
California Consumer Privacy Act Regulations (CCPA) - Article 6. Non-Discrimination -  999.337 Calculating the Value of Consumer Data,0.714303,"Details of Article 6. Non-Discrimination -  999.337 Calculating the Value of Consumer Data in the California Consumer Privacy Act Regulations (CCPA): (a) A business offering a financial incentive or price or service difference subject to Civil Code section 1798.125 shall use and document a reasonable and good faith method for calculating the value of the consumers data. The business shall consider one or more of the following: (1) The marginal value to the business of the sale, collection, or deletion of a consumers data. (2) The average value to the business of the sale, collection, or deletion of a consumers data. (3) The aggregate value to the business of the sale, collection, or deletion of consumers data divided by the total number of consumers. (4) Revenue generated by the business from sale, collection, or retention of consumers personal information. (5) Expenses related to the sale, collection, or retention of consumers personal information. (6) Expenses related to the offer, provision, or imposition of any financial incentive or price or service difference. (7) Profit generated by the business from sale, collection, or retention of consumers personal information. (8) Any other practical and reasonably reliable method of calculation used in good faith. (b) For the purpose of calculating the value of consumer data, a business may consider the value to the business of the data of all natural persons in the United States and not just consumers.",article,"The California Consumer Privacy Act (CCPA) has a new rule, Article 6, which requires businesses to fairly calculate the value of consumer data when offering financial incentives or price/service differences. They must use a reasonable method, considering factors like the value of the data to the business, the revenue and expenses related to the data, and the profit made from the data. They can also use any other reliable calculation method in good faith. When calculating the value of consumer data, businesses may consider the value of data from all individuals in the U.S., not just consumers."
Digital Services Act (DSA) - Article 83 Implementing acts relating to Commission intervention,0.714249253,"Article 83 Implementing acts relating to Commission intervention in the Digital Services Act (DSA):  In relation to the Commission intervention covered by this Section, the Commission may adopt implementing acts concerning the practical arrangements for:

(a) the proceedings pursuant to Articles 69 and 72;
(b) the hearings provided for in Article 79;
(c) the negotiated disclosure of information provided for in Article 79.

Before the adoption of any measures pursuant to the first paragraph of this Article, the Commission shall publish a draft thereof and invite all interested parties to submit their comments within the period set out therein, which shall not be less than one month. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.",article,"The Digital Services Act (DSA) allows the Commission to create practical rules for proceedings, hearings, and information disclosure. Before these rules are made, the Commission will publish a draft and invite public comments for at least a month. The final rules will be adopted following an advisory procedure. This process is outlined in Article 83 of the DSA."
Digital Markets Act (DMA) - Article 16 Opening of a market investigation,0.714224637,"Details of Article 16 Opening of a market investigation in the Digital Markets Act (DMA): 1. When the Commission intends to carry out a market investigation with a view to the possible adoption of decisions pursuant to Articles 17, 18 and 19 it shall adopt a decision opening a market investigation. 2. Notwithstanding paragraph 1, the Commission may exercise its investigative powers under this Regulation before opening a market investigation pursuant to that paragraph. 3. The decision referred to in paragraph 1 shall specify: (a) the date of opening of the market investigation; (b) the description of the issue to which the market investigation relates to; (c) the purpose of the market investigation. 4. The Commission may reopen a market investigation that it has closed where: (a) there has been a material change in any of the facts on which a decision adopted pursuant to Article 17, 18 or 19 was based; or (b) the decision adopted pursuant to Article 17, 18 or 19 was based on incomplete, incorrect or misleading information. 5. The Commission may ask one or more national competent authorities to assist it in its market investigation.",article,"The Digital Markets Act (DMA) has a new provision, Article 16, which outlines the process for market investigations. The Commission can initiate an investigation if it suspects issues that may require decisions under Articles 17, 18, and 19. The Commission can also use its investigative powers before officially starting an investigation. The official decision to start an investigation must specify the start date, the issue being investigated, and the purpose of the investigation. If there are significant changes in the facts or if the decision was based on incorrect or incomplete information, the Commission can reopen a closed investigation. Furthermore, the Commission can ask national authorities to assist in the investigation."
California Consumer Privacy Act Regulations (CCPA) - Article 4. Verification of Requests -  999.326 Authorized Agent,0.714181244,"Details of Article 4. Verification of Requests -  999.326 Authorized Agent in the California Consumer Privacy Act Regulations (CCPA): (a) When a consumer uses an authorized agent to submit a request to know or a request to delete, a business may require that the consumer do the following: (1) Provide the authorized agent signed permission to do so. (2) Verify their own identity directly with the business. (3) Directly confirm with the business that they provided the authorized agent permission to submit the request. (b) Subsection (a) does not apply when a consumer has provided the authorized agent with power of attorney pursuant to Probate Code sections 4121 to 4130. (c) An authorized agent shall implement and maintain reasonable security procedures and practices to protect the consumers information. (d) An authorized agent shall not use a consumers personal information, or any information collected from or about the consumer, for any purposes other than to fulfill the consumers requests, verification, or fraud prevention.",article,"The California Consumer Privacy Act (CCPA) has a new rule, Article 4, about using an ""authorized agent"" to request access to or deletion of your personal data. If you use an agent, the business can ask you to: 1) give the agent written permission, 2) prove your identity to the business, and 3) confirm to the business that you gave the agent permission. However, if you've given the agent legal power of attorney, these requirements don't apply. The agent must also have good security practices to protect your data and can only use your data to carry out your request, verify your identity, or prevent fraud."
Artifical Inellegence Act (AI Act) - Overview paragraph 82,0.714150608,"Aritifical Intelligence Act (AI Act) overview paragraph (82): It is important that AI systems related to products that are not high-risk in accordance with this Regulation and thus are not required to comply with the requirements set out herein are nevertheless safe when placed on the market or put into service. To contribute to this objective,theDirective 2001/95/EC of the European Parliament and of the Council57would apply as a safety net.",recital,"The Artificial Intelligence Act (AI Act) states that even if an AI system is not considered high-risk, it still needs to be safe when it's sold or used. The law does not require these AI systems to meet the same requirements as high-risk ones. However, to ensure safety, another law, Directive 2001/95/EC of the European Parliament and of the Council, will act as a safety net. This means it will apply to these AI systems to ensure they are safe for use."
"General Data Protection Regulation (GDPR) - Article 89 Safeguards and derogations relating to processing for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes",0.714149117,"Details of Article 89 Safeguards and derogations relating to processing for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes in the General Data Protection Regulation (GDPR): 1. Processing for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes, shall be subject to appropriate safeguards, in accordance with this Regulation, for the rights and freedoms of the data subject. Those safeguards shall ensure that technical and organisational measures are in place in particular in order to ensure respect for the principle of data minimisation. Those measures may include pseudonymisation provided that those purposes can be fulfilled in that manner. Where those purposes can be fulfilled by further processing which does not permit or no longer permits the identification of data subjects, those purposes shall be fulfilled in that manner. 2. Where personal data are processed for scientific or historical research purposes or statistical purposes, Union or Member State law may provide for derogations from the rights referred to in Articles 15, 16, 18 and 21 subject to the conditions and safeguards referred to in paragraph 1 of this Article in so far as such rights are likely to render impossible or seriously impair the achievement of the specific purposes, and such derogations are necessary for the fulfilment of those purposes. 3. Where personal data are processed for archiving purposes in the public interest, Union or Member State law may provide for derogations from the rights referred to in Articles 15, 16, 18, 19, 20 and 21 subject to the conditions and safeguards referred to in paragraph 1 of this Article in so far as such rights are likely to render impossible or seriously impair the achievement of the specific purposes, and such derogations are necessary for the fulfilment of those purposes. 4. Where processing referred to in paragraphs 2 and 3 serves at the same time another purpose, the derogations shall apply only to processing for the purposes referred to in those paragraphs.",article,"Article 89 of the General Data Protection Regulation (GDPR) focuses on data processing for public interest, research, or statistical purposes. It states that such processing must have safeguards to protect the rights and freedoms of the individuals whose data is being used. This includes measures to minimize data use and to anonymize data where possible. The law allows for exceptions to certain rights if they would seriously hinder the achievement of these purposes. However, these exceptions only apply if they are necessary for achieving the intended purpose. If the data processing serves multiple purposes, the exceptions only apply to the purposes mentioned in this law."
Digital Markets Act (DMA) - Article 19 Market investigation into new services and new practices,0.714114606,"Details of Article 19 Market investigation into new services and new practices in the Digital Markets Act (DMA): 1. The Commission may conduct a market investigation for the purpose of examining whether one or more services within the digital sector should be added to the list of core platform services laid down in Article 2, point (2) or for the purpose of detecting practices that limit the contestability of core platform services or that are unfair and which are not effectively addressed by this Regulation. In its assessment, the Commission shall take into account any relevant findings of proceedings under Articles 101 and 102 TFEU concerning digital markets as well as any other relevant developments. 2. The Commission may, when conducting a market investigation pursuant to paragraph 1, consult third parties, including business users and end users of services within the digital sector that are being investigated and business users and end users who are subject to practices under investigation. 3. The Commission shall publish its findings in a report within 18 months from the date referred to in Article 16(3), point (a). That report shall be submitted to the European Parliament and to the Council and, where appropriate, shall be accompanied by: (a) a legislative proposal to amend this Regulation in order to include additional services within the digital sector in the list of core platform services laid down in Article 2, point (2), or to include new obligations in Chapter III; or (b) a draft delegated act supplementing this Regulation with regard to the obligations laid down in Articles 5 and 6, or a draft delegated act amending or supplementing this Regulation with regard to the obligations laid down in Article 7, as provided for in Article 12. Where appropriate, the legislative proposal to amend this Regulation under point (a) of the second subparagraph may also propose to remove existing services from the list of core platform services laid down in Article 2, point (2), or to remove existing obligations from Article 5, 6 or 7.",article,"The Digital Markets Act (DMA) allows the Commission to investigate new services and practices in the digital sector. This is to determine if any should be added to the list of core platform services, or if there are any unfair practices that limit competition. The Commission can consult third parties, including business and end users, during the investigation. The findings will be published in a report within 18 months. If necessary, the report may be accompanied by a proposal to amend the DMA to include additional services or obligations, or a draft act to supplement or amend the DMA. The proposal could also suggest removing existing services or obligations."
Digital Markets Act (DMA) - Article 18 Market investigation into systematic non-compliance,0.714035451,"Details of Article 18 Market investigation into systematic non-compliance in the Digital Markets Act (DMA): 1. The Commission may conduct a market investigation for the purpose of examining whether a gatekeeper has engaged in systematic non-compliance. The Commission shall conclude that market investigation within 12 months from the date referred to in Article 16(3), point (a). Where the market investigation shows that a gatekeeper has systematically infringed one or more of the obligations laid down in Article 5, 6 or 7 and has maintained, strengthened or extended its gatekeeper position in relation to the requirements set out in Article 3(1), the Commission may adopt an implementing act imposing on such gatekeeper any behavioural or structural remedies which are proportionate and necessary to ensure effective compliance with this Regulation. That implementing act shall be adopted in accordance with the advisory procedure referred to in Article 50(2). 2. The remedy imposed in accordance with paragraph 1 of this Article may include, to the extent that such remedy is proportionate and necessary in order to maintain or restore fairness and contestability as affected by the systematic noncompliance, the prohibition, during a limited period, for the gatekeeper to enter into a concentration within the meaning of Article 3 of Regulation (EC) No 139/2004 regarding the core platform services or the other services provided in the digital sector or enabling the collection of data that are affected by the systematic non-compliance. 3. A gatekeeper shall be deemed to have engaged in systematic non-compliance with the obligations laid down in Articles 5, 6 and 7, where the Commission has issued at least three non-compliance decisions pursuant to Article 29 against a gatekeeper in relation to any of its core platform services within a period of 8 years prior to the adoption of the decision opening a market investigation in view of the possible adoption of a decision pursuant to this Article. 4. The Commission shall communicate its preliminary findings to the gatekeeper concerned within 6 months from the date referred to in Article 16(3), point (a). In its preliminary findings, the Commission shall explain whether it preliminarily considers that the conditions of paragraph 1 of this Article are met and which remedy or remedies it preliminarily considers necessary and proportionate. 5. In order to enable interested third parties to effectively provide comments, the Commission shall, at the same time as communicating its preliminary findings to the gatekeeper pursuant to paragraph 4 or as soon as possible thereafter, publish a non-confidential summary of the case and the remedies that it is considering imposing. The Commission shall specify a reasonable timeframe within which such comments are to be provided. 6. Where the Commission intends to adopt a decision pursuant to paragraph 1 of this Article by making commitments offered by the gatekeeper pursuant to Article 25 binding, it shall publish a non-confidential summary of the case and the main content of the commitments. Interested third parties may submit their comments within a reasonable timeframe which shall be set by the Commission. 7. In the course of the market investigation, the Commission may extend its duration where such extension is justified on objective grounds and proportionate. The extension may apply to the deadline by which the Commission has to issue its preliminary findings, or to the deadline for adoption of the final decision. The total duration of any extension or extensions pursuant to this paragraph shall not exceed 6 months. 8. In order to ensure effective compliance by the gatekeeper with its obligations laid down in Articles 5, 6 and 7, the Commission shall regularly review the remedies that it imposes in accordance with paragraphs 1 and 2 of this Article. The Commission shall be entitled to modify those remedies if, following a new market investigation, it finds that they are not effective.",article,"The Digital Markets Act (DMA) allows the Commission to investigate if a digital platform (known as a gatekeeper) is repeatedly breaking the rules. If the gatekeeper is found to be in violation, the Commission can impose penalties to ensure they comply with the law. These penalties can include restricting the gatekeeper from expanding its services for a certain period. A gatekeeper is considered to be a repeat offender if the Commission has issued at least three non-compliance decisions against it within an 8 year period. The Commission will share its initial findings with the gatekeeper and allow for third parties to comment on the case. The investigation should be completed within a year, but can be extended if necessary. The Commission will regularly review the penalties imposed to ensure they are effective."
General Data Protection Regulation (GDPR) - Contextual Paragraph (35),0.714019,"Details of the Contextual Paragraph (35) in the General Data Protection Regulation (GDPR): Personal data concerning health should include all data pertaining to the health status of a data subject which reveal information relating to the past, current or future physical or mental health status of the data subject. This includes information about the natural person collected in the course of the registration for, or the provision of, health care services as referred to in Directive 2011/24/EU of the European Parliament and of the Council ( 1 ) to that natural person; a number, symbol or particular assigned to a natural person to uniquely identify the natural person for health purposes; information derived from the testing or examination of a body part or bodily substance, including from genetic data and biological samples; and any information on, for example, a disease, disability, disease risk, medical history, clinical treatment or the physiological or biomedical state of the data subject independent of its source, for example from a physician or other health professional, a hospital, a medical device or an in vitro diagnostic test.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 35) about health-related personal data. This covers all information about a person's past, present, or future physical or mental health. It includes data collected during health care services, unique identifiers used for health purposes, results from tests or examinations, and any other health-related information, such as disease history or treatment details. This information can come from various sources, like doctors, hospitals, or medical devices."
Digital Markets Act (DMA) - Definition of data,0.71401757,"Details of the Definition of data in the Digital Markets Act (DMA): ""data"" means any digital representation of acts, facts or information and any compilation of such acts, facts or information, including in the form of sound, visual or audiovisual recording;",rectial,"The Digital Markets Act (DMA) has a new definition for ""data"". According to this law, ""data"" refers to any information that is digitally represented. This can include actions, facts, or any other type of information. This data can be in the form of sound, visuals, or audiovisual recordings. Essentially, any piece of information that is digitally recorded or represented falls under the definition of ""data"" in this law."
General Data Protection Regulation (GDPR) - Article 91 Existing data protection rules of churches and religious associations,0.713997126,"Details of Article 91 Existing data protection rules of churches and religious associations in the General Data Protection Regulation (GDPR): 1. Where in a Member State, churches and religious associations or communities apply, at the time of entry into force of this Regulation, comprehensive rules relating to the protection of natural persons with regard to processing, such rules may continue to apply, provided that they are brought into line with this Regulation. 2. Churches and religious associations which apply comprehensive rules in accordance with paragraph 1 of this Article shall be subject to the supervision of an independent supervisory authority, which may be specific, provided that it fulfils the conditions laid down in Chapter VI of this Regulation.",article,"Article 91 of the General Data Protection Regulation (GDPR) states that churches and religious associations can continue to use their existing data protection rules, as long as they align with the GDPR. These organizations must be overseen by an independent authority to ensure they comply with the regulation. This authority can be specific to the organization, but must meet the conditions outlined in Chapter VI of the GDPR."
Digital Markets Act (DMA) - Definition of ranking,0.71397841,"Details of the Definition of ranking in the Digital Markets Act (DMA): ""ranking"" means the relative prominence given to goods or services offered through online intermediation services, online social networking services, video-sharing platform services or virtual assistants, or the relevance given to search results by online search engines, as presented, organised or communicated by the undertakings providing online intermediation services, online social networking services, video-sharing platform services, virtual assistants or online search engines, irrespective of the technological means used for such presentation, organisation or communication and irrespective of whether only one result is presented or communicated;",rectial,"The Digital Markets Act (DMA) introduces a new definition for ""ranking"". According to DMA, ""ranking"" refers to the importance or relevance assigned to products or services on online platforms such as social networking sites, video-sharing platforms, virtual assistants, or search engines. This applies no matter how the information is displayed, arranged, or communicated, and regardless of the technology used. It also applies whether only one result or multiple results are shown."
California Consumer Privacy Act Regulations (CCPA) - Definition of Privacy policy,0.713954449,"Details of Definition of Privacy policy in the California Consumer Privacy Act Regulations (CCPA): Privacy policy as referred to in Civil Code section 1798.130, subdivision (a)(5), means the statement that a business shall make available to consumers describing the businesss practices, both online and offline, regarding the collection, use, disclosure, and sale of personal information, and of the rights of consumers regarding their own personal information.",recital,"The California Consumer Privacy Act (CCPA) defines a ""Privacy Policy"" as a statement that businesses must provide to consumers. This policy explains how the business collects, uses, discloses, and sells personal information, both online and offline. It also informs consumers about their rights concerning their own personal information."
Digital Services Act (DSA) - Article 46 Codes of conduct,0.713950157,"Article 46 Codes of conduct in the Digital Services Act (DSA):  1.   The Commission shall encourage and facilitate the drawing up of voluntary codes of conduct at Union level by providers of online platforms and other relevant service providers, such as providers of online advertising intermediary services, other actors involved in the programmatic advertising value chain, or organisations representing recipients of the service and civil society organisations or relevant authorities to contribute to further transparency for actors in the online advertising value chain beyond the requirements of Articles 26 and 39.

2.   The Commission shall aim to ensure that the codes of conduct pursue an effective transmission of information that fully respects the rights and interests of all parties involved, as well as a competitive, transparent and fair environment in online advertising, in accordance with Union and national law, in particular on competition and the protection of privacy and personal data. The Commission shall aim to ensure that the codes of conduct at least address the following:

(a) the transmission of information held by providers of online advertising intermediaries to recipients of the service concerning the requirements set in Article 26(1), points (b), (c) and (d);
(b) the transmission of information held by providers of online advertising intermediaries to the repositories pursuant to Article 39;
(c) meaningful information on data monetisation.

3.   The Commission shall encourage the development of the codes of conduct by 18 February 2025 and their application by 18 August 2025.

4.   The Commission shall encourage all the actors in the online advertising value chain referred to in paragraph 1 to endorse the commitments stated in the codes of conduct, and to comply with them.",article,"The Digital Services Act (DSA) encourages the creation of voluntary codes of conduct for online platforms and related service providers, including those involved in online advertising. These codes aim to enhance transparency beyond the requirements of Articles 26 and 39. The European Commission will ensure that these codes respect the rights and interests of all involved parties, while promoting a competitive, transparent, and fair online advertising environment. The codes should address the transmission of information by online advertising intermediaries, and provide meaningful information on data monetisation. The Commission aims to develop these codes by February 2025 and implement them by August 2025. All participants in the online advertising value chain are encouraged to endorse and comply with these codes."
Artifical Inellegence Act (AI Act) - Article 8,0.713937759,"Aritifical Intelligence Act (AI Act) Article 8 Compliance with the requirements:

1.High-risk AI systems shall comply with the requirements established in this Chapter.

2.The intended purpose of the high-risk AI system and the risk management system referred to in Article 9 shall be taken into account when ensuring compliance with those requirements.",article,"The Artificial Intelligence Act (AI Act) requires that high-risk AI systems must meet certain standards. These standards take into account the system's intended purpose and the risk management system mentioned in Article 9. In simpler terms, if you're using a high-risk AI system, you need to make sure it follows the rules set out in this law. These rules consider what you're using the AI for and how you're managing any risks involved."
Artifical Inellegence Act (AI Act) - Article 69,0.713898897,"Aritifical Intelligence Act (AI Act) Article 69 Codes of conduct:

1.The Commission and the Member States shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems other than high-risk AI systems of the requirements set out in Title III, Chapter 2 on the basis of technical specifications and solutions that are appropriate means of ensuring compliance with such requirements in light of the intended purpose of the systems.

2.The Commission and the Board shall encourage and facilitate the drawing up of codes of conduct intended to foster the voluntary application to AI systems of requirements related for example to environmental sustainability, accessibility for persons with a disability, stakeholders participation in the design and development of the AI systems and diversity of development teams on the basis of clear objectives and key performance indicators to measure the achievement of those objectives.

3.Codes of conduct may be drawn up by individual providers of AI systems or by organisations representing them or by both, including with the involvement of users and any interested stakeholders and their representative organisations. Codes of conduct may cover one or more AI systems taking into account the similarity of the intended purpose of the relevant systems.

4.The Commission and the Board shall take into account the specific interests and needs of the small-scale providers and start-ups when encouraging and facilitating the drawing up of codes of conduct.
",article,"The Artificial Intelligence Act (AI Act) Article 69 encourages the development of codes of conduct for AI systems. These codes should promote voluntary compliance with requirements related to technical specifications and objectives like environmental sustainability, accessibility for disabled persons, and diversity in development teams. These codes can be created by AI providers, organizations representing them, or both, and should consider the interests of small providers and start-ups. The codes can apply to one or more AI systems, depending on their intended purpose."
General Data Protection Regulation (GDPR) - Contextual Paragraph (26),0.713897526,"Details of the Contextual Paragraph (26) in the General Data Protection Regulation (GDPR): The principles of data protection should apply to any information concerning an identified or identifiable natural person. Personal data which have undergone pseudonymisation, which could be attributed to a natural person by the use of additional information should be considered to be information on an identifiable natural person. To determine whether a natural person is identifiable, account should be taken of all the means reasonably likely to be used, such as singling out, either by the controller or by another person to identify the natural person directly or indirectly. To ascertain whether means are reasonably likely to be used to identify the natural person, account should be taken of all objective factors, such as the costs of and the amount of time required for identification, taking into consideration the available technology at the time of the processing and technological developments. The principles of data protection should therefore not apply to anonymous information, namely information which does not relate to an identified or identifiable natural person or to personal data rendered anonymous in such a manner that the data subject is not or no longer identifiable. This Regulation does not therefore concern the processing of such anonymous information, including for statistical or research purposes.",recital,"The General Data Protection Regulation (GDPR) Paragraph 26 states that data protection rules apply to any information related to a person who can be identified directly or indirectly. This includes data that has been pseudonymised (disguised) but could still be linked to a person using additional information. Whether a person can be identified depends on various factors, including the cost and time required for identification, as well as the technology available. However, these rules do not apply to anonymous information that doesn't relate to an identifiable person. Therefore, processing of such anonymous information, for example for research or statistical purposes, is not covered by this regulation."
Artifical Inellegence Act (AI Act) - Article 57,0.7138744,"Aritifical Intelligence Act (AI Act) Article 57 Structure of the Board:

1.The Board shall be composed of the national supervisory authorities, who shall be represented by the head or equivalent high-level official of that authority, and the European Data Protection Supervisor. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.

2.The Board shall adopt its rules of procedure by a simple majority of its members, following the consent of the Commission. The rules of procedure shall also contain the operational aspects related to the execution of the Boards tasks as listed in Article 58. The Board may establish sub-groups as appropriate for the purpose of examining specific questions.

3.The Board shall be chaired by the Commission. The Commission shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and with its rules of procedure. The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.

4.The Board may invite external experts and observers to attend its meetings and may hold exchanges with interested third parties to inform its activities to an appropriate extent. To that end the Commission may facilitate exchanges between the Board and other Union bodies, offices, agencies and advisory groups.",article,"The Artificial Intelligence Act (AI Act) Article 57 discusses the structure of a new board. This board will be made up of national supervisory authorities and the European Data Protection Supervisor. Other national authorities can join meetings if relevant. The board will create its own rules with the approval of the Commission. These rules will also cover how the board will carry out its tasks. The board can form sub-groups to look into specific issues. The Commission will lead the board, organize meetings, set the agenda, and provide administrative and analytical support. The board can invite external experts and observers to its meetings and can interact with interested third parties. The Commission can help facilitate these interactions."
Digital Services Act (DSA) - Article 24 Transparency reporting obligations,0.713784277,"Article 24 Transparency reporting obligations for providers of online platforms in the Digital Services Act (DSA):  1.   In addition to the information referred to in Article 15, providers of online platforms shall include in the reports referred to in that Article information on the following:

(a) the number of disputes submitted to the out-of-court dispute settlement bodies referred to in Article 21, the outcomes of the dispute settlement, and the median time needed for completing the dispute settlement procedures, as well as the share of disputes where the provider of the online platform implemented the decisions of the body;

(b) the number of suspensions imposed pursuant to Article 23, distinguishing between suspensions enacted for the provision of manifestly illegal content, the submission of manifestly unfounded notices and the submission of manifestly unfounded complaints.

2.   By 17 February 2023 and at least once every six months thereafter, providers shall publish for each online platform or online search engine, in a publicly available section of their online interface, information on the average monthly active recipients of the service in the Union, calculated as an average over the period of the past six months and in accordance with the methodology laid down in the delegated acts referred to in Article 33(3), where those delegated acts have been adopted.

3.   Providers of online platforms or of online search engines shall communicate to the Digital Services Coordinator of establishment and the Commission, upon their request and without undue delay, the information referred to in paragraph 2, updated to the moment of such request. That Digital Services Coordinator or the Commission may require the provider of the online platform or of the online search engine to provide additional information as regards the calculation referred to in that paragraph, including explanations and substantiation in respect of the data used. That information shall not include personal data.

4.   When the Digital Services Coordinator of establishment has reasons to consider, based the information received pursuant to paragraphs 2 and 3 of this Article, that a provider of online platforms or of online search engines meets the threshold of average monthly active recipients of the service in the Union laid down in Article 33(1), it shall inform the Commission thereof.

5.   Providers of online platforms shall, without undue delay, submit to the Commission the decisions and the statements of reasons referred to in Article 17(1) for the inclusion in a publicly accessible machine-readable database managed by the Commission. Providers of online platforms shall ensure that the information submitted does not contain personal data.

6.   The Commission may adopt implementing acts to lay down templates concerning the form, content and other details of reports pursuant to paragraph 1 of this Article. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.",article,"The Digital Services Act (DSA) requires online platform providers to be more transparent. They must report on the number of disputes they've had, their outcomes, and how long they took to resolve. They also need to report on suspensions related to illegal content or unfounded complaints. Every six months, starting February 2023, they must publicly disclose the average number of monthly users in the EU. They must also provide this information to the Digital Services Coordinator and the Commission upon request, excluding personal data. If the Coordinator believes a provider meets the threshold for average monthly users, they will inform the Commission. Providers must also submit decisions and reasons for public database inclusion to the Commission, ensuring no personal data is included. The Commission may create templates for these reports."
Digital Markets Act (DMA) - Article 53 Review,0.71374315,"Details of Article 53 Review in the Digital Markets Act (DMA): 2. The evaluations shall assess whether the aims of this Regulation of ensuring contestable and fair markets have been achieved and assess the impact of this Regulation on business users, especially SMEs, and end users. Moreover, the Commission shall evaluate if the scope of Article 7 may be extended to online social networking services. 3. The evaluations shall establish whether it is required to modify rules, including regarding the list of core platform services laid down in Article 2, point (2), the obligations laid down in Articles 5, 6 and 7 and their enforcement, to ensure that digital markets across the Union are contestable and fair. Following the evaluations, the Commission shall take appropriate measures, which may include legislative proposals. 4. The competent authorities of Member States shall provide any relevant information they have that the Commission may require for the purposes of drawing up the report referred to in paragraph 1.",article,"The Digital Markets Act (DMA) Article 53 Review is a new law that will evaluate if the objectives of creating fair and competitive digital markets are being met. It will assess the law's impact on businesses, particularly small and medium-sized enterprises (SMEs), and consumers. It will also consider if the law should be extended to cover online social networking services. The review will determine if changes to the rules are needed to ensure fairness and competitiveness in digital markets across the European Union. Based on the review, the Commission may propose new legislation. Authorities from member states are required to provide any relevant information for this review."
Digital Markets Act (DMA) - Article 3 Designation of gatekeepers,0.713726,"Details of Article 3 Designation of gatekeepers in the Digital Markets Act (DMA): 1. An undertaking shall be designated as a gatekeeper if: (a) it has a significant impact on the internal market; (b) it provides a core platform service which is an important gateway for business users to reach end users; and (c) it enjoys an entrenched and durable position, in its operations, or it is foreseeable that it will enjoy such a position in the near future. 2. An undertaking shall be presumed to satisfy the respective requirements in paragraph 1: (a) as regards paragraph 1, point (a), where it achieves an annual Union turnover equal to or above EUR 7,5 billion in each of the last three financial years, or where its average market capitalisation or its equivalent fair market value amounted to at least EUR 75 billion in the last financial year, and it provides the same core platform service in at least three Member States; (b) as regards paragraph 1, point (b), where it provides a core platform service that in the last financial year has at least 45 million monthly active end users established or located in the Union and at least 10 000 yearly active business users established in the Union, identified and calculated in accordance with the methodology and indicators set out in the Annex; (c) as regards paragraph 1, point (c), where the thresholds in point (b) of this paragraph were met in each of the last three financial years. 3. Where an undertaking providing core platform services meets all of the thresholds in paragraph 2, it shall notify the Commission thereof without delay and in any event within 2 months after those thresholds are met and provide it with the relevant information identified in paragraph 2. That notification shall include the relevant information identified in paragraph 2 for each of the core platform services of the undertaking that meets the thresholds in paragraph 2, point (b). Whenever a further core platform service provided by the undertaking that has previously been designated as a gatekeeper meets the thresholds in paragraph 2, points (b) and (c), such undertaking shall notify the Commission thereof within 2 months after those thresholds are satisfied. Where the undertaking providing the core platform service fails to notify the Commission pursuant to the first subparagraph of this paragraph and fails to provide within the deadline set by the Commission in the request for information pursuant to Article 21 all the relevant information that is required for the Commission to designate the undertaking concerned as gatekeeper pursuant to paragraph 4 of this Article, the Commission shall still be entitled to designate that undertaking as a gatekeeper, based on information available to the Commission. Where the undertaking providing core platform services complies with the request for information pursuant to the second subparagraph of this paragraph or where the information is provided after the expiration of the deadline referred to in that subparagraph, the Commission shall apply the procedure set out in paragraph 4. 4. The Commission shall designate as a gatekeeper, without undue delay and at the latest within 45 working days after receiving the complete information referred to in paragraph 3, an undertaking providing core platform services that meets all the thresholds in paragraph 2. 5. The undertaking providing core platform services may present, with its notification, sufficiently substantiated arguments to demonstrate that, exceptionally, although it meets all the thresholds in paragraph 2, due to the circumstances in which the relevant core platform service operates, it does not satisfy the requirements listed in paragraph 1. Where the Commission considers that the arguments submitted pursuant to the first subparagraph by the undertaking providing core platform services are not sufficiently substantiated because they do not manifestly call into question the presumptions set out in paragraph 2 of this Article, it may reject those arguments within the time limit referred to in paragraph 4, without applying the procedure laid down in Article 17(3). Where the undertaking providing core platform services does present such sufficiently substantiated arguments manifestly calling into question the presumptions in paragraph 2 of this Article, the Commission may, notwithstanding the first subparagraph of this paragraph, within the time limit referred to in paragraph 4 of this Article, open the procedure laid down in Article 17(3). If the Commission concludes that the undertaking providing core platform services was not able to demonstrate that the relevant core platform services that it provides do not satisfy the requirements of paragraph 1 of this Article, it shall designate that undertaking as a gatekeeper in accordance with the procedure laid down in Article 17(3). 6. The Commission is empowered to adopt delegated acts in accordance with Article 49 to supplement this Regulation by specifying the methodology for determining whether the quantitative thresholds laid down in paragraph 2 of this Article are met, and to regularly adjust that methodology to market and technological developments, where necessary. 7. The Commission is empowered to adopt delegated acts in accordance with Article 49 to amend this Regulation by updating the methodology and the list of indicators set out in the Annex. 8. The Commission shall designate as a gatekeeper, in accordance with the procedure laid down in Article 17, any undertaking providing core platform services that meets each of the requirements of paragraph 1 of this Article, but does not satisfy each of the thresholds in paragraph 2 of this Article. For that purpose, the Commission shall take into account some or all of the following elements, insofar as they are relevant for the undertaking providing core platform services under consideration: (a) the size, including turnover and market capitalisation, operations and position of that undertaking; (b) the number of business users using the core platform service to reach end users and the number of end users; c) network effects and data driven advantages, in particular in relation to that undertaking""s access to, and collection of, personal data and non-personal data or analytics capabilities; (d) any scale and scope effects from which the undertaking benefits, including with regard to data, and, where relevant, to its activities outside the Union; (e) business user or end user lock-in, including switching costs and behavioural bias reducing the ability of business users and end users to switch or multi-home; (f) a conglomerate corporate structure or vertical integration of that undertaking, for instance enabling that undertaking to cross subsidise, to combine data from different sources or to leverage its position; or (g) other structural business or service characteristics. In carrying out its assessment under this paragraph, the Commission shall take into account foreseeable developments in relation to the elements listed in the second subparagraph, including any planned concentrations involving another undertaking providing core platform services or providing any other services in the digital sector or enabling the collection of data. Where an undertaking providing a core platform service that does not satisfy the quantitative thresholds of paragraph 2 fails to comply with the investigative measures ordered by the Commission in a significant manner, and that failure persists after that undertaking has been invited to comply within a reasonable time limit and to submit observations, the Commission may designate that undertaking as a gatekeeper on the basis of the facts available to the Commission. 9. For each undertaking designated as a gatekeeper pursuant to paragraph 4 or 8, the Commission shall list in the designation decision the relevant core platform services that are provided within that undertaking and which individually are an important gateway for business users to reach end users as referred to in paragraph 1, point (b). 10. The gatekeeper shall comply with the obligations laid down in Articles 5, 6 and 7 within 6 months after a core platform service has been listed in the designation decision pursuant to paragraph 9 of this Article.",article,"The Digital Markets Act (DMA) introduces the concept of a ""gatekeeper,"" which refers to a company that has a significant impact on the internal market, provides a core platform service that is crucial for businesses to reach consumers, and holds a strong and lasting position in its operations. A company is presumed to be a gatekeeper if it meets certain financial thresholds, such as having a turnover of EUR 7.5 billion in the last three years or a market value of EUR 75 billion in the last year. It must also have at least 45 million monthly active users and 10,000 yearly active business users in the Union. If a company meets these criteria, it must inform the Commission within two months. The Commission then has 45 working days to designate the company as a gatekeeper. If a company argues that it does not meet the gatekeeper criteria despite meeting the financial thresholds, the Commission can reject or accept these arguments based on the evidence provided."
Artifical Inellegence Act (AI Act) - Overview paragraph 43,0.713715315,"Aritifical Intelligence Act (AI Act) overview paragraph (43): Requirements should apply to high-risk AI systems as regards the quality of data sets used, technical documentation and record-keeping, transparency and the provision of information to users, human oversight, and robustness, accuracy and cybersecurity. Those requirements are necessary to effectively mitigate the risks for health, safety and fundamental rights, as applicable in the light of the intended purpose of the system, and no other less trade restrictive measures are reasonably available, thus avoiding unjustified restrictions to trade.",recital,"The Artificial Intelligence Act (AI Act) sets rules for high-risk AI systems to ensure they are safe, transparent, and respect users' rights. These rules cover the quality of data used, technical documentation, record-keeping, transparency, user information, human supervision, and system robustness, accuracy, and cybersecurity. These requirements are essential to reduce risks to health, safety, and basic rights, considering the system's intended use. The Act ensures that there are no unnecessary trade restrictions, as no other less restrictive measures are reasonably available."
Artifical Inellegence Act (AI Act) - Article 59,0.713683605,"Aritifical Intelligence Act (AI Act) Article 59 Designation of national competent authorities:

1.National competent authorities shall be established or designated by each Member State for the purpose of ensuring the application and implementation of this Regulation. National competent authorities shall be organised so as to safeguard the objectivity and impartiality of their activities and tasks.

2.Each Member State shall designate a national supervisory authority among the national competent authorities. The national supervisory authority shall act as notifying authority and market surveillance authority unless a Member State has organisational and administrative reasons to designate more than one authority.

3.Member States shall inform the Commission of their designation or designations and, where applicable, the reasons for designating more than one authority.

4.Member States shall ensure that national competent authorities are provided with adequate financial and human resources to fulfil their tasks under this Regulation. In particular, national competent authorities shall have a sufficient number of personnel permanently available whose competences and expertise shall include an in-depth understanding of artificial intelligence technologies, data and data computing, fundamental rights, health and safety risks and knowledge of existing standards and legal requirements.

5.Member States shall report to the Commission on an annual basis on the status of the financial and human resources of the national competent authorities with an assessment of their adequacy. The Commission shall transmit that information to the Board for discussion and possible recommendations.

6.The Commission shall facilitate the exchange of experience between national competent authorities.

7.National competent authorities may provide guidance and advice on the implementation of this Regulation, including to small-scale providers. Whenever national competent authorities intend to provide guidance and advice with regard to an AI system in areas covered by other Union legislation, the competent national authorities under that Union legislation shall be consulted, as appropriate. Member States may also establish one central contact point for communication with operators.

8.When Union institutions, agencies and bodies fall within the scope of this Regulation, the European Data Protection Supervisor shall act as the competent authority for their supervision.",article,"The Artificial Intelligence Act (AI Act) requires each member state to establish national authorities to ensure the law is applied and implemented properly. These authorities must be objective and impartial. Each state must also designate a national supervisory authority to oversee the market and notify the Commission of their designations. These authorities need to have sufficient resources and staff with expertise in artificial intelligence, data, fundamental rights, health and safety risks, and legal requirements. States must report annually on the status of these resources. The Commission will facilitate experience sharing between authorities and they may provide guidance on the law's implementation, including to small-scale providers. If an AI system is covered by other Union legislation, the relevant authorities must be consulted. A central contact point for communication with operators may be established. The European Data Protection Supervisor will supervise Union institutions, agencies, and bodies under this law."
Artifical Inellegence Act (AI Act) - Context Section 1.2,0.713674128,"Aritifical Intelligence Act (AI Act) context section 1.2.Consistency with existing policy provisions in the policy area: 

The horizontal nature of the proposal requires full consistency with existing Union legislation applicable to sectors where high-risk AI systems are already used or likely to be used in the near future.

Consistency is also ensured with the EU Charter of Fundamental Rights and the existing secondary Union legislation on data protection, consumer protection, non-discrimination and gender equality. The proposal is without prejudice and complements the General Data Protection Regulation (Regulation (EU) 2016/679) and the Law Enforcement Directive (Directive (EU) 2016/680) with a set of harmonised rules applicable to the design, development and use of certain high-risk AI systems and restrictions on certain uses of remote biometric identification systems. Furthermore, the proposal complements existing Union law on non-discrimination with specific requirements that aim to minimise the risk of algorithmic discrimination, in particular in relation to the design and the quality of data sets used for the development of AI systems complemented with obligations for testing, risk management, documentation and human oversight throughout the AI systems lifecycle. The proposal is without prejudice to the application of Union competition law.

As regards high-risk AI systems which are safety components of products, this proposal will be integrated into the existing sectoral safety legislation to ensure consistency, avoid duplications and minimise additional burdens. In particular, as regards high-risk AI systems related to products covered by the New Legislative Framework (NLF) legislation (e.g. machinery, medical devices, toys), the requirements for AI systems set out in this proposal will be checked as part of the existing conformity assessment procedures under the relevant NLF legislation. With regard to the interplay of requirements, while the safety risks specific to AI systems are meant to be covered by the requirements of this proposal, NLF legislation aims at ensuring the overall safety of the final product and therefore may contain specific requirements regarding the safe integration of an AI system into the final product. The proposal for a Machinery Regulation, which is adopted on the same day as this proposal fully reflects this approach. As regards high-risk AI systems related to products covered by relevant Old Approach legislation (e.g. aviation, cars), this proposal would not directly apply. However, the ex-ante essential requirements for high-risk AI systems set out in this proposal will have to be taken into account when adopting relevant implementing or delegated legislation under those acts.

As regards AI systems provided or used by regulated credit institutions, the authorities responsible for the supervision of the Unions financial services legislation should be designated as competent authorities for supervising the requirements in this proposal to ensure a coherent enforcement of the obligations under this proposal and the Unions financial services legislation where AI systems are to some extent implicitly regulated in relation to the internal governance system of credit institutions. To further enhance consistency, the conformity assessment procedure and some of the providers procedural obligations under this proposal are integrated into the procedures under Directive 2013/36/EU on access to the activity of credit institutions and the prudential supervision 14 . 

This proposal is also consistent with the applicable Union legislation on services, including on intermediary services regulated by the e-Commerce Directive 2000/31/EC 15 and the Commissions recent proposal for the Digital Services Act (DSA) 16 .

In relation to AI systems that are components of large-scale IT systems in the Area of Freedom, Security and Justice managed by the European Union Agency for the Operational Management of Large-Scale IT Systems (eu-LISA), the proposal will not apply to those AI systems that have been placed on the market or put into service before one year has elapsed from the date of application of this Regulation, unless the replacement or amendment of those legal acts leads to a significant change in the design or intended purpose of the AI system or AI systems concerned.1.2.Consistency with existing policy provisions in the policy area:

The horizontal nature of the proposal requires full consistency with existing Union legislation applicable to sectors where high-risk AI systems are already used or likely to be used in the near future.

Consistency is also ensured with the EU Charter of Fundamental Rights and the existing secondary Union legislation on data protection, consumer protection, non-discrimination and gender equality. The proposal is without prejudice and complements the General Data Protection Regulation (Regulation (EU) 2016/679) and the Law Enforcement Directive (Directive (EU) 2016/680) with a set of harmonised rules applicable to the design, development and use of certain high-risk AI systems and restrictions on certain uses of remote biometric identification systems. Furthermore, the proposal complements existing Union law on non-discrimination with specific requirements that aim to minimise the risk of algorithmic discrimination, in particular in relation to the design and the quality of data sets used for the development of AI systems complemented with obligations for testing, risk management, documentation and human oversight throughout the AI systems lifecycle. The proposal is without prejudice to the application of Union competition law.

As regards high-risk AI systems which are safety components of products, this proposal will be integrated into the existing sectoral safety legislation to ensure consistency, avoid duplications and minimise additional burdens. In particular, as regards high-risk AI systems related to products covered by the New Legislative Framework (NLF) legislation (e.g. machinery, medical devices, toys), the requirements for AI systems set out in this proposal will be checked as part of the existing conformity assessment procedures under the relevant NLF legislation. With regard to the interplay of requirements, while the safety risks specific to AI systems are meant to be covered by the requirements of this proposal, NLF legislation aims at ensuring the overall safety of the final product and therefore may contain specific requirements regarding the safe integration of an AI system into the final product. The proposal for a Machinery Regulation, which is adopted on the same day as this proposal fully reflects this approach. As regards high-risk AI systems related to products covered by relevant Old Approach legislation (e.g. aviation, cars), this proposal would not directly apply. However, the ex-ante essential requirements for high-risk AI systems set out in this proposal will have to be taken into account when adopting relevant implementing or delegated legislation under those acts.

As regards AI systems provided or used by regulated credit institutions, the authorities responsible for the supervision of the Unions financial services legislation should be designated as competent authorities for supervising the requirements in this proposal to ensure a coherent enforcement of the obligations under this proposal and the Unions financial services legislation where AI systems are to some extent implicitly regulated in relation to the internal governance system of credit institutions. To further enhance consistency, the conformity assessment procedure and some of the providers procedural obligations under this proposal are integrated into the procedures under Directive 2013/36/EU on access to the activity of credit institutions and the prudential supervision 14 . 

This proposal is also consistent with the applicable Union legislation on services, including on intermediary services regulated by the e-Commerce Directive 2000/31/EC 15 and the Commissions recent proposal for the Digital Services Act (DSA) 16 .

In relation to AI systems that are components of large-scale IT systems in the Area of Freedom, Security and Justice managed by the European Union Agency for the Operational Management of Large-Scale IT Systems (eu-LISA), the proposal will not apply to those AI systems that have been placed on the market or put into service before one year has elapsed from the date of application of this Regulation, unless the replacement or amendment of those legal acts leads to a significant change in the design or intended purpose of the AI system or AI systems concerned.",recital,"The Artificial Intelligence Act (AI Act) aims to align with existing EU laws, particularly those related to high-risk AI systems. It supports the EU Charter of Fundamental Rights and legislation on data protection, consumer protection, non-discrimination, and gender equality. It adds to the General Data Protection Regulation and the Law Enforcement Directive by providing rules for high-risk AI systems and restrictions on certain uses of remote biometric identification systems. The Act ensures AI systems do not discriminate by setting standards for design and data quality, and requiring testing, risk management, documentation, and human oversight. The Act will be integrated into existing safety legislation for high-risk AI systems in products like machinery, medical devices, and toys. It will not directly apply to high-risk AI systems in aviation and cars but will influence related legislation. AI systems used by credit institutions will be supervised by financial services authorities. The Act also aligns with EU legislation on services, including e-commerce and digital services, and will apply to AI systems in large-scale IT systems managed by the EU, unless they were in service for over a year before the Act's application."
General Data Protection Regulation (GDPR) - Contextual Paragraph (61),0.713647664,"Details of the Contextual Paragraph (61) in the General Data Protection Regulation (GDPR): The information in relation to the processing of personal data relating to the data subject should be given to him or her at the time of collection from the data subject, or, where the personal data are obtained from another source, within a reasonable period, depending on the circumstances of the case. Where personal data can be legitimately disclosed to another recipient, the data subject should be informed when the personal data are first disclosed to the recipient. Where the controller intends to process the personal data for a purpose other than that for which they were collected, the controller should provide the data subject prior to that further processing with information on that other purpose and other necessary information. Where the origin of the personal data cannot be provided to the data subject because various sources have been used, general information should be provided.",recital,"The General Data Protection Regulation (GDPR) states that individuals must be informed when their personal data is collected, whether it's collected directly from them or obtained from another source. If the data is shared with another party, the individual must be notified at the time of first disclosure. If the data is going to be used for something other than its original purpose, the individual must be informed of this new purpose beforehand. If the data comes from multiple sources and its origin can't be specified, the individual should receive general information about the sources."
Artifical Inellegence Act (AI Act) - Article 14,0.713636696,"Aritifical Intelligence Act (AI Act) Article 14 Human oversight:

1.High-risk AI systems shall be designed and developed in such a way, including with appropriate human-machine interface tools, that they can be effectively overseen by natural persons during the period in which the AI system is in use.

2.Human oversight shall aim at preventing or minimising the risks to health, safety or fundamental rights that may emerge when a high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, in particular when such risks persist notwithstanding the application of other requirements set out in this Chapter.

3.Human oversight shall be ensured through either one or all of the following measures:

(a)identified and built, when technically feasible, into the high-risk AI system by the provider before it is placed on the market or put into service;

(b)identified by the provider before placing the high-risk AI system on the market or putting it into service and that are appropriate to be implemented by the user.

4.The measures referred to in paragraph 3 shall enable the individuals to whom human oversight is assigned to do the following, as appropriate to the circumstances:

(a)fully understand the capacities and limitations of the high-risk AI system and be able to duly monitor its operation, so that signs of anomalies, dysfunctions and unexpected performance can be detected and addressed as soon as possible;

(b)remain aware of the possible tendency of automatically relying or over-relying on the output produced by a high-risk AI system (automation bias), in particular for high-risk AI systems used to provide information or recommendations for decisions to be taken by natural persons;

(c)be able to correctly interpret the high-risk AI systems output, taking into account in particular the characteristics of the system and the interpretation tools and methods available;

(d)be able to decide, in any particular situation, not to use the high-risk AI system or otherwise disregard, override or reverse the output of the high-risk AI system;

(e)be able to intervene on the operation of the high-risk AI system or interrupt the system through a stop button or a similar procedure.

5.For high-risk AI systems referred to in point 1(a) of Annex III, the measures referred to in paragraph 3 shall be such as to ensure that, in addition, no action or decision is taken by the user on the basis of the identification resulting from the system unless this has been verified and confirmed by at least two natural persons.",article,"The Artificial Intelligence Act (AI Act) Article 14 requires high-risk AI systems to be created in a way that allows for human oversight. This is to prevent or minimize potential risks to health, safety, or basic rights that could arise from using the AI system, even when used as intended. This human oversight can be achieved through measures built into the system by the provider before it's released to the market, or identified by the provider and implemented by the user. These measures should allow individuals overseeing the system to fully understand its capabilities and limitations, detect issues, be aware of potential overreliance on the system, interpret the system's output, decide not to use the system or override its output, and intervene in the system's operation. For certain high-risk AI systems, any action or decision based on the system's identification must be verified by at least two people."
California Consumer Privacy Act Regulations (CCPA) - Article 5. Special Rules Regarding Consumers Under 16 Years of Age -  999.331 Consumers 13 to 15 Years of Age,0.713632107,"Details of Article 5. Special Rules Regarding Consumers Under 16 Years of Age -  999.331 Consumers 13 to 15 Years of Age in the California Consumer Privacy Act Regulations (CCPA): (a) A business that has actual knowledge that it sells the personal information of consumers at least 13 years of age and less than 16 years of age shall establish, document, and comply with a reasonable process for allowing such consumers to opt-in to the sale of their personal information, pursuant to section 999.316. (b) When a business receives a request to opt-in to the sale of personal information from a consumer at least 13 years of age and less than 16 years of age, the business shall inform the consumer of the right to opt-out at a later date and of the process for doing so pursuant to section 999.315.",article,"The California Consumer Privacy Act (CCPA) has a new rule, Article 5, for businesses dealing with the personal information of consumers aged 13 to 15. If a business knowingly sells these young consumers' personal data, they must create a clear process allowing these consumers to choose if they want their data sold, as per section 999.316. Additionally, if a consumer within this age group asks to have their information sold, the business must let them know they can change their mind later and how to do so, according to section 999.315."
Digital Markets Act (DMA) - Article 17 Market investigation for designating gatekeepers,0.713575721,"Details of Article 17 Market investigation for designating gatekeepers in the Digital Markets Act (DMA): 1. The Commission may conduct a market investigation for the purpose of examining whether an undertaking providing core platform services should be designated as a gatekeeper pursuant to Article 3(8), or in order to identify the core platform services to be listed in the designation decision pursuant to Article 3(9). The Commission shall endeavour to conclude its market investigation within 12 months from the date referred to in Article 16(3), point (a), In order to conclude its market investigation, the Commission shall adopt an implementing act setting out its decision. That implementing act shall be adopted in accordance with the advisory procedure referred to in Article 50(2). 2. In the course of a market investigation pursuant to paragraph 1 of this Article, the Commission shall endeavour to communicate its preliminary findings to the undertaking providing core platform services concerned within 6 months from the date referred to in Article 16(3), point (a). In the preliminary findings, the Commission shall explain whether it considers, on a provisional basis, that it is appropriate for that undertaking to be designated as a gatekeeper pursuant to Article 3(8), and for the relevant core platform services to be listed pursuant to Article 3(9). 3. Where the undertaking providing core platform services satisfies the thresholds set out in Article 3(2), but has presented sufficiently substantiated arguments in accordance with Article 3(5) that have manifestly called into question the presumption in Article 3(2), the Commission shall endeavour to conclude the market investigation within 5 months from the date referred to in Article 16(3), point (a). In such a case, the Commission shall endeavour to communicate its preliminary findings pursuant to paragraph 2 of this Article to the undertaking concerned within 3 months from the date referred to in Article 16(3), point (a). 4. When the Commission, pursuant to Article 3(8), designates as a gatekeeper an undertaking providing core platform services that does not yet enjoy an entrenched and durable position in its operations, but which will foreseeably enjoy such a position in the near future, it may declare applicable to that gatekeeper only one or more of the obligations laid down in Article 5(3) to (6) and Article 6(4), (7), (9), (10) and (13), as specified in the designation decision. The Commission shall only declare applicable those obligations that are appropriate and necessary to prevent the gatekeeper concerned from achieving, by unfair means, an entrenched and durable position in its operations. The Commission shall review such a designation in accordance with the procedure laid down in Article 4.",article,"The Digital Markets Act (DMA) allows the Commission to investigate whether a company providing core platform services should be designated as a 'gatekeeper'. This process should be completed within 12 months, and the Commission will communicate its preliminary findings to the company within 6 months. If a company meets the criteria but presents strong arguments against being designated as a gatekeeper, the investigation should conclude within 5 months, with preliminary findings communicated within 3 months. If a company is designated as a gatekeeper but doesn't yet have a strong position in its operations, the Commission can apply only certain obligations to prevent the company from unfairly gaining a strong position. This designation will be reviewed as per the procedure in Article 4."
Artifical Inellegence Act (AI Act) - Overview paragraph 29,0.713563204,"Aritifical Intelligence Act (AI Act) overview paragraph (29): As regards high-risk AI systems that are safety components of products or systems, or which are themselves products or systems falling within the scope of Regulation (EC) No 300/2008 of the European Parliament and of the Council39, Regulation (EU) No 167/2013of the European Parliament and of the Council40, Regulation (EU) No 168/2013of the European Parliament and of the Council41, Directive 2014/90/EUofthe European Parliament and of the Council42, Directive (EU) 2016/797of the European Parliament and of the Council43, Regulation (EU) 2018/858of the European Parliament and of the Council44, Regulation (EU) 2018/1139 of the European Parliament and of the Council45, and Regulation (EU) 2019/2144of the European Parliament and of the Council46, it is appropriate to amend those acts to ensure that the Commission takes into account, on the basis of the technical and regulatory specificities of each sector, and without interfering with existing governance, conformity assessment and enforcement mechanisms and authorities established therein, the mandatory requirements for high-risk AI systems laid down in this Regulation when adopting any relevant future delegated or implementing acts on the basis of those acts.",recital,"The Artificial Intelligence Act (AI Act) states that high-risk AI systems, which are either safety components of products or systems, or are products or systems themselves, will be subject to amendments to ensure they comply with the new regulations. These amendments will be made to a range of existing European laws. The aim is to ensure that the Commission considers the mandatory requirements for high-risk AI systems when adopting any relevant future acts. This will be done without interfering with the existing governance, assessment, and enforcement mechanisms and authorities. The changes will be based on the technical and regulatory specifics of each sector."
Artifical Inellegence Act (AI Act) - Overview paragraph 50,0.713532388,"Aritifical Intelligence Act (AI Act) overview paragraph (50): The technical robustness is a key requirement for high-risk AI systems. They should be resilient against risks connected to the limitations of the system (e.g. errors, faults, inconsistencies, unexpected situations) as well as against malicious actions that may compromise the security of the AI system and result in harmful or otherwise undesirable behaviour. Failure to protect against these risks could lead to safety impacts or negatively affect the fundamental rights, for example due to erroneous decisions or wrong or biased outputs generated by the AI system.",recital,"The Artificial Intelligence Act (AI Act) emphasizes the importance of creating strong, reliable AI systems, particularly those considered high-risk. These systems should be able to handle errors, faults, and unexpected situations without compromising their security or causing harm. They should also be resistant to any harmful actions that could negatively affect their function. If these risks aren't properly managed, it could lead to safety issues or violations of fundamental rights, such as making incorrect decisions or producing biased results."
General Data Protection Regulation (GDPR) - Definition of third party,0.713478863,"Details of the Definition of third party in the General Data Protection Regulation (GDPR): ""third party"" means a natural or legal person, public authority, agency or body other than the data subject, controller, processor and persons who, under the direct authority of the controller or processor, are authorised to process personal data;",recital,"The General Data Protection Regulation (GDPR) defines a ""third party"" as any individual, company, government body, or organization that isn't the person whose data is being collected (data subject), the entity collecting the data (controller), the entity processing the data (processor), or someone authorized by the controller or processor to handle the data. This means anyone else who might get access to your personal data is considered a ""third party"" under GDPR."
Digital Markets Act (DMA) - Definition of software application stores,0.713440299,"Details of the Definition of software application stores in the Digital Markets Act (DMA): ""software application stores"" means a type of online intermediation services, which is focused on software applications as the intermediated product or service;",rectial,"The Digital Markets Act (DMA) introduces a new term, ""software application stores"". This refers to online platforms that primarily deal with software applications. These are services which act as a middleman for buying or selling software applications."
General Data Protection Regulation (GDPR) - Article 5 Principles relating to processing of personal data,0.713406503,"Details of Article 5 Principles relating to processing of personal data in the General Data Protection Regulation (GDPR): 1. Personal data shall be: (a) processed lawfully, fairly and in a transparent manner in relation to the data subject (lawfulness, fairness and transparency); (b) collected for specified, explicit and legitimate purposes and not further processed in a manner that is incompatible with those purposes; further processing for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes shall, in accordance with Article 89(1), not be considered to be incompatible with the initial purposes (purpose limitation); (c) adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed (data minimisation); (d) accurate and, where necessary, kept up to date; every reasonable step must be taken to ensure that personal data that are inaccurate, having regard to the purposes for which they are processed, are erased or rectified without delay (accuracy); (e) kept in a form which permits identification of data subjects for no longer than is necessary for the purposes for which the personal data are processed; personal data may be stored for longer periods insofar as the personal data will be processed solely for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes in accordance with Article 89(1) subject to implementation of the appropriate technical and organisational measures required by this Regulation in order to safeguard the rights and freedoms of the data subject (storage limitation); (f) processed in a manner that ensures appropriate security of the personal data, including protection against unauthorised or unlawful processing and against accidental loss, destruction or damage, using appropriate technical or organisational measures (integrity and confidentiality). 2. The controller shall be responsible for, and be able to demonstrate compliance with, paragraph 1 (accountability).",article,"Article 5 of the General Data Protection Regulation (GDPR) outlines the rules for handling personal data. It states that personal data must be processed lawfully, fairly, and transparently. It should only be collected for specific, clear, and legitimate purposes and not used in ways that don't align with these purposes. The data collected should be adequate, relevant, and limited to what is necessary. It should be accurate, up-to-date, and stored only as long as necessary. It should also be kept secure to prevent unauthorized access or accidental loss. The entity controlling the data (the 'controller') must be able to prove they are following these rules."
Digital Markets Act (DMA) - Article 1,0.713395894,"Details of Article 1 in the Digital Markets Act (DMA): Article 1 Subject matter and scope 1. The purpose of this Regulation is to contribute to the proper functioning of the internal market by laying down harmonised rules ensuring for all businesses, contestable and fair markets in the digital sector across the Union where gatekeepers are present, to the benefit of business users and end users. 2. This Regulation shall apply to core platform services provided or offered by gatekeepers to business users established in the Union or end users established or located in the Union, irrespective of the place of establishment or residence of the gatekeepers and irrespective of the law otherwise applicable to the provision of service. 3. This Regulation shall not apply to markets related to: (a) electronic communications networks as defined in Article 2, point (1), of Directive (EU) 2018/1972; (b) electronic communications services as defined in Article 2, point (4), of Directive (EU) 2018/1972, other than those related to number-independent interpersonal communications services. 4. With regard to interpersonal communications services as defined in Article 2, point (5) of Directive (EU) 2018/1972, this Regulation is without prejudice to the powers and responsibilities granted to the national regulatory and other competent authorities by virtue of Article 61 of that Directive. 5. In order to avoid the fragmentation of the internal market, Member States shall not impose further obligations on gatekeepers by way of laws, regulations or administrative measures for the purpose of ensuring contestable and fair markets. Nothing in this Regulation precludes Member States from imposing obligations on undertakings, including undertakings providing core platform services, for matters falling outside the scope of this Regulation, provided that those obligations are compatible with Union law and do not result from the fact that the relevant undertakings have the status of a gatekeeper within the meaning of this Regulation. 6. This Regulation is without prejudice to the application of Articles 101 and 102 TFEU. It is also without prejudice to the application of: (a) national competition rules prohibiting anti-competitive agreements, decisions by associations of undertakings, concerted practices and abuses of dominant positions; (b) national competition rules prohibiting other forms of unilateral conduct insofar as they are applied to undertakings other than gatekeepers or amount to the imposition of further obligations on gatekeepers; and (c) Council Regulation (EC) No 139/2004 ( 23) and national rules concerning merger control. 7. National authorities shall not take decisions which run counter to a decision adopted by the Commission under this Regulation. The Commission and Member States shall work in close cooperation and coordinate their enforcement actions on the basis of the principles established in Articles 37 and 38.",article,"The Digital Markets Act (DMA) aims to ensure fair and competitive digital markets across the European Union (EU). It applies to major digital platforms (gatekeepers) providing services to businesses or users within the EU, regardless of where the gatekeeper is based. The DMA doesn't apply to certain electronic communication networks and services. It doesn't interfere with national authorities' powers over interpersonal communication services. Member states cannot impose additional obligations on gatekeepers to ensure fair competition, but they can impose obligations for matters outside the DMA's scope, as long as they're compatible with EU law. The DMA doesn't affect the application of EU and national competition rules or merger control rules. National authorities must not contradict decisions made by the Commission under the DMA, and they should work closely with the Commission to coordinate enforcement actions."
Artifical Inellegence Act (AI Act) - Definition of 'authorised representative',0.713380218,"Within the Aritifical Intelligence Act (AI Act), the Definition of authorised representative means any natural or legal person established in the Union who has received a written mandate from a provider of an AI system to, respectively, perform and carry out on its behalf the obligations and procedures established by this Regulation;",recital,"The Artificial Intelligence Act (AI Act) defines an 'authorized representative' as any individual or organization based in the Union who has been officially appointed by an AI system provider to fulfill its responsibilities and follow the procedures set by this law. They act on behalf of the AI system provider, based on a written agreement."
Artifical Inellegence Act (AI Act) - Article 20,0.713372707,"Aritifical Intelligence Act (AI Act) Article 19 Conformity assessment:

1.Providers of high-risk AI systems shall ensure that their systems undergo the relevant conformity assessment procedure in accordance with Article 43, prior to their placing on the market or putting into service. Where the compliance of the AI systems with the requirements set out in Chapter 2 of this Title has been demonstrated following that conformity assessment, the providers shall draw up an EU declaration of conformity in accordance with Article 48 and affix the CE marking of conformity in accordance with Article 49.

2.For high-risk AI systems referred to in point 5(b) of Annex III that are placed on the market or put into service by providers that are credit institutions regulated by Directive 2013/36/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.",article,"The Artificial Intelligence Act (AI Act) requires that providers of high-risk AI systems must have their systems go through a conformity assessment procedure before they can be sold or used. This is to ensure that these systems meet certain safety and performance standards. If they pass the assessment, the providers must then make a formal declaration of conformity and mark their products accordingly. For high-risk AI systems provided by credit institutions, the assessment will be part of the procedure outlined in Directive 2013/36/EU."
Artifical Inellegence Act (AI Act) - Article 56,0.713286221,"Aritifical Intelligence Act (AI Act) Article 56 Establishment of the European Artificial Intelligence Board:

1.A European Artificial Intelligence Board (the Board) is established.

2.The Board shall provide advice and assistance to the Commission in order to:

(a)contribute to the effective cooperation of the national supervisory authorities and the Commission with regard to matters covered by this Regulation;

(b)coordinate and contribute to guidance and analysis by the Commission and the national supervisory authorities and other competent authorities on emerging issues across the internal market with regard to matters covered by this Regulation;

(c)assist the national supervisory authorities and the Commission in ensuring the consistent application of this Regulation.",article,"The Artificial Intelligence Act (AI Act) has established a new body called the 'European Artificial Intelligence Board'. This Board is designed to help the Commission by providing advice and assistance. Its main roles are to enhance cooperation between national supervisory authorities and the Commission, help coordinate guidance and analysis on emerging AI-related issues, and ensure the consistent application of this Regulation across the market."
Digital Markets Act (DMA) - Definition of gatekeeper,0.71322459,"Details of the Definition of gatekeeper in the Digital Markets Act (DMA): ""gatekeeper"" means an undertaking providing core platform services, designated pursuant to Article 3",rectial,"The Digital Markets Act (DMA) introduces a new term, ""gatekeeper"". This refers to a business that provides core platform services, as determined by Article 3 of the Act. Essentially, a gatekeeper is a company that controls a key part of the digital market, like a major social media platform or online marketplace. The DMA uses this term to identify and regulate these influential companies."
Artifical Inellegence Act (AI Act) - Context Section 1.3,0.713141084,"Aritifical Intelligence Act (AI Act) context section 1.3.Consistency with other Union policies: 

The proposal is part of a wider comprehensive package of measures that address problems posed by the development and use of AI, as examined in the White Paper on AI. Consistency and complementarity is therefore ensured with other ongoing or planned initiatives of the Commission that also aim to address those problems, including the revision of sectoral product legislation (e.g. the Machinery Directive, the General Product Safety Directive) and initiatives that address liability issues related to new technologies, including AI systems. Those initiatives will build on and complement this proposal in order to bring legal clarity and foster the development of an ecosystem of trust in AI in Europe.

The proposal is also coherent with the Commissions overall digital strategy in its contribution to promoting technology that works for people, one of the three main pillars of the policy orientation and objectives announced in the Communication Shaping Europe's digital future 17 . It lays down a coherent, effective and proportionate framework to ensure AI is developed in ways that respect peoples rights and earn their trust, making Europe fit for the digital age and turning the next ten years into the Digital Decade 18 .

Furthermore, the promotion of AI-driven innovation is closely linked to the Data Governance Act 19 , the Open Data Directive 20 and other initiatives under the EU strategy for data 21 , which will establish trusted mechanisms and services for the re-use, sharing and pooling of data that are essential for the development of data-driven AI models of high quality.

The proposal also strengthens significantly the Unions role to help shape global norms and standards and promote trustworthy AI that is consistent with Union values and interests. It provides the Union with a powerful basis to engage further with its external partners, including third countries, and at international fora on issues relating to AI.1.3.Consistency with other Union policies:

The proposal is part of a wider comprehensive package of measures that address problems posed by the development and use of AI, as examined in the White Paper on AI. Consistency and complementarity is therefore ensured with other ongoing or planned initiatives of the Commission that also aim to address those problems, including the revision of sectoral product legislation (e.g. the Machinery Directive, the General Product Safety Directive) and initiatives that address liability issues related to new technologies, including AI systems. Those initiatives will build on and complement this proposal in order to bring legal clarity and foster the development of an ecosystem of trust in AI in Europe.

The proposal is also coherent with the Commissions overall digital strategy in its contribution to promoting technology that works for people, one of the three main pillars of the policy orientation and objectives announced in the Communication Shaping Europe's digital future 17 . It lays down a coherent, effective and proportionate framework to ensure AI is developed in ways that respect peoples rights and earn their trust, making Europe fit for the digital age and turning the next ten years into the Digital Decade 18 .

Furthermore, the promotion of AI-driven innovation is closely linked to the Data Governance Act 19 , the Open Data Directive 20 and other initiatives under the EU strategy for data 21 , which will establish trusted mechanisms and services for the re-use, sharing and pooling of data that are essential for the development of data-driven AI models of high quality.

The proposal also strengthens significantly the Unions role to help shape global norms and standards and promote trustworthy AI that is consistent with Union values and interests. It provides the Union with a powerful basis to engage further with its external partners, including third countries, and at international fora on issues relating to AI.",recital,"The Artificial Intelligence Act (AI Act) is a new law that's part of a larger package aiming to address issues caused by AI development and use. It aligns with other initiatives, including revisions of product legislation and dealing with liability issues related to new technologies like AI. The goal is to create a trusted AI environment in Europe. The AI Act also aligns with the Commission's digital strategy, promoting technology that benefits people and respects their rights. The Act supports AI-driven innovation, tying in with the Data Governance Act and the Open Data Directive, which facilitate data sharing for high-quality AI models. The Act also strengthens the Union's role in shaping global AI norms and standards, promoting AI that aligns with Union values and interests, and providing a basis for engaging with external partners on AI-related issues."
General Data Protection Regulation (GDPR) - Article 59 Activity reports,0.713134468,"Details of Article 59 Activity reports in the General Data Protection Regulation (GDPR): Each supervisory authority shall draw up an annual report on its activities, which may include a list of types of infringement notified and types of measures taken in accordance with Article 58(2). Those reports shall be transmitted to the national parliament, the government and other authorities as designated by Member State law. They shall be made available to the public, to the Commission and to the Board.",article,"Article 59 of the General Data Protection Regulation (GDPR) mandates that each supervisory authority must compile an annual report of their activities. This report may include a list of notified infringements and measures taken as per Article 58(2). These reports must be submitted to the national parliament, government, and other designated authorities. Furthermore, they must be made publicly available, as well as accessible to the Commission and the Board."
Digital Markets Act (DMA) - Article 50 Committee procedure,0.713092089,"Details of Article 50 Committee procedure in the Digital Markets Act (DMA): 1. The Commission shall be assisted by a committee (""the Digital Markets Advisory Committee""). That committee shall be a committee within the meaning of Regulation (EU) No 182/2011. 2. Where reference is made to this paragraph, Article 4 of Regulation (EU) No 182/2011 shall apply. Where the opinion of the committee is to be obtained by written procedure, that procedure shall be terminated without result when, within the time limit for delivery of the opinion, the chair of the committee so decides or a simple majority of committee members so request. 3. Where reference is made to this paragraph, Article 5 of Regulation (EU) No 182/2011 shall apply. 4. The Commission shall communicate the opinion of the committee to the addressee of an individual decision, together with that decision. It shall make the opinion public together with the individual decision, having regard to the legitimate interest in the protection of professional secrecy.",article,"The Digital Markets Act (DMA) establishes a Digital Markets Advisory Committee to assist the European Commission. This committee operates under the guidelines of Regulation (EU) No 182/2011. The committee's opinion can be obtained through a written procedure, but this can be ended without a result if the chair decides or a majority of members request it. The Commission must share the committee's opinion with the recipient of an individual decision, and make it public, while also maintaining professional secrecy."
Digital Services Act (DSA) - Definition of 'distance contract',0.713044286,"Definition of 'distance contract' in the Digital Services Act (DSA): 'distance contract' as defined in Article 2, point (7), of Directive 2011/83/EU.",recital,"The Digital Services Act (DSA) introduces a term called 'distance contract', which it defines using Article 2, point (7), of Directive 2011/83/EU. In simpler terms, a 'distance contract' refers to any contract made without the buyer and seller meeting in person, such as online purchases or over the phone. This is a part of the new DSA law, which aims to regulate digital services more effectively."
General Data Protection Regulation (GDPR) - Article 34 Communication of a personal data breach to the data subject,0.713000655,"Details of Article 34 Communication of a personal data breach to the data subject in the General Data Protection Regulation (GDPR): 1. When the personal data breach is likely to result in a high risk to the rights and freedoms of natural persons, the controller shall communicate the personal data breach to the data subject without undue delay. 2. The communication to the data subject referred to in paragraph 1 of this Article shall describe in clear and plain language the nature of the personal data breach and contain at least the information and measures referred to in points (b), (c) and (d) of Article 33(3). 3. The communication to the data subject referred to in paragraph 1 shall not be required if any of the following conditions are met: (a) the controller has implemented appropriate technical and organisational protection measures, and those measures were applied to the personal data affected by the personal data breach, in particular those that render the personal data unintelligible to any person who is not authorised to access it, such as encryption; (b) the controller has taken subsequent measures which ensure that the high risk to the rights and freedoms of data subjects referred to in paragraph 1 is no longer likely to materialise; (c) it would involve disproportionate effort. In such a case, there shall instead be a public communication or similar measure whereby the data subjects are informed in an equally effective manner. 4. If the controller has not already communicated the personal data breach to the data subject, the supervisory authority, having considered the likelihood of the personal data breach resulting in a high risk, may require it to do so or may decide that any of the conditions referred to in paragraph 3 are met.",article,"The General Data Protection Regulation (GDPR) Article 34 mandates that if there's a data breach that poses a high risk to individuals' rights and freedoms, the organization responsible must promptly inform the affected individuals. This notification should clearly describe the nature of the breach and the steps taken in response. However, if the organization has already implemented strong data protection measures (like encryption), taken steps to eliminate the risk, or if notifying individuals would require disproportionate effort, they may not need to inform the individuals directly. Instead, a public announcement can be made. If the organization hasn't informed the affected individuals, the supervisory authority can decide whether it's necessary or if the conditions for exemption are met."
Digital Services Act (DSA) - Definition of 'recommender system',0.712994576,"Definition of 'recommender system' in the Digital Services Act (DSA): a fully or partially automated system used by an online platform to suggest in its online interface specific information to recipients of the service or prioritise that information, including as a result of a search initiated by the recipient of the service or otherwise determining the relative order or prominence of information displayed.",recital,"The Digital Services Act (DSA) introduces a term called 'recommender system'. This is a system, either fully or partially automated, used by online platforms to suggest or highlight specific information to its users. This could be through search results initiated by the user or by deciding the order or importance of the information displayed on the platform."
Artifical Inellegence Act (AI Act) - Overview paragraph 80,0.712940454,"Aritifical Intelligence Act (AI Act) overview paragraph (80): Union legislation on financial services includes internal governance and risk management rules and requirements which are applicable to regulated financial institutions in the course of provision of those services, including when they make use of AI systems. In order to ensure coherent application and enforcement of the obligations under this Regulation and relevant rules and requirements of the Union financial services legislation, the authorities responsible for the supervision and enforcement of the financial services legislation,including where applicable the European Central Bank,should be designated as competent authorities for the purpose of supervising the implementation of this Regulation, including for market surveillance activities, as regards AI systems provided or used by regulated and supervised financial institutions. To further enhance the consistency between this Regulation and the rules applicable to credit institutions regulated under Directive 2013/36/EU of the European Parliament and of the Council56, it is also appropriate to integrate the conformity assessment procedure and some of the providers procedural obligations in relation to risk management, post marketing monitoring and documentation into the existing obligations and procedures under Directive 2013/36/EU. In order to avoid overlaps, limited derogations should also be envisaged in relation to the quality management system of providers and the monitoring obligation placed on users of high-risk AI systems to the extent that these apply to credit institutions regulated by Directive 2013/36/EU.",recital,"The Artificial Intelligence Act (AI Act) is a new law that applies to financial institutions using AI systems. It includes rules for internal governance and risk management. The authorities responsible for overseeing financial services, including the European Central Bank, will also supervise the implementation of this law. This includes monitoring the market for AI systems used by regulated financial institutions. The law also integrates some procedures for risk management, monitoring, and documentation into existing obligations under the Directive 2013/36/EU. To avoid duplication, there are some exceptions for credit institutions regulated by Directive 2013/36/EU in relation to the quality management system and the monitoring of high-risk AI systems."
Digital Services Act (DSA) - Article 77 Limitation period for the imposition of penalties,0.712933123,"Article 77 Limitation period for the imposition of penalties in the Digital Services Act (DSA):  1.   The powers conferred on the Commission by Articles 74 and 76 shall be subject to a limitation period of five years.

2.   Time shall begin to run on the day on which the infringement is committed. However, in the case of continuing or repeated infringements, time shall begin to run on the day on which the infringement ceases.

3.   Any action taken by the Commission or by the Digital Services Coordinator for the purpose of the investigation or proceedings in respect of an infringement shall interrupt the limitation period for the imposition of fines or periodic penalty payments. Actions which interrupt the limitation period shall include, in particular, the following:

(a) requests for information by the Commission or by a Digital Services Coordinator;
(b) inspection;
(c) the opening of a proceeding by the Commission pursuant to Article 66(1).

4.   Each interruption shall start time running afresh. However, the limitation period for the imposition of fines or periodic penalty payments shall expire at the latest on the day on which a period equal to twice the limitation period has elapsed without the Commission having imposed a fine or a periodic penalty payment. That period shall be extended by the time during which the limitation period has been suspended pursuant to paragraph 5.

5.   The limitation period for the imposition of fines or periodic penalty payments shall be suspended for as long as the decision of the Commission is the subject of proceedings pending before the Court of Justice of the European Union.",article,"The Digital Services Act (DSA) states that the Commission has up to five years to impose penalties for violations. This five-year period starts from the day the violation occurs, or if the violation is ongoing, from the day it stops. If the Commission or the Digital Services Coordinator takes action, such as requesting information or opening an investigation, this five-year period restarts. However, the maximum time for penalties to be imposed is double the original five-year period, unless the case is still being reviewed by the Court of Justice of the European Union, in which case the time limit is paused."
General Data Protection Regulation (GDPR) - Definition of biometric data,0.712907434,"Details of the Definition of biometric data in the General Data Protection Regulation (GDPR): ""biometric data"" means personal data resulting from specific technical processing relating to the physical, physiological or behavioural characteristics of a natural person, which allow or confirm the unique identification of that natural person, such as facial images or dactyloscopic data;",recital,"The General Data Protection Regulation (GDPR) has defined ""biometric data"" as personal information collected using special technical methods. This information is related to the physical, physiological, or behavioral traits of an individual. It's used to uniquely identify that person. Examples of biometric data include facial images or fingerprint data."
Artifical Inellegence Act (AI Act) - Article 7,0.712906122,"Aritifical Intelligence Act (AI Act) Article 7 Amendments to Annex III:

1.The Commission is empowered to adopt delegated acts in accordance with Article 73 to update the list in Annex III by adding high-risk AI systems where both of the following conditions are fulfilled:

(a)the AI systems are intended to be used in any of the areas listed in points 1 to 8 of Annex III;

(b)the AI systems pose a risk of harm to the health and safety, or a risk of adverse impact on fundamental rights, that is, in respect of its severity and probability of occurrence, equivalent to or greater than the risk of harm or of adverse impact posed by the high-risk AI systems already referred to in Annex III.

2.When assessing for the purposes of paragraph 1 whether an AI system poses a risk of harm to the health and safety or a risk of adverse impact on fundamental rights that is equivalent to or greater than the risk of harm posed by the high-risk AI systems already referred to in Annex III, the Commission shall take into account the following criteria:

(a)the intended purpose of the AI system;

(b)the extent to which an AI system has been used or is likely to be used;

(c)the extent to which the use of an AI system has already caused harm to the health and safety or adverse impact on the fundamental rights or has given rise to significant concerns in relation to the materialisation of such harm or adverse impact, as demonstrated by reports or documented allegations submitted to national competent authorities;

(d)the potential extent of such harm or such adverse impact, in particular in terms of its intensity and its ability to affect a plurality of persons;

(e)the extent to which potentially harmed or adversely impacted persons are dependent on the outcome produced with an AI system, in particular because for practical or legal reasons it is not reasonably possible to opt-out from that outcome;

(f)the extent to which potentially harmed or adversely impacted persons are in a vulnerable position in relation to the user of an AI system, in particular due to an imbalance of power, knowledge, economic or social circumstances, or age;

(g)the extent to which the outcome produced with an AI system is easily reversible, whereby outcomes having an impact on the health or safety of persons shall not be considered as easily reversible;

(h)the extent to which existing Union legislation provides for:

(i)effective measures of redress in relation to the risks posed by an AI system, with the exclusion of claims for damages;

(ii)effective measures to prevent or substantially minimise those risks.",article,"The Artificial Intelligence Act (AI Act) empowers the Commission to add high-risk AI systems to the Annex III list if they are intended for use in certain areas and pose a risk to health, safety, or fundamental rights. The risk must be equivalent to or greater than those posed by existing high-risk AI systems. The Commission will assess these risks based on the AI system's intended purpose, its usage, any previous harm caused, the potential extent of harm, the dependency of individuals on the system's outcomes, the vulnerability of individuals to the user of the system, the reversibility of the system's outcomes, and the existing laws that provide redress or prevention measures for the risks posed by the AI system."
Digital Services Act (DSA) - Definition of 'illegal content',0.712873578,"Definition of 'illegal content' in the Digital Services Act (DSA): any information that, in itself or in relation to an activity, including the sale of products or the provision of services, is not in compliance with Union law or the law of any Member State which is in compliance with Union law, irrespective of the precise subject matter or nature of that law.",recital,"The Digital Services Act (DSA) defines 'illegal content' as any information or activity, including selling products or providing services, that doesn't follow either the Union law or the law of any member state that adheres to the Union law. This applies no matter what the specific topic or type of law is."
Artifical Inellegence Act (AI Act) - Definition of 'national supervisory authority',0.712866366,"Within the Aritifical Intelligence Act (AI Act), the Definition of national supervisory authority means the authority to which a Member State assigns the responsibility for the implementation and application of this Regulation, for coordinating the activities entrusted to that Member State, for acting as the single contact point for the Commission, and for representing the Member State at the European Artificial Intelligence Board;",recital,"The Artificial Intelligence Act (AI Act) introduces a 'national supervisory authority'. This is an organization chosen by each member country to ensure the law is followed within their territory. This authority will also coordinate related activities within the country, act as the main contact for the Commission overseeing the Act, and represent the country in the European Artificial Intelligence Board."
Digital Services Act (DSA) - Article 30 Traceability of traders,0.712840378,"Article 30 Traceability of traders in the Digital Services Act (DSA):  1.   Providers of online platforms allowing consumers to conclude distance contracts with traders shall ensure that traders can only use those online platforms to promote messages on or to offer products or services to consumers located in the Union if, prior to the use of their services for those purposes, they have obtained the following information, where applicable to the trader:

(a) the name, address, telephone number and email address of the trader;
(b) a copy of the identification document of the trader or any other electronic identification as defined by Article 3 of Regulation (EU) No 910/2014 of the European Parliament and of the Council (40);
(c) the payment account details of the trader;
(d)  where the trader is registered in a trade register or similar public register, the trade register in which the trader is registered and its registration number or equivalent means of identification in that register;
(e) a self-certification by the trader committing to only offer products or services that comply with the applicable rules of Union law.

2.   Upon receiving the information referred to in paragraph 1 and prior to allowing the trader concerned to use its services, the provider of the online platform allowing consumers to conclude distance contracts with traders shall, through the use of any freely accessible official online database or online interface made available by a Member State or the Union or through requests to the trader to provide supporting documents from reliable sources, make best efforts to assess whether the information referred to in paragraph 1, points (a) to (e), is reliable and complete. For the purpose of this Regulation, traders shall be liable for the accuracy of the information provided.

As regards traders that are already using the services of providers of online platforms allowing consumers to conclude distance contracts with traders for the purposes referred to in paragraph 1 on 17 February 2024, the providers shall make best efforts to obtain the information listed from the traders concerned within 12 months. Where the traders concerned fail to provide the information within that period, the providers shall suspend the provision of their services to those traders until they have provided all information.

3.   Where the provider of the online platform allowing consumers to conclude distance contracts with traders obtains sufficient indications or has reason to believe that any item of information referred to in paragraph 1 obtained from the trader concerned is inaccurate, incomplete or not up-to-date, that provider shall request that the trader remedy that situation without delay or within the period set by Union and national law.

Where the trader fails to correct or complete that information, the provider of the online platform allowing consumers to conclude distance contracts with traders shall swiftly suspend the provision of its service to that trader in relation to the offering of products or services to consumers located in the Union until the request has been fully complied with.

4.   Without prejudice to Article 4 of Regulation (EU) 2019/1150, if a provider of an online platform allowing consumers to conclude distance contracts with traders refuses to allow a trader to use its service pursuant to paragraph 1, or suspends the provision of its service pursuant to paragraph 3 of this Article, the trader concerned shall have the right to lodge a complaint as provided for in Articles 20 and 21 of this Regulation.

5.   Providers of online platforms allowing consumers to conclude distance contracts with traders shall store the information obtained pursuant to paragraphs 1 and 2 in a secure manner for a period of six months after the end of the contractual relationship with the trader concerned. They shall subsequently delete the information.

6.   Without prejudice to paragraph 2 of this Article, the provider of the online platform allowing consumers to conclude distance contracts with traders shall only disclose the information to third parties where so required in accordance with the applicable law, including the orders referred to in Article 10 and any orders issued by Member States' competent authorities or the Commission for the performance of their tasks under this Regulation.

7.   The provider of the online platform allowing consumers to conclude distance contracts with traders shall make the information referred to in paragraph 1, points (a), (d) and (e) available on its online platform to the recipients of the service in a clear, easily accessible and comprehensible manner. That information shall be available at least on the online platform's online interface where the information on the product or service is presented.",article,"The Digital Services Act (DSA) requires online platforms that facilitate distance contracts between consumers and traders to verify and record trader information. This includes the trader's name, contact details, identification, payment account details, and trade registration details, along with a self-certification that they will comply with Union laws. The platform must verify this information using reliable sources and databases before allowing the trader to use its services. Traders are responsible for the accuracy of the information provided. If the trader fails to provide accurate information, the platform must suspend its services until the issue is resolved. Traders can lodge a complaint if they are denied service. The platform must store the information securely for six months after the contractual relationship ends, and can only disclose it when legally required. Certain trader information must be clearly displayed on the platform."
General Data Protection Regulation (GDPR) - Contextual Paragraph (36),0.712792695,"Details of the Contextual Paragraph (36) in the General Data Protection Regulation (GDPR): The main establishment of a controller in the Union should be the place of its central administration in the Union, unless the decisions on the purposes and means of the processing of personal data are taken in another establishment of the controller in the Union, in which case that other establishment should be considered to be the main establishment. The main establishment of a controller in the Union should be determined according to objective criteria and should imply the effective and real exercise of management activities determining the main decisions as to the purposes and means of processing through stable arrangements. That criterion should not depend on whether the processing of personal data is carried out at that location. The presence and use of technical means and technologies for processing personal data or processing activities do not, in themselves, constitute a main establishment and are therefore not determining criteria for a main establishment. The main establishment of the processor should be the place of its central administration in the Union or, if it has no central administration in the Union, the place where the main processing activities take place in the Union. In cases involving both the controller and the processor, the competent lead supervisory authority should remain the supervisory authority of the Member State where the controller has its main establishment, but the supervisory authority of the processor should be considered to be a supervisory authority concerned and that supervisory authority should participate in the cooperation procedure provided for by this Regulation. In any case, the supervisory authorities of the Member State or Member States where the processor has one or more establishments should not be considered to be supervisory authorities concerned where the draft decision concerns only the controller. Where the processing is carried out by a group of undertakings, the main establishment of the controlling undertaking should be considered to be the main establishment of the group of undertakings, except where the purposes and means of processing are determined by another undertaking.",recital,"The General Data Protection Regulation (GDPR) states that a company's main establishment in the EU is where its central administration is located, unless decisions about personal data processing are made elsewhere. This main establishment isn't determined by where data processing happens or the presence of technical means for processing. If a company doesn't have a central administration in the EU, the main establishment is where most data processing occurs. When both a data controller and processor are involved, the supervisory authority of the country where the controller's main establishment is located is in charge, but the processor's supervisory authority should also participate. However, if a decision only concerns the controller, the processor's supervisory authorities aren't considered involved. If a group of companies is processing data, the main establishment is that of the controlling company, unless another company determines the purposes and means of processing."
General Data Protection Regulation (GDPR) - Definition of controller,0.712774694,"Details of the Definition of controller in the General Data Protection Regulation (GDPR): ""controller"" means the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data; where the purposes and means of such processing are determined by Union or Member State law, the controller or the specific criteria for its nomination may be provided for by Union or Member State law;",recital,"The General Data Protection Regulation (GDPR) introduces a new term, ""controller"". This refers to any individual, company, government agency, or other entity that decides why and how personal data is processed. If EU or member state law dictates how and why the data is processed, it may also specify who the controller is or how one is chosen."
General Data Protection Regulation (GDPR) - Article 56 Competence of the lead supervisory authority,0.712667823,"Details of Article 56 Competence of the lead supervisory authority in the General Data Protection Regulation (GDPR): 1. Without prejudice to Article 55, the supervisory authority of the main establishment or of the single establishment of the controller or processor shall be competent to act as lead supervisory authority for the cross-border processing carried out by that controller or processor in accordance with the procedure provided in Article 60. 2. By derogation from paragraph 1, each supervisory authority shall be competent to handle a complaint lodged with it or a possible infringement of this Regulation, if the subject matter relates only to an establishment in its Member State or substantially affects data subjects only in its Member State. 3. In the cases referred to in paragraph 2 of this Article, the supervisory authority shall inform the lead supervisory authority without delay on that matter. Within a period of three weeks after being informed the lead supervisory authority shall decide whether or not it will handle the case in accordance with the procedure provided in Article 60, taking into account whether or not there is an establishment of the controller or processor in the Member State of which the supervisory authority informed it. 4. Where the lead supervisory authority decides to handle the case, the procedure provided in Article 60 shall apply. The supervisory authority which informed the lead supervisory authority may submit to the lead supervisory authority a draft for a decision. The lead supervisory authority shall take utmost account of that draft when preparing the draft decision referred to in Article 60(3). 5. Where the lead supervisory authority decides not to handle the case, the supervisory authority which informed the lead supervisory authority shall handle it according to Articles 61 and 62. 6. The lead supervisory authority shall be the sole interlocutor of the controller or processor for the cross-border processing carried out by that controller or processor.",article,"Article 56 of the General Data Protection Regulation (GDPR) states that the primary supervisory authority, usually where the main establishment of a data controller or processor is located, is responsible for overseeing cross-border data processing activities. However, any supervisory authority can handle complaints or potential infringements if it only affects their member state. If such a case arises, the lead authority must be informed and has three weeks to decide if it will handle the case. If it decides to handle it, the informing authority can propose a decision draft. If the lead authority decides not to handle the case, the informing authority will take over. The lead authority is the sole point of contact for the data controller or processor for cross-border processing issues."
Artifical Inellegence Act (AI Act) - Article 74,0.712648511,"Aritifical Intelligence Act (AI Act) Article 74 Committee procedure:

1.The Commission shall be assisted by a committee. That committee shall be a committee within the meaning of Regulation (EU) No 182/2011.

2.Where reference is made to this paragraph, Article 5 of Regulation (EU) No 182/2011 shall apply.",article,"The Artificial Intelligence Act (AI Act) Article 74 outlines the formation and operation of a committee to assist the Commission in its work. This committee is established under the guidelines of Regulation (EU) No 182/2011, a pre-existing law in the European Union. The second part of the law refers to the application of Article 5 of Regulation (EU) No 182/2011, which will guide the committee's procedures and operations."
Digital Services Act (DSA) - Definition of 'turnover' ,0.712616563,Definition of 'turnover' in the Digital Services Act (DSA): the amount derived by an undertaking within the meaning of Article 5(1) of Council Regulation (EC) No 139/2004 (39).,recital,"The Digital Services Act (DSA) introduces a new definition for 'turnover'. 'Turnover' refers to the total income generated by a business, as per Article 5(1) of Council Regulation (EC) No 139/2004. In simpler terms, it's the total money a company makes before any expenses are subtracted."
General Data Protection Regulation (GDPR) - Article 72 Procedure,0.712602258,"Details of Article 72 Procedure in the General Data Protection Regulation (GDPR): 1. The Board shall take decisions by a simple majority of its members, unless otherwise provided for in this Regulation. 2. The Board shall adopt its own rules of procedure by a two-thirds majority of its members and organise its own operational arrangements.",article,"Article 72 of the General Data Protection Regulation (GDPR) states that the Board will make decisions using a simple majority vote from its members, unless the Regulation specifies otherwise. Additionally, the Board will establish its own procedural rules and operational arrangements, but this requires a two-thirds majority vote from its members."
Artifical Inellegence Act (AI Act) - Overview paragraph 46,0.71255,"Aritifical Intelligence Act (AI Act) overview paragraph (46): Having information on how high-risk AI systems have been developed and how they perform throughout their lifecycle is essential to verify compliance with the requirements under this Regulation. This requires keeping records and the availability of a technical documentation, containing information which is necessary to assess the compliance of the AI system with the relevant requirements. Such information should include the general characteristics, capabilities and limitations of the system, algorithms, data, training, testing and validation processes used as well as documentation on the relevant risk management system. The technical documentation should be kept up to date.",recital,"The Artificial Intelligence Act (AI Act) requires creators of high-risk AI systems to keep detailed records of the system's development and performance. This includes technical documentation that outlines the system's characteristics, capabilities, limitations, algorithms, data, and the processes used for training, testing, and validation. It also requires documentation on the system's risk management. This information is necessary to check if the AI system meets the law's requirements. The technical documentation must be kept current."
Digital Services Act (DSA) - Definition of 'commercial communication',0.712506831,"Definition of 'commercial communication' in the Digital Services Act (DSA): 'commercial communication' as defined in Article 2, point (f), of Directive 2000/31/EC.",recital,"The Digital Services Act (DSA) has a new definition for 'commercial communication.' This term is defined in Article 2, point (f), of Directive 2000/31/EC. In simpler terms, the DSA has updated the meaning of 'commercial communication' in the context of digital services, as per the specifications in a previous law (Directive 2000/31/EC). This change could affect how businesses communicate online, so it's important to understand the new definition."
Digital Markets Act (DMA) - Article 28 Compliance function,0.71246177,"Details of Article 28 Compliance function in the Digital Markets Act (DMA): 1. Gatekeepers shall introduce a compliance function, which is independent from the operational functions of the gatekeeper and composed of one or more compliance officers, including the head of the compliance function. 2. The gatekeeper shall ensure that the compliance function referred to in paragraph 1 has sufficient authority, stature and resources, as well as access to the management body of the gatekeeper to monitor the compliance of the gatekeeper with this Regulation. 3. The management body of the gatekeeper shall ensure that compliance officers appointed pursuant to paragraph 1 have the professional qualifications, knowledge, experience and ability necessary to fulfil the tasks referred to in paragraph 5. The management body of the gatekeeper shall also ensure that such head of the compliance function is an independent senior manager with distinct responsibility for the compliance function. 4. The head of the compliance function shall report directly to the management body of the gatekeeper and may raise concerns and warn that body where risks of non-compliance with this Regulation arise, without prejudice to the responsibilities of the management body in its supervisory and managerial functions. The head of the compliance function shall not be removed without prior approval of the management body of the gatekeeper. 5. Compliance officers appointed by the gatekeeper pursuant to paragraph 1 shall have the following tasks: (a) organising, monitoring and supervising the measures and activities of the gatekeepers that aim to ensure compliance with this Regulation; (b) informing and advising the management and employees of the gatekeeper on compliance with this Regulation; (c) where applicable, monitoring compliance with commitments made binding pursuant to Article 25, without prejudice to the Commission being able to appoint independent external experts pursuant to Article 26(2); (d) cooperating with the Commission for the purpose of this Regulation. 6. Gatekeepers shall communicate the name and contact details of the head of the compliance function to the Commission. 7. The management body of the gatekeeper shall define, oversee and be accountable for the implementation of the governance arrangements of the gatekeeper that ensure the independence of the compliance function, including the division of responsibilities in the organisation of the gatekeeper and the prevention of conflicts of interest. 8. The management body shall approve and review periodically, at least once a year, the strategies and policies for taking up, managing and monitoring the compliance with this Regulation. 9. The management body shall devote sufficient time to the management and monitoring of compliance with this Regulation. It shall actively participate in decisions relating to the management and enforcement of this Regulation and ensure that adequate resources are allocated to it.",article,"The Digital Markets Act (DMA) requires large digital companies, known as gatekeepers, to establish an independent compliance function. This function will be led by one or more compliance officers, including a head of compliance, who have the necessary qualifications and experience. Their role is to monitor and ensure the company's adherence to the DMA. The head of compliance will report directly to the company's management and can raise any concerns about potential non-compliance. The compliance officers will also inform and advise the company's management and employees about DMA compliance and cooperate with the Commission for this purpose. The company's management is responsible for overseeing the compliance function and ensuring it operates independently, free from conflicts of interest. They must also regularly review and approve strategies for managing compliance. The name and contact details of the head of compliance must be shared with the Commission."
California Consumer Privacy Act Regulations (CCPA) - Article 2. Notice to Consumers -  999.306 Notice of Right to Opt-Out of Sale of Personal Information,0.712439656,"Details of Article 2. Notice to Consumers -  999.306 Notice of Right to Opt-Out of Sale of Personal Information in the California Consumer Privacy Act Regulations (CCPA): (a) Purpose and General Principles (1) The purpose of the notice of right to opt-out is to inform consumers of their right to direct a business that sells their personal information to stop selling their personal information. (2) The notice of right to opt-out shall be designed and presented in a way that is easy to read and understandable to consumers. The notice shall: a. Use plain, straightforward language and avoid technical or legal jargon. b. Use a format that draws the consumers attention to the notice and makes the notice readable, including on smaller screens, if applicable. c. Be available in the languages in which the business in its ordinary course provides contracts, disclaimers, sale announcements, and other information to consumers in California. d. Be reasonably accessible to consumers with disabilities. For notices provided online, the business shall follow generally recognized industry standards, such as the Web Content Accessibility Guidelines, version 2.1 of June 5, 2018, from the World Wide Web Consortium, incorporated herein by reference. In other contexts, the business shall provide information on how a consumer with a disability may access the notice in an alternative format. (b) A business that sells the personal information of consumers shall provide the notice of right to opt-out to consumers as follows: (1) A business shall post the notice of right to opt-out on the Internet webpage to which the consumer is directed after clicking on the Do Not Sell My Personal Information link on the website homepage or the download or landing page of a mobile application. In addition, a business that collects personal information through a mobile application may provide a link to the notice within the application, such as through the applications settings menu. The notice shall include the information specified in subsection (c) or link to the section of the businesss privacy policy that contains the same information. (2) A business that does not operate a website shall establish, document, and comply with another method by which it informs consumers of their right to opt-out. That method shall comply with the requirements set forth in subsection (a)(2). (c) A business shall include the following in its notice of right to opt-out: (1) A description of the consumers right to opt-out of the sale of their personal information by the business; (2) The interactive form by which the consumer can submit their request to opt-out online, as required by section 999.315, subsection (a), or if the business does not operate a website, the offline method by which the consumer can submit their request to opt-out; and (3) Instructions for any other method by which the consumer may submit their request to opt-out. (d) A business does not need to provide a notice of right to opt-out if: (1) It does not sell personal information; and (2) It states in its privacy policy that it does not sell personal information. (e) A business shall not sell the personal information it collected during the time the business did not have a notice of right to opt-out posted unless it obtains the affirmative authorization of the consumer.",article,"The California Consumer Privacy Act (CCPA) has introduced a new law, Article 2, that gives consumers the right to stop businesses from selling their personal information. Businesses must make this opt-out option clear and accessible to all consumers, using simple language and a format that is easy to read, even on small screens. The notice should be available in all languages the business usually uses and should be accessible to people with disabilities. Businesses that sell personal information must provide this opt-out notice on their website or app, or by another method if they don't have a website. The notice should explain how to opt-out and what this means. Businesses that don't sell personal information don't need to provide this notice, but they must state in their privacy policy that they don't sell personal information. Businesses cannot sell personal information collected when they didn't have an opt-out notice, unless the consumer gives explicit permission."
Digital Services Act (DSA) - Definition of 'active recipient of an online search engine',0.71243304,Definition of 'active recipient of an online search engine' in the Digital Services Act (DSA): a recipient of the service that has submitted a query to an online search engine and been exposed to information indexed and presented on its online interface.,recital,The Digital Services Act (DSA) introduces a term called 'active recipient of an online search engine'. This refers to someone who has used an online search engine to look up something and has seen the information provided by the search engine on its website or platform.
Digital Services Act (DSA) - Article 89 Amendments to Directive 2000/31/EC,0.712424636,"Article 89 Amendments to Directive 2000/31/EC in the Digital Services Act (DSA):  1.   Articles 12 to 15 of Directive 2000/31/EC are deleted.

2.   References to Articles 12 to 15 of Directive 2000/31/EC shall be construed as references to Articles 4, 5, 6 and 8 of this Regulation, respectively.",article,"The new law, called the Digital Services Act (DSA), has made changes to a previous law, Directive 2000/31/EC. Specifically, Articles 12 to 15 of the old law have been removed. Any mention of these Articles in other laws or regulations should now be understood as referring to Articles 4, 5, 6, and 8 of the new DSA. In other words, the DSA has replaced certain parts of the old law with its own provisions."
Digital Services Act (DSA) - Definition of 'information society service',0.712334931,"Definition of 'information society service' in the Digital Services Act (DSA): a 'service' as defined in Article 1(1), point (b), of Directive (EU) 2015/1535.",recital,"The Digital Services Act (DSA) introduces the term 'information society service'. This refers to a 'service' as outlined in the Directive (EU) 2015/1535, Article 1(1), point (b). This law aims to regulate digital services, ensuring they operate in a safe, reliable manner. It's important to understand these terms as they're key to understanding your rights and protections under the new law."
Digital Services Act (DSA) - Definition of 'intermediary service',0.712333262,"Definition of 'intermediary service' in the Digital Services Act (DSA): one of the following information society services:
(i)  a 'mere conduit' service, consisting of the transmission in a communication network of information provided by a recipient of the service, or the provision of access to a communication network.
(ii)  a 'caching' service, consisting of the transmission in a communication network of information provided by a recipient of the service, involving the automatic, intermediate and temporary storage of that information, performed for the sole purpose of making more efficient the information's onward transmission to other recipients upon their request.
(iii)  a 'hosting' service, consisting of the storage of information provided by, and at the request of, a recipient of the service.",recital,"The Digital Services Act (DSA) defines an 'intermediary service' as any of the following online services: 
(i) A 'mere conduit' service, which is a service that simply transmits information over a network, or provides access to a network. 
(ii) A 'caching' service, which temporarily stores information to make its transmission to other users more efficient. 
(iii) A 'hosting' service, which stores information provided by a user at their request."
Artifical Inellegence Act (AI Act) - Article 49,0.712322652,"Aritifical Intelligence Act (AI Act) Article 49 CE marking of conformity:

1.The CE marking shall be affixed visibly, legibly and indelibly for high-risk AI systems. Where that is not possible or not warranted on account of the nature of the high-risk AI system, it shall be affixed to the packaging or to the accompanying documentation, as appropriate.

2.The CE marking referred to in paragraph 1 of this Article shall be subject to the general principles set out in Article 30 of Regulation (EC) No 765/2008.

3.Where applicable, the CE marking shall be followed by the identification number of the notified body responsible for the conformity assessment procedures set out in Article 43. The identification number shall also be indicated in any promotional material which mentions that the high-risk AI system fulfils the requirements for CE marking.",article,"The Artificial Intelligence Act (AI Act) requires high-risk AI systems to have a visible, legible, and permanent CE marking. If this isn't possible due to the system's nature, the marking should be on the packaging or included in the documentation. This CE marking must follow the guidelines in Article 30 of Regulation (EC) No 765/2008. If applicable, the marking should be accompanied by the identification number of the body responsible for checking the system meets the required standards. This number should also be included in any promotional material claiming the system meets CE marking requirements."
General Data Protection Regulation (GDPR) - Definition of profiling,0.71231842,"Details of the Definition of profiling in the General Data Protection Regulation (GDPR): ""profiling"" means any form of automated processing of personal data consisting of the use of personal data to evaluate certain personal aspects relating to a natural person, in particular to analyse or predict aspects concerning that natural person's performance at work, economic situation, health, personal preferences, interests, reliability, behaviour, location or movements;",recital,"The General Data Protection Regulation (GDPR) has introduced a new definition for ""profiling"". Profiling, under this law, refers to any automated process that uses personal data to assess various personal aspects of an individual. This could include analysis or predictions about a person's job performance, financial status, health, personal likes and dislikes, trustworthiness, behavior, or even their location and movements."
Digital Services Act (DSA) - Article 59 Referral to the Commission,0.712269783,"Article 59 Referral to the Commission in the Digital Services Act (DSA):  1.   In the absence of a communication within the period laid down in Article 58(5), in the case of a disagreement of the Board with the assessment or the measures taken or envisaged pursuant to Article 58(5) or in the cases referred to in Article 60(3), the Board may refer the matter to the Commission, providing all relevant information. That information shall include at least the request or recommendation sent to the Digital Services Coordinator of establishment, the assessment by that Digital Services Coordinator, the reasons for the disagreement and any additional information supporting the referral.

2.   The Commission shall assess the matter within two months following the referral of the matter pursuant to paragraph 1, after having consulted the Digital Services Coordinator of establishment.

3.   Where, pursuant to paragraph 2 of this Article, the Commission considers that the assessment or the investigatory or enforcement measures taken or envisaged pursuant to Article 58(5) are insufficient to ensure effective enforcement or otherwise incompatible with this Regulation, it shall communicate its views to the Digital Services Coordinator of establishment and the Board and request the Digital Services Coordinator of establishment to review the matter.

The Digital Services Coordinator of establishment shall take the necessary investigatory or enforcement measures to ensure compliance with this Regulation, taking utmost account of the views and request for review by the Commission. The Digital Services Coordinator of establishment shall inform the Commission, as well as the requesting Digital Services Coordinator or the Board that took action pursuant to Article 58(1) or (2), about the measures taken within two months from that request for review.",article,"The Digital Services Act (DSA) has a new clause, Article 59, which allows the Board to refer any disagreements or unresolved issues to the Commission. The Commission then has two months to assess the situation, consulting with the Digital Services Coordinator. If the Commission finds that the actions taken are insufficient or not in line with the DSA, it can ask the Digital Services Coordinator to review the matter. The Coordinator is then responsible for ensuring compliance with the DSA, taking into account the Commission's feedback. The Coordinator must inform the Commission and the Board about any measures taken within two months of the review request."
Digital Markets Act (DMA) - Article 40 The high-level group,0.712220311,"Details of Article 40 The high-level group in the Digital Markets Act (DMA): 1. The Commission shall establish a high-level group for the Digital Markets Act (""the high-level group""). 2. The high-level group shall be composed of the following European bodies and networks: (a) Body of the European Regulators for Electronic Communications; (b) European Data Protection Supervisor and European Data Protection Board; (c) European Competition Network; (d) Consumer Protection Cooperation Network; and (e) European Regulatory Group of Audiovisual Media Regulators. 3. The European bodies and networks referred to in paragraph 2 shall each have an equal number of representatives in the high-level group. The maximum number of members of the high-level group shall not exceed 30. 4. The Commission shall provide secretariat services to the high-level group in order to facilitate its work. The high-level group shall be chaired by the Commission, which shall participate in its meetings. The high-level group shall meet upon request of the Commission at least once per calendar year. The Commission shall also convene a meeting of the group when so requested by the majority of the members composing the group in order to address a specific issue. 5. The high-level group may provide the Commission with advice and expertise in the areas falling within the competences of its members, including: (a) advice and recommendations within their expertise relevant for any general matter of implementation or enforcement of this Regulation; or (b) advice and expertise promoting a consistent regulatory approach across different regulatory instruments. 6. The high-level group may, in particular, identify and assess the current and potential interactions between this Regulation and the sector-specific rules applied by the national authorities composing the European bodies and networks referred to in paragraph 2 and submit an annual report to the Commission presenting such assessment and identifying potential trans-regulatory issues. Such report may be accompanied by recommendations aiming at converging towards consistent transdisciplinary approaches and synergies between the implementation of this Regulation and other sectoral regulations. The report shall be communicated to the European Parliament and to the Council. 7. In the context of market investigations into new services and new practices, the high-level group may provide expertise to the Commission on the need to amend, add or remove rules in this Regulation, to ensure that digital markets across the Union are contestable and fair",article,"The Digital Markets Act (DMA) establishes a high-level group to oversee its implementation. This group is composed of representatives from various European bodies, including those specializing in electronic communications, data protection, competition, consumer protection, and audiovisual media regulation. Each body will have an equal number of representatives in the group, which will not exceed 30 members. The group, chaired by the Commission, will meet at least once a year and can provide advice and expertise on the DMA's implementation and enforcement. They will also assess how the DMA interacts with national rules and submit an annual report on their findings, which may include recommendations for consistency across different regulations. The group can also advise on amending the DMA to ensure fair competition in digital markets."
Digital Markets Act (DMA) - Article 25 Commitments,0.712188721,"Details of Article 25 Commitments in the Digital Markets Act (DMA): 1. If, during proceedings under Article 18, the gatekeeper concerned offers commitments for the relevant core platform services to ensure compliance with the obligations laid down in Articles 5, 6 and 7 the Commission may adopt an implementing act making those commitments binding on that gatekeeper and declare that there are no further grounds for action. That implementing act shall be adopted in accordance with the advisory procedure referred to in Article 50(2). 2. The Commission may, upon request or on its own initiative, reopen by decision the relevant proceedings, where: (a) there has been a material change in any of the facts on which the decision was based; (b) the gatekeeper concerned acts contrary to its commitments; (c) the decision was based on incomplete, incorrect or misleading information provided by the parties; (d) the commitments are not effective. 3. If the Commission considers that the commitments submitted by the gatekeeper concerned cannot ensure effective compliance with the obligations laid down in Articles 5, 6 and 7, it shall explain the reasons for not making those commitments binding in the decision concluding the relevant proceedings.",article,"The Digital Markets Act (DMA) Article 25 states that if a digital platform (gatekeeper) promises to comply with certain obligations during a legal proceeding, the Commission can make those promises legally binding. If the gatekeeper doesn't follow through, or if the situation changes significantly, the Commission can reopen the case. The Commission can also refuse to make the promises binding if it believes the gatekeeper won't effectively comply with the obligations. In such a case, the Commission has to explain its reasons."
Artifical Inellegence Act (AI Act) - Context Section 5.2.7,0.712156177,"Aritifical Intelligence Act (AI Act) context section 5.2.7.CODES OF CONDUCT (TITLE IX): 

Title IX creates a framework for the creation of codes of conduct, which aim to encourage providers of non-high-risk AI systems to apply voluntarily the mandatory requirements for high-risk AI systems (as laid out in Title III). Providers of non-high-risk AI systems may create and implement the codes of conduct themselves. Those codes may also include voluntary commitments related, for example, to environmental sustainability, accessibility for persons with disability, stakeholders participation in the design and development of AI systems, and diversity of development teams.5.2.7.CODES OF CONDUCT (TITLE IX):

Title IX creates a framework for the creation of codes of conduct, which aim to encourage providers of non-high-risk AI systems to apply voluntarily the mandatory requirements for high-risk AI systems (as laid out in Title III). Providers of non-high-risk AI systems may create and implement the codes of conduct themselves. Those codes may also include voluntary commitments related, for example, to environmental sustainability, accessibility for persons with disability, stakeholders participation in the design and development of AI systems, and diversity of development teams.",recital,"The Artificial Intelligence Act (AI Act) includes a section, Title IX, which encourages creators of low-risk AI systems to voluntarily follow the same rules required for high-risk AI systems. This section promotes the creation of codes of conduct by these low-risk AI providers themselves. These codes can include voluntary commitments to various aspects like environmental sustainability, accessibility for disabled individuals, stakeholder involvement in AI design and development, and team diversity."
Artifical Inellegence Act (AI Act) - Article 24,0.712094247,"Aritifical Intelligence Act (AI Act) Article 24 Obligations of product manufacturers:

Where a high-risk AI system related to products to which the legal acts listed in Annex II, section A, apply, is placed on the market or put into service together with the product manufactured in accordance with those legal acts and under the name of the product manufacturer, the manufacturer of the product shall take the responsibility of the compliance of the AI system with this Regulation and, as far as the AI system is concerned, have the same obligations imposed by the present Regulation on the provider.",article,"The Artificial Intelligence Act (AI Act) places responsibility on product manufacturers for any high-risk AI systems that are sold or used with their products. According to Article 24, if these AI systems are associated with their products, the manufacturers must ensure that the AI complies with the regulations of the AI Act. Essentially, the manufacturer is held to the same standards as the AI system provider, meaning they are liable for the AI system's compliance with the law."
Digital Services Act (DSA) - Article 62 Structure of the Board,0.712074,"Article 62 Structure of the Board in the Digital Services Act (DSA):  1.   The Board shall be composed of Digital Services Coordinators who shall be represented by high-level officials. The failure by one or more Member States to designate a Digital Services Coordinator shall not prevent the Board from performing its tasks under this Regulation. Where provided for by national law, other competent authorities entrusted with specific operational responsibilities for the application and enforcement of this Regulation alongside the Digital Services Coordinator may participate in the Board. Other national authorities may be invited to the meetings, where the issues discussed are of relevance for them.

2.   The Board shall be chaired by the Commission. The Commission shall convene the meetings and prepare the agenda in accordance with the tasks of the Board pursuant to this Regulation and in line with its rules of procedure. When the Board is requested to adopt a recommendation pursuant to this Regulation, it shall immediately make the request available to other Digital Services Coordinators through the information sharing system set out in Article 85.

3.   Each Member State shall have one vote. The Commission shall not have voting rights.

The Board shall adopt its acts by simple majority. When adopting a recommendation to the Commission referred to in Article 36(1), first subparagraph, the Board shall vote within 48 hours after the request of the Chair of the Board.

4.   The Commission shall provide administrative and analytical support for the activities of the Board pursuant to this Regulation.

5.   The Board may invite experts and observers to attend its meetings, and may cooperate with other Union bodies, offices, agencies and advisory groups, as well as external experts as appropriate. The Board shall make the results of this cooperation publicly available.

6.   The Board may consult interested parties, and shall make the results of such consultation publicly available.

7.   The Board shall adopt its rules of procedure, following the consent of the Commission.",article,"The Digital Services Act (DSA) establishes a Board made up of Digital Services Coordinators from various member states, represented by high-ranking officials. The Board can still function even if some states fail to appoint a Coordinator. Other national authorities can participate or be invited to meetings if relevant. The Board is chaired by the Commission, which also organizes meetings and sets the agenda. When a recommendation is needed, it is shared with all Coordinators. Each state gets one vote, but the Commission doesn't vote. Decisions are made by simple majority and must be done within 48 hours of a request. The Commission provides administrative and analytical support. The Board can invite experts and observers to meetings and can collaborate with other Union bodies and external experts. It can also consult interested parties. All results from these collaborations and consultations are made public. The Board's procedural rules are adopted with the Commission's consent."
Digital Services Act (DSA) - Article 37 Independent audit,0.712017417,"Article 37 Independent audit in the Digital Services Act (DSA):  1.   Providers of very large online platforms and of very large online search engines shall be subject, at their own expense and at least once a year, to independent audits to assess compliance with the following:
(a) the obligations set out in Chapter III;
(b) any commitments undertaken pursuant to the codes of conduct referred to in Articles 45 and 46 and the crisis protocols referred to in Article 48.

2.   Providers of very large online platforms and of very large online search engines shall afford the organisations carrying out the audits pursuant to this Article the cooperation and assistance necessary to enable them to conduct those audits in an effective, efficient and timely manner, including by giving them access to all relevant data and premises and by answering oral or written questions. They shall refrain from hampering, unduly influencing or undermining the performance of the audit.

Such audits shall ensure an adequate level of confidentiality and professional secrecy in respect of the information obtained from the providers of very large online platforms and of very large online search engines and third parties in the context of the audits, including after the termination of the audits. However, complying with that requirement shall not adversely affect the performance of the audits and other provisions of this Regulation, in particular those on transparency, supervision and enforcement. Where necessary for the purpose of the transparency reporting pursuant to Article 42(4), the audit report and the audit implementation report referred to in paragraphs 4 and 6 of this Article shall be accompanied with versions that do not contain any information that could reasonably be considered to be confidential.

3.   Audits performed pursuant to paragraph 1 shall be performed by organisations which:

(a) are independent from, and do not have any conflicts of interest with, the provider of very large online platforms or of very large online search engines concerned and any legal person connected to that provider; in particular:
(i) have not provided non-audit services related to the matters audited to the provider of very large online platform or of very large online search engine concerned and to any legal person connected to that provider in the 12 months' period before the beginning of the audit and have committed to not providing them with such services in the 12 months' period after the completion of the audit;
(ii) have not provided auditing services pursuant to this Article to the provider of very large online platform or of very large online search engine concerned and any legal person connected to that provider during a period longer than 10 consecutive years;
(iii) are not performing the audit in return for fees which are contingent on the result of the audit;

(b) have proven expertise in the area of risk management, technical competence and capabilities;
(c) have proven objectivity and professional ethics, based in particular on adherence to codes of practice or appropriate standards.

4.   Providers of very large online platforms and of very large online search engines shall ensure that the organisations that perform the audits establish an audit report for each audit. That report shall be substantiated, in writing, and shall include at least the following:

(a) the name, address and the point of contact of the provider of the very large online platform or of the very large online search engine subject to the audit and the period covered;
(b) the name and address of the organisation or organisations performing the audit;
(c) a declaration of interests;
(d) a description of the specific elements audited, and the methodology applied;
(e) a description and a summary of the main findings drawn from the audit;
(f) a list of the third parties consulted as part of the audit;
(g) an audit opinion on whether the provider of the very large online platform or of the very large online search engine subject to the audit complied with the obligations and with the commitments referred to in paragraph 1, namely 'positive', 'positive with comments' or 'negative';
(h) where the audit opinion is not 'positive', operational recommendations on specific measures to achieve compliance and the recommended timeframe to achieve compliance.

5.   Where the organisation performing the audit was unable to audit certain specific elements or to express an audit opinion based on its investigations, the audit report shall include an explanation of the circumstances and the reasons why those elements could not be audited.

6.   Providers of very large online platforms or of very large online search engines receiving an audit report that is not 'positive' shall take due account of the operational recommendations addressed to them with a view to take the necessary measures to implement them. They shall, within one month from receiving those recommendations, adopt an audit implementation report setting out those measures. Where they do not implement the operational recommendations, they shall justify in the audit implementation report the reasons for not doing so and set out any alternative measures that they have taken to address any instances of non-compliance identified.

7.   The Commission is empowered to adopt delegated acts in accordance with Article 87 to supplement this Regulation by laying down the necessary rules for the performance of the audits pursuant to this Article, in particular as regards the necessary rules on the procedural steps, auditing methodologies and reporting templates for the audits performed pursuant to this Article. Those delegated acts shall take into account any voluntary auditing standards referred to in Article 44(1), point (e).",article,"The Digital Services Act (DSA) requires large online platforms and search engines to undergo independent audits annually, at their own expense. These audits will assess their compliance with certain obligations and commitments, including codes of conduct and crisis protocols. Audit organizations must be independent, without any conflicts of interest with the platforms being audited, and have proven expertise in risk management, technical competence and professional ethics. The audit report should detail the findings and, if compliance is not met, provide operational recommendations for achieving it. If a platform receives a 'negative' audit report, it must respond within a month with an implementation report detailing how they plan to address the issues. The law also empowers the Commission to set rules for audit procedures and reporting. Confidentiality is to be maintained throughout the audit process, without hindering transparency, supervision, and enforcement."
Digital Markets Act (DMA) - Definition of operating system,0.712008715,"Details of the Definition of operating system in the Digital Markets Act (DMA): ""operating system"" means a system software that controls the basic functions of the hardware or software and enables software applications to run on it;",rectial,The Digital Markets Act (DMA) defines an 'operating system' as a type of software that manages the basic operations of a computer's hardware or software. It's what allows other software applications to function on the computer.
Artifical Inellegence Act (AI Act) - Overview paragraph 1,0.712003648,"Aritifical Intelligence Act (AI Act) overview paragraph (1): The purpose of this Regulation is to improve the functioning of the internal market by laying down a uniform legal framework in particular for the development, marketing and use of artificial intelligence in conformity with Union values. This Regulation pursues a number of overriding reasons of public interest, such as a high level of protection of health, safety and fundamental rights, and it ensures the free movement of AI-based goods and services cross-border, thus preventing Member States from imposing restrictions on the development, marketing and use of AI systems, unless explicitly authorised by this Regulation.",recital,"The Artificial Intelligence Act (AI Act) is a new law designed to create a consistent legal environment for the development, marketing, and use of artificial intelligence (AI) in line with Union values. The law aims to protect public interests, including health, safety, and fundamental rights. It also facilitates the free movement of AI-based goods and services across borders, preventing member states from imposing restrictions on AI systems unless specifically allowed by this law."
General Data Protection Regulation (GDPR) - Contextual Paragraph (72),0.711996615,"Details of the Contextual Paragraph (72) in the General Data Protection Regulation (GDPR): Profiling is subject to the rules of this Regulation governing the processing of personal data, such as the legal grounds for processing or data protection principles. The European Data Protection Board established by this Regulation (the ""Board"") should be able to issue guidance in that context.",recital,"The General Data Protection Regulation (GDPR) includes a rule, Paragraph 72, about profiling - using personal data to evaluate certain things about a person. This rule says that all the usual GDPR rules about handling personal data apply to profiling. This includes the reasons that make it legally okay to process data and the principles of data protection. The European Data Protection Board, which was created by the GDPR, can provide advice about this."
Artifical Inellegence Act (AI Act) - Article 54,0.711986125,"Aritifical Intelligence Act (AI Act) Article 54 Further processing of personal data for developing certain AI systems in the public interest in the AI regulatory sandbox:

1.In the AI regulatory sandbox personal data lawfully collected for other purposes shall be processed for the purposes of developing and testing certain innovative AI systems in the sandbox under the following conditions:

(a)the innovative AI systems shall be developed for safeguarding substantial public interest in one or more of the following areas:

(i)the prevention, investigation, detection or prosecution of criminal offences or the execution of criminal penalties, including the safeguarding against and the prevention of threats to public security, under the control and responsibility of the competent authorities. The processing shall be based on Member State or Union law;

(ii)public safety and public health, including disease prevention, control and treatment;

(iii)a high level of protection and improvement of the quality of the environment;

(b)the data processed are necessary for complying with one or more of the requirements referred to in Title III, Chapter 2 where those requirements cannot be effectively fulfilled by processing anonymised, synthetic or other non-personal data;

(c)there are effective monitoring mechanisms to identify if any high risks to the fundamental rights of the data subjects may arise during the sandbox experimentation as well as response mechanism to promptly mitigate those risks and, where necessary, stop the processing;

(d)any personal data to be processed in the context of the sandbox are in a functionally separate, isolated and protected data processing environment under the control of the participants and only authorised persons have access to that data;

(e)any personal data processed are not be transmitted, transferred or otherwise accessed by other parties;

(f)any processing of personal data in the context of the sandbox do not lead to measures or decisions affecting the data subjects;

(g)any personal data processed in the context of the sandbox are deleted once the participation in the sandbox has terminated or the personal data has reached the end of its retention period;

(h)the logs of the processing of personal data in the context of the sandbox are kept for the duration of the participation in the sandbox and 1 year after its termination, solely for the purpose of and only as long as necessary for fulfilling accountability and documentation obligations under this Article or other application Union or Member States legislation;

(i)complete and detailed description of the process and rationale behind the training, testing and validation of the AI system is kept together with the testing results as part of the technical documentation in Annex IV;

(j)a short summary of the AI project developed in the sandbox, its objectives and expected results published on the website of the competent authorities.

2.Paragraph 1 is without prejudice to Union or Member States legislation excluding processing for other purposes than those explicitly mentioned in that legislation.",article,"The Artificial Intelligence Act (AI Act) Article 54 allows for the use of personal data in a controlled environment, known as an AI regulatory sandbox, to develop and test AI systems for public interest. These systems must aim to address areas like crime prevention, public safety and health, or environmental protection. The data used must be necessary and cannot be replaced with anonymised or non-personal data. The sandbox must have monitoring mechanisms to identify and mitigate any risks to the data subjects' rights. The data must be kept separate and accessible only by authorized persons, and it cannot be shared with other parties. The data cannot lead to actions affecting the data subjects and must be deleted after use. The processing logs must be kept for accountability. A detailed description of the AI system's training, testing, and validation process must be documented, and a summary of the project must be published."
Artifical Inellegence Act (AI Act) - Overview paragraph 14,0.71194768,"Aritifical Intelligence Act (AI Act) overview paragraph (14): Inorderto introduce a proportionate and effective set of binding rules for AI systems, a clearly defined risk-based approach should be followed. That approach should tailor the type and content of such rules to the intensity and scope of the risks that AI systems can generate. It is therefore necessary to prohibit certain artificial intelligence practices, to lay down requirements for high-risk AI systems and obligations for the relevant operators, and to lay down transparency obligations for certain AI systems.",recital,"The Artificial Intelligence Act (AI Act) aims to establish clear and effective rules for AI systems based on the level of risk they might pose. The law will categorize AI systems based on their potential risk and apply rules accordingly. Certain AI practices will be banned, high-risk AI systems will have specific requirements, and those operating these systems will have certain obligations. The law also includes transparency requirements for some AI systems."
Artifical Inellegence Act (AI Act) - Overview paragraph 88,0.71194315,"Aritifical Intelligence Act (AI Act) overview paragraph (88): This Regulation should apply from  [OP  please insert the date established in Art. 85]. However, the infrastructure related to the governance and the conformity assessment system should be operational before that date, therefore the provisions on notified bodies and governance structure should apply from [OP  please insert the date  three months following the entry into force of this Regulation].In addition, Member States should lay down and notify to the Commission the rules on penalties, including administrative fines, and ensure that they are properly and effectively implemented by the date of application of this Regulation. Therefore the provisions on penalties should apply from [OP  please insert the date twelve months following the entry into force of this Regulation].",recital,"The Artificial Intelligence Act (AI Act) will become effective on a date yet to be determined. However, the systems for managing and assessing compliance with the law must be in place before the law takes effect. This includes notifying bodies and establishing a governance structure. These systems should be operational three months after the law is officially introduced. Furthermore, each member state must establish and inform the Commission of their rules on penalties, including administrative fines. They must also ensure these penalties are effectively enforced by the time the law is implemented. These penalty provisions should be in place twelve months after the law is introduced."
General Data Protection Regulation (GDPR) - Definition of restriction of processing,0.71194011,"Details of the Definition of restriction of processing in the General Data Protection Regulation (GDPR): ""restriction of processing"" means the marking of stored personal data with the aim of limiting their processing in the future;",recital,"The General Data Protection Regulation (GDPR) has a new rule called ""restriction of processing"". This rule is about marking or labeling personal data that's been stored, with the goal of limiting how it's used in the future. This means that your personal data will have added protections to prevent misuse or overuse in the future."
Digital Services Act (DSA) - Article 61 European Board for Digital Services,0.711919963,"Article 61 European Board for Digital Services in the Digital Services Act (DSA):  1.   An independent advisory group of Digital Services Coordinators on the supervision of providers of intermediary services named 'European Board for Digital Services' (the 'Board') is established.

2.   The Board shall advise the Digital Services Coordinators and the Commission in accordance with this Regulation to achieve the following objectives:

(a) contributing to the consistent application of this Regulation and effective cooperation of the Digital Services Coordinators and the Commission with regard to matters covered by this Regulation;
(b) coordinating and contributing to guidelines and analysis of the Commission and Digital Services Coordinators and other competent authorities on emerging issues across the internal market with regard to matters covered by this Regulation;
(c) assisting the Digital Services Coordinators and the Commission in the supervision of very large online platforms.",article,"The Digital Services Act (DSA) has established a new independent advisory group called the 'European Board for Digital Services'. This Board will advise and assist Digital Services Coordinators and the Commission in supervising online service providers. Their goals include ensuring consistent application of the DSA, aiding in cooperation between the Coordinators and the Commission, and helping to guide and analyze emerging issues in the digital market. They will also help supervise large online platforms."
California Consumer Privacy Act Regulations (CCPA) - Definition of CCPA,0.711869776,"Details of Definition of CCPA in the California Consumer Privacy Act Regulations (CCPA): CCPA means the California Consumer Privacy Act of 2018, Civil Code sections 1798.100 et seq.",recital,"The California Consumer Privacy Act (CCPA) is a law established in 2018 that aims to protect the privacy rights of consumers in California. It allows consumers to know what personal data is being collected about them, whether their personal data is sold or disclosed and to whom, say no to the sale of personal data, access their personal data, and request a business to delete any personal information about a consumer collected from that consumer. It applies to any business that collects consumers' personal data, does business in California, and satisfies at least one of several specific conditions."
Artifical Inellegence Act (AI Act) - Definition of 'harmonised standard',0.711860061,"Within the Aritifical Intelligence Act (AI Act), the Definition of harmonised standard means a European standard as defined in Article 2(1)(c) of Regulation (EU) No 1025/2012;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'harmonised standard.' This term refers to a European standard as outlined in Article 2(1)(c) of Regulation (EU) No 1025/2012. Essentially, this means that the AI Act is adopting a standard that has already been set by a European regulation. This standard is used to ensure consistency and uniformity in the application of the law across different situations and contexts."
General Data Protection Regulation (GDPR) - Article 39 Tasks of the data protection officer,0.711859405,"Details of Article 39 Tasks of the data protection officer in the General Data Protection Regulation (GDPR): 1. The data protection officer shall have at least the following tasks: (a) to inform and advise the controller or the processor and the employees who carry out processing of their obligations pursuant to this Regulation and to other Union or Member State data protection provisions; (b) to monitor compliance with this Regulation, with other Union or Member State data protection provisions and with the policies of the controller or processor in relation to the protection of personal data, including the assignment of responsibilities, awareness-raising and training of staff involved in processing operations, and the related audits; (c) to provide advice where requested as regards the data protection impact assessment and monitor its performance pursuant to Article 35; (d) to cooperate with the supervisory authority; (e) to act as the contact point for the supervisory authority on issues relating to processing, including the prior consultation referred to in Article 36, and to consult, where appropriate, with regard to any other matter. 2. The data protection officer shall in the performance of his or her tasks have due regard to the risk associated with processing operations, taking into account the nature, scope, context and purposes of processing.",article,"The General Data Protection Regulation (GDPR) Article 39 outlines the responsibilities of a data protection officer. These include informing and advising those handling data about their obligations under the GDPR and other relevant laws, ensuring compliance with these laws and company policies, providing advice on data protection impact assessments, and cooperating with the supervisory authority. They also act as a contact point for the supervisory authority on issues related to data processing. The officer must consider the risks associated with data processing, taking into account its nature, scope, context, and purposes."
Digital Markets Act (DMA) - Article 7 Obligation for gatekeepers on interoperability of number-independent interpersonal communications services,0.711855054,"Details of Article 7 Obligation for gatekeepers on interoperability of number-independent interpersonal communications services in the Digital Markets Act (DMA): 1. Where a gatekeeper provides number-independent interpersonal communications services that are listed in the designation decision pursuant to Article 3(9), it shall make the basic functionalities of its number-independent interpersonal communications services interoperable with the number-independent interpersonal communications services of another provider offering or intending to offer such services in the Union, by providing the necessary technical interfaces or similar solutions that facilitate interoperability, upon request, and free of charge. 2. The gatekeeper shall make at least the following basic functionalities referred to in paragraph 1 interoperable where the gatekeeper itself provides those functionalities to its own end users: (a) following the listing in the designation decision pursuant to Article 3(9): (i) end-to-end text messaging between two individual end users; (ii) sharing of images, voice messages, videos and other attached files in end to end communication between two individual end users; (b) within 2 years from the designation: (i) end-to-end text messaging within groups of individual end users; (ii) sharing of images, voice messages, videos and other attached files in end-to-end communication between a group chat and an individual end user; (c) within 4 years from the designation: (i) end-to-end voice calls between two individual end users; (ii) end-to-end video calls between two individual end users; (iii) end-to-end voice calls between a group chat and an individual end user; (iv) end-to-end video calls between a group chat and an individual end user. 3. The level of security, including the end-to-end encryption, where applicable, that the gatekeeper provides to its own end users shall be preserved across the interoperable services. 4. The gatekeeper shall publish a reference offer laying down the technical details and general terms and conditions of interoperability with its number-independent interpersonal communications services, including the necessary details on the level of security and end-to-end encryption. The gatekeeper shall publish that reference offer within the period laid down in Article 3(10) and update it where necessary. 5. Following the publication of the reference offer pursuant to paragraph 4, any provider of number-independent interpersonal communications services offering or intending to offer such services in the Union may request interoperability with the number-independent interpersonal communications services provided by the gatekeeper. Such a request may cover some or all of the basic functionalities listed in paragraph 2. The gatekeeper shall comply with any reasonable request for interoperability within 3 months after receiving that request by rendering the requested basic functionalities operational. 6. The Commission may, exceptionally, upon a reasoned request by the gatekeeper, extend the time limits for compliance under paragraph 2 or 5 where the gatekeeper demonstrates that this is necessary to ensure effective interoperability and to maintain the necessary level of security, including end-to-end encryption, where applicable. 7. The end users of the number-independent interpersonal communications services of the gatekeeper and of the requesting provider of number-independent interpersonal communications services shall remain free to decide whether to make use of the interoperable basic functionalities that may be provided by the gatekeeper pursuant to paragraph 1. 8. The gatekeeper shall collect and exchange with the provider of number-independent interpersonal communications services that makes a request for interoperability only the personal data of end users that is strictly necessary to provide effective interoperability. Any such collection and exchange of the personal data of end users shall fully comply with Regulation (EU) 2016/679 and Directive 2002/58/EC. 9. The gatekeeper shall not be prevented from taking measures to ensure that third-party providers of numberindependent interpersonal communications services requesting interoperability do not endanger the integrity, security and privacy of its services, provided that such measures are strictly necessary and proportionate and are duly justified by the gatekeeper.",article,"The Digital Markets Act (DMA) requires large tech companies, referred to as ""gatekeepers"", to make their messaging services compatible with other platforms. This includes basic functions like text messaging, sharing images, voice messages, videos, and other files. The gatekeeper must maintain the same security and encryption levels across all services. They must publish a reference offer detailing technical aspects and terms of this compatibility and update it as necessary. Other service providers can then request this compatibility. The gatekeeper must comply with reasonable requests within three months. Exceptions may be granted if the gatekeeper needs more time to ensure effective compatibility and security. Users can choose whether or not to use these compatible functions. The gatekeeper can only collect and exchange necessary personal data for effective compatibility, and must comply with existing data protection regulations. They can take measures to protect the integrity, security, and privacy of their services from third-party providers."
Digital Markets Act (DMA) - Article 8 Compliance with obligations for gatekeepers,0.711853266,"Details of Article 8 Compliance with obligations for gatekeepers in the Digital Markets Act (DMA): 1. The gatekeeper shall ensure and demonstrate compliance with the obligations laid down in Articles 5, 6 and 7 of this Regulation. The measures implemented by the gatekeeper to ensure compliance with those Articles shall be effective in achieving the objectives of this Regulation and of the relevant obligation. The gatekeeper shall ensure that the implementation of those measures complies with applicable law, in particular Regulation (EU) 2016/679, Directive 2002/58/EC, legislation on cyber security, consumer protection, product safety, as well as with the accessibility requirements. 2. The Commission may, on its own initiative or at the request of a gatekeeper pursuant to paragraph 3 of this Article, open proceedings pursuant to Article 20. The Commission may adopt an implementing act, specifying the measures that the gatekeeper concerned is to implement in order to effectively comply with the obligations laid down in Articles 6 and 7. That implementing act shall be adopted within 6 months from the opening of proceedings pursuant to Article 20 in accordance with the advisory procedure referred to in Article 50(2). When opening proceedings on its own initiative for circumvention pursuant to Article 13, such measures may concern the obligations laid down in Articles 5, 6 and 7. 3. A gatekeeper may request the Commission to engage in a process to determine whether the measures that that gatekeeper intends to implement or has implemented to ensure compliance with Articles 6 and 7 are effective in achieving the objective of the relevant obligation in the specific circumstances of the gatekeeper. The Commission shall have discretion in deciding whether to engage in such a process, respecting the principles of equal treatment, proportionality and good administration. In its request, the gatekeeper shall provide a reasoned submission to explain the measures that it intends to implement or has implemented. The gatekeeper shall furthermore provide a non-confidential version of its reasoned submission that may be shared with third parties pursuant to paragraph 6. 4. Paragraphs 2 and 3 of this Article are without prejudice to the powers of the Commission under Articles 29, 30 and 31. 5. With a view of adopting the decision under paragraph 2, the Commission shall communicate its preliminary findings to the gatekeeper within 3 months from the opening of the proceedings under Article 20. In the preliminary findings, the Commission shall explain the measures that it is considering taking or that it considers the gatekeeper concerned should take in order to effectively address the preliminary findings. 6. In order to effectively enable interested third parties to provide comments, the Commission shall, when communicating its preliminary findings to the gatekeeper pursuant to paragraph 5 or as soon as possible thereafter, publish a non-confidential summary of the case and the measures that it is considering taking or that it considers the gatekeeper concerned should take. The Commission shall specify a reasonable timeframe within which such comments are to be provided. 7. In specifying the measures under paragraph 2, the Commission shall ensure that the measures are effective in achieving the objectives of this Regulation and the relevant obligation, and proportionate in the specific circumstances of the gatekeeper and the relevant service. 8. For the purposes of specifying the obligations under Article 6(11) and (12), the Commission shall also assess whether the intended or implemented measures ensure that there is no remaining imbalance of rights and obligations on business users and that the measures do not themselves confer an advantage on the gatekeeper which is disproportionate to the service provided by the gatekeeper to business users. 9. In respect of proceedings pursuant to paragraph 2, the Commission may, upon request or on its own initiative, decide to reopen them where: (a) there has been a material change in any of the facts on which the decision was based; or (b) the decision was based on incomplete, incorrect or misleading information; or (c) the measures as specified in the decision are not effective.",article,"The Digital Markets Act (DMA) mandates that gatekeepers (major tech companies) must comply with rules laid out in Articles 5, 6, and 7 of the Act, and must demonstrate that their measures for compliance are effective. They must also ensure that these measures adhere to existing laws, including those related to data protection, cybersecurity, and consumer protection. The European Commission can initiate proceedings to ensure compliance, and can specify the necessary measures to be taken by the gatekeeper. The Commission can also reopen proceedings if there are significant changes in the situation or if the measures are not effective. Gatekeepers can request the Commission to review their compliance measures, but the Commission has the discretion to decide whether to engage in this process. The Commission must communicate its preliminary findings within 3 months of opening proceedings. It will also publish a non-confidential summary of the case and the proposed measures, allowing third parties to comment."
General Data Protection Regulation (GDPR) - Article 73 Chair,0.711844087,Details of Article 73 Chair in the General Data Protection Regulation (GDPR): 1. The Board shall elect a chair and two deputy chairs from amongst its members by simple majority. 2. The term of office of the Chair and of the deputy chairs shall be five years and be renewable once.,article,"Article 73 of the General Data Protection Regulation (GDPR) states that the Board will choose a chair and two deputy chairs from its members by a simple majority vote. The chair and deputy chairs will serve for a term of five years, and they can be re-elected once."
Artifical Inellegence Act (AI Act) - Overview paragraph 3,0.711828232,"Aritifical Intelligence Act (AI Act) overview paragraph (3): Artificial intelligence is a fast evolving family of technologies that can contribute to a wide array of economic and societal benefits across the entire spectrum of industries and social activities. By improving prediction, optimising operations and resource allocation, and personalising digital solutions available for individuals and organisations, the use of artificial intelligence can provide key competitive advantages to companies and support socially and environmentally beneficial outcomes, for example in healthcare, farming, education and training, infrastructure management, energy, transport and logistics, public services, security, justice, resource and energy efficiency, and climate change mitigation and adaptation.",recital,"The Artificial Intelligence Act (AI Act) recognizes the rapidly developing field of artificial intelligence (AI) and its potential to positively impact a variety of industries and social activities. The law highlights how AI can enhance predictions, streamline operations, and customize digital solutions for individuals and organizations. This could give companies a competitive edge and support beneficial outcomes in areas like healthcare, education, infrastructure, energy, transport, public services, and climate change mitigation."
General Data Protection Regulation (GDPR) - Article 16 Right to rectification,0.711807191,"Details of Article 16 Right to rectification in the General Data Protection Regulation (GDPR): The data subject shall have the right to obtain from the controller without undue delay the rectification of inaccurate personal data concerning him or her. Taking into account the purposes of the processing, the data subject shall have the right to have incomplete personal data completed, including by means of providing a supplementary statement.",article,"Article 16 of the General Data Protection Regulation (GDPR) gives you the right to correct any personal data about you that is incorrect. You can also add more information if the data about you is incomplete, considering the reasons why your data is being processed. The organization that has your data must make these changes without unnecessary delay."
General Data Protection Regulation (GDPR) - Definition of data concerning health,0.711800694,"Details of the Definition of data concerning health in the General Data Protection Regulation (GDPR): ""data concerning health"" means personal data related to the physical or mental health of a natural person, including the provision of health care services, which reveal information about his or her health status;",recital,"The General Data Protection Regulation (GDPR) has a new definition for ""data concerning health"". This refers to any personal information about a person's physical or mental health. It also includes any data related to health care services that can reveal information about a person's health status."
General Data Protection Regulation (GDPR) - Definition of binding corporate rules,0.711787283,"Details of the Definition of binding corporate rules in the General Data Protection Regulation (GDPR): ""binding corporate rules"" means personal data protection policies which are adhered to by a controller or processor established on the territory of a Member State for transfers or a set of transfers of personal data to a controller or processor in one or more third countries within a group of undertakings, or group of enterprises engaged in a joint economic activity;",recital,"The General Data Protection Regulation (GDPR) introduces a concept called ""binding corporate rules"". These are data protection policies that businesses operating in a Member State must follow when they transfer personal data to another business in a different country or countries. This applies to businesses that are part of the same group or engaged in a joint economic activity. The aim is to ensure personal data is protected, no matter where it's transferred within the company's network."
Artifical Inellegence Act (AI Act) - Definition of 'serious incident',0.711781263,"Within the Aritifical Intelligence Act (AI Act), the Definition of serious incident means any incident that directly or indirectly leads, might have led or might lead to any of the following:
(a)the death of a person or serious damage to a persons health, to property or the environment,
(b)a serious and irreversible disruption of the management and operation of critical infrastructure.",recital,"The Artificial Intelligence Act (AI Act) introduces the term 'serious incident'. This refers to any event that has caused, could have caused, or may cause in the future, either directly or indirectly, serious harm. This harm could be the death or serious injury of a person, significant damage to property or the environment, or a severe and irreversible disruption to the functioning of vital infrastructure."
General Data Protection Regulation (GDPR) - Article 61 Mutual assistance,0.711706936,"Details of Article 61 Mutual assistance in the General Data Protection Regulation (GDPR): 1. Supervisory authorities shall provide each other with relevant information and mutual assistance in order to implement and apply this Regulation in a consistent manner, and shall put in place measures for effective cooperation with one another. Mutual assistance shall cover, in particular, information requests and supervisory measures, such as requests to carry out prior authorisations and consultations, inspections and investigations. 2. Each supervisory authority shall take all appropriate measures required to reply to a request of another supervisory authority without undue delay and no later than one month after receiving the request. Such measures may include, in particular, the transmission of relevant information on the conduct of an investigation. 3. Requests for assistance shall contain all the necessary information, including the purpose of and reasons for the request. Information exchanged shall be used only for the purpose for which it was requested. 4. The requested supervisory authority shall not refuse to comply with the request unless: (a) it is not competent for the subject-matter of the request or for the measures it is requested to execute; or (b) compliance with the request would infringe this Regulation or Union or Member State law to which the supervisory authority receiving the request is subject. 5. The requested supervisory authority shall inform the requesting supervisory authority of the results or, as the case may be, of the progress of the measures taken in order to respond to the request. The requested supervisory authority shall provide reasons for any refusal to comply with a request pursuant to paragraph 4. 6. Requested supervisory authorities shall, as a rule, supply the information requested by other supervisory authorities by electronic means, using a standardised format. 7. Requested supervisory authorities shall not charge a fee for any action taken by them pursuant to a request for mutual assistance. Supervisory authorities may agree on rules to indemnify each other for specific expenditure arising from the provision of mutual assistance in exceptional circumstances. 8. Where a supervisory authority does not provide the information referred to in paragraph 5 of this Article within one month of receiving the request of another supervisory authority, the requesting supervisory authority may adopt a provisional measure on the territory of its Member State in accordance with Article 55(1). In that case, the urgent need to act under Article 66(1) shall be presumed to be met and require an urgent binding decision from the Board pursuant to Article 66(2). 9. The Commission may, by means of implementing acts, specify the format and procedures for mutual assistance referred to in this Article and the arrangements for the exchange of information by electronic means between supervisory authorities, and between supervisory authorities and the Board, in particular the standardised format referred to in paragraph 6 of this Article. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 93(2).",article,"The General Data Protection Regulation (GDPR) Article 61, known as Mutual Assistance, requires supervisory authorities to share relevant information and assist each other to ensure the GDPR is consistently applied. This includes responding to requests for assistance within a month. The requested authority can refuse if they're not competent for the request or if compliance would violate the GDPR or other laws. They must inform the requesting authority of their response progress and reasons for any refusal. Information is usually shared electronically and free of charge, but authorities can agree to cover each other's specific costs in exceptional cases. If a request isn't responded to within a month, the requesting authority can take temporary measures. The Commission can specify the format and procedures for mutual assistance and information exchange."
General Data Protection Regulation (GDPR) - Article 38 Position of the data protection officer,0.711706102,"Details of Article 38 Position of the data protection officer in the General Data Protection Regulation (GDPR): 1. The controller and the processor shall ensure that the data protection officer is involved, properly and in a timely manner, in all issues which relate to the protection of personal data. 2. The controller and processor shall support the data protection officer in performing the tasks referred to in Article 39 by providing resources necessary to carry out those tasks and access to personal data and processing operations, and to maintain his or her expert knowledge. 3. The controller and processor shall ensure that the data protection officer does not receive any instructions regarding the exercise of those tasks. He or she shall not be dismissed or penalised by the controller or the processor for performing his tasks. The data protection officer shall directly report to the highest management level of the controller or the processor. 4. Data subjects may contact the data protection officer with regard to all issues related to processing of their personal data and to the exercise of their rights under this Regulation. 5. The data protection officer shall be bound by secrecy or confidentiality concerning the performance of his or her tasks, in accordance with Union or Member State law. 6. The data protection officer may fulfil other tasks and duties. The controller or processor shall ensure that any such tasks and duties do not result in a conflict of interests.",article,The General Data Protection Regulation (GDPR) Article 38 outlines the role of the data protection officer (DPO). The DPO must be included in all matters related to personal data protection. The company (controller or processor) must provide the DPO with the necessary resources and access to personal data to perform their duties and maintain expertise. The DPO must not be instructed on how to do their tasks and cannot be penalized for performing them. They report directly to the highest management level. Individuals can contact the DPO about issues related to their personal data and rights. The DPO must keep their work confidential and can perform other duties as long as there's no conflict of interest.
California Consumer Privacy Act Regulations (CCPA) - Definition of Categories of third parties,0.711701095,"Details of Definition of Categories of third parties in the California Consumer Privacy Act Regulations (CCPA): Categories of third parties means types or groupings of third parties with whom the business shares personal information, described with enough particularity to provide consumers with a meaningful understanding of the type of third party. They may include advertising networks, internet service providers, data analytics providers, government entities, operating systems and platforms, social networks, and data brokers.",recital,"The California Consumer Privacy Act (CCPA) defines ""Categories of third parties"" as different types or groups of third parties that a business shares personal information with. These categories are described in a way that consumers can understand who these third parties are. Examples include advertising networks, internet service providers, data analytics providers, government entities, operating systems and platforms, social networks, and data brokers."
Digital Markets Act (DMA) - Article 14 Obligation to inform about concentrations,0.71163,"Details of Article 14 Obligation to inform about concentrations in the Digital Markets Act (DMA): 1. A gatekeeper shall inform the Commission of any intended concentration within the meaning of Article 3 of Regulation (EC) No 139/2004, where the merging entities or the target of concentration provide core platform services or any other services in the digital sector or enable the collection of data, irrespective of whether it is notifiable to the Commission under that Regulation or to a competent national competition authority under national merger rules. A gatekeeper shall inform the Commission of such a concentration prior to its implementation and following the conclusion of the agreement, the announcement of the public bid, or the acquisition of a controlling interest. 2. The information provided by the gatekeeper pursuant to paragraph 1 shall at least describe the undertakings concerned by the concentration, their Union and worldwide annual turnovers, their fields of activity, including activities directly related to the concentration, and the transaction value of the agreement or an estimation thereof, along with a summary of the concentration, including its nature and rationale and a list of the Member States concerned by the concentration. The information provided by the gatekeeper shall also describe, for any relevant core platform services, their Union annual turnovers, their numbers of yearly active business users and their numbers of monthly active end users, respectively. 3. If, following any concentration referred to in paragraph 1 of this Article, additional core platform services individually meet the thresholds in Article 3(2), point (b), the gatekeeper concerned shall inform the Commission thereof within 2 months from the implementation of the concentration and provide the Commission with the information referred to in Article 3(2). 4. The Commission shall inform the competent authorities of the Member States of any information received pursuant to paragraph 1 and publish annually the list of acquisitions of which it has been informed by gatekeepers pursuant to that paragraph. The Commission shall take account of the legitimate interest of undertakings in the protection of their business secrets. 5. The competent authorities of the Member States may use the information received under paragraph 1 of this Article to request the Commission to examine the concentration pursuant to Article 22 of Regulation (EC) No 139/2004.",article,"The Digital Markets Act (DMA) requires gatekeepers, or major digital companies, to inform the Commission about any planned mergers or acquisitions (concentrations) in the digital sector, even if they don't meet the usual notification requirements. This must be done before the merger or acquisition takes place. The gatekeeper must provide detailed information about the companies involved, their annual revenues, their activities, and the value of the deal. They must also provide information about their platform services, such as their annual revenues and user numbers. If any new services meet certain thresholds after the merger or acquisition, the gatekeeper must inform the Commission within two months. The Commission will share this information with the relevant authorities in EU member states, but will respect the confidentiality of business secrets. Member states can use this information to ask the Commission to review the merger or acquisition."
Digital Services Act (DSA) - Article 91 Review,0.71160239,"Article 91 Review in the Digital Services Act (DSA):  1.   By 18 February 2027, the Commission shall evaluate and report to the European Parliament, the Council and the European Economic and Social Committee on the potential effect of this Regulation on the development and economic growth of small and medium-sized enterprises.

By 17 November 2025, the Commission shall evaluate and report to the European Parliament, the Council and the European Economic and Social Committee on:

(a) the application of Article 33, including the scope of providers of intermediary services covered by the obligations set out in Section 5 of Chapter III of this Regulation;
(b) the way that this Regulation interacts with other legal acts, in particular the acts referred to in Article 2(3) and (4).

2.   By 17 November 2027, and every five years thereafter, the Commission shall evaluate this Regulation, and report to the European Parliament, the Council and the European Economic and Social Committee.

This report shall address in particular:
(a) the application of paragraph 1, second subparagraph, points (a) and (b);
(b) the contribution of this Regulation to the deepening and efficient functioning of the internal market for intermediary services, in particular as regards the cross-border provision of digital services;
(c) the application of Articles 13, 16, 20, 21, 45 and 46;
(d) the scope of the obligations on small and micro enterprises;
(e) the effectiveness of the supervision and enforcement mechanisms;
(f) the impact on the respect for the right to freedom of expression and information.

3.   Where appropriate, the report referred to in paragraphs 1 and 2 shall be accompanied by a proposal for amendment of this Regulation.

4.   The Commission shall, in the report referred to in paragraph 2 of this Article, also evaluate and report on the annual reports on their activities by the Digital Services Coordinators provided to the Commission and the Board pursuant to Article 55(1).

5.   For the purpose of paragraph 2, Member States and the Board shall send information on the request of the Commission.

6.   In carrying out the evaluations referred to in paragraph 2, the Commission shall take into account the positions and findings of the European Parliament, the Council, and other relevant bodies or sources, and shall pay specific attention to small and medium-sized enterprises and the position of new competitors.

7.   By 18 February 2027, the Commission, after consulting the Board, shall carry out an assessment of the functioning of the Board and of the application of Article 43, and shall report it to the European Parliament, the Council and the European Economic and Social Committee, taking into account the first years of application of the Regulation. On the basis of the findings and taking utmost account of the opinion of the Board, that report shall, where appropriate, be accompanied by a proposal for amendment of this Regulation with regard to the structure of the Board.",article,"The Digital Services Act (DSA) is a new law that will be reviewed by the Commission on specific dates to evaluate its impact on small and medium-sized businesses, as well as its interaction with other laws. The Commission will report its findings to the European Parliament, the Council, and the European Economic and Social Committee. The review will also assess the role of Digital Services Coordinators, the effectiveness of the law's supervision and enforcement mechanisms, and its impact on freedom of expression and information. The Commission will consider feedback from various sources, including small and medium-sized businesses and new competitors. If necessary, the Commission may propose amendments to the DSA. The functioning of the Board and the application of Article 43 will also be assessed, and if necessary, amendments to the DSA may be proposed regarding the structure of the Board."
Digital Markets Act (DMA) - Article 33 Limitation periods for the enforcement of penalties,0.711546719,"Details of Article 33 Limitation periods for the enforcement of penalties in the Digital Markets Act (DMA): 1. The power of the Commission to enforce decisions taken pursuant to Articles 30 and 31 shall be subject to a limitation period of 5 years. 2. Time shall begin to run from the day on which the decision becomes final. 3. The limitation period for the enforcement of penalties shall be interrupted: (a) by notification of a decision varying the original amount of the fine or periodic penalty payment or refusing an application for variation; or (b) by any action of the Commission or of a Member State, acting at the request of the Commission, designed to enforce payment of the fine or periodic penalty payment. 4. Each interruption shall start time running afresh. 5. The limitation period for the enforcement of penalties shall be suspended for so long as: (a) time to pay is allowed; or (b) enforcement of payment is suspended pursuant to a decision of the Court of Justice or to a decision by a national court.",article,"The Digital Markets Act (DMA) Article 33 sets a 5-year limit for the Commission to enforce decisions related to penalties. This 5-year period starts when the decision is finalized. However, this period can be paused or restarted. It can be restarted if the original fine amount is changed or if the Commission or a Member State takes action to enforce payment. It can be paused if there's an allowed payment delay or if payment enforcement is halted by a decision from the Court of Justice or a national court."
Digital Services Act (DSA) - Article 78 Limitation period for the enforcement of penalties,0.711491823,"Article 78 Limitation period for the enforcement of penalties in the Digital Services Act (DSA):  1.   The power of the Commission to enforce decisions taken pursuant to Articles 74 and 76 shall be subject to a limitation period of five years.

2.   Time shall begin to run on the day on which the decision becomes final.

3.   The limitation period for the enforcement of penalties shall be interrupted:

(a) by notification of a decision varying the original amount of the fine or periodic penalty payment or refusing an application for variation;
(b) by any action of the Commission, or of a Member State acting at the request of the Commission, designed to enforce payment of the fine or periodic penalty payment.

4.   Each interruption shall start time running afresh.

5.   The limitation period for the enforcement of penalties shall be suspended for so long as:
(a) time to pay is allowed;
(b) enforcement of payment is suspended pursuant to a decision of the Court of Justice of the European Union or to a decision of a national court.",article,"The Digital Services Act (DSA) states that the Commission has a five-year period to enforce penalties decided under Articles 74 and 76. This five-year period starts on the day the decision is finalized. However, there are circumstances that can interrupt this period. These include a change in the original fine amount, refusal of a change request, or any action taken to enforce payment. Each interruption resets the five-year period. Additionally, the enforcement period can be paused if there is an allowed payment period or if payment enforcement is halted by a decision from the Court of Justice of the European Union or a national court."
General Data Protection Regulation (GDPR) - Definition of cross-border processing,0.711485624,"Details of the Definition of cross-border processing in the General Data Protection Regulation (GDPR): ""cross-border processing"" means either: (a) processing of personal data which takes place in the context of the activities of establishments in more than one Member State of a controller or processor in the Union where the controller or processor is established in more than one Member State; or (b) processing of personal data which takes place in the context of the activities of a single establishment of a controller or processor in the Union but which substantially affects or is likely to substantially affect data subjects in more than one Member State.",recital,"The General Data Protection Regulation (GDPR) defines ""cross-border processing"" as the handling of personal data across multiple countries in two scenarios. Firstly, it applies when a company or individual that controls or processes data is based in more than one European Union (EU) member state and uses personal data in their operations. Secondly, it applies when a company or individual based in a single EU state processes personal data that significantly impacts or has the potential to significantly impact individuals in more than one EU state."
Artifical Inellegence Act (AI Act) - Definition of 'recall of an AI system',0.71146971,"Within the Aritifical Intelligence Act (AI Act), the Definition of recall of an AI system means any measure aimed at achieving the return to the provider of an AI system made available to users;",recital,"The Artificial Intelligence Act (AI Act) includes a provision about 'recall of an AI system'. This means that if there's a problem with an AI system that's been given to users, there are steps in place to get it back to the company that provided it. This could be for any reason, such as needing to fix a problem or update the system."
Artifical Inellegence Act (AI Act) - Article 85,0.711432219,"Aritifical Intelligence Act (AI Act) Article 85 Entry into force and application: 

1.This Regulation shall enter into force on the twentieth day following that of its publication in the Official Journal of the European Union.

2.This Regulation shall apply from [24 months following the entering into force of the Regulation].

3.By way of derogation from paragraph 2: 

(a)Title III, Chapter 4 and Title VI shall apply from [three months following the entry into force of this Regulation];

(b)Article 71 shall apply from [twelve months following the entry into force of this Regulation].

This Regulation shall be binding in its entirety and directly applicable in all Member States.",recital,"The Artificial Intelligence Act (AI Act) will become effective 20 days after it's published in the Official Journal of the European Union. It will be fully applicable 24 months after it comes into effect. However, certain parts of the Act, namely Title III, Chapter 4 and Title VI, will apply three months after the Act becomes effective. Article 71 will apply twelve months after the Act is effective. The AI Act is binding and applies directly to all European Union member states."
California Consumer Privacy Act Regulations (CCPA) - Definition of Verify,0.711430728,"Details of Definition of Verify in the California Consumer Privacy Act Regulations (CCPA): Verify means to determine that the consumer making a request to know or request to delete is the consumer about whom the business has collected information, or if that consumer is less than 13 years of age, the consumers parent or legal guardian.",recital,"The California Consumer Privacy Act (CCPA) includes a term ""Verify"". This means that businesses need to confirm the identity of the person asking for their personal information or asking for their information to be deleted. If the person is under 13 years old, the business needs to confirm the identity of their parent or legal guardian. This is to ensure that the information is only given to or deleted for the right person."
Artifical Inellegence Act (AI Act) - Context Section 2.3,0.711397946,"Aritifical Intelligence Act (AI Act) context section 2.3.Proportionality: 

The proposal builds on existing legal frameworks and is proportionate and necessary to achieve its objectives, since it follows a risk-based approach and imposes regulatory burdens only when an AI system is likely to pose high risks to fundamental rights and safety. For other, non-high-risk AI systems, only very limited transparency obligations are imposed, for example in terms of the provision of information to flag the use of an AI system when interacting with humans. For high-risk AI systems, the requirements of high quality data, documentation and traceability, transparency, human oversight, accuracy and robustness, are strictly necessary to mitigate the risks to fundamental rights and safety posed by AI and that are not covered by other existing legal frameworks. Harmonised standards and supporting guidance and compliance tools will assist providers and users in complying with the requirements laid down by the proposal and minimise their costs. The costs incurred by operators are proportionate to the objectives achieved and the economic and reputational benefits that operators can expect from this proposal.2.3.Proportionality:

The proposal builds on existing legal frameworks and is proportionate and necessary to achieve its objectives, since it follows a risk-based approach and imposes regulatory burdens only when an AI system is likely to pose high risks to fundamental rights and safety. For other, non-high-risk AI systems, only very limited transparency obligations are imposed, for example in terms of the provision of information to flag the use of an AI system when interacting with humans. For high-risk AI systems, the requirements of high quality data, documentation and traceability, transparency, human oversight, accuracy and robustness, are strictly necessary to mitigate the risks to fundamental rights and safety posed by AI and that are not covered by other existing legal frameworks. Harmonised standards and supporting guidance and compliance tools will assist providers and users in complying with the requirements laid down by the proposal and minimise their costs. The costs incurred by operators are proportionate to the objectives achieved and the economic and reputational benefits that operators can expect from this proposal.",recital,"The Artificial Intelligence Act (AI Act) is a new law that aims to regulate the use of AI systems based on their risk level. High-risk AI systems, which could potentially threaten fundamental rights and safety, will face strict regulations including the need for high-quality data, documentation, transparency, human oversight, and robustness. Lower-risk AI systems will have fewer regulations, but must still inform users when they are interacting with an AI system. The law aims to balance the need for safety and rights protection with the costs to AI providers and users. It also provides guidance and tools to help with compliance. The costs of these regulations are considered fair in light of the benefits they bring, including economic gains and a better reputation."
General Data Protection Regulation (GDPR) - Definition of recipient,0.711299837,"Details of the Definition of recipient in the General Data Protection Regulation (GDPR): ""recipient"" means a natural or legal person, public authority, agency or another body, to which the personal data are disclosed, whether a third party or not. However, public authorities which may receive personal data in the framework of a particular inquiry in accordance with Union or Member State law shall not be regarded as recipients; the processing of those data by those public authorities shall be in compliance with the applicable data protection rules according to the purposes of the processing;",recital,"The General Data Protection Regulation (GDPR) defines a ""recipient"" as any individual, organization, or body that receives personal data, regardless of whether they are a third party. However, public authorities receiving personal data for specific investigations under EU or Member State law are not considered recipients. These authorities must process the data in line with data protection rules for the intended purpose."
Artifical Inellegence Act (AI Act) - Context Section 1.112,0.711287,"Aritifical Intelligence Act (AI Act) context section 1.112.Reasons for and objectives of the proposal: 
The proposal also responds to explicit requests from the European Parliament (EP) and the European Council, which have repeatedly expressed calls for legislative action to ensure a well-functioning internal market for artificial intelligence systems (AI systems) where both benefits and risks of AI are adequately addressed at Union level. It supports the objective of the Union being a global leader in the development of secure, trustworthy and ethical artificial intelligence as stated by the European Council 3 and ensures the protection of ethical principles as specifically requested by the European Parliament 4 . 

In 2017, the European Council called for a sense of urgency to address emerging trends including issues such as artificial intelligence , while at the same time ensuring a high level of data protection, digital rights and ethical standards 5 . In its 2019 Conclusions on the Coordinated Plan on the development and use of artificial intelligence Made in Europe 6 , the Council further highlighted the importance of ensuring that European citizens rights are fully respected and called for a review of the existing relevant legislation to make it fit for purpose for the new opportunities and challenges raised by AI. The European Council has also called for a clear determination of the AI applications that should be considered high-risk 7 .

The most recent Conclusions from 21 October 2020 further called for addressing the opacity, complexity, bias, a certain degree of unpredictability and partially autonomous behaviour of certain AI systems, to ensure their compatibility with fundamental rights and to facilitate the enforcement of legal rules 8 .

The European Parliament has also undertaken a considerable amount of work in the area of AI. In October 2020, it adopted a number of resolutions related to AI, including on ethics 9 , liability 10 and copyright 11 . In 2021, those were followed by resolutions on AI in criminal matters 12 and in education, culture and the audio-visual sector 13 . The EP Resolution on a Framework of Ethical Aspects of Artificial Intelligence, Robotics and Related Technologies specifically recommends to the Commission to propose legislative action to harness the opportunities and benefits of AI, but also to ensure protection of ethical principles. The resolution includes a text of the legislative proposal for a regulation on ethical principles for the development, deployment and use of AI, robotics and related technologies. In accordance with the political commitment made by President von der Leyen in her Political Guidelines as regards resolutions adopted by the European Parliament under Article 225 TFEU, this proposal takes into account the aforementioned resolution of the European Parliament in full respect of proportionality, subsidiarity and better law making principles.1.112.Reasons for and objectives of the proposal:
The proposal also responds to explicit requests from the European Parliament (EP) and the European Council, which have repeatedly expressed calls for legislative action to ensure a well-functioning internal market for artificial intelligence systems (AI systems) where both benefits and risks of AI are adequately addressed at Union level. It supports the objective of the Union being a global leader in the development of secure, trustworthy and ethical artificial intelligence as stated by the European Council 3 and ensures the protection of ethical principles as specifically requested by the European Parliament 4 . 

In 2017, the European Council called for a sense of urgency to address emerging trends including issues such as artificial intelligence , while at the same time ensuring a high level of data protection, digital rights and ethical standards 5 . In its 2019 Conclusions on the Coordinated Plan on the development and use of artificial intelligence Made in Europe 6 , the Council further highlighted the importance of ensuring that European citizens rights are fully respected and called for a review of the existing relevant legislation to make it fit for purpose for the new opportunities and challenges raised by AI. The European Council has also called for a clear determination of the AI applications that should be considered high-risk 7 .

The most recent Conclusions from 21 October 2020 further called for addressing the opacity, complexity, bias, a certain degree of unpredictability and partially autonomous behaviour of certain AI systems, to ensure their compatibility with fundamental rights and to facilitate the enforcement of legal rules 8 .

The European Parliament has also undertaken a considerable amount of work in the area of AI. In October 2020, it adopted a number of resolutions related to AI, including on ethics 9 , liability 10 and copyright 11 . In 2021, those were followed by resolutions on AI in criminal matters 12 and in education, culture and the audio-visual sector 13 . The EP Resolution on a Framework of Ethical Aspects of Artificial Intelligence, Robotics and Related Technologies specifically recommends to the Commission to propose legislative action to harness the opportunities and benefits of AI, but also to ensure protection of ethical principles. The resolution includes a text of the legislative proposal for a regulation on ethical principles for the development, deployment and use of AI, robotics and related technologies. In accordance with the political commitment made by President von der Leyen in her Political Guidelines as regards resolutions adopted by the European Parliament under Article 225 TFEU, this proposal takes into account the aforementioned resolution of the European Parliament in full respect of proportionality, subsidiarity and better law making principles.",recital,"The Artificial Intelligence Act (AI Act) is a new law proposed by the European Parliament and the European Council. The law aims to regulate the use of artificial intelligence (AI) systems in the European Union. The goal is to ensure that the benefits and risks of AI are properly addressed and that ethical principles are protected. The law also aims to make the EU a global leader in the development of secure, trustworthy, and ethical AI. The AI Act will address issues such as the complexity, unpredictability, and autonomous behavior of certain AI systems. It will also review existing legislation to make sure it is suitable for the new challenges raised by AI. The law will consider AI applications that are high-risk and ensure that European citizens' rights are fully respected."
Artifical Inellegence Act (AI Act) - Article 11,0.711124063,"Aritifical Intelligence Act (AI Act) Article 11 Technical documentation:

1.The technical documentation of a high-risk AI system shall be drawn up before that system is placed on the market or put into service and shall be kept up-to date.

The technical documentation shall be drawn up in such a way to demonstrate that the high-risk AI system complies with the requirements set out in this Chapter and provide national competent authorities and notified bodies with all the necessary information to assess the compliance of the AI system with those requirements. It shall contain, at a minimum, the elements set out in Annex IV.

2.Where a high-risk AI system related to a product, to which the legal acts listed in Annex II, section A apply, is placed on the market or put into service one single technical documentation shall be drawn up containing all the information set out in Annex IV as well as the information required under those legal acts.

3.The Commission is empowered to adopt delegated acts in accordance with Article 73 to amend Annex IV where necessary to ensure that, in the light of technical progress, the technical documentation provides all the necessary information to assess the compliance of the system with the requirements set out in this Chapter.",article,"The Artificial Intelligence Act (AI Act) requires that any high-risk AI system must have thorough technical documentation before it is released or used. This documentation must prove that the AI system meets the Act's requirements and provides all necessary information for authorities to confirm its compliance. If the AI system is related to a product covered by other legal acts, a single technical document should be created. This document should include all information from Annex IV and any other required information from the related legal acts. The Commission has the power to update Annex IV to ensure that it keeps up with technological advancements and continues to provide all necessary information for system compliance assessment."
Digital Markets Act (DMA) - Article 15 Obligation of an audit,0.711074,"Details of Article 15 Obligation of an audit in the Digital Markets Act (DMA): 1. Within 6 months after its designation pursuant to Article 3, a gatekeeper shall submit to the Commission an independently audited description of any techniques for profiling of consumers that the gatekeeper applies to or across its core platform services listed in the designation decision pursuant to Article 3(9). The Commission shall transmit that audited description to the European Data Protection Board. 2. The Commission may adopt an implementing act referred to in Article 46(1), point (g), to develop the methodology and procedure of the audit. 3. The gatekeeper shall make publicly available an overview of the audited description referred to in paragraph 1. In doing so, the gatekeeper shall be entitled to take account of the need to respect its business secrets. The gatekeeper shall update that description and that overview at least annually.",article,"The Digital Markets Act (DMA) requires a ""gatekeeper"" (a major tech company) to submit an independently audited report detailing their consumer profiling techniques within 6 months of being identified as a gatekeeper. This report is sent to the Commission and the European Data Protection Board. The Commission can establish how the audit is conducted. The gatekeeper must also make a summary of the audit public, while considering the need to keep its business secrets confidential. This summary should be updated at least once a year."
Digital Markets Act (DMA) - Definition of payment system for in-app purchases,0.711017966,"Details of the Definition of payment system for in-app purchases in the Digital Markets Act (DMA): ""payment system for in-app purchases"" means a software application, service or user interface which facilitates purchases of digital content or digital services within a software application, including content, subscriptions, features or functionality, and the payments for such purchases;",rectial,"The Digital Markets Act (DMA) has introduced a new definition for the term ""payment system for in-app purchases"". This refers to any software application, service, or user interface that helps users buy digital content or services within an app. This could include buying things like content, subscriptions, features, or functionality. It also includes the payments made for these purchases."
General Data Protection Regulation (GDPR) - Article 47 Binding corporate rules,0.711004913,"Details of Article 47 Binding corporate rules in the General Data Protection Regulation (GDPR): 1. The competent supervisory authority shall approve binding corporate rules in accordance with the consistency mechanism set out in Article 63, provided that they: (a) are legally binding and apply to and are enforced by every member concerned of the group of undertakings, or group of enterprises engaged in a joint economic activity, including their employees; (b) expressly confer enforceable rights on data subjects with regard to the processing of their personal data; and (c) fulfil the requirements laid down in paragraph 2. 2. The binding corporate rules referred to in paragraph 1 shall specify at least: (a) the structure and contact details of the group of undertakings, or group of enterprises engaged in a joint economic activity and of each of its members; (b) the data transfers or set of transfers, including the categories of personal data, the type of processing and its purposes, the type of data subjects affected and the identification of the third country or countries in question; (c) their legally binding nature, both internally and externally; (d) the application of the general data protection principles, in particular purpose limitation, data minimisation, limited storage periods, data quality, data protection by design and by default, legal basis for processing, processing of special categories of personal data, measures to ensure data security, and the requirements in respect of onward transfers to bodies not bound by the binding corporate rules; (e) the rights of data subjects in regard to processing and the means to exercise those rights, including the right not to be subject to decisions based solely on automated processing, including profiling in accordance with Article 22, the right to lodge a complaint with the competent supervisory authority and before the competent courts of the Member States in accordance with Article 79, and to obtain redress and, where appropriate, compensation for a breach of the binding corporate rules; (f) the acceptance by the controller or processor established on the territory of a Member State of liability for any breaches of the binding corporate rules by any member concerned not established in the Union; the controller or the processor shall be exempt from that liability, in whole or in part, only if it proves that that member is not responsible for the event giving rise to the damage; (g) how the information on the binding corporate rules, in particular on the provisions referred to in points (d), (e) and (f) of this paragraph is provided to the data subjects in addition to Articles 13 and 14; (h) the tasks of any data protection officer designated in accordance with Article 37 or any other person or entity in charge of the monitoring compliance with the binding corporate rules within the group of undertakings, or group of enterprises engaged in a joint economic activity, as well as monitoring training and complaint-handling; (i) the complaint procedures; (j) the mechanisms within the group of undertakings, or group of enterprises engaged in a joint economic activity for ensuring the verification of compliance with the binding corporate rules. Such mechanisms shall include data protection audits and methods for ensuring corrective actions to protect the rights of the data subject. Results of such verification should be communicated to the person or entity referred to in point (h) and to the board of the controlling undertaking of a group of undertakings, or of the group of enterprises engaged in a joint economic activity, and should be available upon request to the competent supervisory authority; (k) the mechanisms for reporting and recording changes to the rules and reporting those changes to the supervisory authority; (l) the cooperation mechanism with the supervisory authority to ensure compliance by any member of the group of undertakings, or group of enterprises engaged in a joint economic activity, in particular by making available to the supervisory authority the results of verifications of the measures referred to in point (j); (m) the mechanisms for reporting to the competent supervisory authority any legal requirements to which a member of the group of undertakings, or group of enterprises engaged in a joint economic activity is subject in a third country which are likely to have a substantial adverse effect on the guarantees provided by the binding corporate rules; and (n) the appropriate data protection training to personnel having permanent or regular access to personal data. 3. The Commission may specify the format and procedures for the exchange of information between controllers, processors and supervisory authorities for binding corporate rules within the meaning of this Article. Those implementing acts shall be adopted in accordance with the examination procedure set out in Article 93(2).",article,"Article 47 of the General Data Protection Regulation (GDPR) states that companies must have approved, legally binding rules for handling personal data. These rules must apply to all members of the company, including employees, and give individuals specific rights regarding their data. The rules must detail the company's structure, the types of data being transferred, how the data is processed, and the countries involved. They must also outline how the company adheres to data protection principles, such as limiting data collection and ensuring data security. Individuals must be informed of their rights, including the right to complain and seek compensation if the rules are breached. The company must accept responsibility for any breaches, unless they can prove they were not at fault. The rules must also include information on how they are monitored and enforced, how changes are reported, and how the company cooperates with supervisory authorities."
Artifical Inellegence Act (AI Act) - Context Section 5.2.3,0.710974038,"Aritifical Intelligence Act (AI Act) context section 5.2.3.HIGH-RISK AI SYSTEMS (TITLE III): 

Title III contains specific rules for AI systems that create a high risk to the health and safety or fundamental rights of natural persons. In line with a risk-based approach, those high-risk AI systems are permitted on the European market subject to compliance with certain mandatory requirements and an ex-ante conformity assessment. The classification of an AI system as high-risk is based on the intended purpose of the AI system, in line with existing product safety legislation. Therefore, the classification as high-risk does not only depend on the function performed by the AI system, but also on the specific purpose and modalities for which that system is used.

Chapter 1 of Title III sets the classification rules and identifies two main categories of high-risk AI systems: 

AI systems intended to be used as safety component of products that are subject to third party ex-ante conformity assessment;

other stand-alone AI systems with mainly fundamental rights implications that are explicitly listed in Annex III.

This list of high-risk AI systems in Annex III contains a limited number of AI systems whose risks have already materialised or are likely to materialise in the near future. To ensure that the regulation can be adjusted to emerging uses and applications of AI, the Commission may expand the list of high-risk AI systems used within certain pre-defined areas, by applying a set of criteria and risk assessment methodology.

Chapter 2 sets out the legal requirements for high-risk AI systems in relation to data and data governance, documentation and recording keeping, transparency and provision of information to users, human oversight, robustness, accuracy and security. The proposed minimum requirements are already state-of-the-art for many diligent operators and the result of two years of preparatory work, derived from the Ethics Guidelines of the HLEG 29 , piloted by more than 350 organisations 30 . They are also largely consistent with other international recommendations and principles, which ensures that the proposed AI framework is compatible with those adopted by the EUs international trade partners. The precise technical solutions to achieve compliance with those requirements may be provided by standards or by other technical specifications or otherwise be developed in accordance with general engineering or scientific knowledge at the discretion of the provider of the AI system. This flexibility is particularly important, because it allows providers of AI systems to choose the way to meet their requirements, taking into account the state-of-the-art and technological and scientific progress in this field.

Chapter 3 places a clear set of horizontal obligations on providers of high-risk AI systems. Proportionate obligations are also placed on users and other participants across the AI value chain (e.g., importers, distributors, authorized representatives).

Chapter 4 sets the framework for notified bodies to be involved as independent third parties in conformity assessment procedures, while Chapter 5 explains in detail the conformity assessment procedures to be followed for each type of high-risk AI system. The conformity assessment approach aims to minimise the burden for economic operators as well as for notified bodies, whose capacity needs to be progressively ramped up over time. AI systems intended to be used as safety components of products that are regulated under the New Legislative Framework legislation (e.g. machinery, toys, medical devices, etc.) will be subject to the same ex-ante and ex-post compliance and enforcement mechanisms of the products of which they are a component. The key difference is that the ex-ante and ex-post mechanisms will ensure compliance not only with the requirements established by sectorial legislation, but also with the requirements established by this regulation.

As regards stand-alone high-risk AI systems that are referred to in Annex III, a new compliance and enforcement system will be established. This follows the model of the New Legislative Framework legislation implemented through internal control checks by the providers with the exception of remote biometric identification systems that would be subject to third party conformity assessment. A comprehensive ex-ante conformity assessment through internal checks, combined with a strong ex-post enforcement, could be an effective and reasonable solution for those systems, given the early phase of the regulatory intervention and the fact the AI sector is very innovative and expertise for auditing is only now being accumulated. An assessment through internal checks for stand-alone high-risk AI systems would require a full, effective and properly documented ex ante compliance with all requirements of the regulation and compliance with robust quality and risk management systems and post-market monitoring. After the provider has performed the relevant conformity assessment, it should register those stand-alone high-risk AI systems in an EU database that will be managed by the Commission to increase public transparency and oversight and strengthen ex post supervision by competent authorities. By contrast, for reasons of consistency with the existing product safety legislation, the conformity assessments of AI systems that are safety components of products will follow a system with third party conformity assessment procedures already established under the relevant sectoral product safety legislation. New ex ante re-assessments of the conformity will be needed in case of substantial modifications to the AI systems (and notably changes which go beyond what is pre-determined by the provider in its technical documentation and checked at the moment of the ex-ante conformity assessment).5.2.3.HIGH-RISK AI SYSTEMS (TITLE III):

Title III contains specific rules for AI systems that create a high risk to the health and safety or fundamental rights of natural persons. In line with a risk-based approach, those high-risk AI systems are permitted on the European market subject to compliance with certain mandatory requirements and an ex-ante conformity assessment. The classification of an AI system as high-risk is based on the intended purpose of the AI system, in line with existing product safety legislation. Therefore, the classification as high-risk does not only depend on the function performed by the AI system, but also on the specific purpose and modalities for which that system is used.

Chapter 1 of Title III sets the classification rules and identifies two main categories of high-risk AI systems:

AI systems intended to be used as safety component of products that are subject to third party ex-ante conformity assessment;

other stand-alone AI systems with mainly fundamental rights implications that are explicitly listed in Annex III.

This list of high-risk AI systems in Annex III contains a limited number of AI systems whose risks have already materialised or are likely to materialise in the near future. To ensure that the regulation can be adjusted to emerging uses and applications of AI, the Commission may expand the list of high-risk AI systems used within certain pre-defined areas, by applying a set of criteria and risk assessment methodology.

Chapter 2 sets out the legal requirements for high-risk AI systems in relation to data and data governance, documentation and recording keeping, transparency and provision of information to users, human oversight, robustness, accuracy and security. The proposed minimum requirements are already state-of-the-art for many diligent operators and the result of two years of preparatory work, derived from the Ethics Guidelines of the HLEG 29 , piloted by more than 350 organisations 30 . They are also largely consistent with other international recommendations and principles, which ensures that the proposed AI framework is compatible with those adopted by the EUs international trade partners. The precise technical solutions to achieve compliance with those requirements may be provided by standards or by other technical specifications or otherwise be developed in accordance with general engineering or scientific knowledge at the discretion of the provider of the AI system. This flexibility is particularly important, because it allows providers of AI systems to choose the way to meet their requirements, taking into account the state-of-the-art and technological and scientific progress in this field.

Chapter 3 places a clear set of horizontal obligations on providers of high-risk AI systems. Proportionate obligations are also placed on users and other participants across the AI value chain (e.g., importers, distributors, authorized representatives).

Chapter 4 sets the framework for notified bodies to be involved as independent third parties in conformity assessment procedures, while Chapter 5 explains in detail the conformity assessment procedures to be followed for each type of high-risk AI system. The conformity assessment approach aims to minimise the burden for economic operators as well as for notified bodies, whose capacity needs to be progressively ramped up over time. AI systems intended to be used as safety components of products that are regulated under the New Legislative Framework legislation (e.g. machinery, toys, medical devices, etc.) will be subject to the same ex-ante and ex-post compliance and enforcement mechanisms of the products of which they are a component. The key difference is that the ex-ante and ex-post mechanisms will ensure compliance not only with the requirements established by sectorial legislation, but also with the requirements established by this regulation.

As regards stand-alone high-risk AI systems that are referred to in Annex III, a new compliance and enforcement system will be established. This follows the model of the New Legislative Framework legislation implemented through internal control checks by the providers with the exception of remote biometric identification systems that would be subject to third party conformity assessment. A comprehensive ex-ante conformity assessment through internal checks, combined with a strong ex-post enforcement, could be an effective and reasonable solution for those systems, given the early phase of the regulatory intervention and the fact the AI sector is very innovative and expertise for auditing is only now being accumulated. An assessment through internal checks for stand-alone high-risk AI systems would require a full, effective and properly documented ex ante compliance with all requirements of the regulation and compliance with robust quality and risk management systems and post-market monitoring. After the provider has performed the relevant conformity assessment, it should register those stand-alone high-risk AI systems in an EU database that will be managed by the Commission to increase public transparency and oversight and strengthen ex post supervision by competent authorities. By contrast, for reasons of consistency with the existing product safety legislation, the conformity assessments of AI systems that are safety components of products will follow a system with third party conformity assessment procedures already established under the relevant sectoral product safety legislation. New ex ante re-assessments of the conformity will be needed in case of substantial modifications to the AI systems (and notably changes which go beyond what is pre-determined by the provider in its technical documentation and checked at the moment of the ex-ante conformity assessment).",recital,"The Artificial Intelligence Act (AI Act) introduces guidelines for high-risk AI systems in Europe. High-risk AI systems are defined by their purpose and the risk they pose to health, safety, or fundamental rights. These systems can only be used in the European market if they meet specific requirements and pass a preliminary assessment. High-risk AI systems are divided into two categories: those used as safety components in products, and stand-alone systems that primarily affect fundamental rights. The act also outlines the legal requirements for these systems, including data governance, documentation, transparency, human oversight, robustness, accuracy, and security. Providers of high-risk AI systems have certain obligations, and there are also obligations for users and other participants. The act sets up a framework for independent bodies to assess conformity, and details the procedures for each type of high-risk AI system. Stand-alone high-risk AI systems will be subject to a new compliance and enforcement system, and any changes to these systems will require new assessments."
General Data Protection Regulation (GDPR) - Definition of processor,0.710959,"Details of the Definition of processor in the General Data Protection Regulation (GDPR): ""processor"" means a natural or legal person, public authority, agency or other body which processes personal data on behalf of the controller;",recital,"The General Data Protection Regulation (GDPR) defines a ""processor"" as any individual, company, government authority, agency, or other entity that handles personal data for someone else, known as the controller. In simpler terms, if you're managing personal information for someone else, you're considered a 'processor' under this law."
General Data Protection Regulation (GDPR) - Contextual Paragraph (50),0.710855365,"Details of the Contextual Paragraph (50) in the General Data Protection Regulation (GDPR): The processing of personal data for purposes other than those for which the personal data were initially collected should be allowed only where the processing is compatible with the purposes for which the personal data were initially collected. In such a case, no legal basis separate from that which allowed the collection of the personal data is required. If the processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller, Union or Member State law may determine and specify the tasks and purposes for which the further processing should be regarded as compatible and lawful. Further processing for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes should be considered to be compatible lawful processing operations. The legal basis provided by Union or Member State law for the processing of personal data may also provide a legal basis for further processing. In order to ascertain whether a purpose of further processing is compatible with the purpose for which the personal data are initially collected, the controller, after having met all the requirements for the lawfulness of the original processing, should take into account, inter alia: any link between those purposes and the purposes of the intended further processing; the context in which the personal data have been collected, in particular the reasonable expectations of data subjects based on their relationship with the controller as to their further use; the nature of the personal data; the consequences of the intended further processing for data subjects; and the existence of appropriate safeguards in both the original and intended further processing operations. Where the data subject has given consent or the processing is based on Union or Member State law which constitutes a necessary and proportionate measure in a democratic society to safeguard, in particular, important objectives of general public interest, the controller should be allowed to further process the personal data irrespective of the compatibility of the purposes. In any case, the application of the principles set out in this Regulation and in particular the information of the data subject on those other purposes and on his or her rights including the right to object, should be ensured. Indicating possible criminal acts or threats to public security by the controller and transmitting the relevant personal data in individual cases or in several cases relating to the same criminal act or threats to public security to a competent authority should be regarded as being in the legitimate interest pursued by the controller. However, such transmission in the legitimate interest of the controller or further processing of personal data should be prohibited if the processing is not compatible with a legal, professional or other binding obligation of secrecy.",recital,"The General Data Protection Regulation (GDPR) states that personal data can only be used for the same reasons it was initially collected. If it needs to be used for another reason, it must be compatible with the original reason and doesn't require a separate legal basis. However, if the data is needed for public interest, legal or scientific purposes, it can be further processed. The controller, or the person handling the data, must consider several factors including the nature of the data, the impact on the individual and the safeguards in place. If the individual has given consent or if it's necessary for public interest, the data can be used regardless of the original purpose. Any potential criminal activity should be reported to the relevant authorities. However, if the processing conflicts with a legal or professional obligation of secrecy, it should be prohibited."
General Data Protection Regulation (GDPR) - Contextual Paragraph (156),0.710812807,"Details of the Contextual Paragraph (156) in the General Data Protection Regulation (GDPR): The processing of personal data for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes should be subject to appropriate safeguards for the rights and freedoms of the data subject pursuant to this Regulation. Those safeguards should ensure that technical and organisational measures are in place in order to ensure, in particular, the principle of data minimisation. The further processing of personal data for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes is to be carried out when the controller has assessed the feasibility to fulfil those purposes by processing data which do not permit or no longer permit the identification of data subjects, provided that appropriate safeguards exist (such as, for instance, pseudonymisation of the data). Member States should provide for appropriate safeguards for the processing of personal data for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes. Member States should be authorised to provide, under specific conditions and subject to appropriate safeguards for data subjects, specifications and derogations with regard to the information requirements and rights to rectification, to erasure, to be forgotten, to restriction of processing, to data portability, and to object when processing personal data for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes. The conditions and safeguards in question may entail specific procedures for data subjects to exercise those rights if this is appropriate in the light of the purposes sought by the specific processing along with technical and organisational measures aimed at minimising the processing of personal data in pursuance of the proportionality and necessity principles. The processing of personal data for scientific purposes should also comply with other relevant legislation such as on clinical trials.",recital,"The General Data Protection Regulation (GDPR) Paragraph 156 states that personal data used for public interest, scientific research, or statistical purposes must be protected. This includes using technical and organizational measures to minimize data use. If personal data is further processed for these purposes, it should be anonymized or pseudonymized to protect the individual's identity. Member States must provide safeguards for this data processing and may set specific conditions for data subjects' rights, such as rectification, erasure, and data portability. These conditions may include special procedures for exercising these rights. Any personal data processing for scientific purposes must also comply with other relevant laws, such as those on clinical trials."
Artifical Inellegence Act (AI Act) - Definition of 'distributor',0.71078217,"Within the Aritifical Intelligence Act (AI Act), the Definition of distributor means any natural or legal person in the supply chain, other than the provider or the importer, that makes an AI system available on the Union market without affecting its properties;",recital,The Artificial Intelligence Act (AI Act) defines a 'distributor' as any individual or business involved in the supply chain that provides an AI system to the European Union market. This excludes the original provider or the importer of the system. The distributor does not make any changes to the AI system's properties.
Digital Markets Act (DMA) - Article 35 Annual reporting,0.710770905,"Details of Article 35 Annual reporting in the Digital Markets Act (DMA): 1. The Commission shall submit to the European Parliament and to the Council an annual report on the implementation of this Regulation and the progress made towards achieving its objectives. 2. The report referred to in paragraph 1 shall include: (a) a summary of the Commission""s activities including any adopted measures or decisions and ongoing market investigations in connection with this Regulation; (b) the findings resulting from the monitoring of the implementation by the gatekeepers of the obligations under this Regulation; (c) an assessment of the audited description referred to in Article 15; (d) an overview of the cooperation between the Commission and national authorities in connection with this Regulation; (e) an overview of the activities and tasks performed by the High Level Group of Digital Regulators, including how its recommendations as regards the enforcement of this Regulation are to be implemented. 3. The Commission shall publish the report on its website.",article,"The Digital Markets Act (DMA) requires the European Commission to submit an annual report to the European Parliament and Council. This report will detail the progress and implementation of the DMA. It will include a summary of the Commission's activities, findings from monitoring the compliance of digital gatekeepers, an assessment of the audited description mentioned in Article 15, and an overview of cooperation between the Commission and national authorities. It will also cover the activities of the High Level Group of Digital Regulators and how their recommendations are being implemented. This report will be made publicly available on the Commission's website."
Artifical Inellegence Act (AI Act) - Article 50,0.710685074,"Aritifical Intelligence Act (AI Act) Article 50 Document retention:

The provider shall, for a period ending 10 years after the AI system has been placed on the market or put into service, keep at the disposal of the national competent authorities:

(a)the technical documentation referred to in Article 11;

(b)the documentation concerning the quality management system referred to Article 17;

(c)the documentation concerning the changes approved by notified bodies where applicable;

(d)the decisions and other documents issued by the notified bodies where applicable;

(e)the EU declaration of conformity referred to in Article 48.",article,"The Artificial Intelligence Act (AI Act) Article 50 requires AI service providers to keep certain documents for 10 years after their AI system is released or used. These documents include technical documentation (Article 11), quality management system documentation (Article 17), documents about approved changes and decisions made by notified bodies, and the EU declaration of conformity (Article 48). These documents must be available to national authorities if needed."
Artifical Inellegence Act (AI Act) - Article 63,0.710629,"Aritifical Intelligence Act (AI Act) Article 63 Market surveillance and control of AI systems in the Union market:

1.Regulation (EU) 2019/1020 shall apply to AI systems covered by this Regulation. However, for the purpose of the effective enforcement of this Regulation:

(a)any reference to an economic operator under Regulation (EU) 2019/1020 shall be understood as including all operators identified in Title III, Chapter 3 of this Regulation;

(b)any reference to a product under Regulation (EU) 2019/1020 shall be understood as including all AI systems falling within the scope of this Regulation.

2.The national supervisory authority shall report to the Commission on a regular basis the outcomes of relevant market surveillance activities. The national supervisory authority shall report, without delay, to the Commission and relevant national competition authorities any information identified in the course of market surveillance activities that may be of potential interest for the application of Union law on competition rules.

3.For high-risk AI systems, related to products to which legal acts listed in Annex II, section A apply, the market surveillance authority for the purposes of this Regulation shall be the authority responsible for market surveillance activities designated under those legal acts.

4.For AI systems placed on the market, put into service or used by financial institutions regulated by Union legislation on financial services, the market surveillance authority for the purposes of this Regulation shall be the relevant authority responsible for the financial supervision of those institutions under that legislation.

5.For AI systems listed in point 1(a) in so far as the systems are used for law enforcement purposes, points 6 and 7 of Annex III, Member States shall designate as market surveillance authorities for the purposes of this Regulation either the competent data protection supervisory authorities under Directive (EU) 2016/680, or Regulation 2016/679 or the national competent authorities supervising the activities of the law enforcement, immigration or asylum authorities putting into service or using those systems.

6.Where Union institutions, agencies and bodies fall within the scope of this Regulation, the European Data Protection Supervisor shall act as their market surveillance authority.

7.Member States shall facilitate the coordination between market surveillance authorities designated under this Regulation and other relevant national authorities or bodies which supervise the application of Union harmonisation legislation listed in Annex II or other Union legislation that might be relevant for the high-risk AI systems referred to in Annex III.",article,"The Artificial Intelligence Act (AI Act) Article 63 focuses on the regulation and surveillance of AI systems in the European Union market. It applies existing EU regulations to AI systems, including all operators and products under its scope. National supervisory authorities are required to regularly report to the Commission on market surveillance activities and share any information that might affect competition rules. High-risk AI systems are overseen by authorities designated under specific legal acts. AI systems used by financial institutions are monitored by the relevant financial supervisory authorities. For AI systems used in law enforcement, either data protection supervisory authorities or national authorities supervising law enforcement activities will oversee them. The European Data Protection Supervisor will act as the surveillance authority for Union institutions using AI systems. Member States are required to coordinate between these authorities and other relevant national bodies."
Digital Markets Act (DMA) - Article 29 Non-compliance,0.710523129,"Details of Article 29 Non-compliance in the Digital Markets Act (DMA): 1. The Commission shall adopt an implementing act setting out its finding of non-compliance (""the non-compliance decision"") where it finds that a gatekeeper does not comply with one or more of the following: (a) any of the obligations laid down in Article 5, 6 or 7; (b) measures specified by the Commission in a decision adopted pursuant to Article 8(2); (c) remedies imposed pursuant to Article 18(1); (d) interim measures ordered pursuant to Article 24; or (e) commitments made legally binding pursuant to Article 25. That implementing act shall be adopted in accordance with the advisory procedure referred to in Article 50(2). 2. The Commission shall endeavour to adopt its non-compliance decision within 12 months from the opening of proceedings pursuant to Article 20. 3. Before adopting the non-compliance decision, the Commission shall communicate its preliminary findings to the gatekeeper concerned. In those preliminary findings, the Commission shall explain the measures it is considering taking or that it considers that the gatekeeper should take in order to effectively address the preliminary findings. 4. Where it intends to adopt a non-compliance decision, the Commission may consult third parties. 5. In the non-compliance decision, the Commission shall order the gatekeeper to cease and desist with the noncompliance within an appropriate deadline and to provide explanations on how it plans to comply with that decision. 6. The gatekeeper shall provide the Commission with the description of the measures that it has taken to ensure compliance with the non-compliance decision. 7. Where the Commission decides not to adopt a non-compliance decision, it shall close the proceedings by a decision.",article,"The Digital Markets Act (DMA) Article 29 outlines the process for handling non-compliance by gatekeepers (major tech companies). If a gatekeeper doesn't follow certain obligations, measures, remedies, interim measures, or legal commitments, the Commission can issue a non-compliance decision. This decision should be made within 12 months of the start of proceedings. Before making this decision, the Commission will share its preliminary findings with the gatekeeper and suggest corrective actions. The Commission may also consult third parties. If a non-compliance decision is made, the gatekeeper must stop the non-compliant behavior by a set deadline and explain how it will comply. The gatekeeper must then tell the Commission how it has ensured compliance. If the Commission decides not to issue a non-compliance decision, it will close the proceedings."
California Consumer Privacy Act Regulations (CCPA) - Definition of Attorney General,0.71048218,Details of Definition of Attorney General in the California Consumer Privacy Act Regulations (CCPA): Attorney General means the California Attorney General or any officer or employee of the California Department of Justice acting under the authority of the California Attorney General.,recital,"The California Consumer Privacy Act Regulations (CCPA) defines ""Attorney General"" as the California Attorney General or any employee of the California Department of Justice who is acting on behalf of the California Attorney General. This means that any actions taken by these individuals are considered actions of the Attorney General under this law."
Digital Services Act (DSA) - Article 47 Codes of conduct for accessibility,0.710456252,"Article 47 Codes of conduct for accessibility in the Digital Services Act (DSA):  1.   The Commission shall encourage and facilitate the drawing up of codes of conduct at Union level with the involvement of providers of online platforms and other relevant service providers, organisations representing recipients of the service and civil society organisations or relevant authorities to promote full and effective, equal participation, by improving access to online services that, through their initial design or subsequent adaptation, address the particular needs of persons with disabilities.

2.   The Commission shall aim to ensure that the codes of conduct pursue the objective of ensuring that those services are accessible in compliance with Union and national law, in order to maximise their foreseeable use by persons with disabilities. The Commission shall aim to ensure that the codes of conduct address at least the following objectives:

(a) designing and adapting services to make them accessible to persons with disabilities by making them perceivable, operable, understandable and robust;
(b) explaining how the services meet the applicable accessibility requirements and making this information available to the public in an accessible manner for persons with disabilities;
(c) making information, forms and measures provided pursuant to this Regulation available in such a manner that they are easy to find, easy to understand, and accessible to persons with disabilities.

3.   The Commission shall encourage the development of the codes of conduct by 18 February 2025 and their application by 18 August 2025.",article,"The Digital Services Act (DSA) includes a new law, Article 47, which encourages the creation of codes of conduct to improve online accessibility for people with disabilities. The European Commission, online platform providers, and other relevant parties will work together to ensure that online services are designed or adapted to meet the needs of disabled individuals. The goal is to make these services perceivable, operable, understandable, and robust. The codes of conduct will also explain how these services meet accessibility requirements and share this information in a way that is accessible to people with disabilities. The Commission aims to develop these codes by February 2025 and implement them by August 2025."
Digital Markets Act (DMA) - Article 5 Obligations for gatekeepers,0.710453093,"Details of Article 5 Obligations for gatekeepers in the Digital Markets Act (DMA): 1. The gatekeeper shall comply with all obligations set out in this Article with respect to each of its core platform services listed in the designation decision pursuant to Article 3(9). 2. The gatekeeper shall not do any of the following: (a) process, for the purpose of providing online advertising services, personal data of end users using services of third parties that make use of core platform services of the gatekeeper; (b) combine personal data from the relevant core platform service with personal data from any further core platform services or from any other services provided by the gatekeeper or with personal data from third-party services; (c) cross-use personal data from the relevant core platform service in other services provided separately by the gatekeeper, including other core platform services, and vice versa; and (d) sign in end users to other services of the gatekeeper in order to combine personal data, unless the end user has been presented with the specific choice and has given consent within the meaning of Article 4, point (11), and Article 7 of Regulation (EU) 2016/679. Where the consent given for the purposes of the first subparagraph has been refused or withdrawn by the end user, the gatekeeper shall not repeat its request for consent for the same purpose more than once within a period of one year. This paragraph is without prejudice to the possibility for the gatekeeper to rely on Article 6(1), points (c), (d) and (e) of Regulation (EU) 2016/679, where applicable. 3. The gatekeeper shall not prevent business users from offering the same products or services to end users through third-party online intermediation services or through their own direct online sales channel at prices or conditions that are different from those offered through the online intermediation services of the gatekeeper. 4. The gatekeeper shall allow business users, free of charge, to communicate and promote offers, including under different conditions, to end users acquired via its core platform service or through other channels, and to conclude contracts with those end users, regardless of whether, for that purpose, they use the core platform services of the gatekeeper. 5. The gatekeeper shall allow end users to access and use, through its core platform services, content, subscriptions, features or other items, by using the software application of a business user, including where those end users acquired such items from the relevant business user without using the core platform services of the gatekeeper. 6. The gatekeeper shall not directly or indirectly prevent or restrict business users or end users from raising any issue of non-compliance with the relevant Union or national law by the gatekeeper with any relevant public authority, including national courts, related to any practice of the gatekeeper. This is without prejudice to the right of business users and gatekeepers to lay down in their agreements the terms of use of lawful complaints-handling mechanisms. 7. The gatekeeper shall not require end users to use, or business users to use, to offer, or to interoperate with, an identification service, a web browser engine or a payment service, or technical services that support the provision of payment services, such as payment systems for in-app purchases, of that gatekeeper in the context of services provided by the business users using that gatekeeper""s core platform services. 8. The gatekeeper shall not require business users or end users to subscribe to, or register with, any further core platform services listed in the designation decision pursuant to Article 3(9) or which meet the thresholds in Article 3(2), point (b), as a condition for being able to use, access, sign up for or registering with any of that gatekeeper""s core platform services listed pursuant to that Article. 9. The gatekeeper shall provide each advertiser to which it supplies online advertising services, or third parties authorised by advertisers, upon the advertiser""s request, with information on a daily basis free of charge, concerning each advertisement placed by the advertiser, regarding: (a) the price and fees paid by that advertiser, including any deductions and surcharges, for each of the relevant online advertising services provided by the gatekeeper, (b) the remuneration received by the publisher, including any deductions and surcharges, subject to the publisher""s consent; and (c) the metrics on which each of the prices, fees and remunerations are calculated. In the event that a publisher does not consent to the sharing of information regarding the remuneration received, as referred to in point (b) of the first subparagraph, the gatekeeper shall provide each advertiser free of charge with information concerning the daily average remuneration received by that publisher, including any deductions and surcharges, for the relevant advertisements. 10. The gatekeeper shall provide each publisher to which it supplies online advertising services, or third parties authorised by publishers, upon the publisher""s request, with free of charge information on a daily basis, concerning each advertisement displayed on the publisher""s inventory, regarding: (a) the remuneration received and the fees paid by that publisher, including any deductions and surcharges, for each of the relevant online advertising services provided by the gatekeeper; (b) the price paid by the advertiser, including any deductions and surcharges, subject to the advertiser""s consent; and (c) the metrics on which each of the prices and remunerations are calculated. In the event an advertiser does not consent to the sharing of information, the gatekeeper shall provide each publisher free of charge with information concerning the daily average price paid by that advertiser, including any deductions and surcharges, for the relevant advertisements.",article,"The Digital Markets Act (DMA) sets obligations for online platforms, or 'gatekeepers'. These platforms can't use personal data from their services for online advertising or combine it with data from other services without user consent. They can't prevent businesses from offering products or services at different prices on other platforms, and must allow businesses to promote offers and communicate with users freely. Users must be able to access content through the platform's services, even if they didn't purchase it there. Gatekeepers can't prevent users or businesses from reporting non-compliance with laws, and can't force users or businesses to use specific services. They can't require users or businesses to register with other services as a condition of use. Gatekeepers must provide advertisers and publishers with detailed information about ad placements, prices, and metrics, even if consent for information sharing isn't given."
Digital Markets Act (DMA) - Definition of turnover,0.710419357,"Details of the Definition of turnover in the Digital Markets Act (DMA): ""turnover"" means the amount derived by an undertaking within the meaning of Article 5(1) of Regulation (EC) No 139/2004;",rectial,"The Digital Markets Act (DMA) has defined the term ""turnover"". In simpler terms, ""turnover"" refers to the total amount of money a business makes from its activities, as outlined in Article 5(1) of Regulation (EC) No 139/2004. This definition is important for understanding how the DMA applies to different businesses."
General Data Protection Regulation (GDPR) - Article 65 Dispute resolution by the Board,0.710405588,"Details of Article 65 Dispute resolution by the Board in the General Data Protection Regulation (GDPR): 1. In order to ensure the correct and consistent application of this Regulation in individual cases, the Board shall adopt a binding decision in the following cases: (a) where, in a case referred to in Article 60(4), a supervisory authority concerned has raised a relevant and reasoned objection to a draft decision of the lead authority or the lead authority has rejected such an objection as being not relevant or reasoned. The binding decision shall concern all the matters which are the subject of the relevant and reasoned objection, in particular whether there is an infringement of this Regulation; (b) where there are conflicting views on which of the supervisory authorities concerned is competent for the main establishment; (c) where a competent supervisory authority does not request the opinion of the Board in the cases referred to in Article 64(1), or does not follow the opinion of the Board issued under Article 64. In that case, any supervisory authority concerned or the Commission may communicate the matter to the Board. 2. The decision referred to in paragraph 1 shall be adopted within one month from the referral of the subject-matter by a two-thirds majority of the members of the Board. That period may be extended by a further month on account of the complexity of the subject-matter. The decision referred to in paragraph 1 shall be reasoned and addressed to the lead supervisory authority and all the supervisory authorities concerned and binding on them. 3. Where the Board has been unable to adopt a decision within the periods referred to in paragraph 2, it shall adopt its decision within two weeks following the expiration of the second month referred to in paragraph 2 by a simple majority of the members of the Board. Where the members of the Board are split, the decision shall by adopted by the vote of its Chair. 4. The supervisory authorities concerned shall not adopt a decision on the subject matter submitted to the Board under paragraph 1 during the periods referred to in paragraphs 2 and 3. 5. The Chair of the Board shall notify, without undue delay, the decision referred to in paragraph 1 to the supervisory authorities concerned. It shall inform the Commission thereof. The decision shall be published on the website of the Board without delay after the supervisory authority has notified the final decision referred to in paragraph 6. 6. The lead supervisory authority or, as the case may be, the supervisory authority with which the complaint has been lodged shall adopt its final decision on the basis of the decision referred to in paragraph 1 of this Article, without undue delay and at the latest by one month after the Board has notified its decision. The lead supervisory authority or, as the case may be, the supervisory authority with which the complaint has been lodged, shall inform the Board of the date when its final decision is notified respectively to the controller or the processor and to the data subject. The final decision of the supervisory authorities concerned shall be adopted under the terms of Article 60(7), (8) and (9). The final decision shall refer to the decision referred to in paragraph 1 of this Article and shall specify that the decision referred to in that paragraph will be published on the website of the Board in accordance with paragraph 5 of this Article. The final decision shall attach the decision referred to in paragraph 1 of this Article.",article,"Article 65 of the General Data Protection Regulation (GDPR) outlines a dispute resolution process by the Board. The Board can make a binding decision in cases where there are disagreements about the application of the GDPR, conflicting views about which supervisory authority is competent, or when a supervisory authority doesn't request or follow the Board's opinion. The decision should be made within one month, but can be extended to two months for complex matters. If no decision is made within these periods, a decision will be made within two weeks by a simple majority vote. The decision will be communicated to the supervisory authorities and published on the Board's website. The supervisory authority must then make its final decision based on the Board's decision within one month. The final decision will also be published on the Board's website."
Artifical Inellegence Act (AI Act) - Article 83,0.710399747,"Aritifical Intelligence Act (AI Act) Article 83 AI systems already placed on the market or put into service:

1.This Regulation shall not apply to the AI systems which are components of the large-scale IT systems established by the legal acts listed in Annex IX that have been placed on the market or put into service before [12 months after the date of application of this Regulation referred to in Article 85(2)], unless the replacement or amendment of those legal acts leads to a significant change in the design or intended purpose of the AI system or AI systems concerned.

The requirements laid down in this Regulation shall be taken into account, where applicable, in the evaluation of each large-scale IT systems established by the legal acts listed in Annex IX to be undertaken as provided for in those respective acts.

2.This Regulation shall apply to the high-risk AI systems, other than the ones referred to in paragraph 1, that have been placed on the market or put into service before [date of application of this Regulation referred to in Article 85(2)], only if, from that date, those systems are subject to significant changes in their design or intended purpose.",article,"The Artificial Intelligence Act (AI Act) will not apply to large-scale IT systems that are already in use or on the market, unless there are significant changes to their design or purpose. This rule also applies to high-risk AI systems not covered in the first part of the law. However, the regulations of the AI Act should be considered when evaluating these large-scale IT systems. The law will only apply to these systems if they undergo major changes after the law has been implemented."
Artifical Inellegence Act (AI Act) - Article 18,0.71037209,"Aritifical Intelligence Act (AI Act) Article 18 Obligation to draw up technical documentation:

1.Providers of high-risk AI systems shall draw up the technical documentation referred to in Article 11 in accordance with Annex IV.

2.Providers that are credit institutions regulated by Directive 2013/36/EU shall maintain the technical documentation as part of the documentation concerning internal governance, arrangements, processes and mechanisms pursuant to Article 74 of that Directive.",article,"The Artificial Intelligence Act (AI Act) requires providers of high-risk AI systems to create technical documentation as outlined in Article 11 and Annex IV of the Act. If the provider is a credit institution regulated by Directive 2013/36/EU, they must keep this documentation as part of their internal governance records, in line with Article 74 of the Directive. This is to ensure transparency and accountability in the use of AI systems."
Digital Markets Act (DMA) - Article 11 Reporting,0.710324109,"Details of Article 11 Reporting in the Digital Markets Act (DMA): 1. Within 6 months after its designation pursuant to Article 3, and in accordance with Article 3(10), the gatekeeper shall provide the Commission with a report describing in a detailed and transparent manner the measures it has implemented to ensure compliance with the obligations laid down in Articles 5, 6 and 7. 2. Within the deadline referred to in paragraph 1, the gatekeeper shall publish and provide the Commission with a nonconfidential summary of that report. The gatekeeper shall update that report and that non-confidential summary at least annually. The Commission shall make a link to that non-confidential summary available on its website.",article,"The Digital Markets Act (DMA) requires a gatekeeper (a dominant digital company) to submit a report to the Commission within six months of its designation. This report should detail how the gatekeeper is complying with obligations laid out in Articles 5, 6, and 7 of the DMA. The gatekeeper must also publish a non-confidential summary of the report and provide it to the Commission within the same timeframe. This summary should be updated at least once a year. The Commission will then make this summary accessible on its website."
Artifical Inellegence Act (AI Act) - Article 71,0.710293293,"Aritifical Intelligence Act (AI Act) Article 71 Penalties:

1.In compliance with the terms and conditions laid down in this Regulation, Member States shall lay down the rules on penalties, including administrative fines, applicable to infringements of this Regulation and shall take all measures necessary to ensure that they are properly and effectively implemented. The penalties provided for shall be effective, proportionate, and dissuasive. They shall take into particular account the interests of small-scale providers and start-up and their economic viability.

2.The Member States shall notify the Commission of those rules and of those measures and shall notify it, without delay, of any subsequent amendment affecting them.

3.The following infringements shall be subject to administrative fines of up to 30 000 000 EUR or, if the offender is company, up to 6 % of its total worldwide annual turnover for the preceding financial year, whichever is higher:

(a)non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5;

(b)non-compliance of the AI system with the requirements laid down in Article 10.

4.The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 20 000 000 EUR or, if the offender is a company, up to 4 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

5.The supply of incorrect, incomplete or misleading information to notified bodies and national competent authorities in reply to a request shall be subject to administrative fines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total worldwide annual turnover for the preceding financial year, whichever is higher.

6.When deciding on the amount of the administrative fine in each individual case, all relevant circumstances of the specific situation shall be taken into account and due regard shall be given to the following:

(a)the nature, gravity and duration of the infringement and of its consequences;

(b)whether administrative fines have been already applied by other market surveillance authorities to the same operator for the same infringement.

(c)the size and market share of the operator committing the infringement;

7.Each Member State shall lay down rules on whether and to what extent administrative fines may be imposed on public authorities and bodies established in that Member State.

8.Depending on the legal system of the Member States, the rules on administrative fines may be applied in such a manner that the fines are imposed by competent national courts of other bodies as applicable in those Member States. The application of such rules in those Member States shall have an equivalent effect.",article,"The Artificial Intelligence Act (AI Act) requires member states to enforce penalties, including fines, for violations of the Act. These penalties must be effective and proportionate, considering the interests of small-scale providers and startups. Member states must inform the Commission of these rules and any changes to them. Violations can result in fines up to 30 million EUR or up to 6% of a company's total annual turnover, whichever is higher. This includes non-compliance with the ban on certain AI practices and not meeting AI system requirements. Other violations can result in fines up to 20 million EUR or 4% of a company's turnover. Providing incorrect or misleading information can result in fines up to 10 million EUR or 2% of a company's turnover. The fine's amount will consider the violation's nature, gravity, and duration, any previous fines, and the violating operator's size and market share. Each member state will decide if public authorities can be fined. Depending on the member state's legal system, national courts or other bodies may impose fines."
Digital Markets Act (DMA) - Definition of information society service,0.71027112,"Details of the Definition of information society service in the Digital Markets Act (DMA): ""information society service"" means any service as defined in Article 1(1), point (b), of Directive (EU) 2015/1535;",rectial,"The Digital Markets Act (DMA) introduces a new term called ""information society service"". This term refers to any service defined under a specific provision (Article 1(1), point (b)) of a previous law, Directive (EU) 2015/1535. This essentially means any service that's delivered electronically, usually over the internet or an electronic network. This could include things like online retail, digital advertising, social media platforms, and more."
General Data Protection Regulation (GDPR) - Article 6 Lawfulness of processing,0.710240543,"Details of Article 6 Lawfulness of processing in the General Data Protection Regulation (GDPR): 1. Processing shall be lawful only if and to the extent that at least one of the following applies: (a) the data subject has given consent to the processing of his or her personal data for one or more specific purposes; (b) processing is necessary for the performance of a contract to which the data subject is party or in order to take steps at the request of the data subject prior to entering into a contract; (c) processing is necessary for compliance with a legal obligation to which the controller is subject; (d) processing is necessary in order to protect the vital interests of the data subject or of another natural person; (e) processing is necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller; (f) processing is necessary for the purposes of the legitimate interests pursued by the controller or by a third party, except where such interests are overridden by the interests or fundamental rights and freedoms of the data subject which require protection of personal data, in particular where the data subject is a child. Point (f) of the first subparagraph shall not apply to processing carried out by public authorities in the performance of their tasks. 2. Member States may maintain or introduce more specific provisions to adapt the application of the rules of this Regulation with regard to processing for compliance with points (c) and (e) of paragraph 1 by determining more precisely specific requirements for the processing and other measures to ensure lawful and fair processing including for other specific processing situations as provided for in Chapter IX. 3. The basis for the processing referred to in point (c) and (e) of paragraph 1 shall be laid down by: (a) Union law; or (b) Member State law to which the controller is subject. The purpose of the processing shall be determined in that legal basis or, as regards the processing referred to in point (e) of paragraph 1, shall be necessary for the performance of a task carried out in the public interest or in the exercise of official authority vested in the controller. That legal basis may contain specific provisions to adapt the application of rules of this Regulation, inter alia: the general conditions governing the lawfulness of processing by the controller; the types of data which are subject to the processing; the data subjects concerned; the entities to, and the purposes for which, the personal data may be disclosed; the purpose limitation; storage periods; and processing operations and processing procedures, including measures to ensure lawful and fair processing such as those for other specific processing situations as provided for in Chapter IX. The Union or the Member State law shall meet an objective of public interest and be proportionate to the legitimate aim pursued. 4. Where the processing for a purpose other than that for which the personal data have been collected is not based on the data subject's consent or on a Union or Member State law which constitutes a necessary and proportionate measure in a democratic society to safeguard the objectives referred to in Article 23(1), the controller shall, in order to ascertain whether processing for another purpose is compatible with the purpose for which the personal data are initially collected, take into account, inter alia: (a) any link between the purposes for which the personal data have been collected and the purposes of the intended further processing; (b) the context in which the personal data have been collected, in particular regarding the relationship between data subjects and the controller; (c) the nature of the personal data, in particular whether special categories of personal data are processed, pursuant to Article 9, or whether personal data related to criminal convictions and offences are processed, pursuant to Article 10; (d) the possible consequences of the intended further processing for data subjects; (e) the existence of appropriate safeguards, which may include encryption or pseudonymisation.",article,"The General Data Protection Regulation (GDPR) Article 6 states that personal data can only be processed lawfully under certain conditions. This includes if the individual has given consent, if it's necessary for a contract, to comply with a legal obligation, to protect someone's life, for public tasks or for legitimate interests, unless these are overridden by the individual's rights, especially if they're a child. Public authorities can't use the 'legitimate interests' basis. Countries can add more specific rules as long as they fit within this framework. The legal basis for processing must be outlined by Union or Member State law. If data is used for a different purpose than originally collected, the controller must ensure it's compatible with the initial purpose, considering factors like the link between the purposes, the context, the nature of the data, potential consequences, and safeguards in place."
Digital Services Act (DSA) - Definition of 'terms and conditions',0.710207939,"Definition of 'terms and conditions' in the Digital Services Act (DSA): all clauses, irrespective of their name or form, which govern the contractual relationship between the provider of intermediary services and the recipients of the service.",recital,"The Digital Services Act (DSA) introduces a new definition for 'terms and conditions'. This refers to any rules or guidelines, regardless of what they're called or how they're presented, that control the relationship between a service provider and the people who use that service. This could be any business that provides a service over the internet and their customers."
Artifical Inellegence Act (AI Act) -  Definition of 'provider',0.710206091,"Within the Aritifical Intelligence Act (AI Act), the Definition of provider means a natural or legal person, public authority, agency or other body that develops an AI system or that has an AI system developed with a view to placing it on the market or putting it into service under its own name or trademark, whether for payment or free of charge;",recital,"The Artificial Intelligence Act (AI Act) defines a 'provider' as any individual, company, government body, or organization that creates an AI system or has one made for them. The purpose of this AI system could be to sell it or use it under their own brand, whether they charge for it or not."
Digital Markets Act (DMA) - Article 32 Limitation periods for the imposition of penalties,0.710200548,"Details of Article 32 Limitation periods for the imposition of penalties in the Digital Markets Act (DMA): 1. The powers conferred on the Commission by Articles 30 and 31 shall be subject to a 5 year limitation period. 2. Time shall begin to run on the day on which the infringement is committed. However, in the case of continuing or repeated infringements, time shall begin to run on the day on which the infringement ceases. 3. Any action taken by the Commission for the purpose of a market investigation or proceedings in respect of an infringement shall interrupt the limitation period for the imposition of fines or periodic penalty payments. The limitation period shall be interrupted with effect from the date on which the action is notified to at least one undertaking or association of undertakings which has participated in the infringement. Actions which interrupt the running of the period shall include in particular the following: (a) requests for information by the Commission; (b) written authorisations to conduct inspections issued to its officials by the Commission; (c) the opening of a proceeding by the Commission pursuant to Article 20. 4. Each interruption shall start time running afresh. However, the limitation period shall expire at the latest on the day on which a period equal to twice the limitation period has elapsed without the Commission having imposed a fine or a periodic penalty payment. That period shall be extended by the time during which limitation is suspended pursuant to paragraph 5. 5. The limitation period for the imposition of fines or periodic penalty payments shall be suspended for as long as the decision of the Commission is the subject of proceedings pending before the Court of Justice.",article,"The Digital Markets Act (DMA) Article 32 outlines the time limits for imposing penalties. The Commission has 5 years from the date of the violation to impose penalties. If the violation is ongoing or repeated, the 5-year period starts when the violation stops. The 5-year period can be paused if the Commission is investigating the violation or if the case is before the Court of Justice. Actions that can pause the 5-year period include requests for information and the opening of a proceeding. If the Commission doesn't impose a fine or penalty within a period equal to twice the 5-year limit, the chance to do so expires. The time limit can be extended if the Commission's decision is being reviewed by the Court of Justice."
Digital Markets Act (DMA) - Article 49 Exercise of the delegation,0.710105121,"Details of Article 49 Exercise of the delegation in the Digital Markets Act (DMA): 1. The power to adopt delegated acts is conferred on the Commission subject to the conditions laid down in this Article. 2. The power to adopt delegated acts referred to in Article 3(6) and (7) and Article 12(1), (3) and (4) shall be conferred on the Commission for a period of 5 years from 1 November 2022. The Commission shall draw up a report in respect of the delegation of power not later than 9 months before the end of the five-year period. The delegation of power shall be tacitly extended for periods of an identical duration, unless the European Parliament or the Council opposes such extension not later than 3 months before the end of each period. 3. The delegation of power referred to in Article 3(6) and (7), and Article 12(1), (3) and (4) may be revoked at any time by the European Parliament or by the Council. A decision to revoke shall put an end to the delegation of the power specified in that decision. It shall take effect the day following the publication of the decision in the Official Journal of the European Union or at a later date specified therein. It shall not affect the validity of any delegated acts already in force. 4. Before adopting a delegated act, the Commission shall consult experts designated by each Member State in accordance with the principles laid down in the Interinstitutional Agreement of 13 April 2016 on Better Law-Making. 5. As soon as it adopts a delegated act, the Commission shall notify it simultaneously to the European Parliament and to the Council. 6. A delegated act adopted pursuant to Article 3(6) and (7), and Article 12(1), (3) and (4) shall enter into force only if no objection has been expressed either by the European Parliament or by the Council within a period of 2 months of notification of that act to the European Parliament and to the Council or if, before the expiry of that period, the European Parliament and the Council have both informed the Commission that they will not object. That period shall be extended by 2 months at the initiative of the European Parliament or of the Council.",article,"The Digital Markets Act (DMA) allows the Commission to adopt delegated acts, which are essentially specific rules or regulations, under certain conditions. The Commission has this power for five years starting from November 1, 2022, and it can be extended unless the European Parliament or the Council objects. The Parliament or Council can also revoke this power at any time, which would take effect the day after its publication in the Official Journal of the European Union. Before adopting a delegated act, the Commission must consult with experts from each Member State. Once an act is adopted, it must be notified to the Parliament and Council and will only come into force if neither body objects within two months. This period can be extended by another two months if needed."
Artifical Inellegence Act (AI Act) - Article 2,0.710029662,"Aritifical Intelligence Act (AI Act) Article 2 Scope:

This Regulation applies to:

(a)providers placing on the market or putting into service AI systems in the Union, irrespective of whether those providers are established within the Union or in a third country;

(b)users of AI systems located within the Union;

(c)providers and users of AI systems that are located in a third country, where the output produced by the system is used in the Union;

2.For high-risk AI systems that are safety components of products or systems, or which are themselves products or systems, falling within the scope of the following acts, only Article 84 of this Regulation shall apply:

(a)Regulation (EC) 300/2008;

(b)Regulation (EU) No 167/2013;

(c)Regulation (EU) No 168/2013;

(d)Directive 2014/90/EU;

(e)Directive (EU) 2016/797;

(f)Regulation (EU) 2018/858;

(g)Regulation (EU) 2018/1139;

(h)Regulation (EU) 2019/2144.

3.This Regulation shall not apply to AI systems developed or used exclusively for military purposes.

4.This Regulation shall not apply to public authorities in a third country nor to international organisations falling within the scope of this Regulation pursuant to paragraph 1, where those authorities or organisations use AI systems in the framework of international agreements for law enforcement and judicial cooperation with the Union or with one or more Member States.

5.This Regulation shall not affect the application of the provisions on the liability of intermediary service providers set out in Chapter II, Section IV of Directive 2000/31/EC of the European Parliament and of the Council 60 [as to be replaced by the corresponding provisions of the Digital Services Act].",article,"The Artificial Intelligence Act (AI Act) applies to providers and users of AI systems in the European Union (EU), regardless of whether the providers are based in the EU or another country. It also applies to providers and users of AI systems located outside the EU if the system's output is used within the EU. However, the law does not apply to AI systems used exclusively for military purposes, public authorities in a third country, or international organizations using AI systems for law enforcement and judicial cooperation with the EU or its member states. For high-risk AI systems, only Article 84 of this Regulation applies. The AI Act does not affect the liability of intermediary service providers as outlined in the Digital Services Act."
Digital Services Act (DSA) - Article 55 Activity reports,0.709988058,"Article 55 Activity reports in the Digital Services Act (DSA):  1.   Digital Services Coordinators shall draw up annual reports on their activities under this Regulation, including the number of complaints received pursuant to Article 53 and an overview of their follow-up. The Digital Services Coordinators shall make the annual reports available to the public in a machine-readable format, subject to the applicable rules on the confidentiality of information pursuant to Article 84, and shall communicate them to the Commission and to the Board.

2.   The annual report shall also include the following information:

(a) the number and subject matter of orders to act against illegal content and orders to provide information issued in accordance with Articles 9 and 10 by any national judicial or administrative authority of the Member State of the Digital Services Coordinator concerned;
(b) the effects given to those orders, as communicated to the Digital Services Coordinator pursuant to Articles 9 and 10.

3.   Where a Member State has designated several competent authorities pursuant to Article 49, it shall ensure that the Digital Services Coordinator draws up a single report covering the activities of all competent authorities and that the Digital Services Coordinator receives all relevant information and support needed to that effect from the other competent authorities concerned.",article,"The Digital Services Act (DSA) requires Digital Services Coordinators to create yearly reports detailing their activities, including the number of complaints received and their responses. These reports must be publicly available in a format that can be read by machines, while respecting confidentiality rules. The report should also include the number and nature of orders to act against illegal content and to provide information, as well as the actions taken in response to these orders. If a member state has multiple authorities, it must ensure that the Digital Services Coordinator creates a single report covering all their activities, with the necessary information and support from the other authorities."
General Data Protection Regulation (GDPR) - Definition of information society service,0.709975719,"Details of the Definition of information society service in the General Data Protection Regulation (GDPR): ""information society service"" means a service as defined in point (b) of Article 1(1) of Directive (EU) 2015/1535 of the European Parliament and of the Council ( 1 );",recital,"The General Data Protection Regulation (GDPR) introduces a term called ""information society service"". This refers to any service delivered over the internet or any electronic network, which essentially includes almost all online services. This definition is based on Directive (EU) 2015/1535 of the European Parliament. In simpler terms, if a service is provided over the internet, it falls under the GDPR's definition of ""information society service""."
Digital Services Act (DSA) - Article 43 Supervisory fee,0.709961772,"Article 43 Supervisory fee in the Digital Services Act (DSA):  1.   The Commission shall charge providers of very large online platforms and of very large online search engines an annual supervisory fee upon their designation pursuant to Article 33.

2.   The overall amount of the annual supervisory fees shall cover the estimated costs that the Commission incurs in relation to its supervisory tasks under this Regulation, in particular costs related to the designation pursuant to Article 33, to the set-up, maintenance and operation of the database pursuant to Article 24(5) and to the information sharing system pursuant to Article 85, to referrals pursuant to Article 59, to supporting the Board pursuant to Article 62 and to the supervisory tasks pursuant to Article 56 and Section 4 of Chapter IV.

3.   The providers of very large online platforms and of very large online search engines shall be charged annually a supervisory fee for each service for which they have been designated pursuant to Article 33.

The Commission shall adopt implementing acts establishing the amount of the annual supervisory fee in respect of each provider of very large online platform or of very large online search engine. When adopting those implementing acts, the Commission shall apply the methodology laid down in the delegated act referred to in paragraph 4 of this Article and shall respect the principles set out in paragraph 5 of this Article. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.

4.   The Commission shall adopt delegated acts, in accordance with Article 87, laying down the detailed methodology and procedures for:

(a) the determination of the estimated costs referred to in paragraph 2;
(b) the determination of the individual annual supervisory fees referred to in paragraph 5, points (b) and (c);
(c) the determination of the maximum overall limit defined in paragraph 5, point (c); and
(d) the detailed arrangements necessary to make payments.

When adopting those delegated acts, the Commission shall respect the principles set out in paragraph 5 of this Article.

5.   The implementing act referred to in paragraph 3 and the delegated act referred to in paragraph 4 shall respect the following principles:

(a) the estimation of the overall amount of the annual supervisory fee takes into account the costs incurred in the previous year;
(b) the annual supervisory fee is proportionate to the number of average monthly active recipients in the Union of each very large online platform or each very large online search engine designated pursuant to Article 33;
(c) the overall amount of the annual supervisory fee charged on a given provider of very large online platform or very large search engine does not, in any case, exceed 0,05 % of its worldwide annual net income in the preceding financial year.

6.   The individual annual supervisory fees charged pursuant to paragraph 1 of this Article shall constitute external assigned revenue in accordance with Article 21(5) of Regulation (EU, Euratom) 2018/1046 of the European Parliament and of the Council (41).

7.   The Commission shall report annually to the European Parliament and to the Council on the overall amount of the costs incurred for the fulfilment of the tasks under this Regulation and the total amount of the individual annual supervisory fees charged in the preceding year.",article,"The Digital Services Act (DSA) mandates that large online platforms and search engines pay an annual supervisory fee to the Commission. This fee covers the Commission's costs related to its supervisory duties, such as maintaining databases and information sharing systems. The fee amount for each provider will be determined by the Commission and is based on the costs incurred in the previous year, the number of average monthly users in the EU, and cannot exceed 0.05% of the provider's global annual net income from the previous financial year. The Commission will report annually to the European Parliament and the Council on the overall costs and the total amount of fees charged."
California Consumer Privacy Act Regulations (CCPA) - Article 3. Business Practices for Handling Consumer Requests -  999.317 Training; Record-Keeping,0.709838808,"Details of Article 3. Business Practices for Handling Consumer Requests -  999.317 Training; Record-Keeping in the California Consumer Privacy Act Regulations (CCPA): (a) All individuals responsible for handling consumer inquiries about the businesss privacy practices or the businesss compliance with the CCPA shall be informed of all of the requirements in the CCPA and these regulations and how to direct consumers to exercise their rights under the CCPA and these regulations. (b) A business shall maintain records of consumer requests made pursuant to the CCPA and how it responded to the requests for at least 24 months. The business shall implement and maintain reasonable security procedures and practices in maintaining these records. (c) The records may be maintained in a ticket or log format provided that the ticket or log includes the date of request, nature of request, manner in which the request was made, the date of the businesss response, the nature of the response, and the basis for the denial of the request if the request is denied in whole or in part. (d) A businesss maintenance of the information required by this section, where that information is not used for any other purpose, does not taken alone violate the CCPA or these regulations. (e) Information maintained for record-keeping purposes shall not be used for any other purpose except as reasonably necessary for the business to review and modify its processes for compliance with the CCPA and these regulations. Information maintained for recordkeeping purposes shall not be shared with any third party except as necessary to comply with a legal obligation. (f) Other than as required by subsection (b), a business is not required to retain personal information solely for the purpose of fulfilling a consumer request made under the CCPA. (g) A business that knows or reasonably should know that it, alone or in combination, buys, receives for the businesss commercial purposes, sells, or shares for commercial purposes the personal information of 10,000,000 or more consumers in a calendar year shall: (1) Compile the following metrics for the previous calendar year: a. The number of requests to know that the business received, complied with in whole or in part, and denied; b. The number of requests to delete that the business received, complied with in whole or in part, and denied; c. The number of requests to opt-out that the business received, complied with in whole or in part, and denied; and d. The median or mean number of days within which the business substantively responded to requests to know, requests to delete, and requests to opt-out. (2) Disclose, by July 1 of every calendar year, the information compiled in subsection (g)(1) within their privacy policy or posted on their website and accessible from a link included in their privacy policy. a. In its disclosure pursuant to subsection (g)(2), a business may choose to disclose the number of requests that it denied in whole or in part because the request was not verifiable, was not made by a consumer, called for information exempt from disclosure, or was denied on other grounds. (3) Establish, document, and comply with a training policy to ensure that all individuals responsible for handling consumer requests made under the CCPA or the businesss compliance with the CCPA are informed of all the requirements in these regulations and the CCPA. (h) A business may choose to compile and disclose the information required by subsection (g)(1) for requests received from all individuals, rather than requests received from consumers. The business shall state whether it has done so in its disclosure and shall, upon request, compile and provide to the Attorney General the information required by subsection (g)(1) for requests received from consumers.",article,"The California Consumer Privacy Act (CCPA) requires businesses to train their staff on privacy practices and CCPA compliance. Businesses must keep records of consumer requests and responses related to the CCPA for at least two years, ensuring security measures are in place to protect these records. These records should include details such as the date, nature, and manner of the request and response. The information kept for record-keeping should not be used for any other purpose or shared with third parties, except for legal obligations or necessary compliance review. Businesses are not required to retain personal information just to fulfill a CCPA request. Businesses dealing with personal information of over 10 million consumers in a year must compile certain metrics related to consumer requests and disclose this information on their website or privacy policy by July 1 each year. They must also establish a training policy for CCPA compliance. They can choose to compile and disclose information for all individuals, not just consumers, but must inform the Attorney General upon request."
General Data Protection Regulation (GDPR) - Definition of personal data breach,0.709797502,"Details of the Definition of personal data breach in the General Data Protection Regulation (GDPR): ""personal data breach"" means a breach of security leading to the accidental or unlawful destruction, loss, alteration, unauthorised disclosure of, or access to, personal data transmitted, stored or otherwise processed;",recital,"The General Data Protection Regulation (GDPR) defines a ""personal data breach"" as any security incident that results in the accidental or illegal destruction, loss, change, unauthorized disclosure, or access to personal data. This can apply to data that is transmitted, stored, or processed in any way. In simpler terms, it's when your personal information is accessed, shared, changed, or destroyed without your permission."
General Data Protection Regulation (GDPR) - Definition of genetic data,0.709727,"Details of the Definition of genetic data in the General Data Protection Regulation (GDPR): ""genetic data"" means personal data relating to the inherited or acquired genetic characteristics of a natural person which give unique information about the physiology or the health of that natural person and which result, in particular, from an analysis of a biological sample from the natural person in question;",recital,"The General Data Protection Regulation (GDPR) defines ""genetic data"" as any personal information related to a person's inherited or acquired genetic traits. This data provides unique insights into a person's health or physical characteristics and is typically obtained through the analysis of a biological sample from the individual."
California Consumer Privacy Act Regulations (CCPA) - Article 3. Business Practices for Handling Consumer Requests -  999.318 Requests to Know or Delete Household Information,0.709646165,"Details of Article 3. Business Practices for Handling Consumer Requests -  999.318 Requests to Know or Delete Household Information in the California Consumer Privacy Act Regulations (CCPA): (a) Where a household does not have a password-protected account with a business, a business shall not comply with a request to know specific pieces of personal information about the household or a request to delete household personal information unless all of the following conditions are satisfied: (1) All consumers of the household jointly request to know specific pieces of information for the household or the deletion of household personal information; (2) The business individually verifies all the members of the household subject to the verification requirements set forth in section 999.325; and (3) The business verifies that each member making the request is currently a member of the household. (b) Where a consumer has a password-protected account with a business that collects personal information about a household, the business may process requests to know and requests to delete relating to household information through the businesss existing business practices and in compliance with these regulations. (c) If a member of a household is a consumer under the age of 13, a business must obtain verifiable parental consent before complying with a request to know specific pieces of information for the household or the deletion of household personal information pursuant to the parental consent provisions in section 999.330.",article,"The California Consumer Privacy Act (CCPA) has a new section, Article 3, which outlines how businesses should handle requests regarding household information. If a household doesn't have a password-protected account with a business, the business can only provide or delete personal household information if all household members request it, their identities are verified, and they are confirmed as current household members. If a household has a password-protected account, the business can handle requests according to its existing practices, but must still follow regulations. If a household member is under 13, the business needs parental consent before providing or deleting personal information."
General Data Protection Regulation (GDPR) - Article 60 Cooperation between the lead supervisory authority and the other supervisory authorities concerned,0.709601879,"Details of Article 60 Cooperation between the lead supervisory authority and the other supervisory authorities concerned in the General Data Protection Regulation (GDPR): 1. The lead supervisory authority shall cooperate with the other supervisory authorities concerned in accordance with this Article in an endeavour to reach consensus. The lead supervisory authority and the supervisory authorities concerned shall exchange all relevant information with each other. 2. The lead supervisory authority may request at any time other supervisory authorities concerned to provide mutual assistance pursuant to Article 61 and may conduct joint operations pursuant to Article 62, in particular for carrying out investigations or for monitoring the implementation of a measure concerning a controller or processor established in another Member State. 3. The lead supervisory authority shall, without delay, communicate the relevant information on the matter to the other supervisory authorities concerned. It shall without delay submit a draft decision to the other supervisory authorities concerned for their opinion and take due account of their views. 4. Where any of the other supervisory authorities concerned within a period of four weeks after having been consulted in accordance with paragraph 3 of this Article, expresses a relevant and reasoned objection to the draft decision, the lead supervisory authority shall, if it does not follow the relevant and reasoned objection or is of the opinion that the objection is not relevant or reasoned, submit the matter to the consistency mechanism referred to in Article 63. 5. Where the lead supervisory authority intends to follow the relevant and reasoned objection made, it shall submit to the other supervisory authorities concerned a revised draft decision for their opinion. That revised draft decision shall be subject to the procedure referred to in paragraph 4 within a period of two weeks. 6. Where none of the other supervisory authorities concerned has objected to the draft decision submitted by the lead supervisory authority within the period referred to in paragraphs 4 and 5, the lead supervisory authority and the supervisory authorities concerned shall be deemed to be in agreement with that draft decision and shall be bound by it. 7. The lead supervisory authority shall adopt and notify the decision to the main establishment or single establishment of the controller or processor, as the case may be and inform the other supervisory authorities concerned and the Board of the decision in question, including a summary of the relevant facts and grounds. The supervisory authority with which a complaint has been lodged shall inform the complainant on the decision. 8. By derogation from paragraph 7, where a complaint is dismissed or rejected, the supervisory authority with which the complaint was lodged shall adopt the decision and notify it to the complainant and shall inform the controller thereof. 9. Where the lead supervisory authority and the supervisory authorities concerned agree to dismiss or reject parts of a complaint and to act on other parts of that complaint, a separate decision shall be adopted for each of those parts of the matter. The lead supervisory authority shall adopt the decision for the part concerning actions in relation to the controller, shall notify it to the main establishment or single establishment of the controller or processor on the territory of its Member State and shall inform the complainant thereof, while the supervisory authority of the complainant shall adopt the decision for the part concerning dismissal or rejection of that complaint, and shall notify it to that complainant and shall inform the controller or processor thereof. 10. After being notified of the decision of the lead supervisory authority pursuant to paragraphs 7 and 9, the controller or processor shall take the necessary measures to ensure compliance with the decision as regards processing activities in the context of all its establishments in the Union. The controller or processor shall notify the measures taken for complying with the decision to the lead supervisory authority, which shall inform the other supervisory authorities concerned. 11. Where, in exceptional circumstances, a supervisory authority concerned has reasons to consider that there is an urgent need to act in order to protect the interests of data subjects, the urgency procedure referred to in Article 66 shall apply. 12. The lead supervisory authority and the other supervisory authorities concerned shall supply the information required under this Article to each other by electronic means, using a standardised format.",article,"The General Data Protection Regulation (GDPR) Article 60 is about cooperation between the lead supervisory authority and other supervisory authorities. They must work together, share information, and try to reach consensus. If there's a disagreement, there are procedures to follow, including a consistency mechanism if the lead authority doesn't agree with an objection. If no objections are raised to a decision, all authorities are bound by it. The lead authority communicates decisions to the relevant businesses and informs other authorities. If a complaint is partially rejected and partially acted upon, separate decisions are made for each part. Businesses must comply with decisions and inform the lead authority of measures taken. In urgent cases, to protect data subjects, an urgency procedure can be applied. All information exchange should be electronic and in a standardised format."
Digital Markets Act (DMA) - Article 46 Implementing provisions,0.709579706,"Details of Article 46 Implementing provisions in the Digital Markets Act (DMA): 1. The Commission may adopt implementing acts laying down detailed arrangements for the application of the following: (a) the form, content and other details of notifications and submissions pursuant to Article 3; (b) the form, content and other details of the technical measures that gatekeepers shall implement in order to ensure compliance with Article 5, 6 or 7; (c) operational and technical arrangements in view of implementing interoperability of number-independent interpersonal communications services pursuant to Article 7; (d) the form, content and other details of the reasoned request pursuant to Article 8(3); (e) the form, content and other details of the reasoned requests pursuant to Articles 9 and 10; (f) the form, content and other details of the regulatory reports delivered pursuant to Article 11; (g) the methodology and procedure for the audited description of techniques used for profiling of consumers provided for in Article 15(1); when developing a draft implementing act for this purpose, the Commission shall consult the European Data Protection Supervisor and may consult the European Data Protection Board, civil society and other relevant experts; (h) the form, content and other details of notifications and submissions made pursuant to Articles 14 and 15; (i) the practical arrangements of the proceedings concerning the market investigations pursuant to Articles 17, 18 and 19, and proceedings pursuant to Articles 24, 25 and 29; (j) the practical arrangements for exercising rights to be heard provided for in Article 34; (k) the practical arrangements for the terms of disclosure provided for in Article 34; (l) the practical arrangements for the cooperation and coordination between the Commission and national authorities provided for in Articles 37 and 38; and (m) the practical arrangements for the calculation and extension of deadlines. 2. The implementing acts referred to in paragraph 1, points (a) to (k), and point (m) of this Article shall be adopted in accordance with the advisory procedure referred to in Article 50(2). The implementing act referred to in paragraph 1, point (l), of this Article shall be adopted in accordance with the examination procedure referred to in Article 50(3). 3. Before the adoption of any implementing act pursuant to paragraph 1, the Commission shall publish a draft thereof and invite all interested parties to submit their comments within a time limit, which may not be less than one month.",article,"The Digital Markets Act (DMA) empowers the Commission to establish implementing acts detailing the application of various aspects of the law. These include the form and content of notifications and submissions, technical measures for compliance, interoperability arrangements, and regulatory reports. It also covers the methodology for consumer profiling, proceedings for market investigations, exercising rights to be heard, terms of disclosure, cooperation between the Commission and national authorities, and deadline calculations. Before these acts are adopted, the Commission will publish a draft and invite public comments. The advisory procedure will be used for most acts, while the examination procedure will be used for cooperation and coordination acts."
California Consumer Privacy Act Regulations (CCPA) - Definition of Household,0.709548056,"Details of Definition of Household in the California Consumer Privacy Act Regulations (CCPA): Household means a person or group of people who: (1) reside at the same address, (2) share a common device or the same service provided by a business, and (3) are identified by the business as sharing the same group account or unique identifier.",recital,"The California Consumer Privacy Act (CCPA) has a new definition for ""Household"". According to this law, a household is a person or group of people living at the same address, using the same device or service from a business, and identified by that business as sharing the same group account or unique identifier. This definition is important for understanding who has rights to privacy under this law."
General Data Protection Regulation (GDPR) - Definition of main establishment,0.709468,"Details of the Definition of main establishment in the General Data Protection Regulation (GDPR): ""main establishment"" means: (a) as regards a controller with establishments in more than one Member State, the place of its central administration in the Union, unless the decisions on the purposes and means of the processing of personal data are taken in another establishment of the controller in the Union and the latter establishment has the power to have such decisions implemented, in which case the establishment having taken such decisions is to be considered to be the main establishment; (b) as regards a processor with establishments in more than one Member State, the place of its central administration in the Union, or, if the processor has no central administration in the Union, the establishment of the processor in the Union where the main processing activities in the context of the activities of an establishment of the processor take place to the extent that the processor is subject to specific obligations under this Regulation;",recital,"The General Data Protection Regulation (GDPR) defines ""main establishment"" for a company that operates in more than one EU country. For a data controller, it's the location of its central administration in the EU, unless another EU-based branch makes and implements decisions about personal data processing. In that case, the branch making the decisions is the main establishment. For a data processor, it's the location of its central administration in the EU. If there's no central administration in the EU, it's the EU-based branch where most data processing activities occur, as long as that branch has specific obligations under the GDPR."
Artifical Inellegence Act (AI Act) - Definition of 'performance of an AI system',0.709437609,"Within the Aritifical Intelligence Act (AI Act), the Definition of notifying authority means the national authority responsible for setting up and carrying out the necessary procedures for the assessment, designation and notification of conformity assessment bodies and for their monitoring;",recital,The Artificial Intelligence Act (AI Act) introduces the concept of a 'notifying authority'. This is a national organization that is tasked with creating and implementing procedures to evaluate and approve bodies that assess compliance with the Act. It also oversees these bodies to ensure they are doing their job correctly.
Artifical Inellegence Act (AI Act) - Article 6,0.709320724,"Aritifical Intelligence Act (AI Act) Article 6 Classification rules for high-risk AI systems:
1.Irrespective of whether an AI system is placed on the market or put into service independently from the products referred to in points (a) and (b), that AI system shall be considered high-risk where both of the following conditions are fulfilled:

(a)the AI system is intended to be used as a safety component of a product, or is itself a product, covered by the Union harmonisation legislation listed in Annex II;

(b)the product whose safety component is the AI system, or the AI system itself as a product, is required to undergo a third-party conformity assessment with a view to the placing on the market or putting into service of that product pursuant to the Union harmonisation legislation listed in Annex II.

2.In addition to the high-risk AI systems referred to in paragraph 1, AI systems referred to in Annex III shall also be considered high-risk.",article,"The Artificial Intelligence Act (AI Act) defines rules for classifying high-risk AI systems. An AI system is considered high-risk if it's used as a safety component of a product, or if it is a product itself, and is covered by specific Union legislation (listed in Annex II). Additionally, the product or AI system must undergo a third-party assessment before it can be marketed or put into service. The law also states that any AI systems mentioned in Annex III are automatically considered high-risk."
Artifical Inellegence Act (AI Act) - Article 58,0.709313452,"Aritifical Intelligence Act (AI Act) Article 58 Tasks of the Board:

When providing advice and assistance to the Commission in the context of Article 56(2), the Board shall in particular:

(a)collect and share expertise and best practices among Member States;

(b)contribute to uniform administrative practices in the Member States, including for the functioning of regulatory sandboxes referred to in Article 53;

(c)issue opinions, recommendations or written contributions on matters related to the implementation of this Regulation, in particular

(i)on technical specifications or existing standards regarding the requirements set out in Title III, Chapter 2,

(ii)on the use of harmonised standards or common specifications referred to in Articles 40 and 41,

(iii)on the preparation of guidance documents, including the guidelines concerning the setting of administrative fines referred to in Article 71.",article,"The Artificial Intelligence Act (AI Act) Article 58 lays out the responsibilities of the Board. These include sharing knowledge and best practices among member states, helping to standardize administrative practices, and providing advice on the implementation of the law. This advice can cover technical specifications or standards, the use of harmonized standards or common specifications, and the creation of guidance documents, such as those concerning administrative fines."
Digital Markets Act (DMA) - Article 21 Requests for information,0.709219873,"Details of Article 21 Requests for information in the Digital Markets Act (DMA): 1. In order to carry out its duties under this Regulation, the Commission may, by simple request or by decision, require from undertakings and associations of undertakings to provide all necessary information. The Commission may also, by simple request or by decision, require access to any data and algorithms of undertakings and information about testing, as well as requesting explanations of them. 2. When sending a simple request for information to an undertaking or association of undertakings, the Commission shall state the legal basis and purpose of the request, specify what information is required and fix the time limit within which the information is to be provided, as well as the fines provided for in Article 30 applicable for supplying incomplete, incorrect or misleading information or explanations. 3. Where the Commission requires undertakings and associations of undertakings to supply information by decision, it shall state the legal basis and purpose of the request, specify what information is required and fix the time limit within which the information is to be provided. Where the Commission requires undertakings to provide access to any data, algorithms and information about testing, it shall state the purpose of the request and fix the time -limit within which it is to be provided. It shall also indicate the fines provided for in Article 30 and indicate or impose the periodic penalty payments provided for in Article 31. It shall further indicate the right to have the decision reviewed by the Court of Justice. 4. The undertakings or associations of undertakings or their representatives shall supply the information requested on behalf of the undertaking or the association of undertakings concerned. Lawyers duly authorised to act may supply the information on behalf of their clients. The latter shall remain fully responsible if the information supplied is incomplete, incorrect or misleading. 5. At the request of the Commission, the competent authorities of the Member States shall provide the Commission with all necessary information in their possession to carry out the duties assigned to it by this Regulation.",article,"The Digital Markets Act (DMA) allows the Commission to request necessary information from businesses and business associations to fulfill its regulatory duties. This can include access to data, algorithms, and testing information, which the Commission can ask for an explanation of. When making a request, the Commission must state the legal basis and purpose, specify what information is needed, and set a deadline for the information to be provided. Fines may be imposed for providing incomplete, incorrect, or misleading information. If the Commission makes a formal decision to request information, it must also indicate the right to have the decision reviewed by the Court of Justice. Businesses and their representatives are responsible for providing the requested information, with legal representatives allowed to supply the information on their clients' behalf. The Commission can also request necessary information from Member State authorities."
Artifical Inellegence Act (AI Act) - Definition of 'biometric data',0.709133327,"Within the Aritifical Intelligence Act (AI Act), the Definition of biometric data means personal data resulting from specific technical processing relating to the physical, physiological or behavioural characteristics of a natural person, which allow or confirm the unique identification of that natural person, such as facial images or dactyloscopic data;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'biometric data'. This refers to personal information collected through specific technical methods about a person's physical, physiological, or behavioral traits. These traits are unique to each individual, like facial images or fingerprint data, and can be used to identify that person."
California Consumer Privacy Act Regulations (CCPA) - Article 3. Business Practices for Handling Consumer Requests -  999.313 Responding to Requests to Know and Requests to Delete,0.709124565,"Details of Article 3. Business Practices for Handling Consumer Requests -  999.313 Responding to Requests to Know and Requests to Delete in the California Consumer Privacy Act Regulations (CCPA): (a) Upon receiving a request to know or a request to delete, a business shall confirm receipt of the request within 10 business days and provide information about how the business will process the request. The information provided shall describe in general the businesss verification process and when the consumer should expect a response, except in instances where the business has already granted or denied the request. The confirmation may be given in the same manner in which the request was received. For example, if the request is made over the phone, the confirmation may be given orally during the phone call. (b) Businesses shall respond to requests to know and requests to delete within 45 calendar days. The 45-day period will begin on the day that the business receives the request, regardless of time required to verify the request. If the business cannot verify the consumer within the 45- day time period, the business may deny the request. If necessary, businesses may take up to an additional 45 calendar days to respond to the consumers request, for a maximum total of 90 calendar days from the day the request is received, provided that the business provides the consumer with notice and an explanation of the reason that the business will take more than 45 days to respond to the request. (c) Responding to Requests to Know. (1) For requests that seek the disclosure of specific pieces of information about the consumer, if a business cannot verify the identity of the person making the request pursuant to the regulations set forth in Article 4, the business shall not disclose any specific pieces of personal information to the requestor and shall inform the requestor that it cannot verify their identity. If the request is denied in whole or in part, the business shall also evaluate the consumers request as if it is seeking the disclosure of categories of personal information about the consumer pursuant to subsection (c)(2). (2) For requests that seek the disclosure of categories of personal information about the consumer, if a business cannot verify the identity of the person making the request pursuant to the regulations set forth in Article 4, the business may deny the request to disclose the categories and other information requested and shall inform the requestor that it cannot verify their identity. If the request is denied in whole or in part, the business shall provide or direct the consumer to its general business practices regarding the collection, maintenance, and sale of personal information set forth in its privacy policy. (3) In responding to a request to know, a business is not required to search for personal information if all of the following conditions are met: a. The business does not maintain the personal information in a searchable or reasonably accessible format; b. The business maintains the personal information solely for legal or compliance purposes; c. The business does not sell the personal information and does not use it for any commercial purpose; and d. The business describes to the consumer the categories of records that may contain personal information that it did not search because it meets the conditions stated above. (4) A business shall not disclose in response to a request to know a consumers Social Security number, drivers license number or other government-issued identification number, financial account number, any health insurance or medical identification number, an account password, security questions and answers, or unique biometric data generated from measurements or technical analysis of human characteristics. The business shall, however, inform the consumer with sufficient particularity that it has collected the type of information. For example, a business shall respond that it collects unique biometric data including a fingerprint scan without disclosing the actual fingerprint scan data. (5) If a business denies a consumers verified request to know specific pieces of personal information, in whole or in part, because of a conflict with federal or state law, or an exception to the CCPA, the business shall inform the requestor and explain the basis for the denial, unless prohibited from doing so by law. If the request is denied only in part, the business shall disclose the other information sought by the consumer. (6) A business shall use reasonable security measures when transmitting personal information to the consumer. (7) If a business maintains a password-protected account with the consumer, it may comply with a request to know by using a secure self-service portal for consumers to access, view, and receive a portable copy of their personal information if the portal fully discloses the personal information that the consumer is entitled to under the CCPA and these regulations, uses reasonable data security controls, and complies with the verification requirements set forth in Article 4. (8) Unless otherwise specified by the business to cover a longer period of time, the 12- month period covered by a consumers verifiable request to know referenced in Civil Code section 1798.130, subdivision (a)(2), shall run from the date the business receives the request, regardless of the time required to verify the request. (9) In responding to a consumers verified request to know categories of personal information, categories of sources, and/or categories of third parties, a business shall provide an individualized response to the consumer as required by the CCPA. It shall not refer the consumer to the businesses general practices outlined in its privacy policy unless its response would be the same for all consumers and the privacy policy discloses all the information that is otherwise required to be in a response to a request to know such categories. (10) In responding to a verified request to know categories of personal information, the business shall provide: a. The categories of personal information the business has collected about the consumer in the preceding 12 months; b. The categories of sources from which the personal information was collected; c. The business or commercial purpose for which it collected or sold the personal information; d. The categories of third parties with whom the business shares personal information; e. The categories of personal information that the business sold in the preceding 12 months, and for each category identified, the categories of third parties to whom it sold that particular category of personal information; and f. The categories of personal information that the business disclosed for a business purpose in the preceding 12 months, and for each category identified, the categories of third parties to whom it disclosed that particular category of personal information. (11) A business shall identify the categories of personal information, categories of sources of personal information, and categories of third parties to whom a business sold or disclosed personal information, in a manner that provides consumers a meaningful understanding of the categories listed. (d) Responding to Requests to Delete. (1) For requests to delete, if a business cannot verify the identity of the requestor pursuant to the regulations set forth in Article 4, the business may deny the request to delete. The business shall inform the requestor that their identity cannot be verified. (2) A business shall comply with a consumers request to delete their personal information by: a. Permanently and completely erasing the personal information on its existing systems with the exception of archived or back-up systems; b. Deidentifying the personal information; or c. Aggregating the consumer information. (3) If a business stores any personal information on archived or backup systems, it may delay compliance with the consumers request to delete, with respect to data stored on the archived or backup system, until the archived or backup system relating to that data is restored to an active system or next accessed or used for a sale, disclosure, or commercial purpose. (4) In responding to a request to delete, a business shall inform the consumer whether or not it has complied with the consumers request. (5) If the business complies with the consumers request, the business shall inform the consumer that it will maintain a record of the request as required by section 999.317, subsection (b). A business may retain a record of the request for the purpose of ensuring that the consumers personal information remains deleted from the businesss records. (6) In cases where a business denies a consumers request to delete, the business shall do all of the following: a. Inform the consumer that it will not comply with the consumers request and describe the basis for the denial, including any conflict with federal or state law, or exception to the CCPA, unless prohibited from doing so by law; b. Delete the consumers personal information that is not subject to the exception; and c. Not use the consumers personal information retained for any other purpose than provided for by that exception. (7) If a business that denies a consumers request to delete sells personal information and the consumer has not already made a request to opt-out, the business shall ask the consumer if they would like to opt-out of the sale of their personal information and shall include either the contents of, or a link to, the notice of right to opt-out in accordance with section 999.306. (8) In responding to a request to delete, a business may present the consumer with the choice to delete select portions of their personal information only if a global option to delete all personal information is also offered and more prominently presented than the other choices.",article,"The California Consumer Privacy Act (CCPA) requires businesses to acknowledge requests to know or delete personal information within 10 business days. They should explain how they will process the request and when the consumer can expect a response. Businesses must respond within 45 days, but can take up to 90 days if necessary, provided they inform the consumer about the delay. If a business cannot confirm the consumer's identity, they can deny the request. Businesses are not required to search for personal information if it's not easily accessible, only used for legal purposes, not sold or used commercially, and if the consumer is informed about the categories of records that were not searched. Certain sensitive information like Social Security numbers, driver's license numbers, and biometric data should not be disclosed. If a request is denied due to a conflict with federal or state law, the business should explain the reason for the denial. Businesses should use secure measures when transmitting personal information and can use a secure self-service portal for consumers to access their information. When responding to requests to know categories of personal information, the business should provide an individualized response. For requests to delete personal information, the business can either erase the information, deidentify it, or aggregate it. If a request to delete is denied, the business should explain why, delete any information not subject to the exception, and not use the retained information for any other purpose."
General Data Protection Regulation (GDPR) - Article 87 Processing of the national identification number,0.708974,Details of Article 87 Processing of the national identification number in the General Data Protection Regulation (GDPR): Member States may further determine the specific conditions for the processing of a national identification number or any other identifier of general application. In that case the national identification number or any other identifier of general application shall be used only under appropriate safeguards for the rights and freedoms of the data subject pursuant to this Regulation.,article,"Article 87 of the General Data Protection Regulation (GDPR) allows countries to set their own rules for handling national identification numbers or similar identifiers. However, these identifiers can only be used if there are suitable protections in place to safeguard the individual's rights and freedoms according to the GDPR."
General Data Protection Regulation (GDPR) - Contextual Paragraph (159),0.708971262,"Details of the Contextual Paragraph (159) in the General Data Protection Regulation (GDPR): Where personal data are processed for scientific research purposes, this Regulation should also apply to that processing. For the purposes of this Regulation, the processing of personal data for scientific research purposes should be interpreted in a broad manner including for example technological development and demonstration, fundamental research, applied research and privately funded research. In addition, it should take into account the Union's objective under Article 179(1) TFEU of achieving a European Research Area. Scientific research purposes should also include studies conducted in the public interest in the area of public health. To meet the specificities of processing personal data for scientific research purposes, specific conditions should apply in particular as regards the publication or otherwise disclosure of personal data in the context of scientific research purposes. If the result of scientific research in particular in the health context gives reason for further measures in the interest of the data subject, the general rules of this Regulation should apply in view of those measures.",recital,"The General Data Protection Regulation (GDPR) has a section (Paragraph 159) that applies to the use of personal data for scientific research. This includes a wide range of research types like technology development, fundamental and applied research, and even privately funded studies. The law also covers studies conducted for public health interests. There are specific conditions when it comes to publishing or disclosing personal data in the context of scientific research. If the research leads to further actions that involve the person whose data was used, the general rules of GDPR will apply to those actions."
Digital Markets Act (DMA) - Definition of digital sector,0.708921552,"Details of the Definition of digital sector in the Digital Markets Act (DMA): ""digital sector"" means the sector of products and services provided by means of, or through, information society services;",rectial,"The Digital Markets Act (DMA) introduces a new term called ""digital sector"". This refers to the area of goods and services that are delivered using or through online platforms or services. This could include anything from online shopping and digital entertainment to online banking and other internet-based services. The DMA is designed to regulate these digital services and ensure fair competition in the market."
Digital Markets Act (DMA) - Definition of undertaking,0.708887696,"Details of the Definition of undertaking in the Digital Markets Act (DMA): ""undertaking"" means an entity engaged in an economic activity, regardless of its legal status and the way in which it is financed, including all linked enterprises or connected undertakings that form a group through the direct or indirect control of an enterprise or undertaking by another;",rectial,"The Digital Markets Act (DMA) introduces the term ""undertaking"" to refer to any entity involved in economic activities. This can be any type of organization, regardless of its legal status or how it gets its funding. The term also includes any related businesses or subsidiaries that are directly or indirectly controlled by another company or ""undertaking""."
Artifical Inellegence Act (AI Act) - Article 10,0.708881676,"Aritifical Intelligence Act (AI Act) Article 10 Data and data governance:
1.High-risk AI systems which make use of techniques involving the training of models with data shall be developed on the basis of training, validation and testing data sets that meet the quality criteria referred to in paragraphs 2 to 5.

2.Training, validation and testing data sets shall be subject to appropriate data governance and management practices. Those practices shall concern in particular,

(a)the relevant design choices;

(b)data collection;

(c)relevant data preparation processing operations, such as annotation, labelling, cleaning, enrichment and aggregation;

(d)the formulation of relevant assumptions, notably with respect to the information that the data are supposed to measure and represent;

(e)a prior assessment of the availability, quantity and suitability of the data sets that are needed;

(f)examination in view of possible biases;

(g)the identification of any possible data gaps or shortcomings, and how those gaps and shortcomings can be addressed.

3.Training, validation and testing data sets shall be relevant, representative, free of errors and complete. They shall have the appropriate statistical properties, including, where applicable, as regards the persons or groups of persons on which the high-risk AI system is intended to be used. These characteristics of the data sets may be met at the level of individual data sets or a combination thereof.

4.Training, validation and testing data sets shall take into account, to the extent required by the intended purpose, the characteristics or elements that are particular to the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used.

5.To the extent that it is strictly necessary for the purposes of ensuring bias monitoring, detection and correction in relation to the high-risk AI systems, the providers of such systems may process special categories of personal data referred to in Article 9(1) of Regulation (EU) 2016/679, Article 10 of Directive (EU) 2016/680 and Article 10(1) of Regulation (EU) 2018/1725, subject to appropriate safeguards for the fundamental rights and freedoms of natural persons, including technical limitations on the re-use and use of state-of-the-art security and privacy-preserving measures, such as pseudonymisation, or encryption where anonymisation may significantly affect the purpose pursued.

6.Appropriate data governance and management practices shall apply for the development of high-risk AI systems other than those which make use of techniques involving the training of models in order to ensure that those high-risk AI systems comply with paragraph 2.",article,"The Artificial Intelligence Act (AI Act) states that high-risk AI systems must be developed using high-quality data sets. These data sets must be managed properly, including steps like data collection, preparation, assumption formulation, bias examination, and identification of data gaps. The data sets should be error-free, complete, and representative, taking into account the specific characteristics of the target group or setting. If necessary, special personal data can be processed to monitor and correct bias in high-risk AI systems, as long as appropriate safeguards are in place to protect individuals' rights, such as pseudonymisation or encryption. The same data management practices apply to high-risk AI systems not using model training techniques."
General Data Protection Regulation (GDPR) - Definition of supervisory authority concerned,0.708851814,"Details of the Definition of supervisory authority concerned in the General Data Protection Regulation (GDPR): ""supervisory authority concerned"" means a supervisory authority which is concerned by the processing of personal data because: (a) the controller or processor is established on the territory of the Member State of that supervisory authority; (b) data subjects residing in the Member State of that supervisory authority are substantially affected or likely to be substantially affected by the processing; or (c) a complaint has been lodged with that supervisory authority;",recital,"The General Data Protection Regulation (GDPR) defines ""supervisory authority concerned"" as an authority involved in the processing of personal data due to one of three reasons: (a) the organization controlling or processing the data is located in the same country as the authority, (b) people living in the same country as the authority are significantly impacted or likely to be significantly impacted by the data processing, or (c) a complaint about data processing has been filed with the authority."
Digital Services Act (DSA) - Definition of 'Digital Services Coordinator of destination',0.708816051,Definition of 'Digital Services Coordinator of destination' in the Digital Services Act (DSA): the Digital Services Coordinator of a Member State where the intermediary service is provided.,recital,"The Digital Services Act (DSA) introduces a new role called the 'Digital Services Coordinator.' This person is responsible for overseeing digital services in a specific member state. Essentially, if a company provides an online service in a particular state, this coordinator will be the main point of contact and regulation for that service in that state."
California Consumer Privacy Act Regulations (CCPA) - Definition of Financial incentive,0.708806336,"Details of Definition of Financial incentive in the California Consumer Privacy Act Regulations (CCPA): Financial incentive means a program, benefit, or other offering, including payments to consumers, related to the collection, deletion, or sale of personal information.",recital,"The California Consumer Privacy Act (CCPA) defines ""Financial incentive"" as a reward or benefit program, which could include payments to consumers. This incentive is associated with the gathering, deletion, or sale of personal data. The law aims to regulate how companies handle personal information of consumers and may offer incentives for certain actions related to this information."
General Data Protection Regulation (GDPR) - Article 8 Conditions applicable to child's consent in relation to information society services,0.708782,"Details of Article 8 Conditions applicable to child's consent in relation to information society services in the General Data Protection Regulation (GDPR): 1. Where point (a) of Article 6(1) applies, in relation to the offer of information society services directly to a child, the processing of the personal data of a child shall be lawful where the child is at least 16 years old. Where the child is below the age of 16 years, such processing shall be lawful only if and to the extent that consent is given or authorised by the holder of parental responsibility over the child. Member States may provide by law for a lower age for those purposes provided that such lower age is not below 13 years. 2. The controller shall make reasonable efforts to verify in such cases that consent is given or authorised by the holder of parental responsibility over the child, taking into consideration available technology. 3. Paragraph 1 shall not affect the general contract law of Member States such as the rules on the validity, formation or effect of a contract in relation to a child.",article,"The General Data Protection Regulation (GDPR) Article 8 states that if an online service is offered directly to a child, it's okay to use the child's personal data if the child is 16 or older. If the child is under 16, a parent or guardian must give permission. However, individual countries can lower this age to as young as 13. The service provider must make a genuine effort to confirm that a parent or guardian has given permission, using the best technology available. This rule doesn't interfere with any other laws about contracts involving children."
Artifical Inellegence Act (AI Act) - Definition of 'conformity assessment',0.708755553,"Within the Aritifical Intelligence Act (AI Act), the Definition of conformity assessment means the process of verifying whether the requirements set out in Title III, Chapter 2 of this Regulation relating to an AI system have been fulfilled;",recital,"The Artificial Intelligence Act (AI Act) includes a process called 'conformity assessment.' This process checks if an AI system meets the requirements stated in a specific part of the law (Title III, Chapter 2). In simpler terms, it's like a test to make sure the AI system is following the rules set by the law."
California Consumer Privacy Act Regulations (CCPA) - Definition of COPPA,0.708713651,"Details of Definition of COPPA in the California Consumer Privacy Act Regulations (CCPA): COPPA means the Childrens Online Privacy Protection Act, 15 U.S.C. sections 6501 to 6508 and 16 Code of Federal Regulations part 312.5.",recital,"The California Consumer Privacy Act Regulations (CCPA) includes a definition of COPPA, which stands for the Children's Online Privacy Protection Act. This U.S. federal law, referenced in sections 6501 to 6508 of the United States Code and part 312.5 of the Code of Federal Regulations, is designed to protect the privacy of children using the internet."
Digital Services Act (DSA) - Article 10 Orders to provide information,0.708591044,"Article 10 Orders to provide information in the Digital Services Act (DSA):  1.   Upon receipt of an order to provide specific information about one or more specific individual recipients of the service, issued by the relevant national judicial or administrative authorities on the basis of the applicable Union law or national law in compliance with Union law, providers of intermediary services shall, without undue delay inform the authority issuing the order, or any other authority specified in the order, of its receipt and of the effect given to the order, specifying if and when effect was given to the order.
2.   Member States shall ensure that when an order referred to in paragraph 1 is transmitted to the provider, it meets at least the following conditions:
(a) that order contains the following elements:
(i) a reference to the legal basis under Union or national law for the order;
(ii) information identifying the issuing authority;
(iii) clear information enabling the provider of intermediary services to identify the specific recipient or recipients on whom information is sought, such as one or more account names or unique identifiers;
(iv) a statement of reasons explaining the objective for which the information is required and why the requirement to provide the information is necessary and proportionate to determine compliance by the recipients of the intermediary services with applicable Union law or national law in compliance with Union law, unless such a statement cannot be provided for reasons related to the prevention, investigation, detection and prosecution of criminal offences;
(v) information about redress mechanisms available to the provider and to the recipients of the service concerned;
(vi) where applicable, information about which authority is to receive the information about the effect given to the orders;
(b) that order only requires the provider to provide information already collected for the purposes of providing the service and which lies within its control;
(c) that order is transmitted in one of the languages declared by the provider of intermediary services pursuant to Article 11(3) or in another official language of the Member States, agreed between the authority issuing the order and the provider, and is sent to the electronic point of contact designated by that provider, in accordance with Article 11; where the order is not drafted in the language declared by the provider of intermediary services or in another bilaterally agreed language, the order may be transmitted in the language of the authority issuing the order, provided that it is accompanied by a translation into such declared or bilaterally agreed language of at least the elements set out in points (a) and (b) of this paragraph.
3.   The authority issuing the order or, where applicable, the authority specified therein, shall transmit it, along with any information received from the provider of intermediary services concerning the effect given to that order to the Digital Services Coordinator from the Member State of the issuing authority.
4.   After receiving the order from the judicial or administrative authority, the Digital Services Coordinator of the Member State concerned shall, without undue delay, transmit a copy of the order referred to in paragraph 1 of this Article to all Digital Services Coordinators through the system established in accordance with Article 85.
5.   At the latest when effect is given to the order, or, where applicable, at the time provided by the issuing authority in its order, providers of intermediary services shall inform the recipient of the service concerned of the order received and the effect given to it. Such information provided to the recipient of the service shall include a statement of reasons and the possibilities for redress that exist, in accordance with paragraph 2.
6.   The conditions and requirements laid down in this Article shall be without prejudice to national civil and criminal procedural law.

",article,"The Digital Services Act (DSA) requires online service providers to comply with orders to provide specific user information from national judicial or administrative authorities. These orders must be based on EU or national law, and providers must promptly notify the issuing authority of the order's receipt and compliance. The order must include legal basis, issuer's identity, user identification details, reasons for information request, information about appeal mechanisms, and recipient authority details. The requested information should already be collected by the provider and within their control. The order must be in a language declared by the provider or agreed upon with the authority. A copy of the order must be sent to the Digital Services Coordinator of the issuing authority's Member State. The service provider must inform the user about the order, its compliance, and their rights to appeal. This law doesn't affect national civil and criminal procedural laws."
General Data Protection Regulation (GDPR) - Article 33 Notification of a personal data breach to the supervisory authority,0.70854187,"Details of Article 33 Notification of a personal data breach to the supervisory authority in the General Data Protection Regulation (GDPR): 1. In the case of a personal data breach, the controller shall without undue delay and, where feasible, not later than 72 hours after having become aware of it, notify the personal data breach to the supervisory authority competent in accordance with Article 55, unless the personal data breach is unlikely to result in a risk to the rights and freedoms of natural persons. Where the notification to the supervisory authority is not made within 72 hours, it shall be accompanied by reasons for the delay. 2. The processor shall notify the controller without undue delay after becoming aware of a personal data breach. 3. The notification referred to in paragraph 1 shall at least: (a) describe the nature of the personal data breach including where possible, the categories and approximate number of data subjects concerned and the categories and approximate number of personal data records concerned; (b) communicate the name and contact details of the data protection officer or other contact point where more information can be obtained; (c) describe the likely consequences of the personal data breach; (d) describe the measures taken or proposed to be taken by the controller to address the personal data breach, including, where appropriate, measures to mitigate its possible adverse effects. 4. Where, and in so far as, it is not possible to provide the information at the same time, the information may be provided in phases without undue further delay. 5. The controller shall document any personal data breaches, comprising the facts relating to the personal data breach, its effects and the remedial action taken. That documentation shall enable the supervisory authority to verify compliance with this Article.",article,"Article 33 of the General Data Protection Regulation (GDPR) states that if a personal data breach occurs, the company in charge of the data (the controller) must notify the relevant authority within 72 hours of becoming aware of the breach. This is unless the breach is unlikely to risk people's rights and freedoms. If the notification is late, the company must provide reasons for the delay. The company that processes the data must also inform the controller about the breach as soon as possible. The notification should detail the breach, including the number of people and records affected, contact details for more information, potential consequences, and any actions taken to address the breach. If all this information can't be provided at once, it can be given in stages. The controller must keep a record of all breaches, their effects, and actions taken, to allow the authority to check compliance with the law."
Artifical Inellegence Act (AI Act) - Article 43,0.708523273,"Aritifical Intelligence Act (AI Act) Article 43 Conformity assessment:

1.For high-risk AI systems listed in point 1 of Annex III, where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has applied harmonised standards referred to in Article 40, or, where applicable, common specifications referred to in Article 41, the provider shall follow one of the following procedures:

(a)the conformity assessment procedure based on internal control referred to in Annex VI;

(b)the conformity assessment procedure based on assessment of the quality management system and assessment of the technical documentation, with the involvement of a notified body, referred to in Annex VII.

Where, in demonstrating the compliance of a high-risk AI system with the requirements set out in Chapter 2 of this Title, the provider has not applied or has applied only in part harmonised standards referred to in Article 40, or where such harmonised standards do not exist and common specifications referred to in Article 41 are not available, the provider shall follow the conformity assessment procedure set out in Annex VII.

For the purpose of the conformity assessment procedure referred to in Annex VII, the provider may choose any of the notified bodies. However, when the system is intended to be put into service by law enforcement, immigration or asylum authorities as well as EU institutions, bodies or agencies, the market surveillance authority referred to in Article 63(5) or (6), as applicable, shall act as a notified body.

2.For high-risk AI systems referred to in points 2 to 8 of Annex III, providers shall follow the conformity assessment procedure based on internal control as referred to in Annex VI, which does not provide for the involvement of a notified body. For high-risk AI systems referred to in point 5(b) of Annex III, placed on the market or put into service by credit institutions regulated by Directive 2013/36/EU, the conformity assessment shall be carried out as part of the procedure referred to in Articles 97 to101 of that Directive.

3.For high-risk AI systems, to which legal acts listed in Annex II, section A, apply, the provider shall follow the relevant conformity assessment as required under those legal acts. The requirements set out in Chapter 2 of this Title shall apply to those high-risk AI systems and shall be part of that assessment. Points 4.3., 4.4., 4.5. and the fifth paragraph of point 4.6 of Annex VII shall also apply.

For the purpose of that assessment, notified bodies which have been notified under those legal acts shall be entitled to control the conformity of the high-risk AI systems with the requirements set out in Chapter 2 of this Title, provided that the compliance of those notified bodies with requirements laid down in Article 33(4), (9) and (10) has been assessed in the context of the notification procedure under those legal acts.

Where the legal acts listed in Annex II, section A, enable the manufacturer of the product to opt out from a third-party conformity assessment, provided that that manufacturer has applied all harmonised standards covering all the relevant requirements, that manufacturer may make use of that option only if he has also applied harmonised standards or, where applicable, common specifications referred to in Article 41, covering the requirements set out in Chapter 2 of this Title.

4.High-risk AI systems shall undergo a new conformity assessment procedure whenever they are substantially modified, regardless of whether the modified system is intended to be further distributed or continues to be used by the current user.

For high-risk AI systems that continue to learn after being placed on the market or put into service, changes to the high-risk AI system and its performance that have been pre-determined by the provider at the moment of the initial conformity assessment and are part of the information contained in the technical documentation referred to in point 2(f) of Annex IV, shall not constitute a substantial modification.

5.The Commission is empowered to adopt delegated acts in accordance with Article 73 for the purpose of updating Annexes VI and Annex VII in order to introduce elements of the conformity assessment procedures that become necessary in light of technical progress.

6.The Commission is empowered to adopt delegated acts to amend paragraphs 1 and 2 in order to subject high-risk AI systems referred to in points 2 to 8 of Annex III to the conformity assessment procedure referred to in Annex VII or parts thereof. The Commission shall adopt such delegated acts taking into account the effectiveness of the conformity assessment procedure based on internal control referred to in Annex VI in preventing or minimizing the risks to health and safety and protection of fundamental rights posed by such systems as well as the availability of adequate capacities and resources among notified bodies.",article,"The Artificial Intelligence Act (AI Act) Article 43 outlines the procedures for ensuring high-risk AI systems comply with certain standards. Providers of these systems must follow one of two assessment procedures: one based on internal control, or one involving a notified body to assess the quality management system and technical documentation. If the provider hasn't applied the harmonised standards or if they don't exist, they must follow the latter procedure. For AI systems used by law enforcement, immigration, or EU institutions, the market surveillance authority will act as the notified body. For certain high-risk AI systems, the provider must follow the assessment procedure based on internal control. If the AI system is significantly modified, it must undergo a new assessment. The Commission can update or amend these procedures to adapt to technical progress and to ensure the safety and protection of fundamental rights."
Artifical Inellegence Act (AI Act) - Overview paragraph 76,0.708477557,"Aritifical Intelligence Act (AI Act) overview paragraph (76): In order to facilitate a smooth, effective and harmonised implementation of this Regulation a European Artificial Intelligence Board should be established. The Board should be responsible for a number of advisory tasks, including issuing opinions, recommendations, advice or guidance on matters related to the implementation of this Regulation, including on technical specifications or existing standards regarding the requirements established in this Regulation and providing advice to and assisting the Commission on specific questions related to artificial intelligence.",recital,"The Artificial Intelligence Act (AI Act) proposes the creation of a European Artificial Intelligence Board. This board's role is to ensure the smooth and uniform application of the Act across Europe. It will provide advice, opinions, and guidance on issues related to the implementation of the Act, including technical aspects and existing standards. The board will also assist the Commission with specific questions about artificial intelligence."
Artifical Inellegence Act (AI Act) - Article 32,0.708385885,"Aritifical Intelligence Act (AI Act) Article 32 Notification procedure:

1.Notifying authorities may notify only conformity assessment bodies which have satisfied the requirements laid down in Article 33.

2.Notifying authorities shall notify the Commission and the other Member States using the electronic notification tool developed and managed by the Commission.

3.The notification shall include full details of the conformity assessment activities, the conformity assessment module or modules and the artificial intelligence technologies concerned.

4.The conformity assessment body concerned may perform the activities of a notified body only where no objections are raised by the Commission or the other Member States within one month of a notification.

5.Notifying authorities shall notify the Commission and the other Member States of any subsequent relevant changes to the notification.",article,"The Artificial Intelligence Act (AI Act) Article 32 explains the notification procedure for AI-related activities. Only those bodies that meet the criteria set in Article 33 can be notified by the authorities. These authorities must then inform the Commission and other Member States using a specific electronic tool. The notification should include all details about the AI activities, assessment methods, and technologies used. The body being assessed can only proceed if there are no objections from the Commission or other Member States within a month. Any significant changes to the notification must also be reported to the Commission and other Member States."
California Consumer Privacy Act Regulations (CCPA) - Definition of Value of the consumer's data,0.708343565,Details of Definition of Value of the consumers data in the California Consumer Privacy Act Regulations (CCPA): Value of the consumers data means the value provided to the business by the consumers data as calculated under section 999.337.,recital,"The California Consumer Privacy Act (CCPA) has a new law that defines the ""value of the consumers data"". This refers to the worth or benefit that a business gets from using a consumer's personal data. The method to calculate this value is outlined in section 999.337 of the CCPA. This law is important because it helps determine how much a consumer's personal information is worth to a business."
Artifical Inellegence Act (AI Act) - Definition of 'post' remote biometric identification system',0.70833385,"Within the Aritifical Intelligence Act (AI Act), the Definition of post remote biometric identification system means a remote biometric identification system other than a real-time remote biometric identification system;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'post' remote biometric identification system. This is a type of remote biometric identification system, but it's different from a 'real-time' system. Biometric identification systems are technologies that identify you by your biological characteristics, like your face or fingerprint. 'Real-time' systems do this immediately, but 'post' systems do it after the fact."
Artifical Inellegence Act (AI Act) - Article 84,0.7082057,"Aritifical Intelligence Act (AI Act) Article 84 Evaluation and review:

1.The Commission shall assess the need for amendment of the list in Annex III once a year following the entry into force of this Regulation.

2.By [three years after the date of application of this Regulation referred to in Article 85(2)] and every four years thereafter, the Commission shall submit a report on the evaluation and review of this Regulation to the European Parliament and to the Council. The reports shall be made public.

3.The reports referred to in paragraph 2 shall devote specific attention to the following:

(a)the status of the financial and human resources of the national competent authorities in order to effectively perform the tasks assigned to them under this Regulation;

(b)the state of penalties, and notably administrative fines as referred to in Article 71(1), applied by Member States to infringements of the provisions of this Regulation.

4.Within [three years after the date of application of this Regulation referred to in Article 85(2)] and every four years thereafter, the Commission shall evaluate the impact and effectiveness of codes of conduct to foster the application of the requirements set out in Title III, Chapter 2 and possibly other additional requirements for AI systems other than high-risk AI systems.

5.For the purpose of paragraphs 1 to 4 the Board, the Member States and national competent authorities shall provide the Commission with information on its request.

6.In carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the Commission shall take into account the positions and findings of the Board, of the European Parliament, of the Council, and of other relevant bodies or sources.

7.The Commission shall, if necessary, submit appropriate proposals to amend this Regulation, in particular taking into account developments in technology and in the light of the state of progress in the information society.
",article,"The Artificial Intelligence Act (AI Act) requires the Commission to review and possibly amend a certain list annually. Every four years, the Commission must submit a public report on the law's effectiveness to the European Parliament and Council. This report will focus on the resources of national authorities, the penalties for breaking the law, and the impact of codes of conduct on AI systems. The Commission will gather information from the Board, Member States, and national authorities, considering their findings in its evaluations. If necessary, the Commission may propose changes to the law, especially in response to technological advancements and societal progress."
Artifical Inellegence Act (AI Act) - Definition of 'reasonably foreseeable misuse',0.708137035,"Within the Aritifical Intelligence Act (AI Act), the Definition of reasonably foreseeable misuse means the use of an AI system in a way that is not in accordance with its intended purpose, but which may result from reasonably foreseeable human behaviour or interaction with other systems;",recital,"The Artificial Intelligence Act (AI Act) includes a term called 'reasonably foreseeable misuse'. This refers to using an AI system in a way that it wasn't designed for, but could happen due to predictable human behavior or interaction with other systems. In simpler terms, it's about misusing an AI system in a way that could have been anticipated."
California Consumer Privacy Act Regulations (CCPA) - Article 3. Business Practices for Handling Consumer Requests -  999.314 Service Providers,0.70796746,"Details of Article 3. Business Practices for Handling Consumer Requests -  999.314 Service Providers in the California Consumer Privacy Act Regulations (CCPA): (a) A business that provides services to a person or organization that is not a business, and that would otherwise meet the requirements and obligations of a service provider under the CCPA and these regulations, shall be deemed a service provider for purposes of the CCPA and these regulations. (b) To the extent that a business directs a second entity to collect personal information directly from a consumer, or about a consumer, on the first businesss behalf, and the second entity would otherwise meet the requirements and obligations of a service provider under the CCPA and these regulations, the second entity shall be deemed a service provider of the first business for purposes of the CCPA and these regulations. (c) A service provider shall not retain, use, or disclose personal information obtained in the course of providing services except: (1) To process or maintain personal information on behalf of the business that provided the personal information or directed the service provider to collect the personal information, and in compliance with the written contract for services required by the CCPA; (2) To retain and employ another service provider as a subcontractor, where the subcontractor meets the requirements for a service provider under the CCPA and these regulations; (3) For internal use by the service provider to build or improve the quality of its services, provided that the use does not include building or modifying household or consumer profiles to use in providing services to another business, or correcting or augmenting data acquired from another source; (4) To detect data security incidents or protect against fraudulent or illegal activity; or (5) For the purposes enumerated in Civil Code section 1798.145, subdivisions (a)(1) through (a)(4). (d) A service provider shall not sell data on behalf of a business when a consumer has opted-out of the sale of their personal information with the business. (e) If a service provider receives a request to know or a request to delete from a consumer, the service provider shall either act on behalf of the business in responding to the request or inform the consumer that the request cannot be acted upon because the request has been sent to a service provider. (f) A service provider that is a business shall comply with the CCPA and these regulations with regard to any personal information that it collects, maintains, or sells outside of its role as a service provider.",article,"The California Consumer Privacy Act (CCPA) has a new law, Article 3, focusing on how businesses handle consumer requests. This law applies to any business providing services to individuals or non-business organizations, and to any entity collecting personal information on behalf of another business. These businesses are considered ""service providers"" under the law. Service providers must not misuse personal information and can only use it for specific purposes like processing data, improving services, detecting fraud, and complying with other legal obligations. They can't sell personal data if a consumer has opted out of such sales. If a service provider receives a request from a consumer to know or delete their personal information, it must either respond or explain why it can't. The law also applies to service providers that collect, maintain, or sell personal information outside their role as a service provider."
Artifical Inellegence Act (AI Act) - Article 41,0.707959056,"Aritifical Intelligence Act (AI Act) Article 41 Common specifications:

1.Where harmonised standards referred to in Article 40 do not exist or where the Commission considers that the relevant harmonised standards are insufficient or that there is a need to address specific safety or fundamental right concerns, the Commission may, by means of implementing acts, adopt common specifications in respect of the requirements set out in Chapter 2 of this Title. Those implementing acts shall be adopted in accordance with the examination procedure referred to in Article 74(2).

2.The Commission, when preparing the common specifications referred to in paragraph 1, shall gather the views of relevant bodies or expert groups established under relevant sectorial Union law.

3.High-risk AI systems which are in conformity with the common specifications referred to in paragraph 1 shall be presumed to be in conformity with the requirements set out in Chapter 2 of this Title, to the extent those common specifications cover those requirements.

4.Where providers do not comply with the common specifications referred to in paragraph 1, they shall duly justify that they have adopted technical solutions that are at least equivalent thereto.",article,"The Artificial Intelligence Act (AI Act) Article 41 allows the Commission to establish common rules for AI if current standards are inadequate or if there are safety or fundamental rights issues. The Commission will consult with relevant experts when creating these rules. AI systems that meet these rules will be assumed to meet the requirements of the AI Act. If providers don't follow these rules, they must prove that their technical solutions are at least as good."
Artifical Inellegence Act (AI Act) - Article 9,0.707923651,"Aritifical Intelligence Act (AI Act) Article 9 Risk management system:

1.A risk management system shall be established, implemented, documented and maintained in relation to high-risk AI systems.

2.The risk management system shall consist of a continuous iterative process run throughout the entire lifecycle of a high-risk AI system, requiring regular systematic updating. It shall comprise the following steps:

(a)identification and analysis of the known and foreseeable risks associated with each high-risk AI system;

(b)estimation and evaluation of the risks that may emerge when the high-risk AI system is used in accordance with its intended purpose and under conditions of reasonably foreseeable misuse;

(c)evaluation of other possibly arising risks based on the analysis of data gathered from the post-market monitoring system referred to in Article 61;

(d)adoption of suitable risk management measures in accordance with the provisions of the following paragraphs.

3.The risk management measures referred to in paragraph 2, point (d) shall give due consideration to the effects and possible interactions resulting from the combined application of the requirements set out in this Chapter 2. They shall take into account the generally acknowledged state of the art, including as reflected in relevant harmonised standards or common specifications.

4.The risk management measures referred to in paragraph 2, point (d) shall be such that any residual risk associated with each hazard as well as the overall residual risk of the high-risk AI systems is judged acceptable, provided that the high-risk AI system is used in accordance with its intended purpose or under conditions of reasonably foreseeable misuse. Those residual risks shall be communicated to the user.

In identifying the most appropriate risk management measures, the following shall be ensured:

(a)elimination or reduction of risks as far as possible through adequate design and development;

(b)where appropriate, implementation of adequate mitigation and control measures in relation to risks that cannot be eliminated;

(c)provision of adequate information pursuant to Article 13, in particular as regards the risks referred to in paragraph 2, point (b) of this Article, and, where appropriate, training to users.

In eliminating or reducing risks related to the use of the high-risk AI system, due consideration shall be given to the technical knowledge, experience, education, training to be expected by the user and the environment in which the system is intended to be used.

5.High-risk AI systems shall be tested for the purposes of identifying the most appropriate risk management measures. Testing shall ensure that high-risk AI systems perform consistently for their intended purpose and they are in compliance with the requirements set out in this Chapter.

6.Testing procedures shall be suitable to achieve the intended purpose of the AI system and do not need to go beyond what is necessary to achieve that purpose.

7.The testing of the high-risk AI systems shall be performed, as appropriate, at any point in time throughout the development process, and, in any event, prior to the placing on the market or the putting into service. Testing shall be made against preliminarily defined metrics and probabilistic thresholds that are appropriate to the intended purpose of the high-risk AI system.

8.When implementing the risk management system described in paragraphs 1 to 7, specific consideration shall be given to whether the high-risk AI system is likely to be accessed by or have an impact on children.

9.For credit institutions regulated by Directive 2013/36/EU, the aspects described in paragraphs 1 to 8 shall be part of the risk management procedures established by those institutions pursuant to Article 74 of that Directive.",article,"The Artificial Intelligence Act (AI Act) mandates the implementation of a risk management system for high-risk AI systems. This system must be continuously updated throughout the AI's lifecycle and should include identification and analysis of potential risks, estimation and evaluation of these risks, and adoption of suitable risk management measures. These measures should consider the state of the art and aim to eliminate or reduce risks as much as possible through design and development. Any remaining risks should be communicated to the user. High-risk AI systems must be tested to ensure they perform as intended and comply with the requirements. Testing should be conducted throughout the development process and before the system is released to the market. The law also requires special consideration for high-risk AI systems that could be accessed by or impact children. For credit institutions, these requirements will be part of their existing risk management procedures."
Digital Markets Act (DMA) - Definition of core platform service,0.707741559,"Details of the Definition of core platform service in the Digital Markets Act (DMA): ""core platform service"" means any of the following: (a) online intermediation services; (b) online search engines; (c) online social networking services; (d) video-sharing platform services; (e) number-independent interpersonal communications services; (f) operating systems; (g) web browsers; (h) virtual assistants; (i) cloud computing services; (j) online advertising services, including any advertising networks, advertising exchanges and any other advertising intermediation services, provided by an undertaking that provides any of the core platform services listed in points (a) to (i);",rectial,"The Digital Markets Act (DMA) has defined ""core platform service"" as any of the following online services: intermediation, search engines, social networking, video-sharing, independent interpersonal communications, operating systems, web browsers, virtual assistants, cloud computing, and advertising services. These advertising services include networks, exchanges, and other intermediation services, but only if they're provided by a company that also offers any of the previously mentioned core platform services."
California Consumer Privacy Act Regulations (CCPA) - Definition of Authorized agent,0.707481682,Details of Definition of Authorized agent in the California Consumer Privacy Act Regulations (CCPA): Authorized agent means a natural person or a business entity registered with the Secretary of State to conduct business in California that a consumer has authorized to act on their behalf subject to the requirements set forth in section 999.326.,recital,"The California Consumer Privacy Act Regulations (CCPA) introduces the term ""Authorized agent"". This refers to an individual or a business that is registered to operate in California, and has been given permission by a consumer to act on their behalf. This agent must follow the rules outlined in section 999.326 of the Act."
California Consumer Privacy Act Regulations (CCPA) - Definition of Categories of sources,0.707389116,"Details of Definition of Categories of sources in the California Consumer Privacy Act Regulations (CCPA): Categories of sources means types or groupings of persons or entities from which a business collects personal information about consumers, described with enough particularity to provide consumers with a meaningful understanding of the type of person or entity. They may include the consumer directly, advertising networks, internet service providers, data analytics providers, government entities, operating systems and platforms, social networks, and data brokers.",recital,"The California Consumer Privacy Act (CCPA) has defined ""Categories of sources"" as the different types or groups from which a business collects personal information about consumers. This includes direct consumer input, advertising networks, internet service providers, data analytics providers, government entities, operating systems and platforms, social networks, and data brokers. The law requires these sources to be described clearly so consumers understand who is collecting their personal information."
General Data Protection Regulation (GDPR) - Definition of pseudonymisation,0.707357764,"Details of the Definition of pseudonymisation in the General Data Protection Regulation (GDPR): ""pseudonymisation"" means the processing of personal data in such a manner that the personal data can no longer be attributed to a specific data subject without the use of additional information, provided that such additional information is kept separately and is subject to technical and organisational measures to ensure that the personal data are not attributed to an identified or identifiable natural person;",recital,"The General Data Protection Regulation (GDPR) introduces a concept called ""pseudonymisation"". This is a process where your personal data is processed in a way that it can't be linked back to you without extra information. This extra information is stored separately and protected with technical and organizational measures. This means that your personal data is kept safe and can't be used to identify you without this additional information."
General Data Protection Regulation (GDPR) - Article 14 Information to be provided where personal data have not been obtained from the data subject,0.707134366,"Details of Article 14 Information to be provided where personal data have not been obtained from the data subject in the General Data Protection Regulation (GDPR): 1. Where personal data have not been obtained from the data subject, the controller shall provide the data subject with the following information: (a) the identity and the contact details of the controller and, where applicable, of the controller's representative; (b) the contact details of the data protection officer, where applicable; (c) the purposes of the processing for which the personal data are intended as well as the legal basis for the processing; (d) the categories of personal data concerned; (e) the recipients or categories of recipients of the personal data, if any; (f) where applicable, that the controller intends to transfer personal data to a recipient in a third country or international organisation and the existence or absence of an adequacy decision by the Commission, or in the case of transfers referred to in Article 46 or 47, or the second subparagraph of Article 49(1), reference to the appropriate or suitable safeguards and the means to obtain a copy of them or where they have been made available. 2. In addition to the information referred to in paragraph 1, the controller shall provide the data subject with the following information necessary to ensure fair and transparent processing in respect of the data subject: (a) the period for which the personal data will be stored, or if that is not possible, the criteria used to determine that period; (b) where the processing is based on point (f) of Article 6(1), the legitimate interests pursued by the controller or by a third party; (c) the existence of the right to request from the controller access to and rectification or erasure of personal data or restriction of processing concerning the data subject and to object to processing as well as the right to data portability; (d) where processing is based on point (a) of Article 6(1) or point (a) of Article 9(2), the existence of the right to withdraw consent at any time, without affecting the lawfulness of processing based on consent before its withdrawal; (e) the right to lodge a complaint with a supervisory authority; (f) from which source the personal data originate, and if applicable, whether it came from publicly accessible sources; (g) the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) and, at least in those cases, meaningful information about the logic involved, as well as the significance and the envisaged consequences of such processing for the data subject. 3. The controller shall provide the information referred to in paragraphs 1 and 2: (a) within a reasonable period after obtaining the personal data, but at the latest within one month, having regard to the specific circumstances in which the personal data are processed; (b) if the personal data are to be used for communication with the data subject, at the latest at the time of the first communication to that data subject; or (c) if a disclosure to another recipient is envisaged, at the latest when the personal data are first disclosed. 4. Where the controller intends to further process the personal data for a purpose other than that for which the personal data were obtained, the controller shall provide the data subject prior to that further processing with information on that other purpose and with any relevant further information as referred to in paragraph 2. 5. Paragraphs 1 to 4 shall not apply where and insofar as: (a) the data subject already has the information; (b) the provision of such information proves impossible or would involve a disproportionate effort, in particular for processing for archiving purposes in the public interest, scientific or historical research purposes or statistical purposes, subject to the conditions and safeguards referred to in Article 89(1) or in so far as the obligation referred to in paragraph 1 of this Article is likely to render impossible or seriously impair the achievement of the objectives of that processing. In such cases the controller shall take appropriate measures to protect the data subject's rights and freedoms and legitimate interests, including making the information publicly available; (c) obtaining or disclosure is expressly laid down by Union or Member State law to which the controller is subject and which provides appropriate measures to protect the data subject's legitimate interests; or (d) where the personal data must remain confidential subject to an obligation of professional secrecy regulated by Union or Member State law, including a statutory obligation of secrecy.",article,"The General Data Protection Regulation (GDPR) Article 14 outlines the rights of individuals when their personal data is collected from a source other than themselves. The company collecting the data (the controller) must provide the individual with their contact details, the purpose and legal basis for processing the data, the types of data processed, and any potential recipients of the data. If the data will be transferred internationally, the individual must be informed. The controller must also inform the individual of how long the data will be stored, their rights to access, correct, or erase their data, the right to object to processing, and the right to lodge a complaint. The individual must be informed of the source of the data and any automated decision-making processes. This information must be provided within a month of obtaining the data, or at the first communication or disclosure. Exceptions apply if the individual already has the information, if providing the information is impossible or would involve a disproportionate effort, or if the data must remain confidential due to professional secrecy obligations."
Artifical Inellegence Act (AI Act) - Article 72,0.707118869,"Aritifical Intelligence Act (AI Act) Article 72 Administrative fines on Union institutions, agencies and bodies:

1.The European Data Protection Supervisor may impose administrative fines on Union institutions, agencies and bodies falling within the scope of this Regulation. When deciding whether to impose an administrative fine and deciding on the amount of the administrative fine in each individual case, all relevant circumstances of the specific situation shall be taken into account and due regard shall be given to the following:

(a)the nature, gravity and duration of the infringement and of its consequences;

(b)the cooperation with the European Data Protection Supervisor in order to remedy the infringement and mitigate the possible adverse effects of the infringement, including compliance with any of the measures previously ordered by the European Data Protection Supervisor against the Union institution or agency or body concerned with regard to the same subject matter;

(c)any similar previous infringements by the Union institution, agency or body;

2.The following infringements shall be subject to administrative fines of up to 500 000 EUR:

(a)non-compliance with the prohibition of the artificial intelligence practices referred to in Article 5;

(b)non-compliance of the AI system with the requirements laid down in Article 10.

3.The non-compliance of the AI system with any requirements or obligations under this Regulation, other than those laid down in Articles 5 and 10, shall be subject to administrative fines of up to 250 000 EUR.

4.Before taking decisions pursuant to this Article, the European Data Protection Supervisor shall give the Union institution, agency or body which is the subject of the proceedings conducted by the European Data Protection Supervisor the opportunity of being heard on the matter regarding the possible infringement. The European Data Protection Supervisor shall base his or her decisions only on elements and circumstances on which the parties concerned have been able to comment. Complainants, if any, shall be associated closely with the proceedings.

5.The rights of defense of the parties concerned shall be fully respected in the proceedings. They shall be entitled to have access to the European Data Protection Supervisors file, subject to the legitimate interest of individuals or undertakings in the protection of their personal data or business secrets.

6.Funds collected by imposition of fines in this Article shall be the income of the general budget of the Union.",article,"The Artificial Intelligence Act (AI Act) allows the European Data Protection Supervisor to fine EU institutions, agencies, and bodies if they violate the rules of the Act. The severity of the fine depends on factors like the nature and duration of the violation, the cooperation of the institution, and any previous violations. Violations related to prohibited AI practices or non-compliance with AI system requirements can result in fines up to 500,000 EUR. Other violations can lead to fines up to 250,000 EUR. Before a fine is imposed, the institution has the right to defend itself. Any fines collected will go into the general budget of the EU."
Digital Markets Act (DMA) - Article 12 Updating obligations for gatekeepers,0.707106829,"Details of Article 12 Updating obligations for gatekeepers in the Digital Markets Act (DMA): 1. The Commission is empowered to adopt delegated acts in accordance with Article 49 to supplement this Regulation with regard to the obligations laid down in Articles 5 and 6. Those delegated acts shall be based on a market investigation pursuant to Article 19 that has identified the need to keep those obligations up to date in order to address practices that limit the contestability of core platform services or that are unfair in the same way as the practices addressed by the obligations laid down in Articles 5 and 6. 2. The scope of a delegated act adopted in accordance with paragraph 1 shall be limited to: (a) extending an obligation that applies only in relation to certain core platform services, to other core platform services listed in Article 2, point (2); (b) extending an obligation that benefits certain business users or end users so that it benefits other business users or end users; (c) specifying the manner in which the obligations laid down in Articles 5 and 6 are to be performed by gatekeepers in order to ensure effective compliance with those obligations; (d) extending an obligation that applies only in relation to certain services provided together with, or in support of, core platform services to other services provided together with, or in support of, core platform services; (e) extending an obligation that applies only in relation to certain types of data to apply in relation to other types of data; (f) adding further conditions where an obligation imposes certain conditions on the behaviour of a gatekeeper; or (g) applying an obligation that governs the relationship between several core platform services of the gatekeeper to the relationship between a core platform service and other services of the gatekeeper. 3. The Commission is empowered to adopt delegated acts in accordance with Article 49 to amend this Regulation with regard to the list of basic functionalities identified in Article 7(2), by adding or removing functionalities of numberindependent interpersonal communications services. Those delegated acts shall be based on a market investigation pursuant to Article 19 that has identified the need to keep those obligations up to date in order to address practices that limit the contestability of core platform services or that are unfair in the same way as the practices addressed by the obligations laid down in Article 7. 4. The Commission is empowered to adopt delegated acts in accordance with Article 49 to supplement this Regulation in respect of the obligations in Article 7 by specifying the manner in which those obligations are to be performed in order to ensure effective compliance with those obligations. Those delegated acts shall be based on a market investigation pursuant to Article 19, which has identified the need to keep those obligations up to date in order to address practices that limit the contestability of core platform services or that are unfair in the same way as the practices addressed by the obligations laid down in Article 7. 5. A practice as referred to in paragraphs 1, 3 and 4 shall be considered to limit the contestability of core platform services or to be unfair where: (a) that practice is engaged in by gatekeepers and is capable of impeding innovation and limiting choice for business users and end users because it: (i) affects or risks affecting the contestability of a core platform service or other services in the digital sector on a lasting basis due to the creation or strengthening of barriers to entry for other undertakings or to expand as providers of a core platform service or other services in the digital sector; or (ii) prevents other operators from having the same access to a key input as the gatekeeper; or (b) there is an imbalance between the rights and obligations of business users and the gatekeeper obtains an advantage from business users that is disproportionate to the service provided by that gatekeeper to those business users.",article,"The Digital Markets Act (DMA) Article 12 empowers the Commission to update regulations to ensure fair competition in digital markets. The Commission can extend obligations to more services, users, or data types, specify how obligations should be met, and add conditions to gatekeeper behavior. These changes are based on market investigations that identify practices limiting competition or being unfair. The Commission can also modify the list of basic functionalities and how obligations related to them should be met. Practices are considered limiting or unfair if they impede innovation, limit choice, create barriers to entry, prevent equal access to key inputs, or create an imbalance between the rights and obligations of business users and gatekeepers."
Digital Services Act (DSA) - Article 15 Transparency reporting obligations for providers of intermediary services,0.707027733,"Article 15 Transparency reporting obligations for providers of intermediary services in the Digital Services Act (DSA):  1.   Providers of intermediary services shall make publicly available, in a machine-readable format and in an easily accessible manner, at least once a year, clear, easily comprehensible reports on any content moderation that they engaged in during the relevant period. Those reports shall include, in particular, information on the following, as applicable:
(a) for providers of intermediary services, the number of orders received from Member States' authorities including orders issued in accordance with Articles 9 and 10, categorised by the type of illegal content concerned, the Member State issuing the order, and the median time needed to inform the authority issuing the order, or any other authority specified in the order, of its receipt, and to give effect to the order;
(b) for providers of hosting services, the number of notices submitted in accordance with Article 16, categorised by the type of alleged illegal content concerned, the number of notices submitted by trusted flaggers, any action taken pursuant to the notices by differentiating whether the action was taken on the basis of the law or the terms and conditions of the provider, the number of notices processed by using automated means and the median time needed for taking the action;
(c) for providers of intermediary services, meaningful and comprehensible information about the content moderation engaged in at the providers' own initiative, including the use of automated tools, the measures taken to provide training and assistance to persons in charge of content moderation, the number and type of measures taken that affect the availability, visibility and accessibility of information provided by the recipients of the service and the recipients' ability to provide information through the service, and other related restrictions of the service; the information reported shall be categorised by the type of illegal content or violation of the terms and conditions of the service provider, by the detection method and by the type of restriction applied;
(d) for providers of intermediary services, the number of complaints received through the internal complaint-handling systems in accordance with the provider's terms and conditions and additionally, for providers of online platforms, in accordance with Article 20, the basis for those complaints, decisions taken in respect of those complaints, the median time needed for taking those decisions and the number of instances where those decisions were reversed;
(e) any use made of automated means for the purpose of content moderation, including a qualitative description, a specification of the precise purposes, indicators of the accuracy and the possible rate of error of the automated means used in fulfilling those purposes, and any safeguards applied.
2.   Paragraph 1 of this Article shall not apply to providers of intermediary services that qualify as micro or small enterprises as defined in Recommendation 2003/361/EC and which are not very large online platforms within the meaning of Article 33 of this Regulation.
3.   The Commission may adopt implementing acts to lay down templates concerning the form, content and other details of reports pursuant to paragraph 1 of this Article, including harmonised reporting periods. Those implementing acts shall be adopted in accordance with the advisory procedure referred to in Article 88.",article,"The Digital Services Act (DSA) requires providers of intermediary services to publish yearly reports detailing their content moderation activities. This includes the number of orders received from authorities, notices submitted, and actions taken in response. It also requires information about any self-initiated content moderation, the use of automated tools, and training provided for content moderators. Providers must also report on the number of complaints received and actions taken, and provide details about the use of automated moderation. This law does not apply to small or micro businesses that are not large online platforms. The Commission may provide templates for these reports."
Artifical Inellegence Act (AI Act) - Definition of 'artificial intelligence system',0.706492424,"Within the Aritifical Intelligence Act (AI Act), the Definition of artificial intelligence system (AI system) means software that is developed with one or more of the techniques and approaches listed in Annex I and can, for a given set of human-defined objectives, generate outputs such as content, predictions, recommendations, or decisions influencing the environments they interact with;",recital,"The Artificial Intelligence Act (AI Act) defines an 'artificial intelligence system' (AI system) as software developed using certain techniques (listed in Annex I of the Act). This software is designed to achieve specific goals set by humans. It can create things like content, predictions, or recommendations, and can make decisions that affect the environments they're used in."
Artifical Inellegence Act (AI Act) - Definition of 'training data',0.706316888,"Within the Aritifical Intelligence Act (AI Act), the Definition of training data means data used for training an AI system through fitting its learnable parameters, including the weights of a neural network;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'training data.' This is the information used to teach an AI system how to function, similar to how we learn from textbooks. This includes adjusting the system's learnable elements, like the weights of a neural network, which is essentially the brain of the AI system."
Digital Markets Act (DMA) - Definition of cloud computing service,0.706263185,"Details of the Definition of cloud computing service in the Digital Markets Act (DMA): ""cloud computing service"" means a cloud computing service as defined in Article 4, point (19), of Directive (EU) 2016/1148 of the European Parliament and of the Council ( 24);",rectial,"The Digital Markets Act (DMA) has defined what a ""cloud computing service"" is. According to this new law, a ""cloud computing service"" is the same as what is described in Article 4, point (19), of Directive (EU) 2016/1148 of the European Parliament and of the Council. This means that the DMA uses the same definition as the previous law for cloud computing services."
Artifical Inellegence Act (AI Act) - Definition of 'input data',0.706104219,"Within the Aritifical Intelligence Act (AI Act), the Definition of input data means data provided to or directly acquired by an AI system on the basis of which the system produces an output;",recital,The Artificial Intelligence Act (AI Act) introduces the term 'input data'. This refers to the information that an AI system receives or collects directly. The AI system then uses this data to generate a result or output.
California Consumer Privacy Act Regulations (CCPA) - Article 2. Notice to Consumers -  999.307 Notice of Financial Incentive,0.706075251,"Details of Article 2. Notice to Consumers -  999.307 Notice of Financial Incentive in the California Consumer Privacy Act Regulations (CCPA): (a) Purpose and General Principles (1) The purpose of the notice of financial incentive is to explain to the consumer the material terms of a financial incentive or price or service difference the business is offering so that the consumer may make an informed decision about whether to participate. A business that does not offer a financial incentive or price or service difference is not required to provide a notice of financial incentive. (2) The notice of financial incentive shall be designed and presented in a way that is easy to read and understandable to consumers. The notice shall: a. Use plain, straightforward language and avoid technical or legal jargon. b. Use a format that draws the consumers attention to the notice and makes the notice readable, including on smaller screens, if applicable. c. Be available in the languages in which the business in its ordinary course provides contracts, disclaimers, sale announcements, and other information to consumers in California. d. Be reasonably accessible to consumers with disabilities. For notices provided online, the business shall follow generally recognized industry standards, such as the Web Content Accessibility Guidelines, version 2.1 of June 5, 2018, from the World Wide Web Consortium, incorporated herein by reference. In other contexts, the business shall provide information on how a consumer with a disability may access the notice in an alternative format. e. Be readily available where consumers will encounter it before opting-in to the financial incentive or price or service difference. (3) If the business offers the financial incentive or price or service difference online, the notice may be given by providing a link to the section of a businesss privacy policy that contains the information required in subsection (b). (b) A business shall include the following in its notice of financial incentive: (1) A succinct summary of the financial incentive or price or service difference offered; (2) A description of the material terms of the financial incentive or price or service difference, including the categories of personal information that are implicated by the financial incentive or price or service difference and the value of the consumers data; (3) How the consumer can opt-in to the financial incentive or price or service difference; (4) A statement of the consumers right to withdraw from the financial incentive at any time and how the consumer may exercise that right; and (5) An explanation of how the financial incentive or price or service difference is reasonably related to the value of the consumers data, including: a. A good-faith estimate of the value of the consumers data that forms the basis for offering the financial incentive or price or service difference; and b. A description of the method the business used to calculate the value of the consumers data.",article,"The California Consumer Privacy Act (CCPA) has a new section, Article 2, which requires businesses to clearly inform consumers about any financial incentives or changes in price or service they're offering. This information must be presented in a simple, easy-to-understand manner, accessible to all, including those with disabilities, and available in all languages the business typically uses. It should be easily found before the consumer opts into the incentive or change. If the business operates online, this information can be included in their privacy policy. The notice must include a summary of the incentive or change, the terms, the types of personal information involved, how to opt-in, how to withdraw, and how the incentive or change relates to the value of the consumer's data."
California Consumer Privacy Act Regulations (CCPA) - Definition of Price or service difference,0.706025541,"Details of Definition of Price or service difference in the California Consumer Privacy Act Regulations (CCPA): Price or service difference means (1) any difference in the price or rate charged for any goods or services to any consumer related to the collection, retention, or sale of personal information, including through the use of discounts, financial payments, or other benefits or penalties; or (2) any difference in the level or quality of any goods or services offered to any consumer related to the collection, retention, or sale of personal information, including the denial of goods or services to the consumer.",recital,"The California Consumer Privacy Act (CCPA) defines ""Price or service difference"" as any change in cost or quality of goods/services based on the collection, retention, or sale of a customer's personal information. This can include discounts, financial rewards, penalties, or even denial of services. In simpler terms, it means companies can't charge you more, give you less, or deny you a product or service based on what they do with your personal data."
Artifical Inellegence Act (AI Act) - Definition of 'real-time' remote biometric identification system',0.705963731,"Within the Aritifical Intelligence Act (AI Act), the Definition of 'real-time remote biometric identification system means a remote biometric identification system whereby the capturing of biometric data, the comparison and the identification all occur without a significant delay. This comprises not only instant identification, but also limited short delays in order to avoid circumvention.",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'real-time remote biometric identification system'. This refers to a system that captures, compares, and identifies biometric data (like fingerprints or facial recognition) almost instantly, with only minor delays allowed to prevent misuse. This system is used for identifying people remotely and promptly."
Artifical Inellegence Act (AI Act) - Definition of 'validation data',0.705651104,"Within the Aritifical Intelligence Act (AI Act), the Definition of validation data means data used for providing an evaluation of the trained AI system and for tuning its non-learnable parameters and its learning process, among other things, in order to prevent overfitting; whereas the validation dataset can be a separate dataset or part of the training dataset, either as a fixed or variable split;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'validation data'. This is the information used to test and adjust an AI system after it's been trained. This process helps to prevent 'overfitting', which is when an AI system is too closely tailored to the training data and may not perform well with new data. The validation data can either be a separate set of data or a portion of the original training data."
Digital Markets Act (DMA) - Definition of technical service supporting payment service,0.705631733,"Details of the Definition of technical service supporting payment service in the Digital Markets Act (DMA): ""technical service supporting payment service"" means a service within the meaning of Article 3, point (j), of Directive (EU) 2015/2366;",rectial,"The Digital Markets Act (DMA) has introduced a new term called ""technical service supporting payment service"". This term refers to a specific type of service that is defined in Article 3, point (j) of Directive (EU) 2015/2366. Essentially, it's a service that assists in facilitating payment transactions."
General Data Protection Regulation (GDPR) - Article 13 Information to be provided where personal data are collected from the data subject,0.705429494,"Details of Article 13 Information to be provided where personal data are collected from the data subject in the General Data Protection Regulation (GDPR): 1. Where personal data relating to a data subject are collected from the data subject, the controller shall, at the time when personal data are obtained, provide the data subject with all of the following information: (a) the identity and the contact details of the controller and, where applicable, of the controller's representative; (b) the contact details of the data protection officer, where applicable; (c) the purposes of the processing for which the personal data are intended as well as the legal basis for the processing; (d) where the processing is based on point (f) of Article 6(1), the legitimate interests pursued by the controller or by a third party; (e) the recipients or categories of recipients of the personal data, if any; (f) where applicable, the fact that the controller intends to transfer personal data to a third country or international organisation and the existence or absence of an adequacy decision by the Commission, or in the case of transfers referred to in Article 46 or 47, or the second subparagraph of Article 49(1), reference to the appropriate or suitable safeguards and the means by which to obtain a copy of them or where they have been made available. 2. In addition to the information referred to in paragraph 1, the controller shall, at the time when personal data are obtained, provide the data subject with the following further information necessary to ensure fair and transparent processing: (a) the period for which the personal data will be stored, or if that is not possible, the criteria used to determine that period; (b) the existence of the right to request from the controller access to and rectification or erasure of personal data or restriction of processing concerning the data subject or to object to processing as well as the right to data portability; (c) where the processing is based on point (a) of Article 6(1) or point (a) of Article 9(2), the existence of the right to withdraw consent at any time, without affecting the lawfulness of processing based on consent before its withdrawal; (d) the right to lodge a complaint with a supervisory authority; (e) whether the provision of personal data is a statutory or contractual requirement, or a requirement necessary to enter into a contract, as well as whether the data subject is obliged to provide the personal data and of the possible consequences of failure to provide such data; (f) the existence of automated decision-making, including profiling, referred to in Article 22(1) and (4) and, at least in those cases, meaningful information about the logic involved, as well as the significance and the envisaged consequences of such processing for the data subject. 3. Where the controller intends to further process the personal data for a purpose other than that for which the personal data were collected, the controller shall provide the data subject prior to that further processing with information on that other purpose and with any relevant further information as referred to in paragraph 2. 4. Paragraphs 1, 2 and 3 shall not apply where and insofar as the data subject already has the information.",article,"The General Data Protection Regulation (GDPR) Article 13 mandates that when a company collects your personal data, they must inform you about who they are, how to contact them, why they need your data, who will receive your data, and if your data will be transferred to another country. They also need to tell you how long they'll keep your data and inform you about your rights to access, correct, or delete your data, and to object to its use. You also have the right to transfer your data elsewhere and to withdraw your consent at any time. You can lodge a complaint if you're not happy with how your data is handled. If the company wants to use your data for a new purpose, they must inform you in advance. If you already know all this, they don't need to tell you again."
General Data Protection Regulation (GDPR) - Contextual Paragraph (162),0.705382586,"Details of the Contextual Paragraph (162) in the General Data Protection Regulation (GDPR): Where personal data are processed for statistical purposes, this Regulation should apply to that processing. Union or Member State law should, within the limits of this Regulation, determine statistical content, control of access, specifications for the processing of personal data for statistical purposes and appropriate measures to safeguard the rights and freedoms of the data subject and for ensuring statistical confidentiality. Statistical purposes mean any operation of collection and the processing of personal data necessary for statistical surveys or for the production of statistical results. Those statistical results may further be used for different purposes, including a scientific research purpose. The statistical purpose implies that the result of processing for statistical purposes is not personal data, but aggregate data, and that this result or the personal data are not used in support of measures or decisions regarding any particular natural person.",recital,"The General Data Protection Regulation (GDPR) includes a section (Paragraph 162) that applies to the use of personal data for statistical purposes. This law states that personal data can be used for statistical analysis, but the specifics of this use should be determined by Union or Member State laws, within the boundaries of the GDPR. The law also requires measures to protect the rights and privacy of the individuals whose data is being used. The statistical results, which are not considered personal data but aggregate data, can be used for various purposes, including scientific research. However, these results or the personal data should not be used to make decisions about specific individuals."
Artifical Inellegence Act (AI Act) - Definition of 'substantial modification',0.705382168,"Within the Aritifical Intelligence Act (AI Act), the Definition of substantial modification means a change to the AI system following its placing on the market or putting into service which affects the compliance of the AI system with the requirements set out in Title III, Chapter 2 of this Regulation or results in a modification to the intended purpose for which the AI system has been assessed;",recital,"The Artificial Intelligence Act (AI Act) defines 'substantial modification' as any change made to an AI system after it has been launched or put into use that either affects its compliance with certain requirements outlined in Title III, Chapter 2 of the Act, or alters the original purpose for which the AI system was assessed. This means if you make a significant change to an AI system that affects how it meets the Act's rules or changes its intended use, it's considered a 'substantial modification' under this law."
Artifical Inellegence Act (AI Act) - Context Section 1.113,0.705330372,"Aritifical Intelligence Act (AI Act) context section 1.113.Reasons for and objectives of the proposal: 
Against this political context, the Commission puts forward the proposed regulatory framework on Artificial Intelligence with the following specific objectives: 

ensure that AI systems placed on the Union market and used are safe and respect existing law on fundamental rights and Union values;

ensure legal certainty to facilitate investment and innovation in AI;

enhance governance and effective enforcement of existing law on fundamental rights and safety requirements applicable to AI systems;

facilitate the development of a single market for lawful, safe and trustworthy AI applications and prevent market fragmentation.

To achieve those objectives, this proposal presents a balanced and proportionate horizontal regulatory approach to AI that is limited to the minimum necessary requirements to address the risks and problems linked to AI, without unduly constraining or hindering technological development or otherwise disproportionately increasing the cost of placing AI solutions on the market. The proposal sets a robust and flexible legal framework. On the one hand, it is comprehensive and future-proof in its fundamental regulatory choices, including the principle-based requirements that AI systems should comply with. On the other hand, it puts in place a proportionate regulatory system centred on a well-defined risk-based regulatory approach that does not create unnecessary restrictions to trade, whereby legal intervention is tailored to those concrete situations where there is a justified cause for concern or where such concern can reasonably be anticipated in the near future. At the same time, the legal framework includes flexible mechanisms that enable it to be dynamically adapted as the technology evolves and new concerning situations emerge.

The proposal sets harmonised rules for the development, placement on the market and use of AI systems in the Union following a proportionate risk-based approach. It proposes a single future-proof definition of AI. Certain particularly harmful AI practices are prohibited as contravening Union values, while specific restrictions and safeguards are proposed in relation to certain uses of remote biometric identification systems for the purpose of law enforcement. The proposal lays down a solid risk methodology to define high-risk AI systems that pose significant risks to the health and safety or fundamental rights of persons. Those AI systems will have to comply with a set of horizontal mandatory requirements for trustworthy AI and follow conformity assessment procedures before those systems can be placed on the Union market. Predictable, proportionate and clear obligations are also placed on providers and users of those systems to ensure safety and respect of existing legislation protecting fundamental rights throughout the whole AI systems lifecycle. For some specific AI systems, only minimum transparency obligations are proposed, in particular when chatbots or deep fakes are used.

The proposed rules will be enforced through a governance system at Member States level, building on already existing structures, and a cooperation mechanism at Union level with the establishment of a European Artificial Intelligence Board. Additional measures are also proposed to support innovation, in particular through AI regulatory sandboxes and other measures to reduce the regulatory burden and to support Small and Medium-Sized Enterprises (SMEs) and start-ups.1.113.Reasons for and objectives of the proposal:
Against this political context, the Commission puts forward the proposed regulatory framework on Artificial Intelligence with the following specific objectives:

ensure that AI systems placed on the Union market and used are safe and respect existing law on fundamental rights and Union values;

ensure legal certainty to facilitate investment and innovation in AI;

enhance governance and effective enforcement of existing law on fundamental rights and safety requirements applicable to AI systems;

facilitate the development of a single market for lawful, safe and trustworthy AI applications and prevent market fragmentation.

To achieve those objectives, this proposal presents a balanced and proportionate horizontal regulatory approach to AI that is limited to the minimum necessary requirements to address the risks and problems linked to AI, without unduly constraining or hindering technological development or otherwise disproportionately increasing the cost of placing AI solutions on the market. The proposal sets a robust and flexible legal framework. On the one hand, it is comprehensive and future-proof in its fundamental regulatory choices, including the principle-based requirements that AI systems should comply with. On the other hand, it puts in place a proportionate regulatory system centred on a well-defined risk-based regulatory approach that does not create unnecessary restrictions to trade, whereby legal intervention is tailored to those concrete situations where there is a justified cause for concern or where such concern can reasonably be anticipated in the near future. At the same time, the legal framework includes flexible mechanisms that enable it to be dynamically adapted as the technology evolves and new concerning situations emerge.

The proposal sets harmonised rules for the development, placement on the market and use of AI systems in the Union following a proportionate risk-based approach. It proposes a single future-proof definition of AI. Certain particularly harmful AI practices are prohibited as contravening Union values, while specific restrictions and safeguards are proposed in relation to certain uses of remote biometric identification systems for the purpose of law enforcement. The proposal lays down a solid risk methodology to define high-risk AI systems that pose significant risks to the health and safety or fundamental rights of persons. Those AI systems will have to comply with a set of horizontal mandatory requirements for trustworthy AI and follow conformity assessment procedures before those systems can be placed on the Union market. Predictable, proportionate and clear obligations are also placed on providers and users of those systems to ensure safety and respect of existing legislation protecting fundamental rights throughout the whole AI systems lifecycle. For some specific AI systems, only minimum transparency obligations are proposed, in particular when chatbots or deep fakes are used.

The proposed rules will be enforced through a governance system at Member States level, building on already existing structures, and a cooperation mechanism at Union level with the establishment of a European Artificial Intelligence Board. Additional measures are also proposed to support innovation, in particular through AI regulatory sandboxes and other measures to reduce the regulatory burden and to support Small and Medium-Sized Enterprises (SMEs) and start-ups.",recital,"The Artificial Intelligence Act (AI Act) aims to regulate the use of AI systems within the Union to ensure they are safe, respect fundamental rights, and align with Union values. The law aims to provide legal certainty to foster investment and innovation in AI, while preventing market fragmentation. It sets out rules for the development and use of AI systems, with a focus on risk management. Certain harmful AI practices are prohibited, and specific restrictions are applied to uses of remote biometric identification systems for law enforcement. High-risk AI systems must comply with mandatory requirements for trustworthy AI and undergo an assessment before being placed on the market. The law also sets transparency obligations for specific AI systems like chatbots or 'deep fakes'. The rules will be enforced at the Member States level and through a European Artificial Intelligence Board. Measures are also proposed to support innovation and reduce regulatory burden on SMEs and start-ups."
Digital Markets Act (DMA) - Definition of identification service,0.705180049,"Details of the Definition of identification service in the Digital Markets Act (DMA): ""identification service"" means a type of service provided together with or in support of core platform services that enables any type of verification of the identity of end users or business users, regardless of the technology used;",rectial,"The Digital Markets Act (DMA) introduces a term called ""identification service"". This refers to any service that verifies the identity of end users or business users. It can be provided alongside or in support of main platform services. The type of technology used for this verification doesn't matter. The main point of this law is to regulate services that confirm user identities in digital markets."
General Data Protection Regulation (GDPR) - Contextual Paragraph (47),0.705169082,"Details of the Contextual Paragraph (47) in the General Data Protection Regulation (GDPR): The legitimate interests of a controller, including those of a controller to which the personal data may be disclosed, or of a third party, may provide a legal basis for processing, provided that the interests or the fundamental rights and freedoms of the data subject are not overriding, taking into consideration the reasonable expectations of data subjects based on their relationship with the controller. Such legitimate interest could exist for example where there is a relevant and appropriate relationship between the data subject and the controller in situations such as where the data subject is a client or in the service of the controller. At any rate the existence of a legitimate interest would need careful assessment including whether a data subject can reasonably expect at the time and in the context of the collection of the personal data that processing for that purpose may take place. The interests and fundamental rights of the data subject could in particular override the interest of the data controller where personal data are processed in circumstances where data subjects do not reasonably expect further processing. Given that it is for the legislator to provide by law for the legal basis for public authorities to process personal data, that legal basis should not apply to the processing by public authorities in the performance of their tasks. The processing of personal data strictly necessary for the purposes of preventing fraud also constitutes a legitimate interest of the data controller concerned. The processing of personal data for direct marketing purposes may be regarded as carried out for a legitimate interest.",recital,"The General Data Protection Regulation (GDPR) has a new rule, Contextual Paragraph (47), which allows companies to use personal data if it's in their legitimate interest and doesn't infringe on the rights and freedoms of the individual. This could apply when the individual is a customer or works for the company. However, the company must carefully assess whether the individual would reasonably expect their data to be used this way. If the data is used in a way the individual wouldn't expect, their rights could override the company's interests. Public authorities can't use this rule to justify data processing. Also, preventing fraud and direct marketing are considered legitimate interests for companies to process personal data."
Artifical Inellegence Act (AI Act) - Article 13,0.705138922,"Aritifical Intelligence Act (AI Act) Article 13 Transparency and provision of information to users:

1.High-risk AI systems shall be designed and developed in such a way to ensure that their operation is sufficiently transparent to enable users to interpret the systems output and use it appropriately. An appropriate type and degree of transparency shall be ensured, with a view to achieving compliance with the relevant obligations of the user and of the provider set out in Chapter 3 of this Title.

2.High-risk AI systems shall be accompanied by instructions for use in an appropriate digital format or otherwise that include concise, complete, correct and clear information that is relevant, accessible and comprehensible to users.

3.The information referred to in paragraph 2 shall specify:

(a)the identity and the contact details of the provider and, where applicable, of its authorised representative;

(b)the characteristics, capabilities and limitations of performance of the high-risk AI system, including:

(i)its intended purpose;

(ii)the level of accuracy, robustness and cybersecurity referred to in Article 15 against which the high-risk AI system has been tested and validated and which can be expected, and any known and foreseeable circumstances that may have an impact on that expected level of accuracy, robustness and cybersecurity;

(iii)any known or foreseeable circumstance, related to the use of the high-risk AI system in accordance with its intended purpose or under conditions of reasonably foreseeable misuse, which may lead to risks to the health and safety or fundamental rights;

(iv)its performance as regards the persons or groups of persons on which the system is intended to be used;

(v)when appropriate, specifications for the input data, or any other relevant information in terms of the training, validation and testing data sets used, taking into account the intended purpose of the AI system.

(c)the changes to the high-risk AI system and its performance which have been pre-determined by the provider at the moment of the initial conformity assessment, if any; 

(d)the human oversight measures referred to in Article 14, including the technical measures put in place to facilitate the interpretation of the outputs of AI systems by the users;

(e)the expected lifetime of the high-risk AI system and any necessary maintenance and care measures to ensure the proper functioning of that AI system, including as regards software updates.",article,"The Artificial Intelligence Act (AI Act) requires that high-risk AI systems be designed transparently, so users can understand and use them correctly. The AI systems must come with clear and complete instructions, in a digital format, that are easy for users to understand. This information should include the provider's contact details, the AI system's capabilities and limitations, its intended purpose, its level of accuracy, any potential risks, and its performance. The instructions should also specify any pre-determined changes to the system, the measures for human oversight, and the expected lifespan of the AI system, including any necessary maintenance and updates."
California Consumer Privacy Act Regulations (CCPA) - Article 2. Notice to Consumers -  999.305 Notice at Collection of Personal Information,0.705117404,"Details of Article 2 - Notice to Consumers -  999.305 Notice at Collection of Personal Information in the California Consumer Privacy Act Regulations (CCPA): (a) Purpose and General Principles (1) The purpose of the notice at collection is to provide consumers with timely notice, at or before the point of collection, about the categories of personal information to be collected from them and the purposes for which the personal information will be used. (2) The notice at collection shall be designed and presented in a way that is easy to read and understandable to consumers. The notice shall: a. Use plain, straightforward language and avoid technical or legal jargon. b. Use a format that draws the consumers attention to the notice and makes the notice readable, including on smaller screens, if applicable. c. Be available in the languages in which the business in its ordinary course provides contracts, disclaimers, sale announcements, and other information to consumers in California. d. Be reasonably accessible to consumers with disabilities. For notices provided online, the business shall follow generally recognized industry standards, such as the Web Content Accessibility Guidelines, version 2.1 of June 5, 2018, from the World Wide Web Consortium, incorporated herein by reference. In other contexts, the business shall provide information on how a consumer with a disability may access the notice in an alternative format. (3) The notice at collection shall be made readily available where consumers will encounter it at or before the point of collection of any personal information. Illustrative examples follow: a. When a business collects consumers personal information online, it may post a conspicuous link to the notice on the introductory page of the businesss website and on all webpages where personal information is collected. b. When a business collects personal information through a mobile application, it may provide a link to the notice on the mobile applications download page and within the application, such as through the applications settings menu. c. When a business collects consumers personal information offline, it may include the notice on printed forms that collect personal information, provide the consumer with a paper version of the notice, or post prominent signage directing consumers to where the notice can be found online. d. When a business collects personal information over the telephone or in person, it may provide the notice orally. (4) When a business collects personal information from a consumers mobile device for a purpose that the consumer would not reasonably expect, it shall provide a just-in-time notice containing a summary of the categories of personal information being collected and a link to the full notice at collection. For example, if the business offers a flashlight application and the application collects geolocation information, the business shall provide a just-in-time notice, such as through a pop-up window when the consumer opens the application, that contains the information required by this subsection. (5) A business shall not collect categories of personal information other than those disclosed in the notice at collection. If the business intends to collect additional categories of personal information, the business shall provide a new notice at collection. (6) If a business does not give the notice at collection to the consumer at or before the point of collection of their personal information, the business shall not collect personal information from the consumer. (b) A business shall include the following in its notice at collection: (1) A list of the categories of personal information about consumers to be collected. Each category of personal information shall be written in a manner that provides consumers a meaningful understanding of the information being collected. (2) The business or commercial purpose(s) for which the categories of personal information will be used. (3) If the business sells personal information, the link titled Do Not Sell My Personal Information required by section 999.315, subsection (a), or in the case of offline notices, where the webpage can be found online. (4) A link to the businesss privacy policy, or in the case of offline notices, where the privacy policy can be found online. (c) If a business collects personal information from a consumer online, the notice at collection may be given to the consumer by providing a link to the section of the businesss privacy policy that contains the information required in subsection (b). (d) A business that does not collect personal information directly from the consumer does not need to provide a notice at collection to the consumer if it does not sell the consumers personal information. (e) A data broker registered with the Attorney General pursuant to Civil Code section 1798.99.80 et seq. does not need to provide a notice at collection to the consumer if it has included in its registration submission a link to its online privacy policy that includes instructions on how a consumer can submit a request to opt-out. (f) A business collecting employment-related information shall comply with the provisions of section 999.305 except with regard to the following: (1) The notice at collection of employment-related information does not need to include the link or web address to the link titled Do Not Sell My Personal Information. (2) The notice at collection of employment-related information is not required to provide a link to the businesss privacy policy. (g) Subsection (f) shall become inoperative on January 1, 2021, unless the CCPA is amended otherwise.",article,"The California Consumer Privacy Act (CCPA) requires businesses to inform consumers about the personal information they collect and how it is used. This information must be provided at or before the point of collection. The notice must be easy to read, in plain language, accessible to those with disabilities, and available in the languages the business typically uses. It must be prominently displayed where consumers can easily find it, whether online, on a mobile app, or in physical forms. If a business collects information from a mobile device in a way the consumer might not expect, it must provide a 'just-in-time' notice. Businesses cannot collect more information than disclosed in the notice. If a business doesn't provide the notice, it cannot collect personal information. The notice must include a list of the information collected, the purpose of collection, and links to the business's privacy policy and 'Do Not Sell My Personal Information' page (if applicable)."
Artifical Inellegence Act (AI Act) - Definition of 'testing data',0.705109835,"Within the Aritifical Intelligence Act (AI Act), the Definition of testing data means data used for providing an independent evaluation of the trained and validated AI system in order to confirm the expected performance of that system before its placing on the market or putting into service;",recital,The Artificial Intelligence Act (AI Act) introduces the term 'testing data'. This refers to the information used to independently assess the performance of an AI system that has been trained and validated. The aim of this testing is to ensure the AI system works as expected before it is launched or used in the market.
California Consumer Privacy Act Regulations (CCPA) - Article 2. Notice to Consumers -  999.308 Privacy Policy,0.704962552,"Details of Article 2. Notice to Consumers -  999.308 Privacy Policy in the California Consumer Privacy Act Regulations (CCPA): (a) Purpose and General Principles (1) The purpose of the privacy policy is to provide consumers with a comprehensive description of a businesss online and offline practices regarding the collection, use, disclosure, and sale of personal information and of the rights of consumers regarding their personal information. (2) The privacy policy shall be designed and presented in a way that is easy to read and understandable to consumers. The policy shall: a. Use plain, straightforward language and avoid technical or legal jargon. b. Use a format that makes the policy readable, including on smaller screens, if applicable. c. Be available in the languages in which the business in its ordinary course provides contracts, disclaimers, sale announcements, and other information to consumers in California. d. Be reasonably accessible to consumers with disabilities. For notices provided online, the business shall follow generally recognized industry standards, such as the Web Content Accessibility Guidelines, version 2.1 of June 5, 2018, from the World Wide Web Consortium, incorporated herein by reference. In other contexts, the business shall provide information on how a consumer with a disability may access the policy in an alternative format. e. Be available in a format that allows a consumer to print it out as a document. (b) The privacy policy shall be posted online through a conspicuous link using the word privacy on the businesss website homepage or on the download or landing page of a mobile application. If the business has a California-specific description of consumers privacy rights on its website, then the privacy policy shall be included in that description. A business that does not operate a website shall make the privacy policy conspicuously available to consumers. A mobile application may include a link to the privacy policy in the applications settings menu. (c) The privacy policy shall include the following information: (1) Right to Know About Personal Information Collected, Disclosed, or Sold. a. Explanation that a consumer has the right to request that the business disclose what personal information it collects, uses, discloses, and sells. b. Instructions for submitting a verifiable consumer request to know and links to an online request form or portal for making the request, if offered by the business. c. General description of the process the business will use to verify the consumer request, including any information the consumer must provide. d. Identification of the categories of personal information the business has collected about consumers in the preceding 12 months. The categories shall be described in a manner that provides consumers a meaningful understanding of the information being collected. e. Identification of the categories of sources from which the personal information is collected. f. Identification of the business or commercial purpose for collecting or selling personal information. The purpose shall be described in a manner that provides consumers a meaningful understanding of why the information is collected or sold. g. Disclosure or Sale of Personal Information. 1. Identification of the categories of personal information, if any, that the business has disclosed for a business purpose or sold to third parties in the preceding 12 months. 2. For each category of personal information identified, the categories of third parties to whom the information was disclosed or sold. 3. Statement regarding whether the business has actual knowledge that it sells the personal information of consumers under 16 years of age. (2) Right to Request Deletion of Personal Information. a. Explanation that the consumer has a right to request the deletion of their personal information collected by the business. b. Instructions for submitting a verifiable consumer request to delete and links to an online request form or portal for making the request, if offered by the business. c. General description of the process the business will use to verify the consumer request, including any information the consumer must provide. (3) Right to Opt-Out of the Sale of Personal Information. a. Explanation that the consumer has a right to opt-out of the sale of their personal information by a business. b. Statement regarding whether or not the business sells personal information. If the business sells personal information, include either the contents of the notice of right to opt-out or a link to it in accordance with section 999.306. (4) Right to Non-Discrimination for the Exercise of a Consumers Privacy Rights. a. Explanation that the consumer has a right not to receive discriminatory treatment by the business for the exercise of the privacy rights conferred by the CCPA. (5) Authorized Agent. a. Instructions on how an authorized agent can make a request under the CCPA on the consumers behalf. (6) Contact for More Information. a. A contact for questions or concerns about the businesss privacy policies and practices using a method reflecting the manner in which the business primarily interacts with the consumer. (7) Date the privacy policy was last updated. (8) If subject to the requirements set forth in section 999.317, subsection (g), the information compiled in section 999.317, subsection (g)(1), or a link to it. (9) If the business has actual knowledge that it sells the personal information of consumers under 16 years of age, a description of the processes required by sections 999.330 and 999.331.",article,"The California Consumer Privacy Act Regulations (CCPA) requires businesses to have a clear privacy policy that explains how they collect, use, and sell personal information. The policy must be easy to understand, accessible to those with disabilities, and available in the languages the business typically uses. It should be easy to find online or in the business's physical location. The policy must inform consumers of their rights to know what personal information the business has about them, to request deletion of their personal information, to opt-out of the sale of their personal information, and to not be discriminated against for exercising these rights. The policy should also provide instructions for making these requests and contact information for any questions or concerns. It must be updated regularly and should state the date of the latest update. If the business sells the personal information of consumers under 16, it must describe the specific processes required by the CCPA."
Digital Markets Act (DMA) - Article 36 Professional secrecy,0.704878569,"Details of Article 36 Professional secrecy in the Digital Markets Act (DMA): 1. The information collected pursuant to this Regulation shall be used for the purposes of this Regulation. 2. The information collected pursuant to Article 14 shall be used for the purposes of this Regulation, Regulation (EC) No 139/2004 and national merger rules. 3. The information collected pursuant to Article 15 shall be used for the purposes of this Regulation and Regulation (EU) 2016/679. 4. Without prejudice to the exchange and to the use of information provided for the purpose of use pursuant to Articles 38, 39, 41 and 43, the Commission, the competent authorities of the Member States, their officials, servants and other persons working under the supervision of those authorities and any natural or legal person, including auditors and experts appointed pursuant to Article 26(2), shall not disclose information acquired or exchanged by them pursuant to this Regulation and of the kind covered by the obligation of professional secrecy.",article,"The Digital Markets Act (DMA) Article 36 focuses on professional secrecy. It states that any information gathered under this law should only be used for the purposes outlined in the law itself. The same rule applies for information gathered under Article 14 and 15, with additional references to other specific regulations. Importantly, the law prohibits the disclosure of any information acquired under this regulation that is subject to professional secrecy. This includes the Commission, member state authorities, their employees, and any individuals or entities, like auditors and experts, working under their supervision."
Digital Markets Act (DMA) - Definition of interoperability,0.70398742,"Details of the Definition of interoperability in the Digital Markets Act (DMA): ""interoperability"" means the ability to exchange information and mutually use the information which has been exchanged through interfaces or other solutions, so that all elements of hardware or software work with other hardware and software and with users in all the ways in which they are intended to function;",rectial,"The Digital Markets Act (DMA) introduces a term called ""interoperability"". This basically means that different types of hardware and software should be able to communicate and work with each other as intended. They should be able to exchange information and use the shared information effectively. This could be through interfaces or other solutions. The goal is to ensure that all parts of a digital system can work together seamlessly."
General Data Protection Regulation (GDPR) - Definition of processing,0.70388329,"Details of the Definition of processing in the General Data Protection Regulation (GDPR): ""processing"" means any operation or set of operations which is performed on personal data or on sets of personal data, whether or not by automated means, such as collection, recording, organisation, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure by transmission, dissemination or otherwise making available, alignment or combination, restriction, erasure or destruction;",recital,"The General Data Protection Regulation (GDPR) has a term called ""processing"". It refers to any action taken with personal data. This can include collecting, recording, organizing, storing, changing, retrieving, using, sharing, aligning or combining, restricting, deleting or destroying the data. These actions can be done manually or through automated systems."
General Data Protection Regulation (GDPR) - Article 11 Processing which does not require identification,0.703784168,"Details of Article 11 Processing which does not require identification in the General Data Protection Regulation (GDPR): 1. If the purposes for which a controller processes personal data do not or do no longer require the identification of a data subject by the controller, the controller shall not be obliged to maintain, acquire or process additional information in order to identify the data subject for the sole purpose of complying with this Regulation. 2. Where, in cases referred to in paragraph 1 of this Article, the controller is able to demonstrate that it is not in a position to identify the data subject, the controller shall inform the data subject accordingly, if possible. In such cases, Articles 15 to 20 shall not apply except where the data subject, for the purpose of exercising his or her rights under those articles, provides additional information enabling his or her identification.",article,"Article 11 of the General Data Protection Regulation (GDPR) states that if a company doesn't need to identify you for the data they're processing, they aren't required to keep, get, or process extra information just to identify you. If a company can't identify you in these cases, they should let you know if they can. However, the rights you have under Articles 15 to 20 of the GDPR won't apply unless you provide extra information that allows them to identify you."
Artifical Inellegence Act (AI Act) - Definition of 'common specifications',0.703647077,"Within the Aritifical Intelligence Act (AI Act), the Definition of common specifications means a document, other than a standard, containing technical solutions providing a means to, comply with certain requirements and obligations established under this Regulation;",recital,"The Artificial Intelligence Act (AI Act) introduces a term called 'common specifications.' These are documents, not standards, that contain technical solutions. They are designed to help meet certain requirements and obligations set out in this law. In other words, 'common specifications' are guides to help you understand and follow the rules of the AI Act."
Artifical Inellegence Act (AI Act) - Article 61,0.702726364,"Aritifical Intelligence Act (AI Act) Article 61 Post-market monitoring by providers and post-market monitoring plan for high-risk AI systems:

1.Providers shall establish and document a post-market monitoring system in a manner that is proportionate to the nature of the artificial intelligence technologies and the risks of the high-risk AI system.

2.The post-market monitoring system shall actively and systematically collect, document and analyse relevant data provided by users or collected through other sources on the performance of high-risk AI systems throughout their lifetime, and allow the provider to evaluate the continuous compliance of AI systems with the requirements set out in Title III, Chapter 2.

3.The post-market monitoring system shall be based on a post-market monitoring plan. The post-market monitoring plan shall be part of the technical documentation referred to in Annex IV. The Commission shall adopt an implementing act laying down detailed provisions establishing a template for the post-market monitoring plan and the list of elements to be included in the plan.

4.For high-risk AI systems covered by the legal acts referred to in Annex II, where a post-market monitoring system and plan is already established under that legislation, the elements described in paragraphs 1, 2 and 3 shall be integrated into that system and plan as appropriate.

The first subparagraph shall also apply to high-risk AI systems referred to in point 5(b) of Annex III placed on the market or put into service by credit institutions regulated by Directive 2013/36/EU.",article,"The Artificial Intelligence Act (AI Act) Article 61 requires providers of high-risk AI systems to establish a post-market monitoring system. This system should collect, document, and analyze data on the performance of these AI systems throughout their lifespan. The aim is to ensure these systems continuously meet set requirements. The monitoring system will be based on a plan that is part of the technical documentation. The Commission will provide a template for this plan and a list of elements to include. If a monitoring system and plan already exist under other legislation for certain high-risk AI systems, the requirements of Article 61 should be integrated into that system and plan. This also applies to high-risk AI systems used by credit institutions regulated by Directive 2013/36/EU."
Artifical Inellegence Act (AI Act) - Overview paragraph 63,0.702713549,"Aritifical Intelligence Act (AI Act) overview paragraph (63): It is appropriate that, in order to minimise the burden on operators and avoid any possible duplication, for high-risk AI systems related to products which are covered by existing Union harmonisation legislation following the New Legislative Framework approach, the compliance of those AI systems with the requirements of this Regulation should be assessed as part of the conformity assessment already foreseen under that legislation. The applicability of the requirements of this Regulation should thus not affect the specific logic, methodology or general structure of conformity assessment under the relevant specific New Legislative Framework legislation. This approach is fully reflected in the interplay between this Regulation and the [Machinery Regulation]. While safety risks of AI systems ensuring safety functions in machinery are addressed by the requirements of this Regulation, certain specific requirements in the [Machinery Regulation] will ensure the safe integration of the AI system into the overall machinery, so as not to compromise the safety of the machinery as a whole.The [Machinery Regulation] applies the same definition of AI system as this Regulation.",recital,"The Artificial Intelligence Act (AI Act) states that high-risk AI systems related to products already covered by existing Union laws will have their compliance assessed as part of the existing conformity assessment. This means the AI Act won't change the way these assessments are currently carried out. The Act also works in conjunction with the Machinery Regulation. While the AI Act addresses safety risks of AI systems in machinery, the Machinery Regulation ensures the AI system doesn't compromise the safety of the entire machine. Both regulations use the same definition of an AI system."
Artifical Inellegence Act (AI Act) - Definition of 'safety component of a product or system',0.702669859,"Within the Aritifical Intelligence Act (AI Act), the Definition of safety component of a product or system means a component of a product or of a system which fulfils a safety function for that product or system or the failure or malfunctioning of which endangers the health and safety of persons or property;",recital,"The Artificial Intelligence Act (AI Act) introduces the term 'safety component of a product or system'. This refers to a part of a product or system that performs a safety function. If this component fails or malfunctions, it could pose a risk to people's health and safety or cause damage to property."
California Consumer Privacy Act Regulations (CCPA) - Definition of Employment-related information,0.702398419,"Details of Definition of Employment-related information in the California Consumer Privacy Act Regulations (CCPA): Employment-related information means personal information that is collected by the business about a natural person for the reasons identified in Civil Code section 1798.145, subdivision (h)(1). The collection of employment-related information, including for the purpose of administering employment benefits, shall be considered a business purpose.",recital,"The California Consumer Privacy Act (CCPA) defines ""Employment-related information"" as personal details collected by a business about an individual for employment purposes, as outlined in Civil Code section 1798.145, subdivision (h)(1). This includes data gathered for managing employment benefits. The law considers the collection of such information as a business activity."
California Consumer Privacy Act Regulations (CCPA) - Definition of Notice of financial incentive,0.70195508,"Details of Definition of Notice of financial incentive in the California Consumer Privacy Act Regulations (CCPA): Notice of financial incentive means the notice given by a business explaining each financial incentive or price or service difference as required by Civil Code section 1798.125, subdivision (b), and specified in these regulations.",recital,"The California Consumer Privacy Act Regulations (CCPA) introduces a ""Notice of Financial Incentive"". This is a notice that businesses need to provide, explaining any financial incentives or differences in price or service. This requirement is based on the Civil Code section 1798.125, subdivision (b), and is further detailed in these regulations. The purpose is to make it clear to consumers if their data is being used in exchange for financial benefits or changes in service."
Artifical Inellegence Act (AI Act) - Definition of 'CE marking of conformity',0.700662851,"Within the Aritifical Intelligence Act (AI Act), the Definition of CE marking of conformity (CE marking) means a marking by which a provider indicates that an AI system is in conformity with the requirements set out in Title III, Chapter 2 of this Regulation and other applicable Unionlegislation harmonising the conditions for the marketing of products (Unionharmonisation legislation) providing for its affixing;",recital,"The Artificial Intelligence Act (AI Act) introduces a new concept called the 'CE marking of conformity' or CE marking. This is a mark given by a provider to show that an AI system meets specific requirements outlined in the AI Act and other relevant European Union laws. These laws aim to standardize the conditions for selling products. So, if an AI system has a CE marking, it means it has met these standards and can be legally sold within the EU."
Artifical Inellegence Act (AI Act) - Definition of 'post-market monitoring',0.700554192,"Within the Aritifical Intelligence Act (AI Act), the Definition of post-market monitoring means all activities carried out by providers of AI systems to proactively collect and review experience gained from the use of AI systems they place on the market or put into service for the purpose of identifying any need to immediately apply any necessary corrective or preventive actions;",recital,The Artificial Intelligence Act (AI Act) introduces the concept of 'post-market monitoring'. This means that companies who provide AI systems are required to actively gather and review data from the usage of their AI systems in the market. The purpose of this is to quickly identify if there are any issues or problems that need immediate correction or prevention. This ensures that AI systems are continuously checked and improved after they have been launched in the market.
California Consumer Privacy Act Regulations (CCPA) - Definition of Request to know,0.700292289,"Details of Definition of Request to know in the California Consumer Privacy Act Regulations (CCPA): Request to know means a consumer request that a business disclose personal information that it has collected about the consumer pursuant to Civil Code sections 1798.100, 1798.110, or 1798.115. It includes a request for any or all of the following: (1) Specific pieces of personal information that a business has collected about the consumer; (2) Categories of personal information it has collected about the consumer; (3) Categories of sources from which the personal information is collected; (4) Categories of personal information that the business sold or disclosed for a business purpose about the consumer; (5) Categories of third parties to whom the personal information was sold or disclosed for a business purpose; and (6) The business or commercial purpose for collecting or selling personal information.",recital,"The California Consumer Privacy Act Regulations (CCPA) introduces a ""Request to know"". This allows consumers to ask businesses to disclose any personal information they've collected about them. This request can include specific details collected, the categories of information collected, where the information came from, any information sold or disclosed for business purposes, who this information was sold or disclosed to, and why the business collected or sold the information."
Digital Services Act (DSA) - Definition of 'content moderation',0.699997067,"Definition of 'content moderation' in the Digital Services Act (DSA): the activities, whether automated or not, undertaken by providers of intermediary services, that are aimed, in particular, at detecting, identifying and addressing illegal content or information incompatible with their terms and conditions, provided by recipients of the service, including measures taken that affect the availability, visibility, and accessibility of that illegal content or that information, such as demotion, demonetisation, disabling of access to, or removal thereof, or that affect the ability of the recipients of the service to provide that information, such as the termination or suspension of a recipient's account.",recital,"The Digital Services Act (DSA) defines 'content moderation' as the actions taken by online service providers to find and manage illegal content or information that doesn't follow their rules. This can include using automated systems or manual checks. The actions they might take can include making the content less visible, removing the ability to make money from it, blocking access to it, or removing it completely. They can also suspend or terminate the account of the person who posted the information."
Artifical Inellegence Act (AI Act) - Context Section 5.2.1,0.699511886,"Aritifical Intelligence Act (AI Act) context section 5.2.1.SCOPE AND DEFINITIONS (TITLE I): 

Title I defines the subject matter of the regulation and the scope of application of the new rules that cover the placing on the market, putting into service and use of AI systems. It also sets out the definitions used throughout the instrument. The definition of AI system in the legal framework aims to be as technology neutral and future proof as possible, taking into account the fast technological and market developments related to AI. In order to provide the needed legal certainty, Title I is complemented by Annex I, which contains a detailed list of approaches and techniques for the development of AI to be adapted by the Commission in line with new technological developments. Key participants across the AI value chain are also clearly defined such as providers and users of AI systems that cover both public and private operators to ensure a level playing field.5.2.1.SCOPE AND DEFINITIONS (TITLE I):

Title I defines the subject matter of the regulation and the scope of application of the new rules that cover the placing on the market, putting into service and use of AI systems. It also sets out the definitions used throughout the instrument. The definition of AI system in the legal framework aims to be as technology neutral and future proof as possible, taking into account the fast technological and market developments related to AI. In order to provide the needed legal certainty, Title I is complemented by Annex I, which contains a detailed list of approaches and techniques for the development of AI to be adapted by the Commission in line with new technological developments. Key participants across the AI value chain are also clearly defined such as providers and users of AI systems that cover both public and private operators to ensure a level playing field.",recital,"The Artificial Intelligence Act (AI Act) outlines rules for the creation, distribution, and use of AI systems. It aims to remain relevant regardless of future technological advancements in AI. The law includes a comprehensive list of AI development methods, which will be updated as technology evolves. The law also clearly defines the roles of all involved in the AI process, including both public and private entities, to ensure fair competition."
California Consumer Privacy Act Regulations (CCPA) - Definition of Notice at collection,0.698459685,"Details of Definition of Notice at collection in the California Consumer Privacy Act Regulations (CCPA): Notice at collection means the notice given by a business to a consumer at or before the point at which a business collects personal information from the consumer as required by Civil Code section 1798.100, subdivision (b), and specified in these regulations.",recital,"The California Consumer Privacy Act Regulations (CCPA) introduces a ""Notice at collection"" rule. This rule requires businesses to inform consumers when they are about to gather their personal information. The notice must be given at or before the time the information is collected. This is to ensure that consumers are aware of what data is being collected about them and why."
California Consumer Privacy Act Regulations (CCPA) - Definition of Request to delete,0.696105897,"Details of Definition of Request to delete in the California Consumer Privacy Act Regulations (CCPA): Request to delete means a consumer request that a business delete personal information about the consumer that the business has collected from the consumer, pursuant to Civil Code section 1798.105.",recital,"The California Consumer Privacy Act (CCPA) includes a provision called ""Request to delete"". This allows you to ask a company to erase any personal information they've collected about you. This request must be made by you, the consumer, and the company is legally obliged to comply under the CCPA."
Artifical Inellegence Act (AI Act) - Definition of 'instructions for use',0.695862532,"Within the Aritifical Intelligence Act (AI Act), the Definition of instructions for use means the information provided by the provider to inform the user of in particular an AI systems intended purpose and proper use, inclusive of the specific geographical, behavioural or functional setting within which the high-risk AI system is intended to be used;",recital,"The Artificial Intelligence Act (AI Act) includes a term called 'instructions for use'. This refers to the information given by the AI provider to help users understand the intended purpose and correct use of the AI system. It also includes details about where (geographical), how (behavioral), and in what conditions (functional setting) the high-risk AI system is meant to be used."
Artifical Inellegence Act (AI Act) - Definition of 'intended purpose',0.693805,"Within the Aritifical Intelligence Act (AI Act), the Definition of intended purpose means the use for which an AI system is intended by the provider, including the specific context and conditions of use, as specified in the information supplied by the provider in the instructions for use, promotional or sales materials and statements, as well as in the technical documentation;",recital,"The Artificial Intelligence Act (AI Act) introduces the term 'intended purpose'. This refers to the specific use or application an AI system is designed for by its provider. This includes how it's supposed to be used, in what context, and under what conditions. This information is usually provided by the AI system's provider in the user instructions, promotional materials, sales documents, and technical documentation."
id,0.0,,,
